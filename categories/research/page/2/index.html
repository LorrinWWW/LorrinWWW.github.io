<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: research - Jue&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jue Wang (王珏)"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jue Wang (王珏)"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Effective and Efficient NLP"><meta property="og:type" content="blog"><meta property="og:title" content="Jue&#039;s Blog"><meta property="og:url" content="https://juewang.me/"><meta property="og:site_name" content="Jue&#039;s Blog"><meta property="og:description" content="Effective and Efficient NLP"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://juewang.me/img/og_image.png"><meta property="article:author" content="Jue Wang"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://juewang.me"},"headline":"Jue's Blog","image":["https://juewang.me/img/og_image.png"],"author":{"@type":"Person","name":"Jue Wang"},"publisher":{"@type":"Organization","name":"Jue's Blog","logo":{"@type":"ImageObject","url":"https://juewang.me/img/favicon.svg"}},"description":"Effective and Efficient NLP"}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-115582186-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-115582186-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Jue's Blog" type="application/atom+xml">
</head><body class="is-3-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/favicon.svg" alt="Jue&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/about">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-6-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">research</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-01-29T00:00:00.000Z" title="1/29/2018, 8:00:00 AM">2018-01-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:12.997Z" title="11/3/2020, 11:26:12 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">18 minutes read (About 2677 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.1.29%5DA-convolution%20BiLSTM-neural-network-model-for-chinese-event-extraction/">A convolution BiLSTM neural network model for chinese event extraction 笔记</a></h1><div class="content"><h2 id="A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction"><a href="#A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction" class="headerlink" title="A convolution BiLSTM neural network model for chinese event extraction"></a>A convolution BiLSTM neural network model for chinese event extraction</h2><p><strong>摘要：</strong>中文事件提取是信息抽取中的一项具有挑战性的任务，以前的方法高度依赖于复杂的特征工程和复杂的自然语言处理（NLP）工具。 在文献[1]中，提出了一种结合LSTM和CNN的卷积双向LSTM神经网络来捕获句级和词汇信息。最终的测试中达到相当不错的水平。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>在事件提取中，我们需要提取事件类别、参与者和其他属性（时间、地点等）。根据Automatic Content Extraction（ACE）定义的事件抽取任务，我们定义：</p>
<ul>
<li>触发词：最主要的、用于表达一个事件的词，通常是句子的谓语。</li>
<li>事件属性：实体、短语或数值。在一个事件中扮演特定作用。</li>
</ul>
<p>因此，我们把事件抽取分为两步，即<strong>触发词标注</strong>和<strong>事件属性标注</strong>。例如：</p>
<p>S1：Intel在中国<strong>成立</strong>了研究中心。</p>
<p>其中，“成立”表明该句子表达了一个商业事件；Intel、中国、研究中心则是事件的属性，属性将被标注为参与者、地点、时间等。</p>
<p>目前的 state-of-the-art [2-4] 通常很依赖于特征的选择。这些特征通常可以被划分为<strong>语义特征</strong>和<strong>结构特征</strong>。再给两个包含”成立“的例子，但它在其中并不表达一个商业事件。</p>
<p>S2：它<strong>成立</strong>于1994年，现在是一支深受欢迎的摇滚乐队。</p></div><a class="article-more button is-small is-size-7" href="/posts/%5B2018.1.29%5DA-convolution%20BiLSTM-neural-network-model-for-chinese-event-extraction/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-01-21T00:00:00.000Z" title="1/21/2018, 8:00:00 AM">2018-01-21</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:13.403Z" title="11/3/2020, 11:26:13 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">12 minutes read (About 1739 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.1.21%5DEvent-detection-and-co-referentce/">Event detection and co-reference with minimal supervision 笔记</a></h1><div class="content"><h2 id="Event-detection-and-co-reference-with-minimal-supervision-1"><a href="#Event-detection-and-co-reference-with-minimal-supervision-1" class="headerlink" title="Event detection and co-reference with minimal supervision [1]"></a>Event detection and co-reference with minimal supervision [1]</h2><p><strong>摘要：</strong>该论文使用了一种弱监督的算法解决了事件检测与共指问题。事件共指问题可以看作是一种事件之间的相似度计算问题，而在该文中，事件检测问题也被看作是一种相似度检测问题。对于ACE或rich ERE划分的所有事件类型，使用每个类型中的几个实例作为该类型事件的向量，然后计算新事件向量与每个类型事件向量之间的相似度，根据这一相似度对事件进行判断。该文的另一个特点在于事件特征的选择，在将事件表示为向量的过程中，使用了Freebase作为特征来对事件进行表示。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202215.jpg" width="70%">

<p>上图是论文提出的MSEP（Minimally Supervised Event Pipeline）框架。这里 Event examples 是唯一的监督来源，用于产生 Example vectors。在MSEP框架中不需要训练。</p>
<p>这篇论文主要是针对两个问题：</p>
<ul>
<li>Event detection 指的是对一段文本内容，检测是否存在符合要求的事件。</li>
<li>Co-reference problem. 为了更好的理解和利用事件的信息，我们需要从文本中提取出时间、地点、人物、行为等信息。此外，我们还需要了解两个事件的关系，例如，判断两个事件是否表示同一个事件，这就是Co-reference problem。</li>
</ul>
<p>在本文中，我们提出了一种更加可行且更加可测的方法来描述事件。对于一个事件e，event detection 所要做的就是判断是否存在一个事件集合，事件e在语义上是否有关联，以至于可以被划分到该集合内；而 co-reference problem 则是判断两个事件e1、e2是否在语义上表述足够接近，以至于我们认为它们所表示的实际上是同一个事件。可以看到两个任务实际上都需要判断相似性，我们可以把它们转化为语义相似性问题。</p>
<p>现在主要问题有：1. 如何表示一个事件；2. 如何表达相似性。前者我们采用了semantic role labeling  representation（SRL），来结构化地描述一个事件；对于后者，我们将对事件做一个embedding，通过计算其余弦距离来表达相似性。</p>
<p>我们提出了一个通用事件检测和指代消解框架，它基本上不需要标记数据。在实践中，为了将一个事件提法（event mention）和一个事件本体（event ontology）相联系起来，我们只需要一些事件示例。这种定义类型的方式是非常合理的，因为给出例子是定义事件类型的最简单的方法。我们的方法比标准的无监督方法要求更少假设，在我们的模型中，给定事件类型的定义（以事件例子的形式），我们可以将单个事件分类到已知本体，并确定两个事件是否是 co-reference 的。</p></div><a class="article-more button is-small is-size-7" href="/posts/%5B2018.1.21%5DEvent-detection-and-co-referentce/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-01-14T00:00:00.000Z" title="1/14/2018, 8:00:00 AM">2018-01-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:13.796Z" title="11/3/2020, 11:26:13 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">13 minutes read (About 1902 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.1.14%5DModels-for-relation-extraction/">几个 relation extraction 远程监督模型</a></h1><div class="content"><h2 id="几个-relation-extraction-远程监督模型"><a href="#几个-relation-extraction-远程监督模型" class="headerlink" title="几个 relation extraction 远程监督模型"></a>几个 relation extraction 远程监督模型</h2><p><strong>摘要：</strong>远程监督（Distant supervision）显著地减少了建立用于分类任务的训练集所需要的人工。但是这一项技术也会带来很大的噪音，并可能因此而大大地影响了模型的性能表现。这里，我们以 relation extraction 这项任务为例，深入讨论分析该噪声的分布。文献[1]提出了 dynamic-transition matrix，并证明了它能很好地代表了由 distant supervision 所带来的噪声。通过该矩阵，我们能够大大提高 relation extraction 的效果。文献[2]则是一种经典的方法，通过定义规则，定义否定模式（negative pattern）过滤掉一些噪音数据，可以很大程度提高性能。缺点是规则依赖人工定义，但是方法本身简单有效。文献[3]将 relation extraction 定义为一个 Multi-instance Multi-label 学习问题，一定程度上解决了错误标签的问题。</p>
<h3 id="1-Problem-of-distant-supervision"><a href="#1-Problem-of-distant-supervision" class="headerlink" title="1. Problem of distant supervision"></a>1. Problem of distant supervision</h3><p>Distant supervision 是一种生成关系抽取训练集的常用方法。它把现有知识库中的三元组 &lt;e1, r, e2&gt; （或写成&lt;subj, r, obj&gt;）作为种子，匹配同时含有 e1 和 e2 的文本，得到的文本用作关系 r 的标注数据。这样可以省去大量人工标记的工作。</p>
<p>但是，相比于人工标注方法，这种匹配方式会产生很多噪音：比如三元组&lt;DonaldTrump, born-in, New York&gt;，可能对齐到“Donald Trump was born in New York”，也可能对齐到“DonaldTrump worked in New York”。其中前一句是我们想要的标注数据，后一句则是噪音数据，它并不表示born-in关系。如何去除这些噪音数据，是一个重要的研究课题。</p>
<h3 id="2-Approaches-to-this-problems"><a href="#2-Approaches-to-this-problems" class="headerlink" title="2. Approaches to this problems"></a>2. Approaches to this problems</h3><ul>
<li> 拟合噪音</li>
<li>dynamic-transition matrix [1]</li>
<li> 去除噪音</li>
<li>通过定义规则过滤掉一些噪音数据[2]，缺点是依赖人工定义，并且被关系种类所限制。</li>
<li>Multi-instance learning[3], 把训练语句分包学习，包内取平均值，或者用 attention 加权，可以中和掉包内的噪音数据。缺点是受限于 at-least-one-assumption：每个包内至少有一个正确的数据。</li>
</ul>
<p>下面我们简单介绍这几个模型。</p>
<h4 id="2-1-Learning-with-dynamic-transition-matrix-1"><a href="#2-1-Learning-with-dynamic-transition-matrix-1" class="headerlink" title="2.1 Learning with dynamic-transition matrix [1]"></a>2.1 Learning with dynamic-transition matrix [1]</h4><p>文献[1] 提出了 dynamic-transition matrix，用于表达 Distant supervision 所产生的噪声。dynamic-transition matrix 可以通过基于 curriculum learning 的方法训练得到。通过该矩阵，我们能够大大提高 relation extraction 的效果，能够达到目前该领域的 state-of-the-art。</p></div><a class="article-more button is-small is-size-7" href="/posts/%5B2018.1.14%5DModels-for-relation-extraction/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-01-04T00:00:00.000Z" title="1/4/2018, 8:00:00 AM">2018-01-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:12.569Z" title="11/3/2020, 11:26:12 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">14 minutes read (About 2154 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.1.4%5DOvercoming-Limited-Supervision-in-Relation-Extraction/">Overcoming Limited Supervision in Relation Extraction 笔记</a></h1><div class="content"><p>这次主要阅读的论文是《Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach》[1]。该文主要针对了现有模型对标注数据的依赖，提出一种比较有意思的思路。基于分布的方法（distributional approach）利用两个实体共同出现的统计频率来预测他们的关系，需要大量标注数据，而基于模式的方法（pattern-based approach）一般使用神经网络建模，但这种方法需要更多的标注数据。本文同时建立两个模型，互相为对方提供监督。以分布模型作为判别模型，模式模型作为生成模型。训练过程中不断迭代，从而提升两个模型的性能。</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201441.jpg" alt="illustration"></p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><h4 id="1-1-Weakly-Supervised-Learning"><a href="#1-1-Weakly-Supervised-Learning" class="headerlink" title="1.1 Weakly Supervised Learning"></a>1.1 Weakly Supervised Learning</h4><p>弱监督学习介于监督学习和无监督学习之间，它提供的标注数据带有较大的噪音，或标注的相对粗糙，标注结果可能出错。对于关系抽取而言，就是将一些关系实例作为seed，用它们从大型语料库中去除冗余信息并提取更多的实例。</p>
<p>弱监督学习的基本思路：</p>
<ol>
<li>用容易获得的标注替代较难获得的标注</li>
<li>选择最需要做精细标注的样例</li>
<li>模型训练和自动标注交替进行</li>
</ol>
<h4 id="1-2-Co-training-strategy"><a href="#1-2-Co-training-strategy" class="headerlink" title="1.2 Co-training strategy"></a>1.2 Co-training strategy</h4><p>以往的工作主要是单个模型，该文采用了co-training策略[2]，将两个模型互相协作，取得了比较好的效果。</p>
<p>co-training策略是一种半监督方法，核心就是利用少量已标记样本，通过两个（或多个）模型去学习，对未标记样本进行标记，挑选置信度最高的样本加入已标记样本阵营。</p></div><a class="article-more button is-small is-size-7" href="/posts/%5B2018.1.4%5DOvercoming-Limited-Supervision-in-Relation-Extraction/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2017-12-17T00:00:00.000Z" title="12/17/2017, 8:00:00 AM">2017-12-17</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:14.244Z" title="11/3/2020, 11:26:14 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">13 minutes read (About 1884 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2017.12.17%5DRelation-Classification-via-Attention-Model/">Relation Classification via Attention Model 笔记</a></h1><div class="content"><h2 id="Relation-Classification-via-Attention-Model"><a href="#Relation-Classification-via-Attention-Model" class="headerlink" title="Relation Classification via Attention Model"></a>Relation Classification via Attention Model</h2><p>这个笔记主要是阅读论文[1]，它的工作重点是在神经网络构成的端到端学习的关系抽取任务中加入Attention机制。作者主要通过自动学习关系句中注意力较高的部分，而引入attention机制，对反映实体关系更加重要的词语给予更大的attention，较好地提高了关系抽取的效果。</p>
<img src="https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png" width="50%">

<h3 id="1-Attention"><a href="#1-Attention" class="headerlink" title="1. Attention"></a>1. Attention</h3><h4 id="1-1-概述"><a href="#1-1-概述" class="headerlink" title="1.1 概述"></a>1.1 概述</h4><p>Attention机制最早是在视觉图像领域被提出来的。在NLP任务上，Bahdanau[2]等人使用类似attention的机制在机器翻译任务上将翻译和对齐同时进行。接着类似的基于attention机制的深度学习模型开始广泛应用到各种NLP任务中。</p>
<h4 id="1-2-Recurrent-Models-of-Visual-Attention"><a href="#1-2-Recurrent-Models-of-Visual-Attention" class="headerlink" title="1.2 Recurrent Models of Visual Attention"></a>1.2 Recurrent Models of Visual Attention</h4><p>人们在进行观察图像的时候，其实并不是一次就把整幅图像的每个位置像素都看过，大多是根据需求将注意力集中到图像的特定部分。由此，在传统的RNN上加入了attention机制，每次当前状态，都会根据前一个状态学习得到的要关注的位置和当前输入的图像，去处理注意力部分像素。可以看到应用Attention机制后，任务的复杂度被降低了很多。</p>
<h4 id="1-3-Attention-based-RNN-in-NLP"><a href="#1-3-Attention-based-RNN-in-NLP" class="headerlink" title="1.3 Attention-based RNN in NLP"></a>1.3 Attention-based RNN in NLP</h4><p>[1]的成果是在机器翻译任务，一般机器翻译工作由一个Encoder和一个Decoder构成，一个典型的Seq2seq任务。Encoder将源句子进行编码，再利用Decoder将编码后的向量解码成目标语言。</p></div><a class="article-more button is-small is-size-7" href="/posts/%5B2017.12.17%5DRelation-Classification-via-Attention-Model/#more">Read more</a></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2017-12-10T00:00:00.000Z" title="12/10/2017, 8:00:00 AM">2017-12-10</time></span><span class="level-item">Updated&nbsp;<time dateTime="2018-01-27T11:07:30.140Z" title="1/27/2018, 7:07:30 PM">2018-01-27</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">13 minutes read (About 1948 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2017.12.10%5DEntity-resolution/">实体解析 Entity resolution</a></h1><div class="content"><h2 id="1-Entity-resolution"><a href="#1-Entity-resolution" class="headerlink" title="1. Entity resolution"></a>1. Entity resolution</h2><p>###1.1 Sequence labeling</p>
<p>我们通常在ML中把Named Entity Recognition任务认为是一个Sequence labeling任务，事实上很多nlp任务都可以被转化为sequence labeling。暑假实习的时候也在这方面看了一些文献。目前业内比较主流的解决方案是RNN-CRF模型，一般来说分为：</p>
<ul>
<li>Embedding layer</li>
<li>Bi-directional RNN (usually LSTM) layer</li>
<li>Tanh hidden layer</li>
<li>CRF layer</li>
</ul>
<p>从结果上来看，该模型对大多数sequence labeling任务有较好的效果，如named entity recognition等。但是对于一些更灵活的标注任务（如暑假实习时，我曾试图将event recognition转化为seq labeling任务），尤其是在训练集不足的情况下，往往效果还是不能令人满意。</p>
<h4 id="1-1-1-应用Attention"><a href="#1-1-1-应用Attention" class="headerlink" title="1.1.1 应用Attention"></a>1.1.1 应用Attention</h4><blockquote>
<p>[1]在 RNN-CRF 模型结构基础上，重点改进了词向量与字符向量的拼接。使用 attention 机制将原始的字符向量和词向量拼接改进为了权重求和，使用两层传统神经网络隐层来学习 attention 的权值，这样就使得模型可以动态地利用词向量和字符向量信息。实验结果表明比原始的拼接方法效果更好。</p>
<p>[2]在原始 BiLSTM-CRF 模型上，加入了音韵特征，并在字符向量上使用 attention 机制来学习关注更有效的字符。</p>
<p>​                      — from paperweekly</p>
</blockquote>
<h4 id="1-1-2-使用少量标注数据"><a href="#1-1-2-使用少量标注数据" class="headerlink" title="1.1.2 使用少量标注数据"></a>1.1.2 使用少量标注数据</h4><p>深度学习方法一般需要大量标注数据，但是在一些领域很难有海量的标注数据。所以在基于神经网络结构方法中如何使用少量标注数据也是一个重点。</p>
<ul>
<li><p><a target="_blank" rel="noopener" href="https://openreview.net/forum?id=ry018WZAZ">Deep Active Learning for Named Entity Recognition</a>[7]</p>
<p>ICLR 2018看到的paper。这片文章把active learning应用到了CNN-CNN-LSTM模型，用于处理NER问题，也就是seq labeling问题。它能够仅使用25%的数据，达到state-of-the-art的水平。</p>
<p>这篇paper总结了很多做seq labeling的方法，本身的思路也深入简出。decoder使用了LSTM而不是常用的CRF，发现LSTM比CRF有一些的优势。同时该文也证明了active learning能提高seq labeling的表现。</p>
</li>
<li><p>Semi-supervised sequence tagging with bidirectional language models[4]</p>
<p>该论文使用海量无标注语料库训练了一个双向神经网络语言模型，然后使用这个训练好的语言模型来获取当前要标注词的语言模型向量（LM embedding），然后将该向量作为特征加入到原始的双向 RNN-CRF 模型中。</p>
<p>实验结果表明，在少量标注数据上，加入这个语言模型向量能够大幅度提高 NER 效果，即使在大量的标注训练数据上，加入这个语言模型向量仍能提供原始 RNN-CRF 模型的效果。</p>
</li>
</ul></div><a class="article-more button is-small is-size-7" href="/posts/%5B2017.12.10%5DEntity-resolution/#more">Read more</a></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous"><a href="/categories/research/">Previous</a></div><div class="pagination-next is-invisible is-hidden-mobile"><a href="/categories/research/page/3/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link" href="/categories/research/">1</a></li><li><a class="pagination-link is-current" href="/categories/research/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Jue Wang"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jue Wang</p><p class="is-size-6 is-block">Ph.D Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">56</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">7</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">72</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/lorrinWWW" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/lorrinWWW/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/JueWANG26088228"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><!--!--><div class="column-right-shadow is-hidden-widescreen"></div></div><div class="column column-right is-4-tablet is-4-desktop is-3-widescreen is-hidden-touch is-hidden-desktop-only order-3"><div class="card widget" data-type="recent-posts"><div class="card-content"><h3 class="menu-label">Recents</h3><article class="media"><div class="media-content"><p class="date"><time dateTime="2022-02-24T08:00:00.000Z">2022-02-24</time></p><p class="title"><a href="/posts/about/">Jue Wang</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2020-02-09T08:18:11.000Z">2020-02-09</time></p><p class="title"><a href="/posts/vps-cheatsheet/">CheatSheet for Setting up New VPS</a></p><p class="categories"><a href="/categories/other/">other</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2018-09-18T03:24:29.000Z">2018-09-18</time></p><p class="title"><a href="/posts/%5B2018.9%5Dnlp-short-reviews-week-1/">nlp short reviews - week 1</a></p><p class="categories"><a href="/categories/research/">research</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2018-08-22T05:58:00.000Z">2018-08-22</time></p><p class="title"><a href="/posts/%5B2018.8.22%5DRegEx-with-NN/">RegEx with NN</a></p><p class="categories"><a href="/categories/research/">research</a></p></div></article><article class="media"><div class="media-content"><p class="date"><time dateTime="2018-07-01T12:59:58.000Z">2018-07-01</time></p><p class="title"><a href="/posts/intro-about-KG/">intro-about-KG</a></p><p class="categories"><a href="/categories/research/">research</a></p></div></article></div></div><div class="card widget" data-type="categories"><div class="card-content"><div class="menu"><h3 class="menu-label">Categories</h3><ul class="menu-list"><li><a class="level is-mobile" href="/categories/francais/"><span class="level-start"><span class="level-item">francais</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/categories/math/"><span class="level-start"><span class="level-item">math</span></span><span class="level-end"><span class="level-item tag">14</span></span></a><ul><li><a class="level is-mobile" href="/categories/math/unfinished/"><span class="level-start"><span class="level-item">unfinished</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/other/"><span class="level-start"><span class="level-item">other</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/categories/programming/"><span class="level-start"><span class="level-item">programming</span></span><span class="level-end"><span class="level-item tag">20</span></span></a><ul><li><a class="level is-mobile" href="/categories/programming/unfinished/"><span class="level-start"><span class="level-item">unfinished</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li></ul></li><li><a class="level is-mobile" href="/categories/research/"><span class="level-start"><span class="level-item">research</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li></ul></div></div></div><div class="card widget" data-type="archives"><div class="card-content"><div class="menu"><h3 class="menu-label">Archives</h3><ul class="menu-list"><li><a class="level is-mobile" href="/archives/2022/02/"><span class="level-start"><span class="level-item">February 2022</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2020/02/"><span class="level-start"><span class="level-item">February 2020</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/09/"><span class="level-start"><span class="level-item">September 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/08/"><span class="level-start"><span class="level-item">August 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/07/"><span class="level-start"><span class="level-item">July 2018</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/05/"><span class="level-start"><span class="level-item">May 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/04/"><span class="level-start"><span class="level-item">April 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/03/"><span class="level-start"><span class="level-item">March 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/02/"><span class="level-start"><span class="level-item">February 2018</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2018/01/"><span class="level-start"><span class="level-item">January 2018</span></span><span class="level-end"><span class="level-item tag">4</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/12/"><span class="level-start"><span class="level-item">December 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/06/"><span class="level-start"><span class="level-item">June 2017</span></span><span class="level-end"><span class="level-item tag">5</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/04/"><span class="level-start"><span class="level-item">April 2017</span></span><span class="level-end"><span class="level-item tag">1</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/03/"><span class="level-start"><span class="level-item">March 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/02/"><span class="level-start"><span class="level-item">February 2017</span></span><span class="level-end"><span class="level-item tag">3</span></span></a></li><li><a class="level is-mobile" href="/archives/2017/01/"><span class="level-start"><span class="level-item">January 2017</span></span><span class="level-end"><span class="level-item tag">2</span></span></a></li><li><a class="level is-mobile" href="/archives/2016/12/"><span class="level-start"><span class="level-item">December 2016</span></span><span class="level-end"><span class="level-item tag">16</span></span></a></li><li><a class="level is-mobile" href="/archives/2016/11/"><span class="level-start"><span class="level-item">November 2016</span></span><span class="level-end"><span class="level-item tag">8</span></span></a></li></ul></div></div></div><div class="card widget" data-type="tags"><div class="card-content"><div class="menu"><h3 class="menu-label">Tags</h3><div class="field is-grouped is-grouped-multiline"><div class="control"><a class="tags has-addons" href="/tags/Bayes/"><span class="tag">Bayes</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/BiLSTM/"><span class="tag">BiLSTM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/CNN/"><span class="tag">CNN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/EDP/"><span class="tag">EDP</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/FEM/"><span class="tag">FEM</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/GAN/"><span class="tag">GAN</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Hilbert/"><span class="tag">Hilbert</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/KGC/"><span class="tag">KGC</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/LSTM/"><span class="tag">LSTM</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/NLP/"><span class="tag">NLP</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/OS/"><span class="tag">OS</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/RNN/"><span class="tag">RNN</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/Sobolev/"><span class="tag">Sobolev</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/aleatoire/"><span class="tag">aleatoire</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/algo/"><span class="tag">algo</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/analyse/"><span class="tag">analyse</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/attention/"><span class="tag">attention</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/chrome/"><span class="tag">chrome</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/classification/"><span class="tag">classification</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/co-reference/"><span class="tag">co-reference</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/complexity/"><span class="tag">complexity</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/compression/"><span class="tag">compression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/convolution/"><span class="tag">convolution</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/crawl/"><span class="tag">crawl</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/data-structure/"><span class="tag">data-structure</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/datamining/"><span class="tag">datamining</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/deep-learning/"><span class="tag">deep-learning</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/distant-supervision/"><span class="tag">distant-supervision</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/docker/"><span class="tag">docker</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/entity-resolution/"><span class="tag">entity-resolution</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/event-detection/"><span class="tag">event-detection</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/event-extraction/"><span class="tag">event-extraction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/firm/"><span class="tag">firm</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/francais/"><span class="tag">francais</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/graph/"><span class="tag">graph</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/hexo/"><span class="tag">hexo</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/kernel/"><span class="tag">kernel</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/knowledge-graph/"><span class="tag">knowledge-graph</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/knowledge-reasoning/"><span class="tag">knowledge-reasoning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/language/"><span class="tag">language</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/latex/"><span class="tag">latex</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/limited-supervision/"><span class="tag">limited-supervision</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/machine-learning/"><span class="tag">machine-learning</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/management/"><span class="tag">management</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/marked/"><span class="tag">marked</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/math/"><span class="tag">math</span><span class="tag">12</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mathjax/"><span class="tag">mathjax</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/matrix/"><span class="tag">matrix</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mongo/"><span class="tag">mongo</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/mongodb/"><span class="tag">mongodb</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/neural-network/"><span class="tag">neural-network</span><span class="tag">3</span></a></div><div class="control"><a class="tags has-addons" href="/tags/nlp/"><span class="tag">nlp</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/prediction/"><span class="tag">prediction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/probability/"><span class="tag">probability</span><span class="tag">7</span></a></div><div class="control"><a class="tags has-addons" href="/tags/programming/"><span class="tag">programming</span><span class="tag">9</span></a></div><div class="control"><a class="tags has-addons" href="/tags/python/"><span class="tag">python</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/qualitative-induction/"><span class="tag">qualitative-induction</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/regular-expression/"><span class="tag">regular-expression</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/reinforcement-learning/"><span class="tag">reinforcement-learning</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/relation-classification/"><span class="tag">relation-classification</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/relation-extraction/"><span class="tag">relation-extraction</span><span class="tag">5</span></a></div><div class="control"><a class="tags has-addons" href="/tags/review/"><span class="tag">review</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/rss/"><span class="tag">rss</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/scrapy/"><span class="tag">scrapy</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/sequence-labeling/"><span class="tag">sequence-labeling</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/spider/"><span class="tag">spider</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/statistic/"><span class="tag">statistic</span><span class="tag">2</span></a></div><div class="control"><a class="tags has-addons" href="/tags/summarization/"><span class="tag">summarization</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vector/"><span class="tag">vector</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/vps/"><span class="tag">vps</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/weak-supervision/"><span class="tag">weak-supervision</span><span class="tag">1</span></a></div><div class="control"><a class="tags has-addons" href="/tags/web/"><span class="tag">web</span><span class="tag">1</span></a></div></div></div></div></div></div></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/favicon.svg" alt="Jue&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 Jue Wang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div><div id="divmap" style="visibility:hidden; position: absolute; top: 0px"><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&amp;w=2&amp;t=n&amp;d=I_238wU69nrKH0DIm55b1z-y84aVsLuSzQSglFoJ1ww&amp;co=ffffff&amp;ct=ffffff&amp;cmo=ffffff&amp;cmn=ffffff"></script></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>