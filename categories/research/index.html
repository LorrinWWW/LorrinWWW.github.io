<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>Category: research - Jue&#039;s Blog</title><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jue Wang (王珏)"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jue Wang (王珏)"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="Effective and Efficient NLP"><meta property="og:type" content="blog"><meta property="og:title" content="Jue&#039;s Blog"><meta property="og:url" content="https://juewang.me/"><meta property="og:site_name" content="Jue&#039;s Blog"><meta property="og:description" content="Effective and Efficient NLP"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://juewang.me/img/og_image.png"><meta property="article:author" content="Jue Wang"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://juewang.me"},"headline":"Jue's Blog","image":["https://juewang.me/img/og_image.png"],"author":{"@type":"Person","name":"Jue Wang"},"publisher":{"@type":"Organization","name":"Jue's Blog","logo":{"@type":"ImageObject","url":"https://juewang.me/img/favicon.svg"}},"description":"Effective and Efficient NLP"}</script><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-115582186-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-115582186-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Jue's Blog" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/favicon.svg" alt="Jue&#039;s Blog" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/posts/about/">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><div class="card-content"><nav class="breadcrumb" aria-label="breadcrumbs"><ul><li><a href="/categories">Categories</a></li><li class="is-active"><a href="#" aria-current="page">research</a></li></ul></nav></div></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-08-22T11:58:00.000Z" title="8/22/2018, 1:58:00 PM">2018-08-22</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:04.399Z" title="11/3/2020, 4:26:04 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">5 minutes read (About 702 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.8.22%5DRegEx-with-NN/">RegEx with NN</a></h1><div class="content"><p>这两天在实习没有太多的时间写笔记orz，正好趁着公司内部分享的时候稍微写几笔。（然而一直没发出来）</p>
<h1 id="Marrying-Up-Regexs-with-Neural-Networks"><a href="#Marrying-Up-Regexs-with-Neural-Networks" class="headerlink" title="Marrying Up Regexs with Neural Networks"></a>Marrying Up Regexs with Neural Networks</h1><h2 id="概述"><a href="#概述" class="headerlink" title="概述"></a>概述</h2><ul>
<li><p>正则表达式 </p>
<ul>
<li><p>简明、扼要、可调，不依赖大规模标注数据</p>
</li>
<li><p>泛化性能差，所以变体、同义词都需要人为编写</p>
</li>
</ul>
</li>
<li><p>神经网络 </p>
<ul>
<li>拟合能力强、泛化性能强  </li>
<li>需要大量标注数据，解释性差</li>
</ul>
</li>
</ul>
<p>因此工程上常常结合两个，正则解决部分cases，剩下交给统计模型，一般来说就是神经网络了。</p>
<p>那么有没有可能正则和神经网络结合起来？Bingfeng et al. 2018[^1]给出了一些思路。</p>
<h2 id="Problem-def-and-the-baselines"><a href="#Problem-def-and-the-baselines" class="headerlink" title="Problem def. and the baselines"></a>Problem def. and the baselines</h2><p>文章主要解决两个问题，intent detection和slot filling，也可以认为是classification和seq2seq的任务。这里的baselines主要有两个，正则表达式的尝试和Liu, Bing, and Ian Lane. 2016[^2]提出的attention-based rnn。思路可以见下图。</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-063410.png" alt="image-20180916143407395"></p>
<h2 id="Approaches"><a href="#Approaches" class="headerlink" title="Approaches"></a>Approaches</h2><p>文章主要在三个方面进行尝试：input level、network level、output level。</p>
<h3 id="Input-level"><a href="#Input-level" class="headerlink" title="Input level"></a>Input level</h3><ul>
<li><p>For intent detection, </p>
<p>two possible approach:</p>
<ul>
<li>Append the embedding to all words (deprecated &lt;= 从结果上看会导致网络过于依赖正则)</li>
<li>Append the embedding to the input of softmax layer(① in Fig(a) )</li>
</ul>
</li>
<li><p>For slot filling, </p>
<p>Embed and average the REtags into a vector fi for each word and append it to the corresponding word embedding wi (① in Fig(b) )</p>
</li>
</ul>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064101.png" alt="image-20180916144059096"></p>
<h3 id="Network-level"><a href="#Network-level" class="headerlink" title="Network level"></a>Network level</h3><ul>
<li><p>For intent detection, </p>
<p>For each intent label k, use different attention ak , which is used to generate the sentence embedding sk   (② in Fig(a) )</p>
<p>Note that a RE can also indicate that a sentence does not express intent k (negative REs), it is also necessary to set another group of attention. </p>
</li>
</ul>
<p>$$<br>  s_{k} = \sum_i {\alpha_{ki} h_i}, \quad \alpha_{ki} = \frac{\exp(h_i^T W_{a} c_k)}{\sum_i {\exp(h_i^T W_{a} c_k)}}<br>$$</p>
<ul>
<li><p>For slot filling, </p>
<p>The mechanism introduced for intent detection is unsuitable for slot filling.</p>
<p>A simple version of the two-side attention, where all the slot labels share the same set of positive and negative attention. (② in Fig(b) )</p>
<p>$$<br>s_{pi} = \sum_j {\alpha_{pij} h_j}, \quad \alpha_{pij} = \frac{\exp(h_j^T W_{sp} h_i)}{\sum_j {\exp(h_j^T W_{sp} h_i)}}<br>$$</p>
</li>
</ul>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064735.png" alt="image-20180916144733081"></p>
<h3 id="Output-level"><a href="#Output-level" class="headerlink" title="Output level"></a>Output level</h3><p>Let $z_k$ be a 0-1 indicator of whether there is at least one matched RE that leads to target label $k$ (intent or slot label), the final logits of label k for a sentence (or a spefic word for slot filling) is:<br>$$<br>logit_k = logit_k’ + w_k z_k<br>$$<br>where $logit′_k$ is the logit produced by the original NN, and $w_k$ is a trainable weight indicating the overall confidence for REs that lead to target label $k$.</p>
<h2 id="Experimental-Results"><a href="#Experimental-Results" class="headerlink" title="Experimental Results"></a>Experimental Results</h2><p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065006.png" alt="image-20180916145004296"> </p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065035.png" alt="image-20180916145033498"></p>
<h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>[^1]: Luo, Bingfeng, et al. Marrying up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding.&nbsp;arXiv preprint arXiv:1805.05588&nbsp;(2018).<br>[^2]: Liu, Bing, and Ian Lane. Attention-based recurrent neural network models for joint intent detection and slot filling. arXiv preprint arXiv:1609.01454 (2016). </p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-07-01T18:59:58.000Z" title="7/1/2018, 8:59:58 PM">2018-07-01</time></span><span class="level-item">Updated&nbsp;<time dateTime="2018-07-01T13:27:45.722Z" title="7/1/2018, 3:27:45 PM">2018-07-01</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">5 minutes read (About 691 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/intro-about-KG/">intro-about-KG</a></h1><div class="content"><h1 id="知识图谱"><a href="#知识图谱" class="headerlink" title="知识图谱"></a>知识图谱</h1><p>之前其实陆陆续续地看了一些知识图谱相关的论文，对其的理解始终停留在比较浅显的层面，或者说一个非常不全面的状态，以至于，在实习中真的要尝试着手建立一个通用知识图谱的时候，却不知道如何下手。在实习期间打算写这篇综述来整理一下之前看到的一些琐碎的知识。</p>
<h2 id="介绍和定义"><a href="#介绍和定义" class="headerlink" title="介绍和定义"></a>介绍和定义</h2><p>知识图谱（knowledge graph）最初是又Google提出的概念，目的是确定一种面相知识的存储结构。通常我们将数据存在一个关系型数据库或是key-value型数据库，数据和数据之间的关系是通过表来定义的；当数据的关系比较复杂而且比较灵活的时候，传统数据库的表达能力和响应速度都有较大的局限性，事实上，知识就是一种关系很强的数据，而且知识千变万化，难以用一些简单的规则来预先确定表。由此，知识图谱的想法也就很自然了，知识是一种关系性很强的数据，知识的存储结构必然应该是类似于图的。</p>
<p>通常来说，在实际应用中，我们可以简单的认为知识图谱就是一个多关系图，其中我们用实体（entity）来表示节点，用关系（relation）来表示边，因此知识的表达是通过一个三元组—（实体h-关系r-实体t）来实现。</p>
<p>TODO</p>
<h2 id="知识图谱构建"><a href="#知识图谱构建" class="headerlink" title="知识图谱构建"></a>知识图谱构建</h2><p>某种程度上来说，知识图谱最困难，最需要人力的部分就是知识图谱的构建。数据来源通常有以下几种</p>
<h3 id="结构化数据"><a href="#结构化数据" class="headerlink" title="结构化数据"></a>结构化数据</h3><p>这个比较理想，但是信息一定是不完善或是滞后的，可以作为初期的构建，后期还是要自己来维护。这里略过。</p>
<h3 id="非结构化数据"><a href="#非结构化数据" class="headerlink" title="非结构化数据"></a>非结构化数据</h3><p>大数据时代更多的是这样的数据，需要一定的信息抽取、ner等nlp技术的支持，必要时需要人工进行审核。在构建类似的图谱过程当中，主要涉及以下几个方面的自然语言处理技术：  </p>
<ul>
<li>实体命名识别（Name Entity Recognition）</li>
<li>关系抽取（Relation Extraction）    </li>
<li>实体统一（Entity Resolution）    </li>
<li>指代消解（Coreference Resolution）</li>
</ul>
<h2 id="知识图谱的存储"><a href="#知识图谱的存储" class="headerlink" title="知识图谱的存储"></a>知识图谱的存储</h2><p>TODO：</p>
<p>RDF和图数据库等</p>
<h2 id="知识图谱的应用"><a href="#知识图谱的应用" class="headerlink" title="知识图谱的应用"></a>知识图谱的应用</h2></div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-05-10T06:00:00.000Z" title="5/10/2018, 8:00:00 AM">2018-05-10</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:05.090Z" title="11/3/2020, 4:26:05 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">24 minutes read (About 3557 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.5.10%5DKnowledge-Graph-Augmented-Neural-Networks-for-NLP/">Learning beyond datasets - Knowledge Graph Augmented Neural Networks for Natural language Processing 阅读笔记</a></h1><div class="content"><h2 id="Knowledge-Graph-Augmented-Neural-Networks-for-Natural-language-Processing-阅读笔记"><a href="#Knowledge-Graph-Augmented-Neural-Networks-for-Natural-language-Processing-阅读笔记" class="headerlink" title="Knowledge Graph Augmented Neural Networks for Natural language Processing 阅读笔记"></a>Knowledge Graph Augmented Neural Networks for Natural language Processing 阅读笔记</h2><p><strong>摘要</strong>：机器学习的效果一般依赖于具体的训练数据。一些学习模型可以结合贝叶斯中的先验知识，但是这些模型不具备根据需要访问任何有组织的知识的能力。在这项工作[^1]中，我们以知识图谱（KG）的形式为NLP模型提供先验知识，使得模型取得更好的效果。我们的目标是开发一种深度学习模型，可以根据任务使用attention机制从知识图谱中提取相关的先验支持事实。为了减少attention空间，我们引入了基于卷积的模型来学习知识图谱实体和关系集的表示。提出的方法是高度可扩展的，并可应用于常用的NLP任务。使用这种方法，我们在实验中显示了文本分类性能的显着提高。我们还证明了，当深度学习模型使用知识图谱以辅助时，可以用较为少量的标记训练数据进行训练。</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>现在机器学习主要是针对特定任务、特定训练数据进行训练的模型。虽然transfer learning试图将学习从一个任务迁移到另一个任务，但在可扩展性方面有局限性，通常是具体地针对某个的任务。另一方面，我们知道人类具有一种内在的能力，可以根据需求从脑中获取所需的知识，并结合我们新学习的概念来解决问题。</p>
<p>这就引出了我们要在本文中讨论的问题：是否有可能设计一个学习模型，除了从培训数据集中学习外，还可以在预测时利用大量外在的知识？<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-03-WX20180503-190446%402x.png" alt="X20180503-190446@2"></p>
<p>我们有一个基本的想法如上图，$\mathcal{X}$是原本的输入，$\mathcal{Y}$是输出。通过知识库补充、增强$\mathcal{X}$，以得到$\mathcal{X_w}$，将两这串联，获得$\mathcal{X’}$作为新的输入。</p>
<p>这里我们知识库以知识图谱的形势呈现，主要将一个事实（fact）表现为三元组：(subject entity, relation, object entity)简记为(h,r,t)。其他关于知识图谱的介绍可以参考以前的笔记和相关的文献，这里不再赘述。</p>
<p>通常我们通过训练集来得到我们所需的模型，但是它往往缺乏world knowledge或者常识，结果往往会有偏差。例如 ：“特朗普慰问了得克萨斯州的飓风幸存者和他们的家人”，我们需要知道$\langle \text{特朗普},\text{总统},\text{美国} \rangle$和$\langle \text{得克萨斯州},\text{州},\text{美国} \rangle$才能判断这是一个政治事件。因此我们认为对于机器学习模型，除了代表ground-truth的用于训练的数据集以外，我们还可以从结构化的知识库获取相关知识，以提高整体性能。</p>
<p>因此我们提出了一个深度学习模型，可以根据需求从知识图谱中提取相关的事实，并将其也作为输入特征加以补充。特别的，当知识图谱非常大的时候，即其中的三元组数量非常大，以至于我们不可能逐一比较来提出相关信息时，我们提出了一种基于深度学习的搜寻机制，来大大提高搜寻速度，我们将在后文具体描述。</p>
<h2 id="2-Knowledge-graph-representations"><a href="#2-Knowledge-graph-representations" class="headerlink" title="2. Knowledge graph representations"></a>2. Knowledge graph representations</h2><p>实体和关系需要进行embedding以进行后续处理，目前有很多种知识图谱的表示方法，主要可以被分为：structure-based embedding，semantically-enriched embedding。</p>
<h4 id="structure-based-embedding"><a href="#structure-based-embedding" class="headerlink" title="structure-based embedding"></a>structure-based embedding</h4><p>其中包括经典的TransE以及其各种变体，它的基本假设就是$h + r = t$. 之前有一篇笔记主要介绍的就是这类知识图谱表示<a target="_blank" rel="noopener" href="https://blog.lorrin.info/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/">这里</a>。</p>
<h4 id="semantically-enriched-embedding"><a href="#semantically-enriched-embedding" class="headerlink" title="semantically-enriched embedding"></a>semantically-enriched embedding</h4><p>这些embedding技术学习表示KG的实体/关系及其语义信息。 神经张量网络（NTN）Socher et al [2011]是该领域的先驱工作，它使用平均词嵌入和基于张量的操作初始化实体向量。 最近涉及这个想法的作品是“联合对齐”Zhong et al。 [2015]和SSP Xiao et al。[2017]。 DKRL Xie et al [2016]是一种KG表示技术，它也保留了TransE模型简单结构的文本描述性。 预训过的word2vec被用来形成实体表示，通过一个卷积神经网络（CNN）来约束要保持的关系。</p>
<p>作者采用了DKRL，因为它强调了文本的语义描述，同时，它也继承了TransE的方法。因此我们能够通过$t = h + r$的关系来提取相关实体或关系。这大大减少了提取fact（三元组）的复杂度，因为实体关系的组合数远小于三元组的数量，因此能够让这个过程的速度更快。</p>
<h2 id="3-The-proposed-model"><a href="#3-The-proposed-model" class="headerlink" title="3. The proposed model"></a>3. The proposed model</h2><p>我们以一个文本分类模型为例，模型的参数为$\Theta$，训练集为$x$，标签为$y$，我们需要最大化下列方程：<br>$$<br>\max_{\Theta}{P(y|x, \Theta)}<br>$$</p>
<p>因此：<br>$$<br>\Theta = \arg\max_{\Theta} {\log{P(y|x, \Theta)}}<br>$$<br>这里，我们通过结合world knowledge特征$x_w$来增强监督学习过程。使用数据$x$检索world knowledge特征，使用单独的模型，其中$x_w = F(x, \Theta^{(2)})$。 因此，我们修改的目标函数为：<br>$$<br>\max_{\Theta}{P(y|x, x_w, \Theta^{(1)})}<br>$$<br>其中$\Theta = {\Theta^{(1)}, \Theta^{(2)}}$。可以获得优化的参数：<br>$$<br>\Theta = \arg\max_{\Theta} {\log{P(y|x,F(x, \Theta^{(2)}), \Theta^{(1)})}}<br>$$<br>后面的部分着重于函数F的表达，该函数使用数据x进行事实三重检索。在实验中，我们使用经过softmax的输入的LSTM Greff et al. [2015]编码作为P的形式。对于F，我们使用soft attention。</p>
<p>基于此，我们提出两种模型：A. 朴素模型；B. 基于卷积的实体和关系集群表示</p>
<h4 id="A-朴素模型"><a href="#A-朴素模型" class="headerlink" title="A. 朴素模型"></a>A. 朴素模型</h4><p>前面解释过，KG的实体和关系使用DKRL进行编码。 令$e_i \in \mathbb{R}^m$代表实体i的编码，$r_j\in \mathbb R^m$代表KG中第j个关系。 输入文本以串联的单词向量$x =(x_1,x_2,…,x_T)$的形式首先使用LSTM Greff et al. [2015]模块如下，<br>$$<br>h_t = f(x_t, h_{t-1})<br>$$<br>以及<br>$$<br>o = \frac{1}{T}\sum_{t=1}^{T}{h_t}<br>$$<br>$h_t \in \mathbb{R}^n$是LSTM的隐藏状态，f是非线性函数，T是序列长度。 然后如下形成一个上下文向量，<br>$$<br>C = ReLU(o^T W)<br>$$<br>其中，$W\in \mathbb R^n \times m$表示权重参数。设置两个同样的过程以形成两个独立的上下文向量，一个用于实体检索($C_E$)和一个用于关系检索($C_R$)。</p>
<p>由于在朴素模型中KG的事实三元组的数量是数以百万计的，所以我们分别对实体和关系空间产生注意力。 然后使用检索到的实体和关系形成事实。使用实体上下文向量的实体的注意力由下式给出：<br>$$<br>\alpha_{e_i} = \frac{\exp{C_E^T{e_i}}}{\sum_{j=0}^{|E|} \exp{C_E^T{e_j}}}<br>$$<br>同理，关系的注意力：<br>$$<br>\alpha_{r_i} = \frac{\exp{C_R^T{r_i}}}{\sum_{j=0}^{|R|} \exp{C_R^T{r_j}}}<br>$$<br><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110007120.png" alt="mage-20180511000712"></p>
<p>图2显示了实体/关系检索的示意图。在计算出最终的实体和关系向量之后，我们希望补充事实三元组。用于实验的KG技术是DKRL，其使用TransE模型假设($h + r = t$)。因此，使用主题实体(subject entity)和关系，我们将对象实体形成为$t = e + r$。 因此，检索的事实三元组是$\mathcal F = [e，r，e + r]$，其中$F \in \mathbb R^{3m}$。 该检索到的事实信息与使用LSTM模块获得的输入x的上下文向量(C)一起连接。 最终分类标签$\mathbb y$的计算如下，<br>$$<br>\mathcal F’ = ReLU(\mathcal F^T V) \<br>\mathbb y = softmax([\mathcal F’ : C]^T U)<br>$$<br>其中，$V∈\mathbb R^{3m \times u}$和$U\in \mathbb R^{2u\times u}$是要学习的模型参数。 $\mathbb y$是预测结果，用于计算交叉熵损失。我们尽量减少训练样本的平均损失，以便使用随机梯度下降来学习各种模型参数。最后的预测$\mathbb y$现在包含了来自数据集特定信息和世界知识的信息，以帮助提高性能。在联合培训注意力机制的同时调整自己，以检索进行最终分类所需的相关事实。</p>
<h4 id="A-预训练KG检索模型"><a href="#A-预训练KG检索模型" class="headerlink" title="A+. 预训练KG检索模型"></a>A+. 预训练KG检索模型</h4><p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110034147.png" alt="mage-20180511003414"></p>
<p>朴素模型需要考虑整个实体/关系空间，这不是一个好的方法，因为我们观察到每个attention的容易饱和。在一起训练分类和检索模块时，模型往往会忽略KG部分，而梯度只通过分类模块进行传播。这在一定程度上是可以预料的，因为当前任务的大多数相关信息来自训练样本，只有背景辅助信息来自KG。经过几个训练阶段后，KG检索到的事实总是收敛到一个固定的向量。为了克服这个问题，我们试图单独预先训练KG检索部分。预训练的KG模型用于检索事实，然后与分类模块连接，同时，在联合训练时通过预先训练的模型可能会导致传递误差。我们推断，KG不会返回噪音，并且对于任务具有基本信息，因为单独的KG部件单独显示出显着的性能（News20为59％，SNLI为66％）。图3描述了整个训练过程。该程序解决了联合训练时KG检索部分中的梯度饱和问题。但是，attention机制必须覆盖大量实体/关系的关键问题依然存在。</p>
<h4 id="B-基于卷积的实体和关系集群表示"><a href="#B-基于卷积的实体和关系集群表示" class="headerlink" title="B. 基于卷积的实体和关系集群表示"></a>B. 基于卷积的实体和关系集群表示</h4><p>在本节中，我们提出了一种机制来减少知识图谱中需要attention的大量实体/关系。 我们通过学习类似实体/关系向量的表示来减少attention空间。</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110044225.png" width="60%">

<p>为了聚类相似的实体/关系向量，我们使用k-means聚类，并在每个聚类中形成具有相同数量的实体/关系向量的$l$个聚类。然后使用CNN对每个cluster进行编码。k-means聚类的输出是一个实体/关系向量序列${e^T_1,e^T_2,…,e^T_q}$，其中$e_i \in\mathbb R^m$，每个聚类中的元素个数为$ q =⌈\frac{| E |}{l}⌉$。对于每个cluster，这些矢量被堆叠形成$\mathcal E$作为到CNN编码器的2D输入，其中$\mathcal E\in\mathbb R^{m\times q}$。 在寻找合适滤波器形状的实验中，我们发现使用2-D滤波器，该模型无法收敛。因此，我们推断，向量$e_i$中两个不同索引的潜在表示不应该被卷积修改。然后，我们采用一维卷积滤波器，只沿$\mathcal E$列滑动，如图4所示。沿着y轴的步长是窗口长度k，卷积层的输出表示为：<br>$$<br>\mathcal E’(i,j) = W^T[e_{i,j}, e_{i+1,j},…,e_{i+k-1, j}]^T<br>$$<br>其中，$\mathcal E’(i,j)$是输出矩阵$\mathcal E’$的第(i, j)个元素，$W\in \mathbb R^k$是卷积权重滤波器。为了减少参数空间，在卷积层之后放置一个pooling层，我们只沿y轴使用一维窗口，类似于上面提到的卷积核。我们使用了一个双层卷积网络，其步长k和最大池窗口n被调整以获得输出$\mathcal E_i\in \mathbb R^m$，其中i是聚类索引。对于关系也进行类似的聚类过程，接着对聚类实体进行编码。这样，实体和关系空间都被缩减为包含更少的元素，每个cluster都有一个元素。在形成紧凑的实体空间$E$和关系空间$R$之后，我们采用了与之前相同的步骤来形成attention，但是现在，由于梯度有效地传递并且没有被过大的空间所阻塞，所以训练更有效。此外，由于卷积架构也同时得到训练，所以attention机制并没有像以前那样通过实体和关系的巨大空间来学习。</p>
<h2 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h2><p>实验表明，引入KG不仅降低了深度学习模型对训练集的依赖，还显著地提高了预测结果的准确度，在数据集不够的情况下效果更佳拔群。此外，本文的方法对world knowledge的处理、embedding的方法是高度可扩展，可以应用于各种NLP任务。</p>
<h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>笔记参考 <a target="_blank" rel="noopener" href="https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742">https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742</a></p>
<p>[^1]: Annervaz, K. M., Somnath Basu Roy Chowdhury, and Ambedkar Dukkipati. ‘Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing.’ arXiv preprint arXiv:1802.05930 (2018).</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-04-14T06:00:00.000Z" title="4/14/2018, 8:00:00 AM">2018-04-14</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:07.006Z" title="11/3/2020, 4:26:07 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">13 minutes read (About 1927 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.4.14%5DReinforcement-Learning-for-Relation-Classification-from-Noisy-Data/">Reinforcement Learning for Relation Classification from Noisy Data 阅读笔记</a></h1><div class="content"><h2 id="Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data-阅读笔记"><a href="#Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data-阅读笔记" class="headerlink" title="Reinforcement Learning for Relation Classification from Noisy Data 阅读笔记"></a>Reinforcement Learning for Relation Classification from Noisy Data 阅读笔记</h2><p><strong>摘要</strong>：现有关系分类方法依赖远程监督(distant supervision)，它假定提到实体对的句子都描述了这个实体对的关系。这样的方法一般在句子集合进行分类，不能识别关系和句子之间的映射，并且很大程度上受到标签噪音问题的影响。在这篇论文[^1]中，作者提出了一个从有噪声多数据的句子层次的关系分类模型。该模型有两个模块：一个实例选择器和一个关系分类器。实例选择器通过增强学习选择高质量的句子，并将选定的句子输入到关系分类器中，关系分类器进行句子级预测，并向实例选择器提供奖励。这两个模块共同训练以优化实例选择和关系分类过程。实验结果表明，我们的模型可以有效地处理数据中的噪音，并在句子级别获得更好的关系分类性能。</p>
<h2 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h2><p>关系抽取是nlp领域中一个非常重要的任务，尤其在知识图谱构建等任务上。相关的工作可以参考我之前写的笔记，主要还是分为两种：传统的手工特征方法，和深度神经网络。</p>
<p>为了获得更大量的训练数据集，半监督、远程监督，甚至无监督模型被提出。半监督模型对一开始的少量数据要求较高，容易产生较大的偏差；无监督学习目前还没有比较成熟的解决方案。</p>
<p>这里主要提一下远程监督模型。远程监督模型有一个很强的假设：如果两个实体在给定的知识库中有一种关系，则包含这两个实体的所有句子都会提及该关系，实际上当然会有很大问题，会带来很多标注错误的信息。有一些解决方法就是转化为bag-level的关系标注。一个bag包含提及相同实体对的句子，但有可能描述不同的关系，如下图。</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-152317%402x.png" alt="X20180414-152317@2"></p>
<p>不过实际上还是会有问题：1. 不能处理句子级别的关系分类；2. 如果一个bag里的句子都不含知识库中的关系，即都是噪声，这样对性能会有很大影响。</p>
<p>为解决上述的两个缺陷，作者提出了实例选取器，并将其定义为一个强化学习任务。它有两个特征：1. 句子选择是一个反复试错的过程，需要从分类器中得到选取句子质量的反馈；2. 反馈在挑选结束后得到，因此是滞后的。这两点非常满足强化学习的特点。</p>
<h2 id="2-Methodology"><a href="#2-Methodology" class="headerlink" title="2. Methodology"></a>2. Methodology</h2><p>作者提出了一个新的关系分类框架，它可以从噪音数据中选择正确的句子用于更好的关系分类。 所提出的框架可以从清理的数据中预测句子级别的关系，而不是在bag级别。句子级别的预测对需要理解句子的任务（如QA和语义分析）更加友好。<br>我们的框架包含两个关键模块：从噪声数据中选择正确句子的实例选择器，以及预测关系并使用清理数据更新其参数的关系分类器。 这两个模块相互作用共同训练。</p>
<h3 id="Problem-definition"><a href="#Problem-definition" class="headerlink" title="Problem definition"></a>Problem definition</h3><p>我们定义两个子任务：实例选择和一个关系分类。</p>
<p>我们定义实例选择问题：给定一组(sentence, relation label)，如$X = {(x_1,r_1),(x_2,r_2),…,(x_n,r_n)}$，其中$x_i$是与两个实体$(e_{1i},e_{2i})$相关的句子，$r_i$是由远程监督产生的关系标签。我们的目标是确定哪个句子真正描述了这种关系，并且应该被选作训练实例。</p>
<p>关系分类问题表述如下：给定一个句子$x_i$和所提到的实体对$(h_i,t_i)$，目标是预测$x_i$中的语义关系$r_i$。模型估计概率：$p_{\Phi}(r_i | x_i,h_i,t_i)$。</p>
<h3 id="Overview"><a href="#Overview" class="headerlink" title="Overview"></a>Overview</h3><p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-165503%402x.png" alt="X20180414-165503@2"></p>
<h3 id="Instance-Selector"><a href="#Instance-Selector" class="headerlink" title="Instance Selector"></a>Instance Selector</h3><p>这里的Instance Selector被当作强化学习问题来处理，因此policy的更新有滞后性，作者为了加快更新速度，把所有句子实例$X={x_1, …,x_n}$分为N个bag $B = {B^1, B^2, …, B^N}$，每一个$B^k$都包含同一个实体对，且标注关系都为$r^k$。</p>
<ul>
<li><p><strong>State</strong>：编码以下信息：1) 当前句子的向量表示，从CNN的非线性层获得用于关系分类的当前句子的向量表示; 2) 被选的句子集合的表示，它是所有选择句子的向量表示的平均值; 3) 一个句子中实体对的向量表示，从预先训练的知识图谱embedding中获得。</p>
</li>
<li><p><strong>Action</strong>：定义action $a_i \in {0,1}$ 表示是否选取第i个句子，$a_i$的取值由policy function得到，定义如下：<br>$$<br>\pi_{\Theta}(s_i,a_i) = a_i \sigma(W * F(s_i) + b) + (1 - a_i)(1 - \sigma(W * F(s_i)+b))<br>$$</p>
</li>
<li><p><strong>Reward</strong>：reward function是所选句子效用的指标。对于某些bag $B = {x_1,… ,x_{| B |}}$，我们为每个句子选择一个action，以确定是否应该选择当前句子。我们假设该模型在完成所有选择时具有最终奖励。 因此，我们只在终端状态$s_{| B | +1}$收到延迟奖励，其他的奖励为零。 reward是基于CNN的分类反馈得到。</p>
</li>
</ul>
<h3 id="Relation-Classifier"><a href="#Relation-Classifier" class="headerlink" title="Relation Classifier"></a>Relation Classifier</h3><p>这里用的分类模型比较简单，一个经典的CNN。</p>
<p>输入层可以被分为两部分：</p>
<ol>
<li>word embedding</li>
<li>position embedding：两个固定长度的向量，表示该词分别到两个实体店距离。</li>
</ol>
<h2 id="3-Analysis"><a href="#3-Analysis" class="headerlink" title="3. Analysis"></a>3. Analysis</h2><p>作者用的数据集是New York Times，作者随机挑选300句子人工标注，再对其做评测。对比的baseline包括CNN、CNN+Max(每个bag选一个正确的句子)、CNN+ATT。最后结果上看出，本文的CNN+RL模型取得了最好的结果，这表明强化学习对于该任务是行之有效的；并且句子层次的模型在评测中普遍好于bag模型。</p>
<p>强化学习是目前比较火热的技术，它在nlp相关任务的应用仍在探索中，但是最近的论文确实有很多都在讨论它，并且也做到了不错的效果。希望从这篇文章为入口，开始了解强化学习及其在nlp上的应用。</p>
<p>这篇文章中，强化学习主要是用于选择噪声数据，用以减少数据集的偏差等。但是我们相信强化学习能做的不仅如此，事实上最近的顶会还是有一些相关的工作的，可以放到以后再看。</p>
<h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>本文的c++实现：<a target="_blank" rel="noopener" href="https://github.com/JuneFeng/RelationClassification-RL">https://github.com/JuneFeng/RelationClassification-RL</a></p>
<p>[^1]: Feng, J., Huang, M., Zhao, L., Yang, Y., &amp; Zhu, X. (2018). Reinforcement Learning for Relation Classification from Noisy Data.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-04-04T06:00:00.000Z" title="4/4/2018, 8:00:00 AM">2018-04-04</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:06.064Z" title="11/3/2020, 4:26:06 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">19 minutes read (About 2860 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.4.4%5DA-Neural-Model-for-Joint-Event-Detection-and-Summarization/">A Neural Model for Joint Event Detection and Summarization 阅读笔记</a></h1><div class="content"><h2 id="A-Neural-Model-for-Joint-Event-Detection-and-Summarization-阅读笔记"><a href="#A-Neural-Model-for-Joint-Event-Detection-and-Summarization-阅读笔记" class="headerlink" title="A Neural Model for Joint Event Detection and Summarization 阅读笔记"></a>A Neural Model for Joint Event Detection and Summarization 阅读笔记</h2><p><strong>摘要</strong>：Twitter事件检测旨在识别推文流中的first stories。一般认为由两个子任务组成。首先，过滤掉普通的或不相关的推文。其次，推文会被自动分类到event cluster中。传统上，尽管这两个任务之间存在相互依赖关系，它们仍被单独处理，并通过pipeline整合。另外，还有一个相关的任务是摘要，即提取能够代表event cluster的简洁摘要。这里和上个暑假看的Wang, Z.[^2]的工作比较相似。</p>
<p>在本文[^1]中，我们构建了一个joint model来筛选、聚类和摘要推文中的event。特别的，我们利用深度表示学习来对推文进行矢量化处理。Neural stacking model用于整合不同子任务的pipeline，并更好地共享前后参数。实验表明，我们提出的neural joint model比pipeline更有效。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>有文献证明了推特、微博这类体裁比起传统的媒体，对新闻事件有更快的反应速度，因此今年对于推特的事件监测也是今年的热点之一，引起了广泛关注。我们在本文主要检测一些典型的事件类别，比如地震、DDos攻击等。我们提出了一个神经网络模型，该模型监视特定事件类别的推特流，共同检测并摘要该类别下的新闻事件。</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-225501%402x.png" width="60%">

<p>整体的架构如上图所示，给定一个推特流，我们的模型考虑三个子任务：推文过滤，事件聚类和事件摘要。</p>
<p>典型的推特事件检测模型的核心部分是<strong>聚类</strong>，其中包括增量聚类和locality sensitive hashing。主要的想法是将同一主题的推文进行分组，以便在新推文不属于现有主题类的情况下检测到新主题。这样的聚类算法通常依赖于推特内容的特征，如TFIDF，用于测量推文之间的相似度。</p>
<p>第二个子任务是<strong>摘要</strong>，它并不直接涉及event detection，但仍然与之高度相关，因为检测到的事件群可能比较大并且包含不同程度信息的推文。 从系统功能的角度来说，对于推特事件检测系统，摘要是十分必要的，因为我们没办法直接读取事件群，只有将其抽取摘要，并将事件摘要作为输出，才能够为我们所用。</p>
<p>此外，由于大部分推文流包含普通或不相关的信息，推文<strong>过滤</strong>是我们考虑的第三个子任务。 我们的目标是根据其与潜在新事件的相关性对传入推文进行分类，以便只保留信息性推文。 过滤可以在聚类之前或之后进行。 在本文中，我们在聚类之前执行这项任务。</p>
<p>这三个子任务形成了一个三阶段pipeline（过滤→聚类→摘要），其中各个阶段是密切相关的。 例如，完整描述事件的推文应该在相关性过滤和抽象摘要步骤中得到高分。 另外，更好地理解推文对于相关性过滤和事件聚类都有帮助。 受此启发，我们考虑使用一个joint model进行筛选、聚类和摘要。</p>
<p>神经网络在近年也在类似任务上展示了良好的表现。我们使用两种联合建模策略。首先，我们以推文的语义表示作为关键连接因素，通过参数共享整合三项任务。其次，我们将neural stacking应用于pipeline，将前一个子模型的隐藏神经层作为其后继子模型的附加输入特征，并将后继的误差传播给前者，使得在培训期间，让前后子模型之间的信息得到更好的共享。</p>
<h3 id="2-Model"><a href="#2-Model" class="headerlink" title="2. Model"></a>2. Model</h3><p>我们系统的输入是一个推特流，实时输出事件报告。三个主要的子任务定义如下：</p>
<ul>
<li><strong>事件筛选</strong>：我们将流中的每条推文分类为与相关事件相关或不相关的事件。由于我们的目标是仅检测某些类型的事件（即地震和DDOS攻击事件），因此我们使用相应的一组关键字来过滤推文流作为预处理步骤。相关分类在预处理步骤之后执行，因为并非所有包含关键字的推文都是相关的。</li>
<li><strong>事件聚类</strong>：我们在事件检测后对推文进行增量聚类。给定一个提到事件的推文，其任务是确定它是否存在于现有的事件集群中、是否是一个新的事件。这个任务的关键是推文之间的相似度计算。</li>
<li><strong>事件摘要</strong>：当一个事件集群足够大时，我们通过提取前n个包含最多信息的推文来创建相应事件的报告。这个子任务可以被看作是一个多文档摘要任务。</li>
</ul>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-232216%402x.png" width="60%">

<p>模型的整体构架如上图，H是推文的embedding，Hd是事件筛选步骤的隐藏层，Hc是聚类的隐藏层，Ps是摘要的输出。我们可以看到，每一个子任务都充分利用了前面的信息，使得各个子模型项目补充辅助，让结果更理想。</p>
<p>结果表明，与独立的pipeline相比，这种neural stacking方法可以产生更好的子模型。请注意，虽然计算两个tweets之间的相似性的过程是用LSTM模型监督的，但聚类算法是一种无监督的在线聚类算法。</p>
<h4 id="2-1-Shared-Tweet-Representation"><a href="#2-1-Shared-Tweet-Representation" class="headerlink" title="2.1 Shared Tweet Representation"></a>2.1 Shared Tweet Representation</h4><p>我们使用标准的LSTM模型来学习不同任务之间的推文表示。 假设$X =(w_1,w_2,…,w_n)$是推文，其中$n$是推文长度，$w_i$是第i个标记。 我们使用$w_i$的word embedding将每个$w_i$转换为实值向量$x_i$，通过查找预先训练的word embedding表D获得。我们使用skip-gram算法来训练embedding。<br>LSTM用以生成隐藏序列$(h_1,h_2,…,h_n)$。 在每个步骤t，基于当前向量$x_t$和前一个向量$h_{t-1}$和$h_t = LSTM(x_t，h_{t-1})$计算LSTM模型的隐藏向量$h_t$。 初始状态和所有LSTM参数随机初始化并在训练过程中调整。 我们使用$H = h_n$作为X的共享表示。</p>
<h4 id="2-2-Joint-Model"><a href="#2-2-Joint-Model" class="headerlink" title="2.2 Joint Model"></a>2.2 Joint Model</h4><h5 id="Event-mention-detection"><a href="#Event-mention-detection" class="headerlink" title="Event mention detection"></a>Event mention detection</h5><p>事件提及检测是一个二元分类任务，使用多层感知器进行描述。给出输入向量H，隐含层用于激发一组高级特征：<br>$$<br>H_d = \sigma(W_d^h H + b_d^h)<br>$$<br>$H_d$被用于softmax输出层的输入：<br>$$<br>P_d = softmax(W_dH_d + B_d)<br>$$<br>这里$W_d^h, b_d^b, W_d$都是模型参数。$P_d$ 长度为2，$P_d(0)$表示推文X相关的概率，$P_d(1)$表示不相关的概率。</p>
<h5 id="Event-clustering"><a href="#Event-clustering" class="headerlink" title="Event clustering"></a>Event clustering</h5><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-234532%402x.png" width="60%">

<p>我们使用基于流的聚类算法将传入的推文分为不同的事件组，每个事件组表示一个特定的事件。该算法随着流中的每个传入推文增长式地工作，计算新推文与现有事件群中的每条推文之间的相似度分数。新传入的推文与每个事件群中最相似的对应文件之间的相似度用于衡量新推文与事件群集之间的相似度。使用阈值$\mu - 3\cdot \sigma$来检测新推文是否属于现有聚类，其中μ是所有先前相似度分数的均值，σ是标准偏差。如果推特和所有现有群集之间的相似度低于阈值，则建立新的事件群集。否则，将推文添加到最相似的现有事件群集中。<br>为了计算两条推文$X_i$和$X_j$之间的相似度，我们使用了一个连体网络，它采用共享表示向量$H_i$和$H_j$，并通过参数化计算相似概率得分$P_c$:<br>$$<br>H_c = \sigma(W_c^h(H_i \oplus H_j)+ b_c^h) \<br>P_c = softmax(W_cH_c + B_c)<br>$$<br>⊕表示向量级联。 $W_c^h，b_b^c,W_c,b_c$是模型参数。</p>
<p>为了更好地整合事件提及检测和事件聚类，我们还将$X_i$和$X_j$的隐藏特征矢量$H_d$馈送到Siamese网络，从而<br>$$<br>H_c = \sigma(W_c^h(H_i \oplus H_j \oplus H_{d_i} \oplus H_{d_j})+ b_c^h)<br>$$</p>
<h5 id="Event-summarization"><a href="#Event-summarization" class="headerlink" title="Event summarization"></a>Event summarization</h5><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180405-000354%402x.png" width="60%">

<p>为了生成事件集群的摘要，我们使用概率分数$P_s$对集群中的所有推文进行排序。 对于集群中的每个推特X，使用多层感知器来估计$P_s$，其中输入是$H \oplus \bar{H_c^h}$。 这里的矢量$\bar{H_c^h}$是推文X与同一集群中所有其他推特之间的$H_c^h$之和。 它有两个用途。首先，$H_c^h$提供有关整个群集的信息，这对于更好地确定群集中给定推文的相关性很有用。 其次，$H_c^h$还把聚类和摘要联系了起来，从而强化了信息共享。<br>$$<br>P_s = softmax(W_sH_s + B_s)<br>$$<br>where<br>$$<br>H_s = \sigma(W_s^h(H\oplus \bar{H_c^h})+ b_s^h)<br>$$<br>$W_s^h, b_s^b, Ws$是模型的参数</p>
<h4 id="2-3-Training"><a href="#2-3-Training" class="headerlink" title="2.3 Training"></a>2.3 Training</h4><p>我们的培训目标是尽量减少这三项任务中标注的标签和预测标签之间的cross-entropy loss。 我们应用在线培训，使用Adagrad调整模型参数。为了避免过拟合，对word embedding使用0.2点dropout。隐藏层$H_d, H_c,H_s$的大小都设置为32。我们使用Skip-gram算法训练word embedding，并在训练期间对它们进行微调。 Word embedding的大小是128。</p>
<h3 id="3-Experiment"><a href="#3-Experiment" class="headerlink" title="3. Experiment"></a>3. Experiment</h3><p>见paper原文</p>
<h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>文献[^1]提出了一个joint model，通过使用全局共享表示和不同子任务之间的堆叠来共同检测、聚类和摘要事件。 实验表明，我们提出的joint model比pipeline模型更有效。该联合神经系统优于采用离散或神经网络进行新闻事件检测和摘要的最新baseline。</p>
<h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>代码开源：<a target="_blank" rel="noopener" href="https://github.com/wangzq870305/joint_event_detection">https://github.com/wangzq870305/joint_event_detection</a></p>
<p>[^1]: Wang, Z., &amp; Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In <em>Proceedings of the 26th International Joint Conference on Artificial Intelligence</em> (pp. 4158-4164). AAAI Press.<br>[^2]: Wang, Z., Shou, L., Chen, K., Chen, G., &amp; Mehrotra, S. (2015). On summarization and timeline generation for evolutionary tweet streams. <em>IEEE Transactions on Knowledge and Data Engineering</em>, <em>27</em>(5), 1301-1315.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-03-20T07:00:00.000Z" title="3/20/2018, 8:00:00 AM">2018-03-20</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:07.533Z" title="11/3/2020, 4:26:07 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">8 minutes read (About 1138 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.3.20%5DEvent-detection/">Event detection 的几个神经网络模型</a></h1><div class="content"><h2 id="Event-detection-的几个神经网络模型"><a href="#Event-detection-的几个神经网络模型" class="headerlink" title="Event detection 的几个神经网络模型"></a>Event detection 的几个神经网络模型</h2><p><strong>摘要：</strong> 根据ace的定义，事件被分为 trigger word 和 attributes，因此 event detection 也可以被认为是 trigger word detection。目前基于神经网络的方法的思路基本大同小异，本文挑选并阐述3篇paper的主要内容，并比较其特点。</p>
<h3 id="1-Dual-CNN"><a href="#1-Dual-CNN" class="headerlink" title="1. Dual CNN"></a>1. Dual CNN</h3><p>这篇[^1]主要是对通常的CNN的改进，增加了一层语义层用以感知上下文信息。</p>
<p>整个pipline可以总结为如下图：</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-221054%402x.png" alt="WX20180320-221054@2x"></p>
<ol>
<li>Text Processing: 数据清洗、分词等，便于后续处理；</li>
<li>Word Vector Initialisation: 初始化词向量，包括加载 pre-trained word embedding 等；</li>
<li>Concept Extraction: 与2.并行运行，这里利用外部工具实现实体的语意概念；</li>
<li>Concept Vector Initialisation: 将实体和实体相关的概念向量化；</li>
<li>Dual-CNN Training: 这一步利用我们提出的 Dual-CNN 训练；</li>
</ol>
<h4 id="Dual-CNN"><a href="#Dual-CNN" class="headerlink" title="Dual-CNN"></a>Dual-CNN</h4><p>我们知道CNN可以用来作为分类器，因此也可以被构造为一个事件检测模型，并能够分出类别。在这个模型中，我们增加一层语意层。一般从正常逻辑出发，我们可以增加一个channel来存放entity related embedding，就像我们图像的多个channel一样；但是这要求实体和原来的句子完全对齐，因此作者用两个CNN并行训练。</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224531%402x.png" alt="WX20180320-224531@2x"></p>
<p>事实上，这篇文章提出的embedding方法并不能跟原来的句子对齐。我们有一个句子 $D = $ ‘Obama attends vigil for Boston Marathon bombing victims.’；分词为 $T_w = $ [‘obama’, ‘attends’, ‘vigil’, ‘for’, ‘boston’, ‘marathon’, ‘bombing’, ‘victims’]；而语意分词将分为$T_s = $ [‘obama’, ‘politician’, ‘none’, ‘none’, ‘none’, ‘boston’, ‘location’, ‘none’, ‘none’, ‘none’]。我们可以看到语意分词采用了 entity-type 的方法，这导致了$T_w$和$T_s$长度并不相同 ，因此无法把他们并为两个channels。（其实这里我感觉可以把entity和type分别embedding之后级联起来，这样就能够对齐了，不知道这样可不可行？）</p>
<p>最后的结果显示，它能够较好地检测和识别事件类别，对比CNN有一些提升；但是对于颗粒度较细的事件反而有所下降。但是这些结果都好于传统的机器学习方法。</p>
<h3 id="2-convolution-BiLSTM"><a href="#2-convolution-BiLSTM" class="headerlink" title="2. convolution BiLSTM"></a>2. convolution BiLSTM</h3><p>文献[^2]其实之前就看过，详细写在2018.1.29的笔记里，这里再简单提一下，模型如下。</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224725%402x.png" alt="WX20180320-224725@2x"></p>
<p>简单来说，就是在通常的biLSTM模型下，并行地训练一个CNN模型，其输出和biLSTM的输出的向量进行连接，Output layer接Softmax输出标签的概率分布。创新点在于引入了CNN捕获局部语意信息，也获得不错的效果。本模型也适用于其他sequence labeling任务。</p>
<h3 id="3-BiLSTM-CNN"><a href="#3-BiLSTM-CNN" class="headerlink" title="3. BiLSTM + CNN"></a>3. BiLSTM + CNN</h3><p>这篇文章[^3]和文章[^2]的思路也很相似，主要的想法是BiLSTM对文本的语意进行编码，后面串联CNN来捕获局部结构信息。</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-225956%402x.png" alt="WX20180320-225956@2x"></p>
<h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>如果认为是一个文本分类任务，CNN能够很好的完成任务，而且由于它本身的特性训练速度比较快；另一方面可以用RNN来做数据标注任务，仅标注触发词；此外可以利用好biLSTM能够处理长距离前后文信息、CNN着重局部信息的关系等特性，构造不同的变体，对于实际任务可能也有不错的效果。</p>
<p>从结果上来看实际上各种变体效果差距并不大，对特定种类特定体裁可能会有较大的差别；可能更重要的可能是如何构造特征（除了word embedding 之外，还可以考虑entity embedding？entity type？还有词性的embedding？）</p>
<h2 id="Bibliographies"><a href="#Bibliographies" class="headerlink" title="Bibliographies"></a>Bibliographies</h2><p>[^1]: Burel, G., Saif, H., Fernandez, M., &amp; Alani, H. (2017). On semantics and deep learning for event detection in crisis situations.</p>
<p>[^2]: Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.<br>[^3]: Feng, X., Huang, L., Tang, D., Ji, H., Qin, B., &amp; Liu, T. (2016). A language-independent neural network for event detection. In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em> (Vol. 2, pp. 66-71).</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-03-10T07:00:00.000Z" title="3/10/2018, 8:00:00 AM">2018-03-10</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:11.105Z" title="11/3/2020, 4:26:11 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">12 minutes read (About 1814 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.3.10%5DSeveral-models-for-kenowledge-graoh-representing-and-completing/">Several models for knowledge graph representing and completing 几个知识图谱模型</a></h1><div class="content"><h1 id="2018-3-10"><a href="#2018-3-10" class="headerlink" title="2018.3.10"></a>2018.3.10</h1><h2 id="Several-models-for-knowledge-graph-representing-and-completing"><a href="#Several-models-for-knowledge-graph-representing-and-completing" class="headerlink" title="Several models for knowledge graph representing and completing"></a>Several models for knowledge graph representing and completing</h2><p><strong>摘要</strong>：上次看到的ConMask在开放领域knowledge graph completion有着不错的表现，这次我们不考虑开放领域，介绍几个经典的模型。</p>
<h3 id="1-Series-of-Trans"><a href="#1-Series-of-Trans" class="headerlink" title="1. Series of Trans"></a>1. Series of Trans</h3><h4 id="1-1-TransE"><a href="#1-1-TransE" class="headerlink" title="1.1 TransE"></a>1.1 TransE</h4><p>TransE [^1] 可能是最为常用也最为基础的方法是一种基于强化学习(RL)的模型. 它有一个简单实用的假设：<br>$$<br>h+r = t<br>$$<br>其中h是head entity的向量，t是tail entity的向量，r是关系向量。</p>
<p>TransE定义了loss function：<br>$$<br>\mathcal{L(T)} = \sum_{&lt;h,r,t&gt;\in T} [\gamma + E(&lt;h,r,t&gt;) - E(&lt;h’,r’,t’&gt;)]<em>+<br>$$<br>其中 $T$ 代表一个三元组的集合；$E(&lt;h,r,t&gt;) = ||h+r-t||</em>{L_n}$是energy function；$&lt;h,r,t&gt;$是G中的一个三元组；$&lt;h’,r’,t’&gt;$代表一个不存在于 $T$ 的三元组，通过随机替换一部分$&lt;h,r,t&gt;$来得到；$\gamma$ 表示边际距离</p>
<p>算法的核心是令正例的 h+r-t 趋近于 0，而负例的 h+r-t 趋近于无穷大。整个 TransE 模型的训练过程比较简单，首先对头尾节点以及关系进行初始化，然后每对一个正例取一个负例样本，然后利用 hinge loss function 尽可能使正例和负例分开，最后采用 SGD(Stochastic Gradient Descent) 方法更新参数。</p>
<p>由TransE又衍生出了许多模型。</p>
<h4 id="1-2-TransH"><a href="#1-2-TransH" class="headerlink" title="1.2 TransH"></a>1.2 TransH</h4><p>虽然 TransE 模型训练速度快、易于实现，但是它不能够解决多对一和一对多关系的问题。为了解决这个问题并仍然维持较低的复杂度，TransH [^2] 不再严格要求 h+r-l=0，而是只需要保证头结点和尾节点在关系平面上的投影在一条直线上，因此能够得到图中头结点向量正确的表示。</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202332.jpg">

<p>论文另一个亮点是设计了一种负类抽样的方法，即一对多的时候，给head更多的抽样概率， 同样的多对一的时候，给tail更多抽样概率。</p>
<h4 id="1-3-TransR-CTrans"><a href="#1-3-TransR-CTrans" class="headerlink" title="1.3 TransR/CTrans"></a>1.3 TransR/CTrans</h4><p>TransE和TransH都假设了实体和关系都在同一个空间内，但由于实体和关系本身的不同，简单地认为它们embedding在同一个空间内是不充分的。因此，TransR[^3]对于<strong>每一个r</strong>，我们设置mapping矩阵$M_r$，使得<br>$$<br>h_{\perp} + r \simeq t_{\perp} \quad \text{where } h_{\perp} = M_{r}\cdot h, t_{\perp} = M_{r} \cdot t<br>$$<br>后面的方法就和TransE较为类似了。</p>
<h4 id="1-4-TransD"><a href="#1-4-TransD" class="headerlink" title="1.4 TransD"></a>1.4 TransD</h4><p>实际上TransD[^4]是对TransR/CTrans的改进。TransR有以下缺点：</p>
<ul>
<li>对于每个r，所有的实体都使用同一个mapping矩阵$M_{r}$，但是实际上对应于一个r的实体有不同的种类、特征，这么做会有一些问题；</li>
<li>mapping是entity和relation之间的交互过程，mapping矩阵仅由关系决定是不合理的；</li>
<li>矩阵与向量的运算的计算比较复杂，如果在一个Knowledge graph里有较多的relation，那么就会有大量的参数，以及较高的复杂度，因此导致计算量过大，无法应用到大规模knowledge graph。</li>
</ul>
<p>对于任意一个entity或relation，TransD定义两个向量，第一个表示entity或relation的含义，另一个用于把entity投影到relation空间（或者说用于构造mapping矩阵）。因此对于每个entity-relation pair，都有一个动态生成的唯一的mapping矩阵。此外，上述过程没有用到矩阵向量运算，而用向量的运算代替了。</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202326.jpg">

<p>TransD大大降低计算复杂度，但仍然保持不错的效果。</p>
<h4 id="1-5-TransA"><a href="#1-5-TransA" class="headerlink" title="1.5 TransA"></a>1.5 TransA</h4><p>前面的模型都是基于欧式距离计算，也就是认为每一维的重要性是相同的。但实际上，有一些维度能较好的区分不同的entity和relation，但也有许多不包含什么有效信息，因此甚至可以被认为是噪音，因此不同维度的重要性显然是不同的。</p>
<p>TransA[^5] 模型通过引入加权矩阵，赋给每一维度权重。</p>
<p>结果如下图，欧式距离每一维都是同等重要的，体现为圆形；而TransA体现为椭圆形，显然更符合数据的分布。</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202330.jpg">



<h3 id="2-ProjE"><a href="#2-ProjE" class="headerlink" title="2. ProjE"></a>2. ProjE</h3><p>ProjE[^6]的作者就是Open-World Knowledge Graph Completion的作者，两篇文章分别被AAAI2017和AAAI2018收录，可以认为是KGC任务的 state-of-the-art。这里提一下ProjE的思路。</p>
<h4 id="2-1-Model-Architecture"><a href="#2-1-Model-Architecture" class="headerlink" title="2.1 Model Architecture"></a>2.1 Model Architecture</h4><p>给出&lt;h, r, ?&gt;，已知h、r，要求预测 ? 。通常的做法就是把所有的候选entity都拿来打分，得分最高的就是预测的结果。为了得到这一系列打分，首先我们通过一个运算符来合并h和r，得到一个向量，然后我们把所有候选entity投影到这个向量上，随后运算得到分数。</p>
<p>现有的模型（包括上面提到的一系列trans）往往通过mapping矩阵来合并entity和relation，这里作者也是这么做，但是他认为目前还不需要考虑各个维度之间的相互作用，因此这个mapping矩阵应该是一个对角矩阵。所以这个合并操作可以被定义为：<br>$$<br>e \oplus r = D_e e + D_r r + b_c<br>$$<br>其中$D_e$和$D_r$就是两个对角矩阵。</p>
<p>由此，我们可以定义embedding映射函数：<br>$$<br>h(e, r) = g(W^c f(e \oplus r) + b_r )<br>$$<br>其中f和g是激活函数(activation function)，我们在后面定义；$W^c$是候选entity构成的矩阵。因此h就是对所有候选entity的打分矩阵。</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202328.jpg">

<p>上图是ProjE的结构，包括两部分神经网络层，其中上半部分是合并操作，即$e \oplus r$；下半部分是映射函数，或者说打分函数，即$h(e,r)$。</p>
<h4 id="2-2-Loss-function"><a href="#2-2-Loss-function" class="headerlink" title="2.2 Loss function"></a>2.2 Loss function</h4><p>我们这里分析方便只看pointwise loss function：<br>$$<br>\mathcal{L}(e, r, y) = - \sum_{i\in{i|y_i=1} } {log(h(e,r)<em>i)} - \sum</em>{m} {\mathbb{E}_{j \sim P_y} log(h(e,r)_j)}<br>$$<br>其中$y$是一个布尔向量，1为正例，0为反例；m个反例。pointwise ProjE 可以被看作是多类分类问题，所以我们选取 f 和 g 分别为 sigmoid 和 tanh 函数。</p>
<p>代码实现 <a target="_blank" rel="noopener" href="https://github.com/bxshi/ProjE">https://github.com/bxshi/ProjE</a></p>
<h2 id="Bibliographies"><a href="#Bibliographies" class="headerlink" title="Bibliographies"></a>Bibliographies</h2><p>笔记参考：</p>
<p><a target="_blank" rel="noopener" href="http://www.infosec-wiki.com/?p=175755">http://www.infosec-wiki.com/?p=175755</a></p>
<p><a target="_blank" rel="noopener" href="https://www.jiqizhixin.com/articles/2017-11-03-5">https://www.jiqizhixin.com/articles/2017-11-03-5</a></p>
<p>[^1]: Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).<br>[^2]: Wang, Z., Zhang, J., Feng, J., &amp; Chen, Z. (2014, July). Knowledge Graph Embedding by Translating on Hyperplanes. In <em>AAAI</em> (Vol. 14, pp. 1112-1119).</p>
<p>[^3]: Lin, Y., Liu, Z., Sun, M., Liu, Y., &amp; Zhu, X. (2015, January). Learning entity and relation embeddings for knowledge graph completion. In <em>AAAI</em> (Vol. 15, pp. 2181-2187).<br>[^4]: Ji, G., He, S., Xu, L., Liu, K., &amp; Zhao, J. (2015). Knowledge graph embedding via dynamic mapping matrix. In <em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em> (Vol. 1, pp. 687-696).<br>[^5]: Xiao, H., Huang, M., Hao, Y., &amp; Zhu, X. (2015). TransA: An adaptive approach for knowledge graph embedding. <em>arXiv preprint arXiv:1509.05490</em>.<br>[^6]: Shi, B., &amp; Weninger, T. (2017, February). ProjE: Embedding Projection for Knowledge Graph Completion. In <em>AAAI</em> (Vol. 17, pp. 1236-1242).</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-02-26T07:00:00.000Z" title="2/26/2018, 8:00:00 AM">2018-02-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:12.121Z" title="11/3/2020, 4:26:12 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">18 minutes read (About 2761 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.2.26%5DOpen-World-Knowledge-Graph-Completion/">Open-World Knowledge Graph Completion 笔记</a></h1><div class="content"><h2 id="Open-World-Knowledge-Graph-Completion"><a href="#Open-World-Knowledge-Graph-Completion" class="headerlink" title="Open-World Knowledge Graph Completion"></a>Open-World Knowledge Graph Completion</h2><p><strong>摘要</strong>：[1]文首先讨论了Closed-World KGC，它无法处理从 KG 外部加入的新实体，并严重依赖已有KG连接的，不能对弱连接有好的预测。为此定义了 Open-World KGC，可以接收 新的实体并链接到 KG；并依此提出了ConMask模型，在给定关系和实体名、实体描述的前提下，利用attention机制通过关系定位实体描述中最相关的词，再以这些词和实体得到要链接的实体。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>知识图谱（KG）是一种信息网络，它用三元组 $(h,r,t)$ 来表示知识（h: head entity, t: tail entity, r: relation），目前比较出名的KG有 DBPedia，ConceptNet 等，目前的大多数KG都有噪音且不完整，比如基于Wikipedia的DBPedia有460万个实体，但其中一半实体拥有少于5个的关系。</p>
<p>这说明了大部分的知识图谱仍然是非常不完善的，我们必须从一开始就要考虑系统的修改、补充完善的可能性。这项任务被定义为Knowledge Graph Completion (KGC)。</p>
<h4 id="Closed-World-KGC"><a href="#Closed-World-KGC" class="headerlink" title="Closed-World KGC"></a>Closed-World KGC</h4><p>给定一个不完整的KG $G=(E,R,T)$ 其中 $E,R,T$ 分别表示实体集，关系集以及三元组集，Closed-World KGC的任务就是通过找到一系列丢失的三元组 $ T’ = { \langle h,r,t \rangle|h \in E, r \in R, t \in E, \langle h,r,t \rangle \notin T }$ 来补充现有的 $G$.</p>
<p>一个很重要的地方在于，Closed-World KGC 假定了新的实体、关系都被原有的 $G$ 包含，对于不在 $G$ 中的实体则一筹莫展。</p>
<p>目前的Closed-World KGC方法很多往往使用TranE或者低维特征表示模型，前者的核心思想就是 $h+r=t$ ，后者则指 Embedding 等。</p>
<p>该方法仅对固定的或者缓慢更新的KG有效，对于快速变更的KG则效果一般。</p>
<h4 id="Open-World-KGC"><a href="#Open-World-KGC" class="headerlink" title="Open-World KGC"></a>Open-World KGC</h4><p>给定一个不完整的KG $G=(E,R,T)$ 其中 $E,R,T$ 分别表示实体集，关系集以及三元组集，Open-World KGC 的任务就是找到 $G$ 中没有的三元组集，$T’ ={&lt;h,r,t&gt;|h\in E^i,r\in R, t\in E^i,&lt;h,r,t&gt;\notin T}$ 其中 $E^i$ 是G的实体超集。</p>
<p>Closed-World方法就是根据知识图谱的拓扑结构更新一个随机的向量作为实体和关系的embedding，但对于不在网络中的实体，这个方法就失效了，这个时候就需要用别的特征来代替这个用网络拓扑结构得到的特征。</p>
<p>一般直觉就是用实体的描述（entity description），根据实体的描述来得到特征，但从非结构化文本中学习向量表示比在网络的拓扑结构中要难得多，原因如下：</p>
<ol>
<li>在Closed-world KGC模型中，每个实体都有一个embedding (从与它相连的实体上学得的)，但Open-World KGC模型则需要从实体描述的word embedding中得到entity embedding。而无论实体之间的联系情况是什么，word embedding的更新都会导致有相同词的entities的更新。</li>
<li>因为使用了非结构化文本，所以Open-World KGC模型可能会引入噪音或者冗余信息。</li>
</ol>
<h3 id="2-Closed-World-KGC"><a href="#2-Closed-World-KGC" class="headerlink" title="2. Closed-World KGC"></a>2. Closed-World KGC</h3><p>在 Closed-World KGC 中，最为常用也最为基础的方法是一种给予强化学习(RL)的模型，被称为TransE [2]. 它有一个简单实用的假设：<br>$$<br>h+r = t<br>$$<br>其中h是head entity的向量，t是tail entity的向量，r是关系向量。</p>
<p>TransE定义了loss function：<br>$$<br>\mathcal{L(T)} = \sum_{&lt;h,r,t&gt;\in T} [\gamma + E(\langle h,r,t \rangle) - E(\langle h’,r’,t’ \rangle)]<em>+<br>$$<br>其中 $T$ 代表一个三元组的集合；$E(\langle h,r,t \rangle) = ||h+r-t||</em>{L_n}$是energy function；$\langle h,r,t \rangle$是G中的一个三元组；$h’,\langle r’,t’ \rangle$代表一个不存在于 $T$ 的三元组，通过随机替换一部分$\langle h,r,t \rangle$来得到。</p>
<p>这里还略去了很多TransE的变体等其他模型，但它们都是基于Closed-World KGC来做的。</p>
<h3 id="3-ConMask-for-Open-World-KGC"><a href="#3-ConMask-for-Open-World-KGC" class="headerlink" title="3. ConMask for Open-World KGC"></a>3. ConMask for Open-World KGC</h3><p>首先通过一个例子来说明：</p>
<p><strong>任务：</strong>填补三元组 $\langle \text{Ameen Sayani, residence, ?}\rangle$，其中KG中并没有Ameen Sayani这个实体。</p>
<p><strong>描述：</strong>“… <strong>Ameen Sayani</strong> was introduced to All India Radio, <strong>Bombay</strong>, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years …” ，</p>
<p><strong>目标预测实体：</strong>Bombay (or Mumbai)</p>
<p>为了找到Ameen Sayani的住址，在处理这个任务的过程中，我们不会从头看到尾，而是找到相关的关键词比如家庭或工作相关的词。这里，我们发现Ameen Sayani的工作地点All India Radio在Bombay，因此我们推测Ameen Sayani也住在Bombay（Bombay就是现在的Mumbai）。</p>
<p>这个过程也可以被归纳为：</p>
<ol>
<li>定位与该任务相关的信息。</li>
<li>根据上下文和相关文本推断。</li>
<li>根据相关文本推出正确目标实体。</li>
</ol>
<p>仿照这个过程，ConMask的工作方式被设计为：</p>
<ol>
<li><strong>Relationship-dependent content masking</strong> – 标记那些与任务相关的词语。</li>
<li><strong>Target fusion</strong> – 从相关文本中抽取目标实体的embedding。</li>
<li><strong>Target entity resolution</strong> – 通过计算KG中的候选目标实体，2中抽取出的实体embedding以及其它文本特征之间的相似度来选定目标实体。</li>
</ol>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202310.jpg" width="60%">

<p>ConMask模型总体结构如上，ConMask通过选择与给定关系相关的词来避免引入不相关的和有噪音的词。对于相关的文本，ConMask通过全连接卷积神经网络（FCN）来提取word-embedding。最后它将提取的embedding于KG中存在的实体进行比较，从而获得一系列目标实体。</p>
<h4 id="3-1-Relationship-dependent-content-masking"><a href="#3-1-Relationship-dependent-content-masking" class="headerlink" title="3.1 Relationship-dependent content masking"></a>3.1 Relationship-dependent content masking</h4><p>ConMask根据给定的关系预处理输入文本，来选择一些相关的小片段，从而屏蔽掉无关文本。content-masking这一灵感来源于基于attention机制的RNN网络[3]，关于attention之前的笔记也有学习过。</p>
<p>基于相似度得到选择最相关的词，具体公式如下：<br>$$<br>\tau(\phi(e), \psi(r)) = W_{\phi(e)} \circ f_w(W_{\phi(e)}, W_{\psi(r)})<br>$$<br>其中 $e$ 是一个实体，$r$ 是某个关系, $\phi$ 是description function并返回一个向量用于表示对一个实体或关系的描述，$\psi$ 是name mapping function并返回一个向量用于表示一个实体或关系的名字， $ W_{\phi{(e)}} \in \mathbb{R}^{|\phi(r)|\times k} $ 是一个描述矩阵每一行表示一个k维的描述中的word-embedding， $W_{\phi{(e)}} \in \mathbb{R}^{|\phi(r)|\times k} $ 是一个名字矩阵每一行表示一个k维的实体名字word-embedding，$\circ$ 是row-wise product，$f_w$ 用于计算的每一行的屏蔽比重。</p>
<p>作者给了一个简单的$f_w$ ，Maximal Word-Relationship Weights(MWRW)，就是计算实体描述中每个词向量与关系名称的每个词向量的最大cos相似度:<br>$$<br>f_w^{MWRW}(W_{\phi(e)}, W_{\psi(r)})<em>{[i]} =  max_j(\frac{\sum_m^k{W</em>{\phi(e)[i,m]} W_{\psi(r)[j,m]}}}{\sqrt{\sum_m^k{W^2_{\phi(e)[i,m]}}}\sqrt{\sum_m^k{W^2_{\psi(e)[j,m]}}}})<br>$$<br>这个公式会给与给定关系无关的词更小的权重，与关系语义接近的词更大的权重，但权重最高的词一般不是目标实体，如下图所示，给定关系spouse，得到最大权重的是married，虽然married与spouse在语义上接近，但它并不是目标实体，因此作者称这种有着最大MWRW权重的词为指示词（indicator word），因为正确的词一般就在该词附近，在下图例子中可以发现目标实体barack obama就在married后面。</p>
<p>为了给目标实体word正确的权重，作者改进了这个公式，具体公式如下，这个公式就是每个词的权重不会小于之前 $k_m$ 称为 Maximal Context-Relationship Weights (MCRW)：<br>$$<br>f_w^{MCRW}(W_{\phi(e)}, W_{\psi(r)})<em>{[i]} =  max(f_w^{MWRW}(W</em>{\phi(e)}, W_{\psi(r)})_{[i-k_m:i]})<br>$$<br><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202313.jpg"></p>
<h4 id="3-2-Target-Fusion"><a href="#3-2-Target-Fusion" class="headerlink" title="3.2 Target Fusion"></a>3.2 Target Fusion</h4><p>这一步骤用于输出基于词的实体embedding，这个过程记为$\xi$，使用Conetent Masking $\tau$ 的输出。它使用全连接卷积网络，其结构如下：</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202312.jpg">

<p><strong>Semantic Averaging</strong></p>
<p>我们可以对所有实体进行embedding，但是这会产生大量的参数，使计算变得非常复杂。事实上，因为Target fusion函数用于抽取，所以对不需要抽取的实体名字使用target fusion就会显得很奇怪也很没有必要。</p>
<p>这里作者提出了一个简单的语义平均法来计算这些实体的embedding：$\eta(W) = \frac{1}{k_l}\sum_i^{k_i}W_i$</p>
<h4 id="3-3-Loss-function"><a href="#3-3-Loss-function" class="headerlink" title="3.3 Loss function"></a>3.3 Loss function</h4><p>为了加速训练，我们参考 list-wise ranking loss function (Shi and Weninger 2017)，并设计 partial list-wise ranking loss function，拥有正负目标采样。正样本就是训练集的标注内容，记为$E^+$；负样本就是替换正样本的head entity或tail entity所得到的，记为$E^-$ 。<br>$$<br>\mathcal{L}(h, r, t) =  \begin{cases}<br>\sum_{h_+\in E^+}{-\frac{log(S(h_+,r,t,E^+\cup E^-))}{|E^+|}}, &amp; \text{if }p_c &gt; 0.5; \<br>\sum_{h_+\in E^+}{-\frac{log(S(h,r,t_+,E^+\cup E^-))}{|E^+|}}, &amp; \text{if }p_c \le 0.5; .<br>\end{cases}<br>$$<br>$p_c$ 服从$[0,1]$的均匀分布，大于0.5时，把输入实体作为tail entity，小于0.5的时候就是作为head entity，表示替换head entity和tail entity的概率各为50%。另有$S$, 即 softmax normalized output of ConMask：<br>$$<br>S(h,r,t,E^+) = \begin{cases}<br>\sum_{e \in E^\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} &amp; \text{if } p_c &gt; 0.5 \<br>\sum_{e \in E^\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} &amp; \text{if } p_c \le 0.5 \<br>\end{cases}<br>$$</p>
<h3 id="4-Results"><a href="#4-Results" class="headerlink" title="4. Results"></a>4. Results</h3><p>从结果上看，对比其他模型，在开放领域，ConMask获得了最佳的效果；在Closed-World中，尽管ConMask不是为此设计的，但是对比TransE和TransR依然不逊色，结果相仿。</p>
<p>目前而言，ConMask模型只能预测在实体描述中表达的关系，将来还应考虑扩展它，使其能够发现新的或隐含的关系。</p>
<h2 id="Bibliographies"><a href="#Bibliographies" class="headerlink" title="Bibliographies"></a>Bibliographies</h2><p>笔记参考：<a target="_blank" rel="noopener" href="https://zhuanlan.zhihu.com/p/33026043%EF%BC%8Chttp://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178">https://zhuanlan.zhihu.com/p/33026043，http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178</a></p>
<p>代码实现：<a target="_blank" rel="noopener" href="https://github.com/bxshi/ConMask">https://github.com/bxshi/ConMask</a></p>
<p>[1] Shi, Baoxu, and Tim Weninger. “Open-World Knowledge Graph Completion.” <em>arXiv preprint arXiv:1711.03438</em> (2017).</p>
<p>[2] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).</p>
<p>[3] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., &amp; Bengio, Y. (2015). Attention-based models for speech recognition. In <em>Advances in neural information processing systems</em> (pp. 577-585).</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-02-05T07:00:00.000Z" title="2/5/2018, 8:00:00 AM">2018-02-05</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:11.654Z" title="11/3/2020, 4:26:11 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">13 minutes read (About 1914 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.2.5%5DNested-LSTMs/">Nested LSTMs 笔记</a></h1><div class="content"><h2 id="Nested-LSTMs"><a href="#Nested-LSTMs" class="headerlink" title="Nested LSTMs"></a>Nested LSTMs</h2><p><strong>摘要</strong>：最近，一种新的 Nested LSTMs 网络被提出。在通常的LSTM网络中，我们通过将LSTM单元堆叠，从而形成深度RNN网络，提高其效果；Nested LSTM则通过嵌套而不是堆栈来增添LSTM的深度。在NLSTM中，记忆单元的值是由LSTM单元计算的，其中，LSTM单元具有自身内在的记忆单元。具体而言，NLSTM记忆单元并不是按照等式：$c_t^{outer} = f_t \odot c_{t-1} + i_t \odot g_t$ 对（外部）记忆单元的值进行计算，而是使用级联：$(f_t \odot c_{t-1}, i_t \odot g_t)$ 将其作为内部LSTM（或NLSTM）记忆单元的输入，并设定 $c_t^{outer} = h_t^{inner}$。在访问内部记忆时，Nested LSTM 相比传统的堆栈 LSTM 有更高的自由度，从而能处理更长时间规模的内部记忆；实验也表明，在参数数量相似的情况下，NLSTM 在多种任务上都超越了堆栈 LSTM。作者认为Nested LSTM 有潜力直接取代堆栈 LSTM。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>学习长期的依赖关系是当前人工智能领域中，尤其是在nlp领域，机器学习方法的关键性挑战。基于循环神经网络的体系结构已经在使得机器能够模仿这种能力方面取得了显著进展。</p>
<h4 id="single-layer-LSTM"><a href="#single-layer-LSTM" class="headerlink" title="single-layer LSTM"></a>single-layer LSTM</h4><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202251.jpg" width="90%">

<p>RNN的输入是以当前的状态为依据，适合学习时间上的抽象特征。在实践中，许多专家已经证明，更为复杂的体系结构是解决许多任务的关键。其中一个原因是梯度消失问题（Hochreiter于1991年、Bengio等人于1994年提出），它使得简单的RNN难以学习长期依赖关系。Hochreiter和Schmidhuber于1997年提出了LSTM，包含能够改善梯度消失问题的记忆机制。单层LSTM如上图，图中的三个单元实际上是同一个单元，它循环地将内部的参数传递给自己。</p>
<h4 id="Stacked-LSTMs"><a href="#Stacked-LSTMs" class="headerlink" title="Stacked LSTMs"></a>Stacked LSTMs</h4><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202254.jpg" width="60%">

<p>堆栈 LSTM 架构使用一系列 LSTM 一层层地堆叠在一起来处理数据，一层的输出成为下一层的输入。上图为一个两层的LSTM网络。</p>
<p>引入多层的结构，即将多个LSTM单元堆叠，每一层的输出成为下一层的输入。 每层处理我们希望解决的任务的一部分，并将其传递给下一层。额外的隐藏层可以添加到多层感知器神经网络，使其有更深入的“理解”。 额外的隐藏层被认为重新组合了来自先前层的学习表示，并在高度抽象层次上找到新的表示。 例如，从线条到形状到对象。</p>
<h4 id="Nested-LSTMs-1"><a href="#Nested-LSTMs-1" class="headerlink" title="Nested LSTMs"></a>Nested LSTMs</h4><p>在 NLSTM 中，LSTM 的记忆单元可以访问内部记忆。相比于传统的堆栈 LSTM，这一关键特征使得该模型能实现更有效的时间层级。在 NLSTM 中，外部记忆单元可自由选择读取、编写的相关长期信息到内部单元。相比之下，在Stacked LSTM 中，高层级的激活（类似内部记忆）直接生成输出，因此必须包含所有的与当前预测相关的短期信息。换言之，Stacked LSTM 与Nested LSTM 之间的主要不同在于，NLSTM 可以选择性地访问内部记忆。这使得，即使这些事件与当前事件不相关，内部记忆也能够记住、处理更长时间规模上的事件。我们在后面一章更详细地介绍它。</p>
<h3 id="2-Model-of-Nested-LSTMs"><a href="#2-Model-of-Nested-LSTMs" class="headerlink" title="2. Model of Nested LSTMs"></a>2. Model of Nested LSTMs</h3><p>LSTM 中的输出门会编码可能与当前的时间步骤不相关，但是仍然值得记忆的信息。Nested LSTM 根据这一直观理解来创造一种记忆的时间层级。以同样的方式被gate控访问内部记忆，因此长期信息只有在情景相关的条件下才能选择性地访问。</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202253.jpg" width="80%">

<h4 id="The-architecture"><a href="#The-architecture" class="headerlink" title="The architecture"></a>The architecture</h4><p>在 LSTM 网络中，单元状态的更新公式和门控机制可以表示为以下方程式：<br>$$<br>i_t = \sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \<br>f_t = \sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \<br>c_t = f_t \odot c_{c-1} + \sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \<br>o_t = \sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \<br>h_t = o_t \odot \sigma_h(c_t)<br>$$<br>Nested LSTM 使用已学习的状态函数 $c_t = m_t(f_t\odot c_{t−1}, i_t \odot g_t)​$ 来替代 LSTM 中计算 $c_t​$ 的加运算。我们将函数的状态表示为 m 在时间 t 的内部记忆（inner memory），调用该函数以计算 $c_t​$ 和 $m_{t+1}​$。我们可以使用另一个 LSTM 单元来实现该记忆函数，就生成了 Nested LSTM。同样，该记忆函数能够由另一个 Nested LSTM 单元替换，因此就能构建任意深的嵌套网络。</p>
<p>因此，我们得到NLSTM 中记忆函数的输入和隐藏状态：<br>$$<br>\tilde{h}<em>{t-1} = f_t \odot c</em>{t-1} \<br>\tilde{x}<em>t = i_t \odot \sigma_c (x_t W</em>{xc} + h_{t-1} W_{hc} + b_c)<br>$$<br>注意如果记忆函数是加性的，那么$c_t = f_t \odot c_{c-1} + \sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) =  \tilde{h}_{t-1} + \tilde{x}_t $，整个系统将退化到经典的 LSTM。</p>
<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202250.jpg">

<p><em>LSTM、Stacked LSTM 和 Nested LSTM 的计算图形。隐藏的状态、外部记忆单元和内部记忆单元分别由h、c和d进行表示。虽然当前的隐藏状态可以直接影响下一个内部记忆单元的内容，但内部记忆只有通过外部记忆才能够影响隐藏状态。</em><br>$$<br>\widetilde{i}<em>t = \widetilde{\sigma}<em>i (\widetilde{x}<em>t \widetilde{W}</em>{xi} + \widetilde{h}</em>{t-1} \widetilde{W}</em>{hi} + \widetilde{b}_i) \<br>\widetilde{f}<em>t = \widetilde{\sigma}<em>t (\widetilde{x}<em>t \widetilde{W}</em>{xf} + \widetilde{h}</em>{t-1} \widetilde{W}</em>{hf} + \widetilde{b}_i) \<br>\widetilde{c}<em>t = \widetilde{f}<em>t \odot \widetilde{c}</em>{c-1} + \widetilde{\sigma}<em>c (\widetilde{x}<em>t \widetilde{W}</em>{xc} + \widetilde{h}</em>{t-1} \widetilde{W}</em>{hc} + \widetilde{b}<em>c) \<br>\widetilde{o_t} = \widetilde{\sigma}<em>o (\widetilde{x}<em>t \widetilde{W}</em>{xo} + \widetilde{h}</em>{t-1} \widetilde{W}</em>{ho} + \widetilde{b}_o) \<br>\widetilde{h}_t = \widetilde{o}_t \odot \widetilde{\sigma}_h(\widetilde{c}<em>t)<br>$$<br>现在，外部 LSTM 的单元状态更新方式为 $ c_t = \tilde{h}</em>{t} $ 。</p>
<h3 id="3-Experiments"><a href="#3-Experiments" class="headerlink" title="3. Experiments"></a>3. Experiments</h3><p>见附件论文[1]</p>
<h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>Nested LSTM（NLSTM）是LSTM模型的简单扩展，通过嵌套来增加深度，而不是通过堆叠。 NLSTM的内部存储器单元形成内部存储器，其仅通过外部存储器单元被其他计算元件访问，实现了时间层级的形式。</p>
<p>论文[1]的实验表明，在相似的参数设置下，Nested LSTM 在多种字符级语言建模任务中的表现都超越了Stacked LSTM和single-layer LSTM，并且和Stacked LSTM 的高层级单元相比，LSTM 的内部记忆可以学习更长期的依赖关系。</p>
<p><a target="_blank" rel="noopener" href="https://github.com/hannw/nlstm">NLSTM的Tensorflow实现</a></p>
<p><a target="_blank" rel="noopener" href="https://github.com/titu1994/Nested-LSTM">NLSTM的Keras实现</a></p>
<h2 id="Bibliographies"><a href="#Bibliographies" class="headerlink" title="Bibliographies"></a>Bibliographies</h2><p>笔记参考：<a target="_blank" rel="noopener" href="http://www.sohu.com/a/220745456_390227%EF%BC%8Chttp://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title">http://www.sohu.com/a/220745456_390227，http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title</a></p>
<p>[1] Moniz, Joel Ruben Antony, and David Krueger. “Nested LSTMs.” <em>Asian Conference on Machine Learning</em>. 2017.</p>
<p>[2] Hochreiter, Sepp, and Jürgen Schmidhuber. “Long short-term memory.” <em>Neural computation</em> 9.8 (1997): 1735-1780.</p>
</div></article></div><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2018-01-29T07:00:00.000Z" title="1/29/2018, 8:00:00 AM">2018-01-29</time></span><span class="level-item">Updated&nbsp;<time dateTime="2020-11-03T03:26:12.997Z" title="11/3/2020, 4:26:12 AM">2020-11-03</time></span><span class="level-item"><a class="link-muted" href="/categories/research/">research</a></span><span class="level-item">18 minutes read (About 2677 words)</span></div></div><h1 class="title is-3 is-size-4-mobile"><a class="link-muted" href="/posts/%5B2018.1.29%5DA-convolution%20BiLSTM-neural-network-model-for-chinese-event-extraction/">A convolution BiLSTM neural network model for chinese event extraction 笔记</a></h1><div class="content"><h2 id="A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction"><a href="#A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction" class="headerlink" title="A convolution BiLSTM neural network model for chinese event extraction"></a>A convolution BiLSTM neural network model for chinese event extraction</h2><p><strong>摘要：</strong>中文事件提取是信息抽取中的一项具有挑战性的任务，以前的方法高度依赖于复杂的特征工程和复杂的自然语言处理（NLP）工具。 在文献[1]中，提出了一种结合LSTM和CNN的卷积双向LSTM神经网络来捕获句级和词汇信息。最终的测试中达到相当不错的水平。</p>
<h3 id="1-Introduction"><a href="#1-Introduction" class="headerlink" title="1. Introduction"></a>1. Introduction</h3><p>在事件提取中，我们需要提取事件类别、参与者和其他属性（时间、地点等）。根据Automatic Content Extraction（ACE）定义的事件抽取任务，我们定义：</p>
<ul>
<li>触发词：最主要的、用于表达一个事件的词，通常是句子的谓语。</li>
<li>事件属性：实体、短语或数值。在一个事件中扮演特定作用。</li>
</ul>
<p>因此，我们把事件抽取分为两步，即<strong>触发词标注</strong>和<strong>事件属性标注</strong>。例如：</p>
<p>S1：Intel在中国<strong>成立</strong>了研究中心。</p>
<p>其中，“成立”表明该句子表达了一个商业事件；Intel、中国、研究中心则是事件的属性，属性将被标注为参与者、地点、时间等。</p>
<p>目前的 state-of-the-art [2-4] 通常很依赖于特征的选择。这些特征通常可以被划分为<strong>语义特征</strong>和<strong>结构特征</strong>。再给两个包含”成立“的例子，但它在其中并不表达一个商业事件。</p>
<p>S2：它<strong>成立</strong>于1994年，现在是一支深受欢迎的摇滚乐队。</p>
<p>S3：医院已<strong>成立</strong>救援中心。</p>
<p>从结构特征上来看，S2可以被缩写为“它是乐队”，因此“成立”在这个句子中不是一个触发词，这个句子不是一个事件。</p>
<p>从语义特征上来看，S3中的“救援中心”的语义上看，这个事件不是一个商业行为，因此“成立”不表达一个商业事件。</p>
<p>传统的方法[2, 3]通常依赖于大量的NLP工具，对于语义特征而言，有词性标注、命名实体识别等；对于结构特征而言，有依存关系分析。尽管最终效果很好，但是这需要大量的人工特征，并且需要忍受传递误差。</p>
<p>Chen et al. [5] 提出了一个用于完成事件抽取的卷积神经网络。受此激发，本文提出一个卷积双向LSTM神经网络，用来同时捕获语义特征和结构特征。我们首先使用双向LSTM将整个句子中的单词的语义编码成句子级别的特征。 然后，我们可以利用卷积神经网络来捕获突出的局部词汇特征，以便在没有任何POS标签或NER帮助的情况下进行触发词消歧。</p>
<h3 id="2-Trigger-Labeling"><a href="#2-Trigger-Labeling" class="headerlink" title="2. Trigger Labeling"></a>2. Trigger Labeling</h3><h4 id="2-1-Language-Specific-Issues"><a href="#2-1-Language-Specific-Issues" class="headerlink" title="2.1 Language Specific Issues"></a>2.1 Language Specific Issues</h4><p>由于中文的特殊性，触发词可以被分为两类：</p>
<ul>
<li>多词触发词：任何拆开后就无法被人为是触发词的，我们把它组合起来认为是触发词。例如“犯罪嫌疑人都落入法网”，其中“落入法网”被认为是触发词。</li>
<li>单词触发词：往往是谓语，但也可以是组合词中的一部分。例如“警察击毙了一名歹徒”中的“击毙”，“这是一件预谋的凶杀案”中的“凶杀”</li>
</ul>
<p>为了解决这个问题，我们将事件检测视为序列标记任务而不是分类任务。 采用BIO方案，其中标记B是事件触发词的开始，I型是在触发词内，否则标记为O。我们利用卷积双向LSTM神经网络来完成这个任务。</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202231.jpg" alt="trigger-labeling"></p>
<p>我们基于单词模型的主要架构。 （a）中的每个词wt的局部上下文特征ct（灰色矩形）由CNN计算（b）所示。 我们的卷积神经网络学习了关于中心词“落入”的本地上下文信息的表示。 这里的上下文大小是7（中心词的左右各3个词），我们使用一个大小为4的内核与两个特征映射。 （b）句子中的符号P表示填充词。</p>
<h4 id="2-2-Word-Based-Method"><a href="#2-2-Word-Based-Method" class="headerlink" title="2.2 Word-Based Method"></a>2.2 Word-Based Method</h4><p><strong>LSTM Network</strong>  在nlp任务中LSTM相对常用，特别的，双向LSTM能够联系历史和未来的信息，能够重复利用句子信息，有利于我们进行判断。因为之前的报告已经叙述过，故这里略写。</p>
<p><strong>CNN</strong>  卷积神经网络最一开始用于图像领域，近年也在nlp领域大放光彩。这里，我们采用卷积神经网络来提取句子中每个单词的局部上下文信息。</p>
<p>给定一个包含n个单词{w1, w2, … , wn}的句子和当前中心词wt，卷积运算包含一个内核，将其应用于wt周围的单词以生成特征映射。 我们可以利用不同宽度的多个内核来提取不同粒度的局部特征。 然后在每个map上执行最大汇集，以便仅记录每个特征地图的最大数量。 池的一个特性是它产生一个固定大小的输出向量，这使我们能够应用不同的大小内核。 而通过执行最大操作，我们保持最显着的信息。 最后，将固定长度的输出向量cwt作为关于中心词wt的本地上下文信息的表示。</p>
<p>在我们的实现中，滑动窗口大小为7（中心词的左右各3个词），并且我们使用不同的内核来捕获各种粒度的上下文信息。</p>
<p><strong>Output Layer</strong>  我们将BiLSTM的隐藏状态与CNN在每个时间步t提取的上下文特征cwt连接起来。 然后[ht; cwt]被送入softmax层以产生wt的每个标记的对数概率。<br>然而，基于单词的方法仍然不能解决内部词触发引起的一致性问题，即无法识别长词内部的触发词。</p>
<h4 id="2-3-Character-Based-Method"><a href="#2-3-Character-Based-Method" class="headerlink" title="2.3 Character-Based Method"></a>2.3 Character-Based Method</h4><p>为了解决一致性问题，我们可以采用Character-embedding，唯一的区别就在input layer。</p>
<p><img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202234.jpg" alt="character"></p>
<h3 id="3-Argument-Labeling"><a href="#3-Argument-Labeling" class="headerlink" title="3. Argument Labeling"></a>3. Argument Labeling</h3><p>上面介绍的触发词标注模型依然可以被沿用，我们将介绍用于触发词标注和事件属性标注的模型之间的主要区别。</p>
<h4 id="3-1-Input-Layer"><a href="#3-1-Input-Layer" class="headerlink" title="3.1 Input Layer"></a>3.1 Input Layer</h4><p>作为一个pipeline系统，除了word embeddings之外，还可以使用从上面触发词标记任务中提取的信息。 因此，我们提出了另外四种类型的特征embedding来形成BiLSTM和CNN的输入层。</p>
<ul>
<li>触发位置特征：一个单词是否属于触发词的一部分</li>
<li>触发类型特征：单词触发类型，NONE类型对于非触发词</li>
<li>实体位置特征：一个单词是否属于实体的一部分</li>
<li>实体类型特征：单词的实体类型，NONE类型对于非实体。 ACE数据集提供了实体识别的结果，无需使用外部NLP工具。（<em>思考</em>：若数据集不提供实体信息，两种解决方法：1. 不embed实体特征；2. 借助外部工具）<br>然后，我们通过查表将这些特征转换成矢量，并将它们与原始单词嵌入级联，作为BiLSTM和CNN的最终输入层。</li>
</ul>
<h4 id="3-2-Output-Layer"><a href="#3-2-Output-Layer" class="headerlink" title="3.2 Output Layer"></a>3.2 Output Layer</h4><p>值得一提的是，事件属性标注不再是一个序列标注任务，而是一个分类任务。 ACE数据集提供了实体识别的结果，它保证了事件属性只能出现在这些实体。 因此，我们只需要预测标记实体的角色，而不是整个句子中的每个单词。 例如，S4中有三个触发器（粗体字）和三个实体（斜体字），它们共同组成九对要分类的触发词和事件属性候选。</p>
<p>S7：六起<strong>谋杀案</strong>发生在<em>法国</em>，包括<em>Bob</em>的<strong>暗杀</strong>和<em>Joe</em>的<strong>杀害</strong>。</p>
<p>我们修改CNN和BiLSTM网络的输出层以适应新的任务。</p>
<p>对于BiLSTM，我们仍然试图利用其记忆长序列的能力，所以我们把最后一个单词hN的隐藏状态视为句子信息。</p>
<p>对于CNN，我们把整个句子的所有单词作为上下文，而不是每个中心单词的浅窗口。 最后，我们将来自两个网络的输出向量的串联输入到softmax分类器中，就像处理之前的触发词标注任务一样。</p>
<h3 id="4-Conclusion"><a href="#4-Conclusion" class="headerlink" title="4. Conclusion"></a>4. Conclusion</h3><p>论文[1]主要提出了卷积双向LSTM神经网络，用以完成中文事件抽取任务，在ACE 2005数据集上获得了不错的结果。我在暑假时，将事件抽取认为为一个序列标注任务，使用BiLSTM+CRF；相比而言，论文[1]的模型考虑更全面，并充分利用已知的实体信息。不过对于现实问题而言，标注实体信息的成本也很高，故在没有实体标注的情况下保持性能也是一个难点。</p>
<h2 id="Bibliography"><a href="#Bibliography" class="headerlink" title="Bibliography"></a>Bibliography</h2><p>[1] Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.</p>
<p>[2] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529–544. Citeseer (2012)</p>
<p>[3] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167–176 (2015)</p>
<p>[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 73–82 (2013)</p>
<p>[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167–176 (2015)</p>
</div></article></div><nav class="pagination" role="navigation" aria-label="pagination"><div class="pagination-previous is-invisible is-hidden-mobile"><a href="/categories/research/page/0/">Previous</a></div><div class="pagination-next"><a href="/categories/research/page/2/">Next</a></div><ul class="pagination-list is-hidden-mobile"><li><a class="pagination-link is-current" href="/categories/research/">1</a></li><li><a class="pagination-link" href="/categories/research/page/2/">2</a></li></ul></nav></div><div class="column column-left is-4-tablet is-4-desktop is-4-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.png" alt="Jue Wang"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jue Wang</p><p class="is-size-6 is-block">Ph.D Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Posts</p><a href="/archives"><p class="title">16</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Category</p><a href="/categories"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">26</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/lorrinWWW" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Scholar" href="https://scholar.google.com/citations?user=PykI8xcAAAAJ&amp;hl=en"><i class="ai ai-google-scholar"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/lorrinWWW/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/JueWANG26088228"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/favicon.svg" alt="Jue&#039;s Blog" height="28"></a><p class="is-size-7"><span>&copy; 2022 Jue Wang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div><div id="divmap" style="visibility:hidden; position: absolute; top: 0px"><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&amp;w=2&amp;t=n&amp;d=I_238wU69nrKH0DIm55b1z-y84aVsLuSzQSglFoJ1ww&amp;co=ffffff&amp;ct=ffffff&amp;cmo=ffffff&amp;cmn=ffffff"></script></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>