---
title: A Neural Model for Joint Event Detection and Summarization 阅读笔记
date: 2018-04-04 08:00:00
categories: [research]
tags: [event-detection, summarization]
hidden: true
---

## A Neural Model for Joint Event Detection and Summarization 阅读笔记

**摘要**：Twitter事件检测旨在识别推文流中的first stories。一般认为由两个子任务组成。首先，过滤掉普通的或不相关的推文。其次，推文会被自动分类到event cluster中。传统上，尽管这两个任务之间存在相互依赖关系，它们仍被单独处理，并通过pipeline整合。另外，还有一个相关的任务是摘要，即提取能够代表event cluster的简洁摘要。这里和上个暑假看的Wang, Z.[^2]的工作比较相似。

在本文[^1]中，我们构建了一个joint model来筛选、聚类和摘要推文中的event。特别的，我们利用深度表示学习来对推文进行矢量化处理。Neural stacking model用于整合不同子任务的pipeline，并更好地共享前后参数。实验表明，我们提出的neural joint model比pipeline更有效。

### 1. Introduction

有文献证明了推特、微博这类体裁比起传统的媒体，对新闻事件有更快的反应速度，因此今年对于推特的事件监测也是今年的热点之一，引起了广泛关注。我们在本文主要检测一些典型的事件类别，比如地震、DDos攻击等。我们提出了一个神经网络模型，该模型监视特定事件类别的推特流，共同检测并摘要该类别下的新闻事件。

<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-225501%402x.png" width="60%">

整体的架构如上图所示，给定一个推特流，我们的模型考虑三个子任务：推文过滤，事件聚类和事件摘要。

典型的推特事件检测模型的核心部分是**聚类**，其中包括增量聚类和locality sensitive hashing。主要的想法是将同一主题的推文进行分组，以便在新推文不属于现有主题类的情况下检测到新主题。这样的聚类算法通常依赖于推特内容的特征，如TFIDF，用于测量推文之间的相似度。

第二个子任务是**摘要**，它并不直接涉及event detection，但仍然与之高度相关，因为检测到的事件群可能比较大并且包含不同程度信息的推文。 从系统功能的角度来说，对于推特事件检测系统，摘要是十分必要的，因为我们没办法直接读取事件群，只有将其抽取摘要，并将事件摘要作为输出，才能够为我们所用。

此外，由于大部分推文流包含普通或不相关的信息，推文**过滤**是我们考虑的第三个子任务。 我们的目标是根据其与潜在新事件的相关性对传入推文进行分类，以便只保留信息性推文。 过滤可以在聚类之前或之后进行。 在本文中，我们在聚类之前执行这项任务。

这三个子任务形成了一个三阶段pipeline（过滤→聚类→摘要），其中各个阶段是密切相关的。 例如，完整描述事件的推文应该在相关性过滤和抽象摘要步骤中得到高分。 另外，更好地理解推文对于相关性过滤和事件聚类都有帮助。 受此启发，我们考虑使用一个joint model进行筛选、聚类和摘要。

神经网络在近年也在类似任务上展示了良好的表现。我们使用两种联合建模策略。首先，我们以推文的语义表示作为关键连接因素，通过参数共享整合三项任务。其次，我们将neural stacking应用于pipeline，将前一个子模型的隐藏神经层作为其后继子模型的附加输入特征，并将后继的误差传播给前者，使得在培训期间，让前后子模型之间的信息得到更好的共享。

### 2. Model

我们系统的输入是一个推特流，实时输出事件报告。三个主要的子任务定义如下：

- **事件筛选**：我们将流中的每条推文分类为与相关事件相关或不相关的事件。由于我们的目标是仅检测某些类型的事件（即地震和DDOS攻击事件），因此我们使用相应的一组关键字来过滤推文流作为预处理步骤。相关分类在预处理步骤之后执行，因为并非所有包含关键字的推文都是相关的。
- **事件聚类**：我们在事件检测后对推文进行增量聚类。给定一个提到事件的推文，其任务是确定它是否存在于现有的事件集群中、是否是一个新的事件。这个任务的关键是推文之间的相似度计算。
- **事件摘要**：当一个事件集群足够大时，我们通过提取前n个包含最多信息的推文来创建相应事件的报告。这个子任务可以被看作是一个多文档摘要任务。

<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-232216%402x.png" width="60%">

模型的整体构架如上图，H是推文的embedding，Hd是事件筛选步骤的隐藏层，Hc是聚类的隐藏层，Ps是摘要的输出。我们可以看到，每一个子任务都充分利用了前面的信息，使得各个子模型项目补充辅助，让结果更理想。

结果表明，与独立的pipeline相比，这种neural stacking方法可以产生更好的子模型。请注意，虽然计算两个tweets之间的相似性的过程是用LSTM模型监督的，但聚类算法是一种无监督的在线聚类算法。

#### 2.1 Shared Tweet Representation

我们使用标准的LSTM模型来学习不同任务之间的推文表示。 假设$X =(w_1,w_2,…,w_n)$是推文，其中$n$是推文长度，$w_i$是第i个标记。 我们使用$w_i$的word embedding将每个$w_i$转换为实值向量$x_i$，通过查找预先训练的word embedding表D获得。我们使用skip-gram算法来训练embedding。
LSTM用以生成隐藏序列$(h_1,h_2,…,h_n)$。 在每个步骤t，基于当前向量$x_t$和前一个向量$h_{t-1}$和$h_t = LSTM(x_t，h_{t-1})$计算LSTM模型的隐藏向量$h_t$。 初始状态和所有LSTM参数随机初始化并在训练过程中调整。 我们使用$H = h_n$作为X的共享表示。

#### 2.2 Joint Model 

##### Event mention detection

事件提及检测是一个二元分类任务，使用多层感知器进行描述。给出输入向量H，隐含层用于激发一组高级特征：
$$
H_d = \sigma(W_d^h H + b_d^h)
$$
$H_d$被用于softmax输出层的输入：
$$
P_d = softmax(W_dH_d + B_d)
$$
这里$W_d^h, b_d^b, W_d$都是模型参数。$P_d$ 长度为2，$P_d(0)$表示推文X相关的概率，$P_d(1)$表示不相关的概率。

##### Event clustering

<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-234532%402x.png" width="60%">

我们使用基于流的聚类算法将传入的推文分为不同的事件组，每个事件组表示一个特定的事件。该算法随着流中的每个传入推文增长式地工作，计算新推文与现有事件群中的每条推文之间的相似度分数。新传入的推文与每个事件群中最相似的对应文件之间的相似度用于衡量新推文与事件群集之间的相似度。使用阈值$\mu - 3\cdot \sigma$来检测新推文是否属于现有聚类，其中μ是所有先前相似度分数的均值，σ是标准偏差。如果推特和所有现有群集之间的相似度低于阈值，则建立新的事件群集。否则，将推文添加到最相似的现有事件群集中。
为了计算两条推文$X_i$和$X_j$之间的相似度，我们使用了一个连体网络，它采用共享表示向量$H_i$和$H_j$，并通过参数化计算相似概率得分$P_c$:
$$
H_c = \sigma(W_c^h(H_i \oplus H_j)+ b_c^h) \\
P_c = softmax(W_cH_c + B_c)
$$
⊕表示向量级联。 $W_c^h，b_b^c,W_c,b_c$是模型参数。

为了更好地整合事件提及检测和事件聚类，我们还将$X_i$和$X_j$的隐藏特征矢量$H_d$馈送到Siamese网络，从而
$$
H_c = \sigma(W_c^h(H_i \oplus H_j \oplus H_{d_i} \oplus H_{d_j})+ b_c^h)
$$

##### Event summarization

<img src="https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180405-000354%402x.png" width="60%">

为了生成事件集群的摘要，我们使用概率分数$P_s$对集群中的所有推文进行排序。 对于集群中的每个推特X，使用多层感知器来估计$P_s$，其中输入是$H \oplus \bar{H_c^h}$。 这里的矢量$\bar{H_c^h}$是推文X与同一集群中所有其他推特之间的$H_c^h$之和。 它有两个用途。首先，$H_c^h$提供有关整个群集的信息，这对于更好地确定群集中给定推文的相关性很有用。 其次，$H_c^h$还把聚类和摘要联系了起来，从而强化了信息共享。
$$
P_s = softmax(W_sH_s + B_s)
$$
where
$$
H_s = \sigma(W_s^h(H\oplus \bar{H_c^h})+ b_s^h)
$$
$W_s^h, b_s^b, Ws$是模型的参数

#### 2.3 Training

我们的培训目标是尽量减少这三项任务中标注的标签和预测标签之间的cross-entropy loss。 我们应用在线培训，使用Adagrad调整模型参数。为了避免过拟合，对word embedding使用0.2点dropout。隐藏层$H_d, H_c,H_s$的大小都设置为32。我们使用Skip-gram算法训练word embedding，并在训练期间对它们进行微调。 Word embedding的大小是128。

### 3. Experiment

见paper原文

### 4. Conclusion

文献[^1]提出了一个joint model，通过使用全局共享表示和不同子任务之间的堆叠来共同检测、聚类和摘要事件。 实验表明，我们提出的joint model比pipeline模型更有效。该联合神经系统优于采用离散或神经网络进行新闻事件检测和摘要的最新baseline。

## Bibliography

代码开源：https://github.com/wangzq870305/joint_event_detection

[^1]: Wang, Z., & Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In *Proceedings of the 26th International Joint Conference on Artificial Intelligence* (pp. 4158-4164). AAAI Press.
[^2]: Wang, Z., Shou, L., Chen, K., Chen, G., & Mehrotra, S. (2015). On summarization and timeline generation for evolutionary tweet streams. *IEEE Transactions on Knowledge and Data Engineering*, *27*(5), 1301-1315.