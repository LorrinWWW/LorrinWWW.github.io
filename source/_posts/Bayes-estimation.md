---
title: 贝叶斯估计 Bayes estimation
date: 2017-01-07 16:46:31
categories: [math]
tags: [Bayes, statistic]
hidden: true
---

在机器学习中，贝叶斯这个名字被不止一次的提到。正好又看到了贝叶斯参数估计，简单记录方法，可能没有严谨的数学推导，见谅。

首先我们必须提及的就是历史上的两大学派——经典统计学派和贝叶斯统计学派。

这里我们假设要估计的参数为$\theta$，简单来说，经典统计学派认为$\theta$是一个未知但固定的常数，而贝叶斯学派认为$\theta$是一个变量。

## 贝叶斯公式

我们为什么需要贝叶斯估计呢？

我们不妨看一个例子，经典统计学派我们使用极大似然估计法。

假如学生在做一道题，当一个学生会做这道题时，他的正确率是98%。当他不会做这道题时，答题的正确率为5%。现在，有一个学生的对这道题测验结果为错误，问这个人会做这道题吗？ 
既然会做并做对的概率为98%，不会做但做对的概率为5%，如果用最大似然估计的方法，我们认为这个人已经感染了病毒。 

但是如果如果这道题十分容易呢？比如，题目是1+1=？，事实上，就算是幼儿园的小孩也会做。那么这个估计结果其实是有时偏颇的。

此时我们用贝叶斯方法进行估计，如果我们得知有一个先验概率，比如整体学生中只有1%的人会感染此种病毒，那么由贝叶斯公式： 
$$
p(y_i|x) = \frac{p(x|y_i)p(y_i)}{p(x)}
$$

$$
p(不会做|做错)=\frac{p(做错|不会做)p(不会做)}{p(做错)}=\frac{0.95\times 0.01}{0.95 \times 0.01 + 0.02 \times 0.99} = 0.324
$$

这么看来，还是会做的概率比较高，只不过这个学生比较粗心罢了。

## 利用贝叶斯进行参数估计

贝叶斯估计中，需要对参数有一个先验估计，并记录其分布为：
$$
\theta: \pi(\theta)
$$
已知样本为
$$
\widetilde{X} = \{ X_1,...,X_n \}
$$
参数的联合分布为
$$
p(\widetilde{x},\theta) = p(\widetilde{x} |\theta)\pi(\theta)
$$
所以
$$
\pi(\theta|\widetilde{x} ) = \frac{p(\widetilde{x} ,\theta)}{p(\widetilde{x})} \\
= \frac{p(\widetilde{x} |\theta)\pi(\theta)}{\int{p(\widetilde{x} |\theta)\pi(\theta) d\theta}}
$$
特别的，若T是一个充分统计量
$$
p(\widetilde{x}|\theta) = p(\widetilde{x} |T = t)p_T(t|\theta) \varpropto p_T(t|\theta)
$$
从而
$$
\pi(\theta|\widetilde{x} ) = \pi(\theta|t )
$$
这样，参数的分布就已经得到了，接下来一般通过三种方法进行估计：

- 后验分布的众数进行估计
- 后验分布的中位数进行估计
- 后验分布的期望进行估计

总结一下，贝叶斯估计就是，认为被估计参数是一个随机变量，通过已有的数据得到一个先验分布，结合这个先验分布再通过现有的条件，最后得到一个较为合理的后验分布。

注：

- 如果x的方差趋于无穷，意味着样本没有任何意义，估计结果等于先验估计。
- 如果样本数量趋于无穷，则估计结果与先验估计无关。这说明先验估计实际上是为了弥补样本的不足。