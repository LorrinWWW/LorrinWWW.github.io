<!doctype html>
<html lang="en"><head><meta charset="utf-8"><meta name="viewport" content="width=device-width, initial-scale=1, maximum-scale=1"><meta><title>数据挖掘-分类与预测 - Jue Wang</title><meta name="robots" content="noindex"><link rel="manifest" href="/manifest.json"><meta name="application-name" content="Jue Wang (王珏)"><meta name="msapplication-TileImage" content="/img/favicon.svg"><meta name="apple-mobile-web-app-capable" content="yes"><meta name="apple-mobile-web-app-title" content="Jue Wang (王珏)"><meta name="apple-mobile-web-app-status-bar-style" content="default"><meta name="description" content="基本知识主要分为两个步骤：  建立一个描述已知数据集类别或概念的模型。 分类规则形式、决策树形式，或数学公式形式。  利用所获得的模型进行分类操作。 首先要对模型分类准确率进行估计。 若其准确率可以接受，则可以使用该模型进行分类。          可以根据以下几条标准对各种分类方法进行比较:  预测准确率，它描述(学习所获)模型能够正确预测未知对象类别或(类别)数值的能力。 速度，它描述在构造和"><meta property="og:type" content="blog"><meta property="og:title" content="数据挖掘-分类与预测"><meta property="og:url" content="https://lorrinwww.github.io/posts/datamining-class-pred/"><meta property="og:site_name" content="Jue Wang"><meta property="og:description" content="基本知识主要分为两个步骤：  建立一个描述已知数据集类别或概念的模型。 分类规则形式、决策树形式，或数学公式形式。  利用所获得的模型进行分类操作。 首先要对模型分类准确率进行估计。 若其准确率可以接受，则可以使用该模型进行分类。          可以根据以下几条标准对各种分类方法进行比较:  预测准确率，它描述(学习所获)模型能够正确预测未知对象类别或(类别)数值的能力。 速度，它描述在构造和"><meta property="og:locale" content="en_US"><meta property="og:image" content="https://lorrinwww.github.io/img/og_image.png"><meta property="article:published_time" content="2016-12-26T19:56:57.000Z"><meta property="article:modified_time" content="2022-05-08T13:53:50.526Z"><meta property="article:author" content="Jue Wang"><meta property="article:tag" content="programming"><meta property="article:tag" content="datamining"><meta property="article:tag" content="classification"><meta property="article:tag" content="prediction"><meta property="twitter:card" content="summary"><meta property="twitter:image" content="/img/og_image.png"><script type="application/ld+json">{"@context":"https://schema.org","@type":"BlogPosting","mainEntityOfPage":{"@type":"WebPage","@id":"https://lorrinwww.github.io/posts/datamining-class-pred/"},"headline":"数据挖掘-分类与预测","image":["https://lorrinwww.github.io/img/og_image.png"],"datePublished":"2016-12-26T19:56:57.000Z","dateModified":"2022-05-08T13:53:50.526Z","author":{"@type":"Person","name":"Jue Wang"},"publisher":{"@type":"Organization","name":"Jue Wang","logo":{"@type":"ImageObject","url":"https://lorrinwww.github.io/img/favicon.svg"}},"description":"基本知识主要分为两个步骤：  建立一个描述已知数据集类别或概念的模型。 分类规则形式、决策树形式，或数学公式形式。  利用所获得的模型进行分类操作。 首先要对模型分类准确率进行估计。 若其准确率可以接受，则可以使用该模型进行分类。          可以根据以下几条标准对各种分类方法进行比较:  预测准确率，它描述(学习所获)模型能够正确预测未知对象类别或(类别)数值的能力。 速度，它描述在构造和"}</script><link rel="canonical" href="https://lorrinwww.github.io/posts/datamining-class-pred/"><link rel="icon" href="/img/favicon.svg"><link rel="stylesheet" href="https://use.fontawesome.com/releases/v5.15.2/css/all.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/highlight.js@9.12.0/styles/atom-one-light.css"><link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Ubuntu:wght@400;600&amp;family=Source+Code+Pro"><link rel="stylesheet" href="/css/default.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/gh/jpswalsh/academicons/css/academicons.min.css"><style>body>.footer,body>.navbar,body>.section{opacity:0}</style><!--!--><!--!--><!--!--><!--!--><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/css/lightgallery.min.css"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/css/justifiedGallery.min.css"><script src="https://www.googletagmanager.com/gtag/js?id=UA-115582186-1" async></script><script>window.dataLayer = window.dataLayer || [];
        function gtag(){dataLayer.push(arguments);}
        gtag('js', new Date());
    
        gtag('config', 'UA-115582186-1');</script><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/pace-js@1.0.2/pace.min.js"></script><!--!--><!--!--><meta name="generator" content="Hexo 5.4.0">
<style>.github-emoji { position: relative; display: inline-block; width: 1.2em; min-height: 1.2em; overflow: hidden; vertical-align: top; color: transparent; }  .github-emoji > span { position: relative; z-index: 10; }  .github-emoji img, .github-emoji .fancybox { margin: 0 !important; padding: 0 !important; border: none !important; outline: none !important; text-decoration: none !important; user-select: none !important; cursor: auto !important; }  .github-emoji img { height: 1.2em !important; width: 1.2em !important; position: absolute !important; left: 50% !important; top: 50% !important; transform: translate(-50%, -50%) !important; user-select: none !important; cursor: auto !important; } .github-emoji-fallback { color: inherit; } .github-emoji-fallback img { opacity: 0 !important; }</style>
<link rel="alternate" href="/atom.xml" title="Jue Wang" type="application/atom+xml">
</head><body class="is-2-column"><nav class="navbar navbar-main"><div class="container"><div class="navbar-brand justify-content-center"><a class="navbar-item navbar-logo" href="/"><img src="/img/favicon.svg" alt="Jue Wang" height="28"></a></div><div class="navbar-menu"><div class="navbar-start"><a class="navbar-item" href="/">Home</a><a class="navbar-item" href="/archives">Archives</a><a class="navbar-item" href="/categories">Categories</a><a class="navbar-item" href="/tags">Tags</a><a class="navbar-item" href="/posts/about/">About</a></div><div class="navbar-end"><a class="navbar-item" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a><a class="navbar-item search" title="Search" href="javascript:;"><i class="fas fa-search"></i></a></div></div></div></nav><section class="section"><div class="container"><div class="columns"><div class="column order-2 column-main is-8-tablet is-8-desktop is-8-widescreen"><div class="card"><article class="card-content article" role="article"><div class="article-meta is-size-7 is-uppercase level is-mobile"><div class="level-left"><span class="level-item">Posted&nbsp;<time dateTime="2016-12-26T19:56:57.000Z" title="12/26/2016, 2:56:57 PM">2016-12-26</time></span><span class="level-item">Updated&nbsp;<time dateTime="2022-05-08T13:53:50.526Z" title="5/8/2022, 9:53:50 AM">2022-05-08</time></span><span class="level-item"><a class="link-muted" href="/categories/programming/">programming</a></span><span class="level-item">19 minutes read (About 2837 words)</span></div></div><h1 class="title is-3 is-size-4-mobile">数据挖掘-分类与预测</h1><div class="content"><h1 id="基本知识"><a href="#基本知识" class="headerlink" title="基本知识"></a>基本知识</h1><p>主要分为两个步骤：</p>
<ol>
<li><p>建立一个描述已知数据集类别或概念的模型。</p>
<p>分类规则形式、决策树形式，或数学公式形式。</p>
</li>
<li><p>利用所获得的模型进行分类操作。</p>
<p>首先要对模型分类准确率进行估计。</p>
<p>若其准确率可以接受，则可以使用该模型进行分类。       </p>
</li>
</ol>
<p>可以根据以下几条标准对各种分类方法进行比较:</p>
<ol>
<li>预测准确率，它描述(学习所获)模型能够正确预测未知对象类别或(类别)数值的能力。</li>
<li>速度，它描述在构造和使用模型时的计算效率。 </li>
<li>鲁棒性，它描述在数据带有噪声和有数据遗失情况下，(学习所获)模型仍能进行正确预测的能力。 </li>
<li>可扩展性，它描述对处理大量数据并构造相应学习模型所需要的能力。</li>
<li>易理解性，它描述学习所获模型表示的可理解程度。 在本章的后面各节，将要陆续介绍上述有关问题的实现方法。</li>
</ol>
<h1 id="基于决策树的分类"><a href="#基于决策树的分类" class="headerlink" title="基于决策树的分类"></a>基于决策树的分类</h1><ol>
<li><p>决策树的生成算法</p>
<ul>
<li><p>基本决策树算法</p>
<p>本质是一个贪心算法，自上而下分而治之。</p>
</li>
</ul>
</li>
<li><p>属性选择方法</p>
<p>信息量<br>$$<br>I(s_1,…,s_m) = - \sum_{i=1}^{m}{p_i \log (p_i)}<br>$$<br>利用属性A划分当前样本集合所需要的信息可以计算：<br>$$<br>E(A) = \sum_{j=1}^{v}{\frac{s_{1j}+s_{2j}+…+s_{mj}}{s}I(s_1,…,s_m) }<br>$$<br>E(A)的值越小，说明其子集划分结果越纯，即越好。而对于一个子集Sj，它的信息为<br>$$<br>I(s_{1j},…,s_{mj}) = - \sum_{i=1}^{m}{p_{ij} \log (p_{ij})}<br>$$<br>这样利用属性A对当前分支结点进行相应样本集合划分所获得的信息增益是:<br>$$<br>Gain(A) =I(s_1,…,s_m)- E(A)<br>$$<br>也就是说Gain(A)被认为是利用属性A进行划分后，所获的的信息熵的减少量。</p>
<p>决策树归纳算法计算每个属性的Gain，选择信息增益最大的属性，作为测试属性并由此产生相应的分支节点。</p>
</li>
<li><p>树枝的修剪</p>
<ol>
<li><p>事前修剪</p>
<p>基本原理是设置一个阀值，当某一节点的的样本数少于阀值，则停止细分。难点在于设置一个合理的阀值。</p>
</li>
<li><p>事后修剪</p>
<p>从一个充分生长的树中修建。</p>
<p>可以使用基于代价成本的方法，也可以使用最短描述长度(MDL)。</p>
<p>前者计算其分类错误率，若修剪枝导致分类错误率变高，则保留，否则剪枝；后者选择最简单的，无需独立的数据测试</p>
</li>
</ol>
</li>
<li><p>规则获取</p>
<p>在已经获得了一个决策树的基础上，可以使用”if…else…”语句描述该决策树。</p>
</li>
<li><p>基本决策树方法改进及其扩展性</p>
</li>
</ol>
<h1 id="贝叶斯分类方法"><a href="#贝叶斯分类方法" class="headerlink" title="贝叶斯分类方法"></a>贝叶斯分类方法</h1><p>贝叶斯分类器是一个统计分类器，基于贝叶斯定理。</p>
<p>简单贝叶斯分类器的分类性能可以与决策树和神经网络相比。</p>
<p>简单贝叶斯分类器假设一个指定类别中各属性的取值是互相独立的，它可以帮助减少计算量。</p>
<ol>
<li><p>贝叶斯定理</p>
<p>设X为一个类别未知的数据样本，H为某个假设，则：<br>$$<br>P(H|X) = \frac{P(X|H)P(H)}{P(X)}<br>$$</p>
</li>
<li><p>简单贝叶斯分类方法</p>
<p>步骤说明如下：</p>
<ol>
<li><p>每一个数据都是有一个n维特征向量X={x1,…,xn}构成，分别描述其n个属性(A1,…,An)。</p>
</li>
<li><p>若有m个不同的类别(C1,…,Cm)，分类器将未知X归属到类别Ci，当仅当<br>$$<br>P(C_i|X) = \max(P(C_j|X)|1\le j\le m)<br>$$<br>所以我们要找到最大的<br>$$<br>P(C_i|X) = \frac{P(X|C_i)P(C_i)}{P(X)}<br>$$</p>
</li>
<li><p>要找到它，只需要P(X|Ci)P(Ci)取最大即可。由于各类别的事前概率是未知的，我们假设P(Ci)是互相相等的，这样，第二步中的式子取最大就转化为了寻找最大的P(X|Ci)</p>
</li>
<li><p>由于所含的属性比较多，直接计算P(X|Ci)的计算量还是很大的。由于简单贝叶斯分类器假设各属性独立，则：<br>$$<br>P(X|C_i) = \prod{P(x_k|C_i)}<br>$$<br>可以根据训练数据样本估算P(xk|Ci)的值。具体如下：</p>
<ul>
<li><p>若Ak是符号量<br>$$<br>P(x_k|Ci)=\frac{s_{ik}}{s_i}<br>$$<br>这里sik为训练样本中类别为Ci且属性Ak取vk的样本数。si为训练样本中类别为Ci的样本数。</p>
</li>
<li><p>若Ak是连续量<br>$$<br>P(x_k|Ci)=g(x_k,\mu_{C_i},\sigma_{C_i}) = \frac{1}{\sqrt{2\pi}\sigma_{C_i}}e^{-\frac{(x-\mu_{C_i})^2}{2\sigma^2_{C_i}}}<br>$$<br>其中$g(x_k,\mu_{C_i},\sigma_{C_i})$ï为属性为Ak的高斯规范密度函数。</p>
</li>
</ul>
</li>
<li><p>为了预测X的分类，我们通过上述方法估计各个类别的正确率，将X归属到可能性最高的类别。</p>
</li>
</ol>
</li>
<li><p>贝叶斯信念网络</p>
<p>简单贝叶斯假设属性相互独立，从而简化计算，而实际上属性相互依赖的情况比较常见，所以又出现了贝叶斯信念网络，用于描述这种相互关联的概率分布。</p>
<p>贝叶斯信念网络提供了一个图形模型来描述其中的因果关系。信念网络包括两个部分。</p>
<ul>
<li><p>第一部分是有向无环图</p>
<p>每一个节点代表随机变量。</p>
<p>每一条弧代表一个概率依赖。</p>
<p>给定父节点，每个变量有条件的独立于图中非子节点。</p>
</li>
<li><p>第二部分是包含所有变量的条件概率表(CPT)</p>
<p>对于一个变量Z，CPT定义了P(Z|parent(Z))，由此可以得到一个表。</p>
<p>例如，LunCancer的父节点是FamilyHistory和Smoker，</p>
</li>
</ul>
</li>
</ol>
<table>
<thead>
<tr>
<th></th>
<th>FH, S</th>
<th>FH, ~S</th>
<th>~FH, S</th>
<th>~FH, ~S</th>
</tr>
</thead>
<tbody><tr>
<td>LungCancer</td>
<td>0.8</td>
<td>0.5</td>
<td>0.7</td>
<td>0.1</td>
</tr>
<tr>
<td>~LungCancer</td>
<td>0.2</td>
<td>0.5</td>
<td>0.3</td>
<td>0.9</td>
</tr>
</tbody></table>
<p>数据对象的联合概率通过如下公式计算。<br>$$<br>P(z_1,…,z_n) = \prod{P(z_i|parent(z_i))}<br>$$</p>
<ol start="4">
<li><p>贝叶斯信念网络的学习</p>
<p>学习算法步骤如下：</p>
<ol>
<li><p>计算下降梯度<br>$$<br>\frac{\partial\ln{P_w(S)}}{\partial w_{ijk}} = \sum_{d=1}^{s}{\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}<br>$$<br>​<br>左边是计算训练集合S中每个样本Xd的概率。设这一概率为p。</p>
<p>由Yi和Ui表示隐含变量，p可通过样本中可观察到的变量以及标准贝叶斯网络推理计算得到。</p>
</li>
<li><p>沿梯度方向前进一小步，权重更新计算如下<br>$$<br>w_{ijk} \leftarrow w_{ijk} + (l)\frac{\partial\ln{P_w(S)}}{\partial w_{ijk}}<br>$$<br>l为学习速率代表学习步长。通常学习速率为较小的常数。</p>
</li>
<li><p>重新规格化权重</p>
<p>保证wijk的取值在0～1，其和等于1.</p>
</li>
</ol>
</li>
</ol>
<h1 id="神经网络分类方法"><a href="#神经网络分类方法" class="headerlink" title="神经网络分类方法"></a>神经网络分类方法</h1><ol>
<li><p>多层反馈神经网络</p>
<p>输入同时赋给第一层(输入层)单元，这些单元输出赋予权重，输出给第二层(隐藏层)。</p>
<p>隐藏层的带权输出又作为输入再馈给另一隐层。</p>
<p>最后的隐层结点带权输出馈给输出层单元，最终给出相应样本的预测输出。</p>
<p>该网络是前馈的，即每一个反馈只能发送到前面的输出层或隐含层。</p>
<p>它也是全连接的，即每一个层中单元均与前面一层的各单元相连接。</p>
<p>只要中间隐层足够多的话，多层前馈网络中的线性阈值函数，可以充分逼近任何函数。</p>
</li>
<li><p>神经网络结构</p>
<p>确定结构，即：</p>
<ul>
<li>输入层的单元数</li>
<li>隐含层的个数(和层数)</li>
<li>每个隐含层的单元数目</li>
<li>输出层单元数目</li>
</ul>
<p>对输入值规格化，一般取值在0～1.</p>
<p>离散数据可以为每一个取值增加一个节点进行编码。例如A={a0,a1,a2}则我们设立三个输入单元I0, I1, I2，每个单元默认为0，若A=a0，则I1置为1.</p>
<p>此外没有什么特定的规律或规则来指导隐含层的最佳单元数量，它的确定是一个不断试错的过程。</p>
</li>
<li><p>后传方法</p>
<p>后传方法不断地处理一个训练样本集。将处理结果与训练样本已知类别比较所获误差，修改权重，使网络输出与实际类别之间的均方差最小。权重的修改是后传的，即从前向后的。</p>
<p>其收敛性不能保证。</p>
<p>流程(伪代码)：</p>
<figure class="highlight python"><table><tbody><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br></pre></td><td class="code"><pre><span class="line"><span class="comment"># 定义sum函数，以变量x对f(x)求和</span></span><br><span class="line"><span class="function"><span class="keyword">def</span> <span class="title">sum</span>(<span class="params">f(<span class="params">x</span>), x</span>):</span></span><br><span class="line">    <span class="keyword">pass</span></span><br><span class="line"></span><br><span class="line"><span class="comment"># 初始化</span></span><br><span class="line">init();</span><br><span class="line"></span><br><span class="line"><span class="keyword">while</span> !conditions:           <span class="comment"># 条件不满足时</span></span><br><span class="line">    <span class="keyword">for</span> X <span class="keyword">in</span> samples:</span><br><span class="line">        <span class="keyword">for</span> each layer:      <span class="comment"># 每个隐含层和输出层</span></span><br><span class="line">            O[j] = <span class="number">1</span> / (<span class="number">1</span> + exp( - I[j]))</span><br><span class="line">            I[j] = <span class="built_in">sum</span>(w[i][j]O[i], i) + theta[j]</span><br><span class="line">        <span class="keyword">for</span> each unit of output layer <span class="keyword">as</span> j:    <span class="comment"># 每个输出层单元j，计算向后传播误差</span></span><br><span class="line">            Err[j] = O[j] * (<span class="number">1</span> - O[j]) * (T[j] - O[j])</span><br><span class="line">        <span class="keyword">for</span> each unit of hidden layer <span class="keyword">as</span> j:    <span class="comment"># 每个隐含层单元j，从最后一层到第一层隐含层</span></span><br><span class="line">            Err[j] = O[j] * (<span class="number">1</span> - O[j]) * <span class="built_in">sum</span>(Err[k] * w[i][j][k], k)</span><br><span class="line">        <span class="keyword">for</span> each w[i][j] <span class="keyword">in</span> the network:       <span class="comment"># network中的权重wij</span></span><br><span class="line">            delta_w[i][j] = (l) * Err[j] * O[i]     <span class="comment"># (l)是学习速率，取值在0～1</span></span><br><span class="line">            w[i][j] += delta_w[i][j]</span><br><span class="line">        <span class="keyword">for</span> each theta[j] <span class="keyword">in</span> the network:      <span class="comment"># network中的偏差thetaij</span></span><br><span class="line">            delta_theta[j] = (l) * Err[j]</span><br><span class="line">            v[i] = theta[j] + delta_theta[j]</span><br><span class="line">        </span><br></pre></td></tr></tbody></table></figure>

<p>看伪代码基本就能明白它的过程了。虽然伪代码可能写的比较迷。。。</p>
</li>
</ol>
<h1 id="基于关联的分类方法"><a href="#基于关联的分类方法" class="headerlink" title="基于关联的分类方法"></a>基于关联的分类方法</h1><p>略，后面会详细说。</p>
<h1 id="其他分类"><a href="#其他分类" class="headerlink" title="其他分类"></a>其他分类</h1><p>其他分类我也没有细看，纪录一下名字，以后有时间再看。</p>
<ol>
<li><p>k-最邻近方法</p>
<p>这个很简单，就是比较两个点的欧式距离。比较基本的分类方法，略。</p>
</li>
<li><p>基于示例推理</p>
</li>
<li><p>遗传算法</p>
</li>
<li><p>粗糙集方法</p>
</li>
<li><p>模糊集合方法</p>
</li>
</ol>
<h1 id="预测方法"><a href="#预测方法" class="headerlink" title="预测方法"></a>预测方法</h1><ol>
<li><p>线形与多变量回归</p>
<p>线性代数、概率统计、数值计算方法里都学过。核心是利用最小二乘法。</p>
</li>
<li><p>非线性回归</p>
<p>例如多项式回归<br>$$<br>Y = \alpha + \beta_1 X+\beta_2 X^2+\beta_3 X^3<br>$$<br>为了将其转化为线性形式，令：<br>$$<br>X_1 = X;X_2 = X^2 ; X_3 = X^3<br>$$<br>接下来就用最小二乘法即可。</p>
</li>
<li><p>其他回归模型</p>
<p>对数回归、泊松回归等</p>
</li>
</ol>
<h1 id="分类器准确性"><a href="#分类器准确性" class="headerlink" title="分类器准确性"></a>分类器准确性</h1><p>分层k次交叉验证方法普遍应用于对分类器预测准确性的评估方面。而bagging方法和boosting方法则通过学习和组合多个(单)分类器来帮助提高整个(数据训练样本所获)分类器的预测准确性。</p>
<!-- flag of hidden posts --></div><div class="article-licensing box"><div class="licensing-title"><p>数据挖掘-分类与预测</p><p><a href="https://lorrinwww.github.io/posts/datamining-class-pred/">https://lorrinwww.github.io/posts/datamining-class-pred/</a></p></div><div class="licensing-meta level is-mobile"><div class="level-left"><div class="level-item is-narrow"><div><h6>Author</h6><p>Jue Wang</p></div></div><div class="level-item is-narrow"><div><h6>Posted on</h6><p>2016-12-26</p></div></div><div class="level-item is-narrow"><div><h6>Updated on</h6><p>2022-05-08</p></div></div><div class="level-item is-narrow"><div><h6>Licensed under</h6><p><a class="icons" rel="noopener" target="_blank" title="Creative Commons" href="https://creativecommons.org/"><i class="icon fab fa-creative-commons"></i></a><a class="icons" rel="noopener" target="_blank" title="Attribution" href="https://creativecommons.org/licenses/by/4.0/"><i class="icon fab fa-creative-commons-by"></i></a><a class="icons" rel="noopener" target="_blank" title="Noncommercial" href="https://creativecommons.org/licenses/by-nc/4.0/"><i class="icon fab fa-creative-commons-nc"></i></a></p></div></div></div></div></div><div class="article-tags is-size-7 mb-4"><span class="mr-2">#</span><a class="link-muted mr-2" rel="tag" href="/tags/programming/">programming</a><a class="link-muted mr-2" rel="tag" href="/tags/datamining/">datamining</a><a class="link-muted mr-2" rel="tag" href="/tags/classification/">classification</a><a class="link-muted mr-2" rel="tag" href="/tags/prediction/">prediction</a></div><div class="sharethis-inline-share-buttons"></div><script src="https://platform-api.sharethis.com/js/sharethis.js#property=610cdfe06a9baf001281bbf4&amp;product=inline-share-buttons" defer></script></article></div><!--!--><div class="card"><div class="card-content"><h3 class="title is-5">Comments</h3><div id="comment-container"></div><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.css"><script src="https://cdn.jsdelivr.net/npm/gitalk@1.7.2/dist/gitalk.min.js"></script><script>var gitalk = new Gitalk({
            id: "448b1e8df5e5650b242b1b288ebbae6b",
            repo: "LorrinWWW.github.io",
            owner: "lorrinWWW",
            clientID: "bc305d76488227d8c5cf",
            clientSecret: "f7a2801a15ead49e3258304a0cf20f249f3962f3",
            admin: ["lorrinWWW"],
            createIssueManually: false,
            distractionFreeMode: false,
            perPage: 10,
            pagerDirection: "last",
            
            
            enableHotKey: true,
            
        })
        gitalk.render('comment-container')</script></div></div></div><div class="column column-left is-3-tablet is-3-desktop is-3-widescreen  order-1"><div class="card widget" data-type="profile"><div class="card-content"><nav class="level"><div class="level-item has-text-centered flex-shrink-1"><div><figure class="image is-128x128 mx-auto mb-2"><img class="avatar is-rounded" src="/img/avatar.jpeg" alt="Jue Wang"></figure><p class="title is-size-4 is-block" style="line-height:inherit;">Jue Wang</p><p class="is-size-6 is-block">Ph.D Student</p><p class="is-size-6 is-flex justify-content-center"><i class="fas fa-map-marker-alt mr-1"></i><span>Hangzhou, China</span></p></div></div></nav><nav class="level is-mobile"><div class="level-item has-text-centered is-marginless"><div><p class="heading">Post</p><a href="/archives"><p class="title">1</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Categories</p><a href="/categories"><p class="title">0</p></a></div></div><div class="level-item has-text-centered is-marginless"><div><p class="heading">Tags</p><a href="/tags"><p class="title">0</p></a></div></div></nav><div class="level"><a class="level-item button is-primary is-rounded" href="https://github.com/lorrinWWW" target="_blank" rel="noopener">Follow</a></div><div class="level is-mobile is-multiline"><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Scholar" href="https://scholar.google.com/citations?user=PykI8xcAAAAJ&amp;hl=en"><i class="ai ai-google-scholar"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Github" href="https://github.com/lorrinWWW/"><i class="fab fa-github"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="Twitter" href="https://twitter.com/JueWANG26088228"><i class="fab fa-twitter"></i></a><a class="level-item button is-transparent is-marginless" target="_blank" rel="noopener" title="RSS" href="/atom.xml"><i class="fas fa-rss"></i></a></div></div></div><!--!--></div><!--!--></div></div></section><footer class="footer"><div class="container"><div class="level"><div class="level-start"><a class="footer-logo is-block mb-2" href="/"><img src="/img/favicon.svg" alt="Jue Wang" height="28"></a><p class="is-size-7"><span>&copy; 2025 Jue Wang</span>  Powered by <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a> &amp; <a href="https://github.com/ppoffice/hexo-theme-icarus" target="_blank" rel="noopener">Icarus</a></p></div><div class="level-end"><div class="field has-addons"><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Creative Commons" href="https://creativecommons.org/"><i class="fab fa-creative-commons"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Attribution 4.0 International" href="https://creativecommons.org/licenses/by/4.0/"><i class="fab fa-creative-commons-by"></i></a></p><p class="control"><a class="button is-transparent is-large" target="_blank" rel="noopener" title="Download on GitHub" href="https://github.com/ppoffice/hexo-theme-icarus"><i class="fab fa-github"></i></a></p></div></div></div></div><div id="divmap" style="visibility:hidden; position: absolute; top: 0px"><script type="text/javascript" id="clustrmaps" src="//cdn.clustrmaps.com/map_v2.js?cl=ffffff&amp;w=2&amp;t=n&amp;d=I_238wU69nrKH0DIm55b1z-y84aVsLuSzQSglFoJ1ww&amp;co=ffffff&amp;ct=ffffff&amp;cmo=ffffff&amp;cmn=ffffff"></script></div></footer><script src="https://cdn.jsdelivr.net/npm/jquery@3.3.1/dist/jquery.min.js"></script><script src="https://cdn.jsdelivr.net/npm/moment@2.22.2/min/moment-with-locales.min.js"></script><script src="https://cdn.jsdelivr.net/npm/clipboard@2.0.4/dist/clipboard.min.js" defer></script><script>moment.locale("en");</script><script>var IcarusThemeSettings = {
            article: {
                highlight: {
                    clipboard: true,
                    fold: 'unfolded'
                }
            }
        };</script><script src="/js/column.js"></script><script src="/js/animation.js"></script><a id="back-to-top" title="Back to top" href="javascript:;"><i class="fas fa-chevron-up"></i></a><script src="/js/back_to_top.js" defer></script><!--!--><!--!--><!--!--><script src="https://cdn.jsdelivr.net/npm/cookieconsent@3.1.1/build/cookieconsent.min.js" defer></script><script>window.addEventListener("load", () => {
      window.cookieconsent.initialise({
        type: "info",
        theme: "edgeless",
        static: false,
        position: "bottom-left",
        content: {
          message: "This website uses cookies to improve your experience.",
          dismiss: "Got it!",
          allow: "Allow cookies",
          deny: "Decline",
          link: "Learn more",
          policy: "Cookie Policy",
          href: "https://www.cookiesandyou.com/",
        },
        palette: {
          popup: {
            background: "#edeff5",
            text: "#838391"
          },
          button: {
            background: "#4b81e8"
          },
        },
      });
    });</script><script src="https://cdn.jsdelivr.net/npm/lightgallery@1.6.8/dist/js/lightgallery.min.js" defer></script><script src="https://cdn.jsdelivr.net/npm/justifiedGallery@3.7.0/dist/js/jquery.justifiedGallery.min.js" defer></script><script>window.addEventListener("load", () => {
            if (typeof $.fn.lightGallery === 'function') {
                $('.article').lightGallery({ selector: '.gallery-item' });
            }
            if (typeof $.fn.justifiedGallery === 'function') {
                if ($('.justified-gallery > p > .gallery-item').length) {
                    $('.justified-gallery > p > .gallery-item').unwrap();
                }
                $('.justified-gallery').justifiedGallery();
            }
        });</script><!--!--><!--!--><script type="text/x-mathjax-config">MathJax.Hub.Config({
            'HTML-CSS': {
                matchFontHeight: false
            },
            SVG: {
                matchFontHeight: false
            },
            CommonHTML: {
                matchFontHeight: false
            },
            tex2jax: {
                inlineMath: [
                    ['$','$'],
                    ['\\(','\\)']
                ]
            }
        });</script><script src="https://cdn.jsdelivr.net/npm/mathjax@2.7.5/unpacked/MathJax.js?config=TeX-MML-AM_CHTML" defer></script><!--!--><!--!--><!--!--><script src="/js/main.js" defer></script><div class="searchbox"><div class="searchbox-container"><div class="searchbox-header"><div class="searchbox-input-container"><input class="searchbox-input" type="text" placeholder="Type something..."></div><a class="searchbox-close" href="javascript:;">×</a></div><div class="searchbox-body"></div></div></div><script src="/js/insight.js" defer></script><script>document.addEventListener('DOMContentLoaded', function () {
            loadInsight({"contentUrl":"/content.json"}, {"hint":"Type something...","untitled":"(Untitled)","posts":"Posts","pages":"Pages","categories":"Categories","tags":"Tags"});
        });</script></body></html>