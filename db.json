{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"dae5e9f3c18b9e2802942424812ac755776aaca0","modified":1517050493626},{"_id":"source/google50e2fbd5160eafe4.html","hash":"83768ebbfc295d00d798936de171951e469685f9","modified":1481235745000},{"_id":"themes/next/.DS_Store","hash":"9457f542cf2c3f2a50b9ecd64858fc6f50b0d0c4","modified":1481024229000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1480248297000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1480248297000},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1480248297000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1480248297000},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1480248297000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1480248297000},{"_id":"themes/next/README.en.md","hash":"565ba52b3825b85a9f05b41183caca7f18b741d4","modified":1480248297000},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1480248297000},{"_id":"themes/next/_config.yml","hash":"8a1711a5a17126aae0a8192557a136e56b3d3611","modified":1480543695000},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1480248297000},{"_id":"themes/next/gulpfile.coffee","hash":"61ef0606a8134894d7ac796bc8d0fa4ba6a94483","modified":1480248297000},{"_id":"themes/next/package.json","hash":"877cb98025e59015532c4c9a04a33e2af4ad56f9","modified":1480248297000},{"_id":"source/categories/index.md","hash":"e499584b3f5a05f5274b82dd34859016d064d7f9","modified":1487104253000},{"_id":"source/_posts/.DS_Store","hash":"d9438448ec49af9c2969e8463b6ce704851099e1","modified":1520108363234},{"_id":"source/_posts/Bayes-estimation.md","hash":"3e5aad795853e179d954d3205db4e7b2289908a9","modified":1483807698000},{"_id":"source/_posts/EDP-basic-matrix-review.md","hash":"c1fbeae751298cce65cc1985c9690442e015336b","modified":1486464009000},{"_id":"source/_posts/EDP-basic-models.md","hash":"80c26fd753d9e2648551ee0afc29dca700bcd40d","modified":1488798686000},{"_id":"source/_posts/EDP-finite-element-method.md","hash":"b94164cd9990c46a88bcfaf364c99235f9e3630c","modified":1490993312000},{"_id":"source/_posts/Generative-Adversarial-Network.md","hash":"0573686b81cccae78feb145fd79d78dabc3e6b4d","modified":1498718975000},{"_id":"source/_posts/Hands-on-Scrapy.md","hash":"5f8b0cbc7126f9e21a2fedb93944cf5e9f647b59","modified":1498140911000},{"_id":"source/_posts/Hilbert-space.md","hash":"3c6db443cefd12c241cbb609a6b75e7765101f9a","modified":1486817852000},{"_id":"source/_posts/ML-CNN.md","hash":"ef69323536f07aab053cd6d2895c486ad8f21ac9","modified":1481816209000},{"_id":"source/_posts/Method-of-programming-facing-to-exams.md","hash":"1a8fd1060250aede23ca2874e6128a18d349f844","modified":1480502724000},{"_id":"source/_posts/MongoDB-Docker-and-Python.md","hash":"c18c88e9b8c0e3c851ebc5fdb03c7208151154ce","modified":1498115279000},{"_id":"source/_posts/Note-of-NLP.md","hash":"bf0a5c3d8ad8149978bdef469deef2d33d26bc35","modified":1498641238000},{"_id":"source/_posts/Note-of-datamining.md","hash":"33cfd2f704bd9ae07d4ead3c17696e0a1a52400e","modified":1481058293000},{"_id":"source/_posts/Note-of-knowledge-graph.md","hash":"1807aafc17a5b04a03842cb403395c4f9f0ad49e","modified":1498369219000},{"_id":"source/_posts/Note-of-learning-Algo.md","hash":"b7b7e260aaeb65905941d8b4bd4571e1574b7c55","modified":1480503398000},{"_id":"source/_posts/Note-of-probability.md","hash":"ad5d49330cc0839512071921029120eda20f715c","modified":1480947409000},{"_id":"source/_posts/Note-of-statistic.md","hash":"4b9ce4b578af1309675aaa85a8d39c9634a632db","modified":1485626526000},{"_id":"source/_posts/OS-notes.md","hash":"bc3910e673839fe47e8d3263d8a120b20a78597f","modified":1492368056000},{"_id":"source/_posts/QuadTree.md","hash":"f49ef2bd1def94710756b31b74f3208bc2397d20","modified":1481664012000},{"_id":"source/_posts/Sobolev-space.md","hash":"ccf8b23ac2f15a49576f204f3b309f6c94493017","modified":1486831727000},{"_id":"source/_posts/[2017.12.10]Entity-resolution.md","hash":"16f28c7814d71616705dba24cceff08615abc5d4","modified":1517051250139},{"_id":"source/_posts/[2017.12.17]Relation-Classification-via-Attention-Model.md","hash":"d4e289b265c8e93dc0b5f6979e18911300db813f","modified":1517051383612},{"_id":"source/_posts/[2018.1.14]Models-for-relation-extraction.md","hash":"f1adc2c36835ff0c72b9663ca341448247780b62","modified":1517051843317},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce.md","hash":"bf4685235d48ba7e20d7004ba8c195476e2cd716","modified":1517051909654},{"_id":"source/_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction.md","hash":"4baf209f0acbab5202de6b93cbc46eae6bed152b","modified":1520108242105},{"_id":"source/_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction.md","hash":"85c2dee9cac241d86884c7e47df0552c249b89e4","modified":1517051658400},{"_id":"source/_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion.md","hash":"cad766b84ff0d9f43c9b95198daef57618751c5f","modified":1520108476156},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs.md","hash":"5672ccca950ae1fd587f8dad73cc65055a3ae840","modified":1520108478918},{"_id":"source/_posts/complexity.md","hash":"884bea5a67590cca6019d9a12442352f0e5aa284","modified":1480502588000},{"_id":"source/_posts/compression.md","hash":"6c09d635d6e901b27df17fe64aa759930e9e4ada","modified":1480502772000},{"_id":"source/_posts/datamining-class-pred.md","hash":"bed4bfa4b40d639d5a22a25c135d2ac7fb65eda2","modified":1482767562000},{"_id":"source/_posts/datamining-pretreatment.md","hash":"c274b6cd8f6388eae82e6786eae0da41b0a20a1c","modified":1481228966000},{"_id":"source/_posts/datamining-qualitative-induction.md","hash":"732e1ebd08758c64a7325b269d7f788671221e1b","modified":1482476111000},{"_id":"source/_posts/graph.md","hash":"fb81eb7a78b150f0133ada157a40e8437d3a135c","modified":1486814910000},{"_id":"source/_posts/hexo-with-latex.md","hash":"8bb31822f906a82bc52db60a54d08e6e85c9a94e","modified":1480542334000},{"_id":"source/_posts/learning-OS-and-building-LorriOS.md","hash":"62c7e96f2a44fe667c35e3074986dc8c60551010","modified":1492441961000},{"_id":"source/_posts/machine-learning.md","hash":"5304e7f0e49d9060a8bf3556e1c5a940e249d37c","modified":1481576860000},{"_id":"source/_posts/management-of-the-firm.md","hash":"720d9655a8216e9732a4af5e20cc76e88e7cde5b","modified":1481664406000},{"_id":"source/_posts/participe-present-et-gerondif.md","hash":"754b1e438f2f1c593b0a33993af2b8788db80232","modified":1481664512000},{"_id":"source/_posts/proba-ch1.md","hash":"dba3dc8fb9720b16d533037452729bd83b6599c5","modified":1480591178000},{"_id":"source/_posts/proba-ch2.md","hash":"ce0ed109def5c1802f4cbe2f545698830ac41053","modified":1480599840000},{"_id":"source/_posts/proba-ch3.md","hash":"c83c5d8f3c8b9631fb804fa14bca32b7c8f3df98","modified":1480606117000},{"_id":"source/_posts/proba-ch4.md","hash":"7cd6e2d4d3b7fb4e5f8547082cea9611aa13e542","modified":1482153097000},{"_id":"source/_posts/proba-ch5.md","hash":"ccd8f72481bdf1b8ad53605254a3d3d43c3f3787","modified":1481454317000},{"_id":"source/_posts/proba-ch6.md","hash":"25e4cdddd7bcf976a6491622111db0c7a195e2c3","modified":1480712994000},{"_id":"source/_posts/projet-enjeu-plugin-chrome-101.md","hash":"2b82eded6334d7d1afd6a427c6db2bf71431b4de","modified":1480504742000},{"_id":"source/tags/index.md","hash":"e9f9acd08b85f950a4f28cfcb1e6e237265f6a45","modified":1487104253000},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1480248297000},{"_id":"themes/next/.git/config","hash":"bf7d1df65cf34d0f25a7184a58c37a09f72e4be7","modified":1480248297000},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1480248279000},{"_id":"themes/next/.git/index","hash":"138cae75aa9e592129f7fea1a4281e8fe72c1863","modified":1492522215000},{"_id":"themes/next/.git/packed-refs","hash":"09a09da39b7d77dcf2904850874cf00817abdb45","modified":1480248297000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1480248297000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1480248297000},{"_id":"themes/next/languages/de.yml","hash":"1fdea1f84b7f691f5b4dd4d2b43eeb27b10fa0c8","modified":1480248297000},{"_id":"themes/next/languages/default.yml","hash":"767470a80dc257e23e14c3a78e8c52a46c9d6209","modified":1480248297000},{"_id":"themes/next/languages/en.yml","hash":"40057d6608e825d06e0864bac4dcd27ed88ada87","modified":1480248297000},{"_id":"themes/next/languages/id.yml","hash":"34396bef27c4ab9e9a3c5d3e3aa94b0e3b3a7b0d","modified":1480248297000},{"_id":"themes/next/languages/fr-FR.yml","hash":"9fca01ef917d33ae2ae6bc04561ec6799dff5351","modified":1480248297000},{"_id":"themes/next/languages/ja.yml","hash":"49f12149edcc1892b26a6207328cda64da20116d","modified":1480248297000},{"_id":"themes/next/languages/ko.yml","hash":"b6bc5d6b0c000deb44099b42d3aebb8c49dbfca9","modified":1480248297000},{"_id":"themes/next/languages/pt-BR.yml","hash":"7742ba4c0d682cbe1d38305332ebc928abd754b5","modified":1480248297000},{"_id":"themes/next/languages/pt.yml","hash":"6b660b117314cad93f08757601df3adb04c68beb","modified":1480248297000},{"_id":"themes/next/languages/ru.yml","hash":"257d11e626cbe4b9b78785a764190b9278f95c28","modified":1480248297000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"f6c9fafa0f5f0050cd07ca2cf5e38fbae3e28145","modified":1480248297000},{"_id":"themes/next/languages/zh-hk.yml","hash":"34c84c6d04447a25bd5eac576922a13947c000e2","modified":1480248297000},{"_id":"themes/next/languages/zh-tw.yml","hash":"c97a5c41149de9b17f33439b0ecf0eff6fdae50e","modified":1480248297000},{"_id":"themes/next/layout/_layout.swig","hash":"7a1e4443c3ba1e08c20e64ddbf0b8255d034dab0","modified":1480248297000},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1480248297000},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1480248297000},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1480248297000},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1480248297000},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1480248297000},{"_id":"themes/next/layout/schedule.swig","hash":"1f1cdc268f4ef773fd3ae693bbdf7d0b2f45c3a3","modified":1480248297000},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1480248297000},{"_id":"themes/next/scripts/merge-configs.js","hash":"0c56be2e85c694247cfa327ea6d627b99ca265e8","modified":1480248297000},{"_id":"themes/next/source/.DS_Store","hash":"3037d5331d92d3f549f33102664cadfff9459707","modified":1481024235000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1480248297000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1480248297000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1480248297000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"source/_posts/[2018.1.14]Models-for-relation-extraction/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1517050998422},{"_id":"source/_posts/[2018.1.14]Models-for-relation-extraction/overview.png","hash":"c224e9ebe4cccb3ebdac23530bf34ea7160c6aa7","modified":1515929992000},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1520108081668},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce/augmented_event.png","hash":"2aaf68ccdfa8c11ed635b097d2e6bea4dcf92cfe","modified":1516574691432},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce/basic_event.png","hash":"6d966d42c069d3b4130d8e244c451f67e3deb00a","modified":1516574693417},{"_id":"source/_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1520108363233},{"_id":"source/_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1517050610862},{"_id":"source/_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/MWRW.png","hash":"b265ab4543b43c71c8b84e3acc4d9bb2b7e2f080","modified":1520108371210},{"_id":"source/_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/arch.png","hash":"fe2c2d54c53a6708924205616fd8b2805f920a51","modified":1520108365754},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1520108358226},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/ComputationalGraph.png","hash":"4320aaa366876d41db28d0e4840e502390a28242","modified":1520108178828},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/NestedLSTM.png","hash":"45408662df9015fd9cee7a23cf3d430868792aeb","modified":1520108175032},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/StackedLSTM.png","hash":"b1ee2f1705b2bbbc6b83df966b656844d6e3babd","modified":1520108170088},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1480248279000},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1480248279000},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1480248279000},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1480248279000},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1480248279000},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1480248279000},{"_id":"themes/next/.git/logs/HEAD","hash":"54213eda4d20b2a283cee08a3595ada36e83cb1c","modified":1480248297000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1480248297000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1480248297000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"43c3433155ccd9abcbe7dce2e6bfa1f3a66af18b","modified":1480248297000},{"_id":"themes/next/layout/_macro/post.swig","hash":"f12f108c1f8e91cc55d49805d42c1fd96cdf51a6","modified":1480248297000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1480248297000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"b8aaa008aafe4c6e325f7513719e1c251430883e","modified":1480248297000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1480248297000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"7a3ef28678467c45ee9416b41b943252e8036285","modified":1480248297000},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1480248297000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"1a43dde8c7bc53891be26b915a172b1f01e6bc26","modified":1480248297000},{"_id":"themes/next/layout/_partials/head.swig","hash":"ca56f92e2fa82b03853869f5073ee1a5626a4796","modified":1480248297000},{"_id":"themes/next/layout/_partials/header.swig","hash":"f3627f51810bc906e4020a3fef61bc3629b63581","modified":1480248297000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"39d613e5a9f8389d4ea52d6082502af8e833b9f2","modified":1480248297000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1480248297000},{"_id":"themes/next/layout/_partials/search.swig","hash":"1431719d1dbba3f5ee385eebc46376d1a960b2d5","modified":1480248297000},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1480248297000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1480248297000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1480248297000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"0b91cadecead8e0b5211cc42b085998d94af503a","modified":1480248297000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1480248297000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1480248297000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1480248297000},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1480248297000},{"_id":"themes/next/source/css/.DS_Store","hash":"bbd874d841ee8ed19a25b4fd8382ed8fc6f2c115","modified":1481024373000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1480248297000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1480248297000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1480248297000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1480248297000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1480248297000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1480248297000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1480248297000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1480248297000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1480248297000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1480248297000},{"_id":"source/_posts/[2018.1.14]Models-for-relation-extraction/wrong_label_reduction.png","hash":"7bf67222e13359a6be5507ff13eaa1e1a89c96b5","modified":1515931684000},{"_id":"source/_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/character.png","hash":"2047682e5dc674ba0f491dedf86c2e05d6640fc7","modified":1520108076453},{"_id":"source/_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/illustration.png","hash":"850490e1de15716548426f5c11c3dd61d9812b36","modified":1520108368013},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce/overview.png","hash":"63840233165ca42bf6a82222e1b41af076a4957c","modified":1516574695385},{"_id":"source/_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/trigger_labeling.png","hash":"9cf3fff26c6b386c510cdf0a6f96956455b31a05","modified":1520108079110},{"_id":"source/_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/algo.png","hash":"6cccb33d32c7a598ffbf6fdb7a7514be354323b8","modified":1515061502000},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/GNMT_residual.png","hash":"c4296248b686bca6cae82a5cdd01ea76ab14b691","modified":1520108177170},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/singleLSTM.png","hash":"fe48376830ec3f50d45b33804142511e0f543196","modified":1520108172928},{"_id":"themes/next/.git/refs/heads/master","hash":"776e91b78b954875a8d38297e05b80eab20df4b9","modified":1480248297000},{"_id":"themes/next/layout/_components/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1480248297000},{"_id":"themes/next/layout/_components/algolia-search/dom.swig","hash":"636f1181dd5887a70b4a08ca8f655d4e46635792","modified":1480248297000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1480248297000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1480248297000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"ff5523d5dacaa77a55a24e50e6e6530c3b98bfad","modified":1480248297000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1480248297000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1480248297000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1480248297000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1480248297000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1480248297000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1480248297000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1480248297000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"394d9fff7951287cc90f52acc2d4cbfd1bae079d","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"82a2ac14d4200480a36bf10abcc3cc554ad744d6","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"b460e27db3dcd4ab40b17d8926a5c4e624f293a9","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1480248297000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1480248297000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1480248297000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"c5b28519b446c2af1e8754a6ae4d766823e6b348","modified":1480248297000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"3f0d6aa424f434e82ea507f740eeff110f996269","modified":1480248297000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1480248297000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"96b29f69b8b916b22f62c9959a117b5a968200a5","modified":1480248297000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1480248297000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1480248297000},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1480248297000},{"_id":"themes/next/source/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1480248297000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1480248297000},{"_id":"themes/next/source/js/src/utils.js","hash":"384e17ff857f073060f5bf8c6e4f4b7353236331","modified":1480248297000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"c1072942459fa0880e8a33a1bd929176b62b4171","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1480248297000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1480248297000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1480248297000},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"54213eda4d20b2a283cee08a3595ada36e83cb1c","modified":1480248297000},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"7c43d66da93cde65b473a7d6db2a86f9a42647d6","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"4fcbf57c4918528ab51d3d042cff92cf5aefb599","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"fb1d04ede838b52ca7541973f86c3810f1ad396e","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"b49efc66bd055a2d0be7deabfcb02ee72a9a28c8","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"10994990d6e0b4d965a728a22cf7f6ee29cae9f6","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1480248297000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5304f99581da3a31de3ecec959b7adf9002fde83","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"54c90cf7bdbf5c596179d8dae6e671bad1292662","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"4303776991ef28f5742ca51c7dffe6f12f0acf34","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"be22ad34f546a07f6d56b424338cdd898683eea4","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_full-image.styl","hash":"938d39eedc6e3d33918c1145a5bf1e79991d3fcf","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"7b206cd8921bc042f8e37a74aea1abc8a5ec8ab4","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"d09280e5b79f3b573edb30f30c7a5f03ac640986","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"d4b7bd610ca03dbb2f5b66631c0e84a79fb4660b","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"1b10ba2d3ad0c063c418dc94a0b7e0db4b342c53","modified":1480248297000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"7506e7490c69a200831393c38d25e91c156bd471","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"4eda182cbcc046dbf449aef97c02c230cf80a494","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"fb5b49426dee7f1508500e698d1b3c6b04c8fcce","modified":1480248297000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1480248297000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1480248297000},{"_id":"themes/next/.git/objects/pack/pack-5c4d26201d7d4cf7b7a109eab4d66f2aa3d88bca.idx","hash":"3a1a29007edd8fef8ba11b3a97678e2904c934ff","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1480248297000},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"54213eda4d20b2a283cee08a3595ada36e83cb1c","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"c890ce7fe933abad7baf39764a01894924854e92","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"4b7f81e1006e7acee3d1c840ccba155239f830cc","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"c44f6a553ec7ea5508f2054a13be33a62a15d3a9","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"2d3abbc85b979a648e0e579e45f16a6eba49d1e7","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"5357db10656b260f8b332c67bb06e486bc64a4ad","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-more-link.styl","hash":"15063d79b5befc21820baf05d6f20cc1c1787477","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"c6dab7661a6b8c678b21b7eb273cef7100f970f6","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"4eb18b12fa0ea6c35925d9a64f64e2a7dae8c7fd","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"618f73450cf541f88a4fddc3d22898aee49d105d","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"3eb73cee103b810fa56901577ecb9c9bb1793cff","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"eba491ae624b4c843c8be4c94a044085dad4ba0f","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"b03f891883446f3a5548b7cc90d29c77e62f1053","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"637c6b32c58ecf40041be6e911471cd82671919b","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"5433b6bc9d8f0c4685e760b326445ac51245b0a8","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1480248297000},{"_id":"source/_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/illustration.png","hash":"9c2acae5a552988ce560e5a421cdba162400c3da","modified":1515041712000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1480248297000},{"_id":"source/_posts/Generative-Adversarial-Network/gan.png","hash":"389484961aeaa1b5d5d030dc75d0d53a5dfadff0","modified":1498390315000},{"_id":"themes/next/.git/objects/pack/pack-5c4d26201d7d4cf7b7a109eab4d66f2aa3d88bca.pack","hash":"ed727435eb82de0486b2a011827e53b71342c928","modified":1480248297000},{"_id":"public/google50e2fbd5160eafe4.html","hash":"b8d5d5a8de84985f9fa8f95a1e3c6a1131130797","modified":1520109494009},{"_id":"public/categories/index.html","hash":"5e8cd0f8dc192f9e78a32c3b8fac16360c1fa013","modified":1520109494009},{"_id":"public/tags/index.html","hash":"e08d3d9bbde467acc47cf931c4752aa9b665d24c","modified":1520109494009},{"_id":"public/2017/03/31/EDP-finite-element-method/index.html","hash":"88f72bd57f419bd87ff52013d12d2d6a6ec16d9e","modified":1520109494009},{"_id":"public/2016/12/12/machine-learning/index.html","hash":"f544300dd58ff89aaa431cc9ffb3b8a968a1c94b","modified":1520109494009},{"_id":"public/2016/12/02/proba-ch6/index.html","hash":"cc62259bc2218b7068059b8150317651abb8872c","modified":1520109494009},{"_id":"public/2016/12/01/proba-ch4/index.html","hash":"b9cd11e0f19a9b437a1ba0d246855aea9f4d9c3c","modified":1520109494009},{"_id":"public/2016/12/01/proba-ch1/index.html","hash":"4d2c1a0fc9f5066ff4dc945f3f084e9f83705b2d","modified":1520109494009},{"_id":"public/2016/11/30/hexo-with-latex/index.html","hash":"c47c9e4d54c7d5b070d43ce76b4e4bd256e53a0c","modified":1520109494009},{"_id":"public/2016/11/27/compression/index.html","hash":"fa46d848ae7eb561fd490b929b1d9b01b259b500","modified":1520109494009},{"_id":"public/archives/page/5/index.html","hash":"64f01d6c4a9959a7eaf5586fde5fbf310f50f145","modified":1520109494010},{"_id":"public/archives/2016/page/3/index.html","hash":"09cd08438221be76bbcea83582b09f2f2ba9a310","modified":1520109494010},{"_id":"public/archives/2016/11/index.html","hash":"d8fa72a9159375306c5f822740e873f92a4923c3","modified":1520109494010},{"_id":"public/archives/2016/12/page/2/index.html","hash":"11c15582fb8941b6982ca1dcfd73338090124076","modified":1520109494010},{"_id":"public/archives/2017/page/2/index.html","hash":"57ee120a0569242455ab11b448f7fd28f433ca9a","modified":1520109494010},{"_id":"public/archives/2017/01/index.html","hash":"25f95190e6399faf8cb18c3d8466cbeb6bc5aa7a","modified":1520109494010},{"_id":"public/archives/2017/02/index.html","hash":"0b7ccdc11cfafdebd5d4610c2ca917f8f38cb163","modified":1520109494010},{"_id":"public/archives/2017/03/index.html","hash":"4dbcdb4a31b074a236ec497b21f7654f1036b1fe","modified":1520109494010},{"_id":"public/archives/2017/04/index.html","hash":"7895cdcb56f865d4c74f45cea641d959f248754f","modified":1520109494010},{"_id":"public/archives/2017/06/index.html","hash":"28d9f5c16adde0f042d01ee742edfa7dfd39a469","modified":1520109494010},{"_id":"public/archives/2017/12/index.html","hash":"e2951878e1ba7ef8674314bdc9fdc47fddf2bcbf","modified":1520109494010},{"_id":"public/archives/2018/index.html","hash":"024f14b3e11ce9fd3991d957e11a58aa00ee6437","modified":1520109494010},{"_id":"public/archives/2018/01/index.html","hash":"2cad9c587ea039908796a57ca36cd4cc3450b130","modified":1520109494010},{"_id":"public/archives/2018/02/index.html","hash":"dd6eb8b378781766e9a8a48bd18e84b8da0f241a","modified":1520109494010},{"_id":"public/categories/math/index.html","hash":"7c423294d7f433a66601d21ac844817533159816","modified":1520109494010},{"_id":"public/categories/math/page/2/index.html","hash":"0675bb42d63a5ffcb42c0c3fcf7e7baf1f0ed2ac","modified":1520109494010},{"_id":"public/categories/math/unfinished/index.html","hash":"8239cec7b08ee4e70349f5e61ecf64f48ac1ba2c","modified":1520109494010},{"_id":"public/categories/programming/index.html","hash":"10107c8c553a8e8a12506f731b9099c932b555ad","modified":1520109494010},{"_id":"public/categories/programming/page/2/index.html","hash":"a9cd5c9e22ae31daaaefdf803af64d26f9a65aaa","modified":1520109494010},{"_id":"public/categories/programming/unfinished/index.html","hash":"9b8a269e27d2e4831a85d5c84935e895e9295440","modified":1520109494010},{"_id":"public/categories/research/index.html","hash":"14e441d12d07f1701f581a5f25f9ad664e0785a0","modified":1520109494010},{"_id":"public/categories/other/index.html","hash":"7527adbb717deb245bd1619dd9d4c35152c150f5","modified":1520109494010},{"_id":"public/categories/francais/index.html","hash":"05c4e3c0dda10babb52c06cfe1f0b45823820c74","modified":1520109494011},{"_id":"public/tags/Bayes/index.html","hash":"e1a644f31d704a8b2a4ddb22e79996761a20529d","modified":1520109494011},{"_id":"public/tags/statistic/index.html","hash":"d3f95a553d4eaf6897e049010d1c33255cee8436","modified":1520109494011},{"_id":"public/tags/EDP/index.html","hash":"06009470db8fa0df3e00f173c07d3a4f21753dc6","modified":1520109494011},{"_id":"public/tags/matrix/index.html","hash":"fdbafae6aa5e4d7df9a49db353df789d759e196f","modified":1520109494011},{"_id":"public/tags/math/index.html","hash":"d4c393bcbe82e8cd874d745b6b125e2d6fdf7809","modified":1520109494011},{"_id":"public/tags/math/page/2/index.html","hash":"b90058b6b29677a70783ee70525c0ccb2d294d99","modified":1520109494011},{"_id":"public/tags/FEM/index.html","hash":"e59b9c3739fadc64938864f7239b1ad607b72478","modified":1520109494011},{"_id":"public/tags/GAN/index.html","hash":"8764230f73b75cb246d95be1a2bfe66ac9a12201","modified":1520109494011},{"_id":"public/tags/deep-learning/index.html","hash":"092d1572b352b0c699234312bcfd47d52553c341","modified":1520109494011},{"_id":"public/tags/scrapy/index.html","hash":"571b6e3ae6d1e77bd6e5cc3785761c813cf1cd0f","modified":1520109494011},{"_id":"public/tags/python/index.html","hash":"3db76d64ac9194bf948768e1b3dd1f853a7d8a6e","modified":1520109494011},{"_id":"public/tags/spider/index.html","hash":"6c6e017eadc770efc43488c831f2a239ffda8165","modified":1520109494011},{"_id":"public/tags/crawl/index.html","hash":"a9dc4c5c232315417a8449cd6040463428815e3e","modified":1520109494011},{"_id":"public/tags/Hilbert/index.html","hash":"d1c878fb4d3f6826dc2788d908ec37ce92dc5488","modified":1520109494011},{"_id":"public/tags/analyse/index.html","hash":"82bfb067706638f4fa132ef57ba89ca83bce5f3c","modified":1520109494011},{"_id":"public/tags/machine-learning/index.html","hash":"7cc108f11cddb525c4ee25c730ef643f2262d6e0","modified":1520109494011},{"_id":"public/tags/programming/index.html","hash":"35dca6ec8675c269f9f1a70d94b372f7d11521ce","modified":1520109494011},{"_id":"public/tags/algo/index.html","hash":"ae733897b1517d8e6fe230748f9a197b1547c25c","modified":1520109494011},{"_id":"public/tags/CNN/index.html","hash":"ec3bb02f2bb015ca425ab3ebc110d0d1cad60756","modified":1520109494011},{"_id":"public/tags/mongo/index.html","hash":"988f771e10558aba350f699efdb7bb9bf6a2d5ea","modified":1520109494011},{"_id":"public/tags/mongodb/index.html","hash":"94f3f2db045d597d834a46f96f38fcc11cbc63df","modified":1520109494012},{"_id":"public/tags/docker/index.html","hash":"8fc0f35290fb50e3e689d562fac3665bf6cafa1f","modified":1520109494012},{"_id":"public/tags/nlp/index.html","hash":"b6762485cf4609f275db51b27984942dcf61b52a","modified":1520109494012},{"_id":"public/tags/datamining/index.html","hash":"326e2d2797eea62f2d4e891b8ae52559dbc36216","modified":1520109494012},{"_id":"public/tags/knowledge-graph/index.html","hash":"79576f293f7b663e4ea4c0a4296495a24c01be05","modified":1520109494012},{"_id":"public/tags/probability/index.html","hash":"5cb4087b84266f8b79807e98deb73ca0284246cd","modified":1520109494012},{"_id":"public/tags/OS/index.html","hash":"1d0390954ebd879f63a444d8ddc3eb2b59dabd00","modified":1520109494012},{"_id":"public/tags/data-structure/index.html","hash":"e9c8f5952e4e5afab2d733b8ac0f103a27489229","modified":1520109494012},{"_id":"public/tags/Sobolev/index.html","hash":"9579d79eac4f3d8ab1cd33a1b4a3be5ca5c18b81","modified":1520109494012},{"_id":"public/tags/relation-classification/index.html","hash":"52e91f62fc6035453b9f2fe728fc7fa6a219f62e","modified":1520109494012},{"_id":"public/tags/attention/index.html","hash":"c9b70291fe527c5935e5e2e8ec5831a5ef76602d","modified":1520109494012},{"_id":"public/tags/relation-extraction/index.html","hash":"0c4334db50afab15021513eb879a095c9d6acffd","modified":1520109494012},{"_id":"public/tags/entity-resolution/index.html","hash":"317c35d7ff7df5ac05b7eb9e78b2a11733ae9dda","modified":1520109494012},{"_id":"public/tags/sequence-labeling/index.html","hash":"b94a0bcf1c183f84cc0948b566a3f784db7837e3","modified":1520109494013},{"_id":"public/tags/LSTM/index.html","hash":"18d7b3ace2be002062bdbd18dbefc7ba104e1f97","modified":1520109494013},{"_id":"public/tags/RNN/index.html","hash":"f24947f918b4b807bd2c1e7d9eae882de00b1d41","modified":1520109494013},{"_id":"public/tags/distant-supervision/index.html","hash":"705f2f7d8a181e6a5259cb65ab6d2d6dba36ac51","modified":1520109494013},{"_id":"public/tags/event-detection/index.html","hash":"b526117598be41e9a90ad207e583dcac40af0e3b","modified":1520109494013},{"_id":"public/tags/co-reference/index.html","hash":"b04a1a6f414dee296c4757a4f0d040b1dc5c80ae","modified":1520109494013},{"_id":"public/tags/convolution/index.html","hash":"048a924f1ed7f5963f6da5e9d38556aad83d5671","modified":1520109494013},{"_id":"public/tags/BiLSTM/index.html","hash":"c19636d69827e711ac211a95bfa5eb201f07d6bd","modified":1520109494013},{"_id":"public/tags/event-extraction/index.html","hash":"248628749a0f9994d8512948876ea246f6ab2fa3","modified":1520109494013},{"_id":"public/tags/limited-supervision/index.html","hash":"8f6584aff279a28973bdeb41061987cdb3306416","modified":1520109494013},{"_id":"public/tags/weak-supervision/index.html","hash":"2cff7b8db0a74d5661c5a073c411a90973f58a72","modified":1520109494013},{"_id":"public/tags/KGC/index.html","hash":"e65e16a1cc9ecfcb49e11bd6828389006d0a1b52","modified":1520109494013},{"_id":"public/tags/complexity/index.html","hash":"5e15133966c3a14415d6a1a89684f1b7bb2b41fa","modified":1520109494013},{"_id":"public/tags/compression/index.html","hash":"fa6b20fdf522e3f7300df085ce97756a8a2ba238","modified":1520109494013},{"_id":"public/tags/classification/index.html","hash":"36d4a50969e53e7ed70129ae557787e8fa5e8a08","modified":1520109494013},{"_id":"public/tags/prediction/index.html","hash":"b35b1e4edd47883693d5c64b8cdbc09e09811b09","modified":1520109494013},{"_id":"public/tags/qualitative-induction/index.html","hash":"1a801acec6040e8ee63c645b878ca05a07e932c7","modified":1520109494013},{"_id":"public/tags/graph/index.html","hash":"d835fd36d888f99d82d1dd8e1308b8afb0d737d3","modified":1520109494013},{"_id":"public/tags/hexo/index.html","hash":"afd84447c6368c64e311849663bc1f7eaae7aa33","modified":1520109494013},{"_id":"public/tags/latex/index.html","hash":"4e020a87b58ea44113397eb99d7830aaa9f631c4","modified":1520109494013},{"_id":"public/tags/mathjax/index.html","hash":"9869d1764e79b6523d7384359430d064727d7626","modified":1520109494013},{"_id":"public/tags/marked/index.html","hash":"2a0010c993be4d979e6923c30516f3bae5081e98","modified":1520109494013},{"_id":"public/tags/kernel/index.html","hash":"b9a23e89dcfe34dbb309c87730bb0124871f5bf0","modified":1520109494013},{"_id":"public/tags/management/index.html","hash":"58ed845993b46809bd6ebfadb486f85ceb55b81e","modified":1520109494013},{"_id":"public/tags/firm/index.html","hash":"288e85024bd886642f980da721d8fe6cee382e11","modified":1520109494013},{"_id":"public/tags/francais/index.html","hash":"5116240287eb0fda92967f42792cba2f02866a63","modified":1520109494014},{"_id":"public/tags/language/index.html","hash":"b3fb470f5ea0beb62401bc5c716e4c9bbaa131d7","modified":1520109494014},{"_id":"public/tags/aleatoire/index.html","hash":"852c8a5a949b9d6ac90bcd2c8e051e3248ae8c8a","modified":1520109494014},{"_id":"public/tags/vector/index.html","hash":"fad4e5d9c2f3c3cb3abcf9d8603750f8cf579fa3","modified":1520109494014},{"_id":"public/tags/web/index.html","hash":"ae9c0e3c0981ba254abfaa0699022fcb8547c02a","modified":1520109494014},{"_id":"public/tags/chrome/index.html","hash":"9608080881a4055c71f099b2f71012f6e28408db","modified":1520109494014},{"_id":"public/2018/02/26/[2018.2.26]Open-World-Knowledge-Graph-Completion/index.html","hash":"08fc637a309b2e7921d40b587d4d0830bf77cff4","modified":1520109494014},{"_id":"public/2018/02/05/[2018.2.5]Nested-LSTMs/index.html","hash":"393874f5356e6702c2f6c7326cdbd4eadf8a78ec","modified":1520109494014},{"_id":"public/2018/01/29/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/index.html","hash":"ce9a75a7aa1eefa630770f1d0968b162fb9f94ca","modified":1520109494014},{"_id":"public/2018/01/21/[2018.1.21]Event-detection-and-co-referentce/index.html","hash":"b19ccb6e7b361c5c644938818f85d482be072f18","modified":1520109494014},{"_id":"public/2018/01/14/[2018.1.14]Models-for-relation-extraction/index.html","hash":"70e67fb20c8c3defc6dfe231048356d847116396","modified":1520109494014},{"_id":"public/2018/01/04/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/index.html","hash":"fc94e5d858f7cbcd3774f89b6ffa867623704c58","modified":1520109494014},{"_id":"public/2017/12/17/[2017.12.17]Relation-Classification-via-Attention-Model/index.html","hash":"04bb89a17b9c7c059dd610574dc100f4e45a2f6c","modified":1520109494014},{"_id":"public/2017/12/10/[2017.12.10]Entity-resolution/index.html","hash":"fe0feecbcd547f62abdc05d5a59f086a3db6de71","modified":1520109494014},{"_id":"public/2017/06/26/Note-of-NLP/index.html","hash":"68596c094569ed69a839063a284fc8b2d1fa5045","modified":1520109494014},{"_id":"public/2017/06/25/Generative-Adversarial-Network/index.html","hash":"d79284afa7e8573c79756f7192f52d8304eccfee","modified":1520109494014},{"_id":"public/2017/06/25/Note-of-knowledge-graph/index.html","hash":"f68b7abe87562c231f8ce54e4bb120e020dd9f4e","modified":1520109494014},{"_id":"public/2017/06/22/MongoDB-Docker-and-Python/index.html","hash":"e4e6eecb500d6c80faed0d7a1e1bb20c78d92d86","modified":1520109494014},{"_id":"public/2017/06/21/Hands-on-Scrapy/index.html","hash":"383c3f96d249ecb176f611f842148437b164383f","modified":1520109494014},{"_id":"public/2017/04/15/OS-notes/index.html","hash":"006ac4f809e63b8e8851e5680e5c151074378bb4","modified":1520109494014},{"_id":"public/2017/03/06/EDP-basic-models/index.html","hash":"8a99cae4a75fbba2cfa5ca65d94d86500a1df0a1","modified":1520109494014},{"_id":"public/2017/02/11/Sobolev-space/index.html","hash":"0e02cf1f042fe64d9a8b273dbeb446f4ce22a273","modified":1520109494015},{"_id":"public/2017/02/11/Hilbert-space/index.html","hash":"5896d05bc0571b05e0aad7df53ac739bac53a066","modified":1520109494015},{"_id":"public/2017/02/07/EDP-basic-matrix-review/index.html","hash":"d546cbe7f248a02095c8f4c31f30eda95f807659","modified":1520109494015},{"_id":"public/2017/01/28/Note-of-statistic/index.html","hash":"bcb01e068a9ec575e7533eded4d6550a4abb24ac","modified":1520109494015},{"_id":"public/2017/01/07/Bayes-estimation/index.html","hash":"a43cb9b140f43b2fe8d87e6f229178d23998f292","modified":1520109494015},{"_id":"public/2016/12/28/learning-OS-and-building-LorriOS/index.html","hash":"f0d41134bda5c682deab57878e6f215b7fceade0","modified":1520109494015},{"_id":"public/2016/12/26/datamining-class-pred/index.html","hash":"30eb344f04017778572dc6609b1724397ea493ba","modified":1520109494015},{"_id":"public/2016/12/14/ML-CNN/index.html","hash":"7911f16a85f2054b0932d223e73f5a3f51e774dc","modified":1520109494015},{"_id":"public/2016/12/13/QuadTree/index.html","hash":"7bb90720bd07e3be296fb8d9f7ee69fc83b607af","modified":1520109494015},{"_id":"public/2016/12/10/management-of-the-firm/index.html","hash":"d2e509e10a3d7ff163ed56935025350bbd2b6d4e","modified":1520109494015},{"_id":"public/2016/12/08/datamining-qualitative-induction/index.html","hash":"f59265e5c830617147d9b4d60a62ae3a8850b757","modified":1520109494015},{"_id":"public/2016/12/06/datamining-pretreatment/index.html","hash":"4fd2c58f55afa3a39b1d2196885f1a870b072f89","modified":1520109494015},{"_id":"public/2016/12/06/participe-present-et-gerondif/index.html","hash":"9db67da3232c4cb89fe07be5fe54d5421915bed5","modified":1520109494015},{"_id":"public/2016/12/06/Note-of-datamining/index.html","hash":"52011628e1acb77fa82e87506eb7c2657ecd75b0","modified":1520109494015},{"_id":"public/2016/12/01/proba-ch5/index.html","hash":"700d8843bd18e9648d58a3c9bde50f26b99e4898","modified":1520109494015},{"_id":"public/2016/12/01/proba-ch3/index.html","hash":"f16ea47fecd0c353aa7625e2438df45f07c83975","modified":1520109494015},{"_id":"public/2016/12/01/proba-ch2/index.html","hash":"5a959109dab60dc41129426f348df2fb389d263f","modified":1520109494015},{"_id":"public/2016/11/30/Note-of-probability/index.html","hash":"e78b4b0ffe49224b82984368a8579d66b004f7de","modified":1520109494015},{"_id":"public/2016/11/30/projet-enjeu-plugin-chrome-101/index.html","hash":"6fd849cb18d72459b8b2b9a16a00a828481c812e","modified":1520109494015},{"_id":"public/2016/11/27/graph/index.html","hash":"5ff61faacb18e83f829a751c5a53d6feb3ba5439","modified":1520109494016},{"_id":"public/2016/11/27/Method-of-programming-facing-to-exams/index.html","hash":"6566e9a207d940c8adf242555a470327a34d8d81","modified":1520109494016},{"_id":"public/2016/11/27/Note-of-learning-Algo/index.html","hash":"91173ebfc7a15acee0cac2d7aaf7f4e5375ae39f","modified":1520109494016},{"_id":"public/2016/11/27/complexity/index.html","hash":"21d3c95bb05a2f286aff61ed3b78bdb59eb21816","modified":1520109494016},{"_id":"public/archives/index.html","hash":"0b5a25077f211bce64d371c71c4aca19800b3910","modified":1520109494017},{"_id":"public/archives/page/2/index.html","hash":"bf251c637ca6e2a060f65692fcd47140154e02ff","modified":1520109494017},{"_id":"public/archives/page/3/index.html","hash":"5de324c82024739deb8b58c31e2af825109095b0","modified":1520109494017},{"_id":"public/archives/page/4/index.html","hash":"3c1d075cfc4533eaa934230f974c249345510502","modified":1520109494017},{"_id":"public/archives/2016/index.html","hash":"581f061cb38c6724f0d74fcccf9e0fed4229982f","modified":1520109494017},{"_id":"public/archives/2016/page/2/index.html","hash":"a3515f423b7b918b5f5aee10d808840690ce4c78","modified":1520109494017},{"_id":"public/archives/2016/12/index.html","hash":"4b9cd79597cf5f94021284105b27acd849fc967d","modified":1520109494017},{"_id":"public/archives/2017/index.html","hash":"71d33bfe3da0113c9196c3b2688938e5c8ea480e","modified":1520109494017},{"_id":"public/index.html","hash":"2c07115614d3aefccba5fed30e91e56e591cff68","modified":1520109494017},{"_id":"public/page/2/index.html","hash":"a2e2bf9ed8126fc4122ae1ae784effea0b229380","modified":1520109494017},{"_id":"public/page/3/index.html","hash":"7b19e3818b8f6dd94cb0612af04c0efed0cecaa6","modified":1520109494017},{"_id":"public/page/4/index.html","hash":"48eb5d1e012a52a29e64fd2e56327f0a56ea5c85","modified":1520109494017},{"_id":"public/page/5/index.html","hash":"b4ad03be4b5346e562cc98da8df114b7e072b74e","modified":1520109494017},{"_id":"public/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1520109494034},{"_id":"public/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1520109494034},{"_id":"public/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1520109494034},{"_id":"public/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1520109494034},{"_id":"public/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1520109494034},{"_id":"public/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1520109494034},{"_id":"public/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1520109494035},{"_id":"public/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1520109494035},{"_id":"public/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1520109494035},{"_id":"public/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1520109494035},{"_id":"public/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1520109494035},{"_id":"public/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1520109494035},{"_id":"public/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1520109494035},{"_id":"public/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1520109494035},{"_id":"public/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1520109494035},{"_id":"public/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1520109494035},{"_id":"public/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1520109494035},{"_id":"public/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1520109494035},{"_id":"public/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1520109494035},{"_id":"public/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1520109494035},{"_id":"public/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1520109494035},{"_id":"public/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1520109494035},{"_id":"public/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1520109494035},{"_id":"public/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1520109494035},{"_id":"public/2018/01/14/[2018.1.14]Models-for-relation-extraction/overview.png","hash":"c224e9ebe4cccb3ebdac23530bf34ea7160c6aa7","modified":1520109494036},{"_id":"public/2018/01/21/[2018.1.21]Event-detection-and-co-referentce/augmented_event.png","hash":"2aaf68ccdfa8c11ed635b097d2e6bea4dcf92cfe","modified":1520109494036},{"_id":"public/2018/01/21/[2018.1.21]Event-detection-and-co-referentce/basic_event.png","hash":"6d966d42c069d3b4130d8e244c451f67e3deb00a","modified":1520109494036},{"_id":"public/2018/02/26/[2018.2.26]Open-World-Knowledge-Graph-Completion/MWRW.png","hash":"b265ab4543b43c71c8b84e3acc4d9bb2b7e2f080","modified":1520109494036},{"_id":"public/2018/02/26/[2018.2.26]Open-World-Knowledge-Graph-Completion/arch.png","hash":"fe2c2d54c53a6708924205616fd8b2805f920a51","modified":1520109494036},{"_id":"public/2018/02/05/[2018.2.5]Nested-LSTMs/ComputationalGraph.png","hash":"4320aaa366876d41db28d0e4840e502390a28242","modified":1520109494036},{"_id":"public/2018/02/05/[2018.2.5]Nested-LSTMs/NestedLSTM.png","hash":"45408662df9015fd9cee7a23cf3d430868792aeb","modified":1520109494036},{"_id":"public/2018/02/05/[2018.2.5]Nested-LSTMs/StackedLSTM.png","hash":"b1ee2f1705b2bbbc6b83df966b656844d6e3babd","modified":1520109494036},{"_id":"public/lib/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1520109494767},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1520109494779},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1520109494785},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1520109494785},{"_id":"public/2018/01/14/[2018.1.14]Models-for-relation-extraction/wrong_label_reduction.png","hash":"7bf67222e13359a6be5507ff13eaa1e1a89c96b5","modified":1520109494785},{"_id":"public/2018/01/29/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/character.png","hash":"2047682e5dc674ba0f491dedf86c2e05d6640fc7","modified":1520109494786},{"_id":"public/2018/02/26/[2018.2.26]Open-World-Knowledge-Graph-Completion/illustration.png","hash":"850490e1de15716548426f5c11c3dd61d9812b36","modified":1520109494786},{"_id":"public/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1520109494796},{"_id":"public/js/src/algolia-search.js","hash":"96b29f69b8b916b22f62c9959a117b5a968200a5","modified":1520109494796},{"_id":"public/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1520109494796},{"_id":"public/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1520109494796},{"_id":"public/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1520109494796},{"_id":"public/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1520109494796},{"_id":"public/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1520109494796},{"_id":"public/js/src/utils.js","hash":"384e17ff857f073060f5bf8c6e4f4b7353236331","modified":1520109494796},{"_id":"public/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1520109494796},{"_id":"public/lib/fastclick/bower.json","hash":"4dcecf83afddba148464d5339c93f6d0aa9f42e9","modified":1520109494796},{"_id":"public/lib/font-awesome/bower.json","hash":"64394a2a9aa00f8e321d8daa5e51a420f0e96dad","modified":1520109494796},{"_id":"public/lib/jquery_lazyload/bower.json","hash":"ae3c3b61e6e7f9e1d7e3585ad854380ecc04cf53","modified":1520109494796},{"_id":"public/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1520109494797},{"_id":"public/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1520109494797},{"_id":"public/lib/velocity/bower.json","hash":"0ef14e7ccdfba5db6eb3f8fc6aa3b47282c36409","modified":1520109494797},{"_id":"public/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1520109494797},{"_id":"public/js/src/schemes/pisces.js","hash":"7506e7490c69a200831393c38d25e91c156bd471","modified":1520109494797},{"_id":"public/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1520109494797},{"_id":"public/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1520109494797},{"_id":"public/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1520109494797},{"_id":"public/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1520109494797},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1520109494797},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1520109494797},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1520109494797},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1520109494797},{"_id":"public/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1520109494797},{"_id":"public/lib/fastclick/README.html","hash":"c07b353b4efa132290ec4479102a55d80ac6d300","modified":1520109494797},{"_id":"public/lib/jquery_lazyload/CONTRIBUTING.html","hash":"06811ca2f722dead021493457f27cdc264ef928d","modified":1520109494797},{"_id":"public/lib/jquery_lazyload/README.html","hash":"a08fccd381c8fdb70ba8974b208254c5ba23a95f","modified":1520109494797},{"_id":"public/css/main.css","hash":"5f51daf3142d5f8be9482e3c55f233f24e4a89f3","modified":1520109494797},{"_id":"public/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1520109494797},{"_id":"public/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1520109494797},{"_id":"public/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1520109494797},{"_id":"public/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1520109494798},{"_id":"public/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1520109494798},{"_id":"public/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1520109494798},{"_id":"public/lib/font-awesome/css/font-awesome.css","hash":"4eda182cbcc046dbf449aef97c02c230cf80a494","modified":1520109494798},{"_id":"public/lib/font-awesome/css/font-awesome.min.css","hash":"fb5b49426dee7f1508500e698d1b3c6b04c8fcce","modified":1520109494798},{"_id":"public/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1520109494798},{"_id":"public/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1520109494798},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1520109494798},{"_id":"public/2018/01/29/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/trigger_labeling.png","hash":"9cf3fff26c6b386c510cdf0a6f96956455b31a05","modified":1520109494798},{"_id":"public/2018/01/04/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/algo.png","hash":"6cccb33d32c7a598ffbf6fdb7a7514be354323b8","modified":1520109494798},{"_id":"public/2018/01/21/[2018.1.21]Event-detection-and-co-referentce/overview.png","hash":"63840233165ca42bf6a82222e1b41af076a4957c","modified":1520109494798},{"_id":"public/2018/02/05/[2018.2.5]Nested-LSTMs/GNMT_residual.png","hash":"c4296248b686bca6cae82a5cdd01ea76ab14b691","modified":1520109494798},{"_id":"public/2018/02/05/[2018.2.5]Nested-LSTMs/singleLSTM.png","hash":"fe48376830ec3f50d45b33804142511e0f543196","modified":1520109494798},{"_id":"public/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1520109494822},{"_id":"public/2018/01/04/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/illustration.png","hash":"9c2acae5a552988ce560e5a421cdba162400c3da","modified":1520109494874},{"_id":"public/2017/06/25/Generative-Adversarial-Network/gan.png","hash":"389484961aeaa1b5d5d030dc75d0d53a5dfadff0","modified":1520109494926}],"Category":[{"name":"math","_id":"cjebtxvpb0004pzm9vzyfrzfh"},{"name":"unfinished","parent":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvpt000kpzm9w9cjpwac"},{"name":"programming","_id":"cjebtxvq2000rpzm9537rgxgy"},{"name":"unfinished","parent":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvrb001ypzm9zi3ru51g"},{"name":"research","_id":"cjebtxvrk002ipzm9onbjtm6h"},{"name":"other","_id":"cjebtxvs9003zpzm9sm2wvicu"},{"name":"francais","_id":"cjebtxvsb0048pzm99vutybjv"}],"Data":[],"Page":[{"_content":"google-site-verification: google50e2fbd5160eafe4.html","source":"google50e2fbd5160eafe4.html","raw":"google-site-verification: google50e2fbd5160eafe4.html","date":"2017-02-14T20:18:29.000Z","updated":"2016-12-08T22:22:25.000Z","path":"google50e2fbd5160eafe4.html","title":"","comments":1,"layout":"page","_id":"cjebtxvng0000pzm9umwyv6u1","content":"google-site-verification: google50e2fbd5160eafe4.html","excerpt":"","more":"google-site-verification: google50e2fbd5160eafe4.html"},{"title":"categories","date":"2016-11-27T12:13:12.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2016-11-27 13:13:12\ntype: \"categories\" \n---\n","updated":"2017-02-14T20:30:53.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"cjebtxvp40001pzm9uutvjk84","content":"","excerpt":"","more":""},{"title":"tags","date":"2016-11-27T12:15:12.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2016-11-27 13:15:12\ntype: \"tags\"\n---\n","updated":"2017-02-14T20:30:53.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"cjebtxvwr009epzm91tybegis","content":"","excerpt":"","more":""}],"Post":[{"title":" Bayes estimation","date":"2017-01-07T15:46:31.000Z","_content":"\n\n\n\n\n$\\theta$$\\theta$$\\theta$\n\n## \n\n\n\n\n\n98%5% \n98%5% \n\n1+1=\n\n1% \n$$\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}\n$$\n\n$$\np(|)=\\frac{p(|)p()}{p()}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324\n$$\n\n\n\n## \n\n\n$$\n\\theta: \\pi(\\theta)\n$$\n\n$$\n\\widetilde{X} = \\{ X_1,...,X_n \\}\n$$\n\n$$\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)\n$$\n\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}\n$$\nT\n$$\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)\n$$\n\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )\n$$\n\n\n- \n- \n- \n\n\n\n\n\n- x\n- ","source":"_posts/Bayes-estimation.md","raw":"---\ntitle:  Bayes estimation\ndate: 2017-01-07 16:46:31\ncategories: [math]\ntags: [Bayes, statistic]\n---\n\n\n\n\n\n$\\theta$$\\theta$$\\theta$\n\n## \n\n\n\n\n\n98%5% \n98%5% \n\n1+1=\n\n1% \n$$\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}\n$$\n\n$$\np(|)=\\frac{p(|)p()}{p()}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324\n$$\n\n\n\n## \n\n\n$$\n\\theta: \\pi(\\theta)\n$$\n\n$$\n\\widetilde{X} = \\{ X_1,...,X_n \\}\n$$\n\n$$\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)\n$$\n\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}\n$$\nT\n$$\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)\n$$\n\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )\n$$\n\n\n- \n- \n- \n\n\n\n\n\n- x\n- ","slug":"Bayes-estimation","published":1,"updated":"2017-01-07T16:48:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvp60002pzm97n61od1o","content":"<p></p>\n<p></p>\n<p>$\\theta$$\\theta$$\\theta$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p></p>\n<p>98%5%<br>98%5% </p>\n<p>1+1=</p>\n<p>1% </p>\n<script type=\"math/tex; mode=display\">\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}</script><script type=\"math/tex; mode=display\">\np(|)=\\frac{p(|)p()}{p()}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324</script><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\n\\theta: \\pi(\\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\widetilde{X} = \\{ X_1,...,X_n \\}</script><p></p>\n<script type=\"math/tex; mode=display\">\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}</script><p>T</p>\n<script type=\"math/tex; mode=display\">\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )</script><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<p></p>\n<ul>\n<li>x</li>\n<li></li>\n</ul>\n","excerpt":"","more":"<p></p>\n<p></p>\n<p>$\\theta$$\\theta$$\\theta$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p></p>\n<p>98%5%<br>98%5% </p>\n<p>1+1=</p>\n<p>1% </p>\n<script type=\"math/tex; mode=display\">\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}</script><script type=\"math/tex; mode=display\">\np(|)=\\frac{p(|)p()}{p()}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324</script><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\n\\theta: \\pi(\\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\widetilde{X} = \\{ X_1,...,X_n \\}</script><p></p>\n<script type=\"math/tex; mode=display\">\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}</script><p>T</p>\n<script type=\"math/tex; mode=display\">\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )</script><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<p></p>\n<ul>\n<li>x</li>\n<li></li>\n</ul>\n"},{"title":"EDP","date":"2017-02-07T09:22:27.000Z","_content":"\n## \n\n1. A est une matrice hermitienne <=> A=A* et donc A est normale\n2. A est une matrice  unitaire () <=> A^-1 = A* et donc A est normale\n3. A est une matrice orthogonale <=> A=A^T\n\n\n\n## Schur\n\n$$\nA = [a_{ij}]_{n\\times n} , \\lambda_i , x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n,A \\\\\nA = SDS^{-1}\n$$\n\n**A***n**n*U*n*T\n$$\nA = UTU^{-1}\n$$\n\n## \n\n$$\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}\n$$\n\nU\n\n\n\n## Cholesky\n\n\n\n1. une matrice hermitienneHermitiankxy(x*)Ay\n2. Positive-definiteAx(x^T)Ax((x*)Ax>0)\n\nL A = LL*\n\n\n\n## QR\n\nA = QR*Q**Q*T*Q*=*I**R*\n\n","source":"_posts/EDP-basic-matrix-review.md","raw":"---\ntitle: 'EDP'\ndate: 2017-02-07 10:22:27\ncategories: [math]\ntags: [EDP, matrix]\n---\n\n## \n\n1. A est une matrice hermitienne <=> A=A* et donc A est normale\n2. A est une matrice  unitaire () <=> A^-1 = A* et donc A est normale\n3. A est une matrice orthogonale <=> A=A^T\n\n\n\n## Schur\n\n$$\nA = [a_{ij}]_{n\\times n} , \\lambda_i , x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n,A \\\\\nA = SDS^{-1}\n$$\n\n**A***n**n*U*n*T\n$$\nA = UTU^{-1}\n$$\n\n## \n\n$$\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}\n$$\n\nU\n\n\n\n## Cholesky\n\n\n\n1. une matrice hermitienneHermitiankxy(x*)Ay\n2. Positive-definiteAx(x^T)Ax((x*)Ax>0)\n\nL A = LL*\n\n\n\n## QR\n\nA = QR*Q**Q*T*Q*=*I**R*\n\n","slug":"EDP-basic-matrix-review","published":1,"updated":"2017-02-07T10:40:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvp90003pzm9py4ale94","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>A est une matrice hermitienne &lt;=&gt; A=A* et donc A est normale</li>\n<li>A est une matrice  unitaire () &lt;=&gt; A^-1 = A* et donc A est normale</li>\n<li>A est une matrice orthogonale &lt;=&gt; A=A^T</li>\n</ol>\n<h2 id=\"Schur\"><a href=\"#Schur\" class=\"headerlink\" title=\"Schur\"></a>Schur</h2><script type=\"math/tex; mode=display\">\nA = [a_{ij}]_{n\\times n} , \\lambda_i , x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n,A \\\\\nA = SDS^{-1}</script><p><strong>A</strong><em>n</em><em>n</em>U<em>n</em>T</p>\n<script type=\"math/tex; mode=display\">\nA = UTU^{-1}</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><script type=\"math/tex; mode=display\">\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}</script><p>U</p>\n<h2 id=\"Cholesky\"><a href=\"#Cholesky\" class=\"headerlink\" title=\"Cholesky\"></a>Cholesky</h2><p></p>\n<ol>\n<li>une matrice hermitienneHermitiankxy(x*)Ay</li>\n<li>Positive-definiteAx(x^T)Ax((x*)Ax&gt;0)</li>\n</ol>\n<p>L A = LL*</p>\n<h2 id=\"QR\"><a href=\"#QR\" class=\"headerlink\" title=\"QR\"></a>QR</h2><p>A = QR<em>Q</em><em>Q</em>T<em>Q</em> = <em>I</em><em>R</em></p>\n","excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>A est une matrice hermitienne &lt;=&gt; A=A* et donc A est normale</li>\n<li>A est une matrice  unitaire () &lt;=&gt; A^-1 = A* et donc A est normale</li>\n<li>A est une matrice orthogonale &lt;=&gt; A=A^T</li>\n</ol>\n<h2 id=\"Schur\"><a href=\"#Schur\" class=\"headerlink\" title=\"Schur\"></a>Schur</h2><script type=\"math/tex; mode=display\">\nA = [a_{ij}]_{n\\times n} , \\lambda_i , x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n,A \\\\\nA = SDS^{-1}</script><p><strong>A</strong><em>n</em><em>n</em>U<em>n</em>T</p>\n<script type=\"math/tex; mode=display\">\nA = UTU^{-1}</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><script type=\"math/tex; mode=display\">\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}</script><p>U</p>\n<h2 id=\"Cholesky\"><a href=\"#Cholesky\" class=\"headerlink\" title=\"Cholesky\"></a>Cholesky</h2><p></p>\n<ol>\n<li>une matrice hermitienneHermitiankxy(x*)Ay</li>\n<li>Positive-definiteAx(x^T)Ax((x*)Ax&gt;0)</li>\n</ol>\n<p>L A = LL*</p>\n<h2 id=\"QR\"><a href=\"#QR\" class=\"headerlink\" title=\"QR\"></a>QR</h2><p>A = QR<em>Q</em><em>Q</em>T<em>Q</em> = <em>I</em><em>R</em></p>\n"},{"title":"EDP basic models","date":"2017-03-06T09:04:58.000Z","_content":"\n# Examples of moedels\n\n1.    Problem of Cauchy\n\n      **Nomenclature** : problem of Cauchy\n\n      **Equation** : system of 2 differential equations of order 2\n\n      **Conditions** : initials (all the data from the same point) i.e. fix time\n\n      $$\n      \\begin{equation}\n        \\begin{cases}\n          \\frac{dS}{dt}(t) = F(S,R)  ,  \\\\\n          \\frac{dR}{dt}(t) = G(S,R) ,  \\\\\n          S(0) = S^0 \\\\\n          R(0) = R^0\n        \\end{cases}\n      \\end{equation}\n      $$\n\n2.    Problem of Dirichlet\n\n      **Nomenclature** : problem of Dirichlet\n\n      **Equation** : scalar differential equation of order 2.\n\n      **Conditions** : prescribed value at the edge\n\n      $$\n      \\begin{equation}\n        \\begin{cases}\n      - \\frac{d}{dx} ( k \\frac{d\\theta}{dx})(x) + \\theta(x) = f(x) 0<x<L, \\\\\n        \\theta(0) = \\theta_0, \\theta(L) = \\theta_L \\\\\n     \\end{cases}\n   \\end{equation}\n$$\n\n   **Remark:**\n\n   - kles differences finies et les elements finis.\n   - **$\\theta(L)$$\\theta'(0)$$\\theta'(0)$$\\theta(L)=\\theta(L) = \\theta_L$\n\n### Physic examples\n\n- Fluide environnant au repos\n$$\n  \\rho c_v \\partial_t{\\theta} - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n$$\n  - init condition:\n$$\n    \\theta(0,.) = \\theta_0\n    $$\n\n-   condition at the edges could be:\n\n    - condition of Dirichlet:\n      $$\n      \\theta(t,.) = g(t)\n      $$\n\n    - Condition of Neumann:\n      $$\n      \\overrightarrow{grad}(\\theta)(t,.) \\cdot \\vec{n}= h(t)\n      $$\n\n    - Condition of Dirichlet and Neumann: Mix\n\n-   Fluide environnant en mouvement a une vitesse $\\vec u(t,x)$\n    $$\n    \\rho c_v \\partial_t{\\theta} - div(\\rho c_v \\theta \\vec u) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n    $$\n    si le fluide est incompressible i.e $\\partial_t \\rho = 0$ soit encore $div(\\vec u) = 0$ (), alors:\n    $$\n    \\rho c_v \\partial_t{\\theta} - \\vec u \\cdot div(\\rho c_v \\theta ) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n    $$\n    \n\n    ","source":"_posts/EDP-basic-models.md","raw":"---\ntitle: EDP basic models\ncategories: [math]\ntags:\n  - math\n  - EDP\ndate: 2017-03-06 10:04:58\n---\n\n# Examples of moedels\n\n1.    Problem of Cauchy\n\n      **Nomenclature** : problem of Cauchy\n\n      **Equation** : system of 2 differential equations of order 2\n\n      **Conditions** : initials (all the data from the same point) i.e. fix time\n\n      $$\n      \\begin{equation}\n        \\begin{cases}\n          \\frac{dS}{dt}(t) = F(S,R)  ,  \\\\\n          \\frac{dR}{dt}(t) = G(S,R) ,  \\\\\n          S(0) = S^0 \\\\\n          R(0) = R^0\n        \\end{cases}\n      \\end{equation}\n      $$\n\n2.    Problem of Dirichlet\n\n      **Nomenclature** : problem of Dirichlet\n\n      **Equation** : scalar differential equation of order 2.\n\n      **Conditions** : prescribed value at the edge\n\n      $$\n      \\begin{equation}\n        \\begin{cases}\n      - \\frac{d}{dx} ( k \\frac{d\\theta}{dx})(x) + \\theta(x) = f(x) 0<x<L, \\\\\n        \\theta(0) = \\theta_0, \\theta(L) = \\theta_L \\\\\n     \\end{cases}\n   \\end{equation}\n$$\n\n   **Remark:**\n\n   - kles differences finies et les elements finis.\n   - **$\\theta(L)$$\\theta'(0)$$\\theta'(0)$$\\theta(L)=\\theta(L) = \\theta_L$\n\n### Physic examples\n\n- Fluide environnant au repos\n$$\n  \\rho c_v \\partial_t{\\theta} - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n$$\n  - init condition:\n$$\n    \\theta(0,.) = \\theta_0\n    $$\n\n-   condition at the edges could be:\n\n    - condition of Dirichlet:\n      $$\n      \\theta(t,.) = g(t)\n      $$\n\n    - Condition of Neumann:\n      $$\n      \\overrightarrow{grad}(\\theta)(t,.) \\cdot \\vec{n}= h(t)\n      $$\n\n    - Condition of Dirichlet and Neumann: Mix\n\n-   Fluide environnant en mouvement a une vitesse $\\vec u(t,x)$\n    $$\n    \\rho c_v \\partial_t{\\theta} - div(\\rho c_v \\theta \\vec u) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n    $$\n    si le fluide est incompressible i.e $\\partial_t \\rho = 0$ soit encore $div(\\vec u) = 0$ (), alors:\n    $$\n    \\rho c_v \\partial_t{\\theta} - \\vec u \\cdot div(\\rho c_v \\theta ) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n    $$\n    \n\n    ","slug":"EDP-basic-models","published":1,"updated":"2017-03-06T11:11:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvpe0006pzm9psg9y3w8","content":"<h1 id=\"Examples-of-moedels\"><a href=\"#Examples-of-moedels\" class=\"headerlink\" title=\"Examples of moedels\"></a>Examples of moedels</h1><ol>\n<li><p>Problem of Cauchy</p>\n<p><strong>Nomenclature</strong> : problem of Cauchy</p>\n<p><strong>Equation</strong> : system of 2 differential equations of order 2</p>\n<p><strong>Conditions</strong> : initials (all the data from the same point) i.e. fix time</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n  \\begin{cases}\n    \\frac{dS}{dt}(t) = F(S,R)  ,  \\\\\n    \\frac{dR}{dt}(t) = G(S,R) ,  \\\\\n    S(0) = S^0 \\\\\n    R(0) = R^0\n  \\end{cases}\n\\end{equation}</script></li>\n<li><p>Problem of Dirichlet</p>\n<p><strong>Nomenclature</strong> : problem of Dirichlet</p>\n<p><strong>Equation</strong> : scalar differential equation of order 2.</p>\n<p><strong>Conditions</strong> : prescribed value at the edge</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n  \\begin{cases}\n- \\frac{d}{dx} ( k \\frac{d\\theta}{dx})(x) + \\theta(x) = f(x) 0<x<L, \\\\\n  \\theta(0) = \\theta_0, \\theta(L) = \\theta_L \\\\\n\\end{cases}\n\\end{equation}</script><p><strong>Remark:</strong></p>\n<ul>\n<li>kles differences finies et les elements finis.</li>\n<li><em></em>$\\theta(L)$$\\theta(0)$$\\theta(0)$$\\theta(L)=\\theta(L) = \\theta_L$</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"Physic-examples\"><a href=\"#Physic-examples\" class=\"headerlink\" title=\"Physic examples\"></a>Physic examples</h3><ul>\n<li><p>Fluide environnant au repos</p>\n<script type=\"math/tex; mode=display\">\n\\rho c_v \\partial_t{\\theta} - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f</script><ul>\n<li>init condition:<script type=\"math/tex; mode=display\">\n\\theta(0,.) = \\theta_0</script></li>\n</ul>\n</li>\n<li><p>condition at the edges could be:</p>\n<ul>\n<li><p>condition of Dirichlet:</p>\n<script type=\"math/tex; mode=display\">\n\\theta(t,.) = g(t)</script></li>\n<li><p>Condition of Neumann:</p>\n<script type=\"math/tex; mode=display\">\n\\overrightarrow{grad}(\\theta)(t,.) \\cdot \\vec{n}= h(t)</script></li>\n<li><p>Condition of Dirichlet and Neumann: Mix</p>\n</li>\n</ul>\n</li>\n<li><p>Fluide environnant en mouvement a une vitesse $\\vec u(t,x)$</p>\n<script type=\"math/tex; mode=display\">\n\\rho c_v \\partial_t{\\theta} - div(\\rho c_v \\theta \\vec u) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f</script><p>si le fluide est incompressible i.e $\\partial_t \\rho = 0$ soit encore $div(\\vec u) = 0$ (), alors:</p>\n<script type=\"math/tex; mode=display\">\n\\rho c_v \\partial_t{\\theta} - \\vec u \\cdot div(\\rho c_v \\theta ) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f</script><p></p>\n<p></p>\n</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"Examples-of-moedels\"><a href=\"#Examples-of-moedels\" class=\"headerlink\" title=\"Examples of moedels\"></a>Examples of moedels</h1><ol>\n<li><p>Problem of Cauchy</p>\n<p><strong>Nomenclature</strong> : problem of Cauchy</p>\n<p><strong>Equation</strong> : system of 2 differential equations of order 2</p>\n<p><strong>Conditions</strong> : initials (all the data from the same point) i.e. fix time</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n  \\begin{cases}\n    \\frac{dS}{dt}(t) = F(S,R)  ,  \\\\\n    \\frac{dR}{dt}(t) = G(S,R) ,  \\\\\n    S(0) = S^0 \\\\\n    R(0) = R^0\n  \\end{cases}\n\\end{equation}</script></li>\n<li><p>Problem of Dirichlet</p>\n<p><strong>Nomenclature</strong> : problem of Dirichlet</p>\n<p><strong>Equation</strong> : scalar differential equation of order 2.</p>\n<p><strong>Conditions</strong> : prescribed value at the edge</p>\n<script type=\"math/tex; mode=display\">\n\\begin{equation}\n  \\begin{cases}\n- \\frac{d}{dx} ( k \\frac{d\\theta}{dx})(x) + \\theta(x) = f(x) 0<x<L, \\\\\n  \\theta(0) = \\theta_0, \\theta(L) = \\theta_L \\\\\n\\end{cases}\n\\end{equation}</script><p><strong>Remark:</strong></p>\n<ul>\n<li>kles differences finies et les elements finis.</li>\n<li><em></em>$\\theta(L)$$\\theta(0)$$\\theta(0)$$\\theta(L)=\\theta(L) = \\theta_L$</li>\n</ul>\n</li>\n</ol>\n<h3 id=\"Physic-examples\"><a href=\"#Physic-examples\" class=\"headerlink\" title=\"Physic examples\"></a>Physic examples</h3><ul>\n<li><p>Fluide environnant au repos</p>\n<script type=\"math/tex; mode=display\">\n\\rho c_v \\partial_t{\\theta} - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f</script><ul>\n<li>init condition:<script type=\"math/tex; mode=display\">\n\\theta(0,.) = \\theta_0</script></li>\n</ul>\n</li>\n<li><p>condition at the edges could be:</p>\n<ul>\n<li><p>condition of Dirichlet:</p>\n<script type=\"math/tex; mode=display\">\n\\theta(t,.) = g(t)</script></li>\n<li><p>Condition of Neumann:</p>\n<script type=\"math/tex; mode=display\">\n\\overrightarrow{grad}(\\theta)(t,.) \\cdot \\vec{n}= h(t)</script></li>\n<li><p>Condition of Dirichlet and Neumann: Mix</p>\n</li>\n</ul>\n</li>\n<li><p>Fluide environnant en mouvement a une vitesse $\\vec u(t,x)$</p>\n<script type=\"math/tex; mode=display\">\n\\rho c_v \\partial_t{\\theta} - div(\\rho c_v \\theta \\vec u) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f</script><p>si le fluide est incompressible i.e $\\partial_t \\rho = 0$ soit encore $div(\\vec u) = 0$ (), alors:</p>\n<script type=\"math/tex; mode=display\">\n\\rho c_v \\partial_t{\\theta} - \\vec u \\cdot div(\\rho c_v \\theta ) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f</script><p></p>\n<p></p>\n</li>\n</ul>\n"},{"title":"EDP finite element method","date":"2017-03-31T20:42:08.000Z","_content":"\n","source":"_posts/EDP-finite-element-method.md","raw":"---\ntitle: EDP finite element method\ncategories: [math, unfinished]\ntags:\n  - math\n  - FEM\ndate: 2017-03-31 22:42:08\n---\n\n","slug":"EDP-finite-element-method","published":1,"updated":"2017-03-31T20:48:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvpf0007pzm9wz4vz332","content":"","excerpt":"","more":""},{"title":"Generative Adversarial Network","date":"2017-06-25T12:41:15.000Z","_content":"\n# Generative Adversarial Network\n\n## Generater\n\n1. Auto encoder\n\n   input => nn encoder => code => nn decoder => output\n\n   Output compared with input as close as possible\n\n   [code => nn decoder => output] := a generater\n\n2. VAE\n\n   Auto-encoder Variational Bayes:\n\n   input => nn encoder \n\n   => {\n\n       code : [$m_i$],\n\n       variation : [$\\sigma_i$],\n\n       error : [$e_i$],\n\n   } \n\n   => {$c_i = exp(\\sigma_i) \\times e_i + m_i$}\n\n   => nn decoder => output\n\n   The goal is to monimize the expression as followed:\n   $$\n   \\sum(exp(\\sigma_i) - (1+\\sigma_i) + (m_i)^2)\n   $$\n\n\n\n\n## GAN\n\n(true or false)\n\n$P_{data}(x; \\theta) , P_G(x;\\theta)$\n\n- Generator G\n\n  - G is a function, input z, output x\n  - Given a prior distribution $P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G\n\n- Discriminator D\n\n  - D is a function, input x, output scalar\n  - Evaluate the \"difference\" between $P_G(x)$ and $P_{data}(x)$\n\n- Function V(G, D)\n  $$\n  G^* = {arg} {min}_G {max}_D V(G,D)\n  $$\n\n\n\nG*DGV$P_{data}$$P_G$GGD\n\nV\n$$\nV = E_{x~P_{data}}[logD(x)]+ E_{x~P_G}[log(1-D(x))] \\\\\n= \\int_x P_{data}(x)logD(x)dx +\\int_xP_G(x)log(1-D(X))dx \\\\\n= \\int_x[P_{data}(x)logD(x) + P_G(x)log(1-D(x))]dx\n$$\nV\n$$\nP_{data}(x)logD(x) + P_G(x)log(1-D(x))\n$$\ni.e. find D* maximizing: $f(D) = alog(D)+blog(1-D)$\n$$\n=> D^* = \\frac{a}{a+b} = \\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}\n$$\n\n$$\nmax_D V(G,D) = V(G, D^*) \\\\\n= -2log2 + \\int_x P_{data}(x) log\\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\ + \\int_x P_{data}(x) log\\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\\n= -2log2 + KL(P_{data}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\ \n+ KL(P_{G}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\\n= -2log2 + 2JSD(P_{data}(X||P_G(x))\n$$\n\n$$\nKL := KL divergence \\\\\nJSD(P||Q) = \\frac{1}{2}(KL(P||M) + KL(Q||M)), M= \\frac{P+Q}{2}\n$$\n$max_D(G,D)$$P_G = P_{data}$\n\n### ****\n\n- Given $G_0$\n- Find $D_0^*$ maximizing $V(G_0,D)$\n- $\\theta_G \\leftarrow \\theta_G - \\eta \\partial V(G, D_0^*)/ \\partial \\theta_G $ => Obtain G1\n- Find $D_1^*$ maximizing $V(G_1,D)$\n- ...\n\n#### \n\n\n\nmV\n$$\nV = \\frac{1}{m}\\sum logD(x_i) + \\frac{1}{m} \\sum log(1-D(x_i^G)) \\\\\nwhere \\{x_1, ..., x_m\\}  from P_{data}(x), \\{x_1^G,...,x_m^G\\} from P_G(x)\n$$\n","source":"_posts/Generative-Adversarial-Network.md","raw":"---\ntitle: Generative Adversarial Network\ndate: 2017-06-25 14:41:15\ncategories: [programming]\ntags: [GAN, deep-learning]\n---\n\n# Generative Adversarial Network\n\n## Generater\n\n1. Auto encoder\n\n   input => nn encoder => code => nn decoder => output\n\n   Output compared with input as close as possible\n\n   [code => nn decoder => output] := a generater\n\n2. VAE\n\n   Auto-encoder Variational Bayes:\n\n   input => nn encoder \n\n   => {\n\n       code : [$m_i$],\n\n       variation : [$\\sigma_i$],\n\n       error : [$e_i$],\n\n   } \n\n   => {$c_i = exp(\\sigma_i) \\times e_i + m_i$}\n\n   => nn decoder => output\n\n   The goal is to monimize the expression as followed:\n   $$\n   \\sum(exp(\\sigma_i) - (1+\\sigma_i) + (m_i)^2)\n   $$\n\n\n\n\n## GAN\n\n(true or false)\n\n$P_{data}(x; \\theta) , P_G(x;\\theta)$\n\n- Generator G\n\n  - G is a function, input z, output x\n  - Given a prior distribution $P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G\n\n- Discriminator D\n\n  - D is a function, input x, output scalar\n  - Evaluate the \"difference\" between $P_G(x)$ and $P_{data}(x)$\n\n- Function V(G, D)\n  $$\n  G^* = {arg} {min}_G {max}_D V(G,D)\n  $$\n\n\n\nG*DGV$P_{data}$$P_G$GGD\n\nV\n$$\nV = E_{x~P_{data}}[logD(x)]+ E_{x~P_G}[log(1-D(x))] \\\\\n= \\int_x P_{data}(x)logD(x)dx +\\int_xP_G(x)log(1-D(X))dx \\\\\n= \\int_x[P_{data}(x)logD(x) + P_G(x)log(1-D(x))]dx\n$$\nV\n$$\nP_{data}(x)logD(x) + P_G(x)log(1-D(x))\n$$\ni.e. find D* maximizing: $f(D) = alog(D)+blog(1-D)$\n$$\n=> D^* = \\frac{a}{a+b} = \\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}\n$$\n\n$$\nmax_D V(G,D) = V(G, D^*) \\\\\n= -2log2 + \\int_x P_{data}(x) log\\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\ + \\int_x P_{data}(x) log\\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\\n= -2log2 + KL(P_{data}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\ \n+ KL(P_{G}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\\n= -2log2 + 2JSD(P_{data}(X||P_G(x))\n$$\n\n$$\nKL := KL divergence \\\\\nJSD(P||Q) = \\frac{1}{2}(KL(P||M) + KL(Q||M)), M= \\frac{P+Q}{2}\n$$\n$max_D(G,D)$$P_G = P_{data}$\n\n### ****\n\n- Given $G_0$\n- Find $D_0^*$ maximizing $V(G_0,D)$\n- $\\theta_G \\leftarrow \\theta_G - \\eta \\partial V(G, D_0^*)/ \\partial \\theta_G $ => Obtain G1\n- Find $D_1^*$ maximizing $V(G_1,D)$\n- ...\n\n#### \n\n\n\nmV\n$$\nV = \\frac{1}{m}\\sum logD(x_i) + \\frac{1}{m} \\sum log(1-D(x_i^G)) \\\\\nwhere \\{x_1, ..., x_m\\}  from P_{data}(x), \\{x_1^G,...,x_m^G\\} from P_G(x)\n$$\n","slug":"Generative-Adversarial-Network","published":1,"updated":"2017-06-29T06:49:35.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvpi0008pzm9dwby3sc0","content":"<h1 id=\"Generative-Adversarial-Network\"><a href=\"#Generative-Adversarial-Network\" class=\"headerlink\" title=\"Generative Adversarial Network\"></a>Generative Adversarial Network</h1><h2 id=\"Generater\"><a href=\"#Generater\" class=\"headerlink\" title=\"Generater\"></a>Generater</h2><ol>\n<li><p>Auto encoder</p>\n<p>input =&gt; nn encoder =&gt; code =&gt; nn decoder =&gt; output</p>\n<p>Output compared with input as close as possible</p>\n<p>[code =&gt; nn decoder =&gt; output] := a generater</p>\n</li>\n<li><p>VAE</p>\n<p>Auto-encoder Variational Bayes:</p>\n<p>input =&gt; nn encoder </p>\n<p>=&gt; {</p>\n<p>    code : [$m_i$],</p>\n<p>    variation : [$\\sigma_i$],</p>\n<p>    error : [$e_i$],</p>\n<p>} </p>\n<p>=&gt; {$c_i = exp(\\sigma_i) \\times e_i + m_i$}</p>\n<p>=&gt; nn decoder =&gt; output</p>\n<p>The goal is to monimize the expression as followed:</p>\n<script type=\"math/tex; mode=display\">\n\\sum(exp(\\sigma_i) - (1+\\sigma_i) + (m_i)^2)</script></li>\n</ol>\n<h2 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN\"></a>GAN</h2><p>(true or false)</p>\n<p>$P_{data}(x; \\theta) , P_G(x;\\theta)$</p>\n<ul>\n<li><p>Generator G</p>\n<ul>\n<li>G is a function, input z, output x</li>\n<li>Given a prior distribution $P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G</li>\n</ul>\n</li>\n<li><p>Discriminator D</p>\n<ul>\n<li>D is a function, input x, output scalar</li>\n<li>Evaluate the difference between $P<em>G(x)$ and $P</em>{data}(x)$</li>\n</ul>\n</li>\n<li><p>Function V(G, D)</p>\n<script type=\"math/tex; mode=display\">\nG^* = {arg} {min}_G {max}_D V(G,D)</script></li>\n</ul>\n<p>G*DGV$P_{data}$$P_G$GGD</p>\n<p>V</p>\n<script type=\"math/tex; mode=display\">\nV = E_{x~P_{data}}[logD(x)]+ E_{x~P_G}[log(1-D(x))] \\\\\n= \\int_x P_{data}(x)logD(x)dx +\\int_xP_G(x)log(1-D(X))dx \\\\\n= \\int_x[P_{data}(x)logD(x) + P_G(x)log(1-D(x))]dx</script><p>V</p>\n<script type=\"math/tex; mode=display\">\nP_{data}(x)logD(x) + P_G(x)log(1-D(x))</script><p>i.e. find D* maximizing: $f(D) = alog(D)+blog(1-D)$</p>\n<script type=\"math/tex; mode=display\">\n=> D^* = \\frac{a}{a+b} = \\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}</script><p></p>\n<script type=\"math/tex; mode=display\">\nmax_D V(G,D) = V(G, D^*) \\\\\n= -2log2 + \\int_x P_{data}(x) log\\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\ + \\int_x P_{data}(x) log\\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\\n= -2log2 + KL(P_{data}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\ \n+ KL(P_{G}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\\n= -2log2 + 2JSD(P_{data}(X||P_G(x))</script><p></p>\n<script type=\"math/tex; mode=display\">\nKL := KL divergence \\\\\nJSD(P||Q) = \\frac{1}{2}(KL(P||M) + KL(Q||M)), M= \\frac{P+Q}{2}</script><p>$max<em>D(G,D)$$P_G = P</em>{data}$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><strong></strong></h3><ul>\n<li>Given $G_0$</li>\n<li>Find $D_0^*$ maximizing $V(G_0,D)$</li>\n<li>$\\theta_G \\leftarrow \\theta_G - \\eta \\partial V(G, D_0^*)/ \\partial \\theta_G $ =&gt; Obtain G1</li>\n<li>Find $D_1^*$ maximizing $V(G_1,D)$</li>\n<li></li>\n</ul>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p>mV</p>\n<script type=\"math/tex; mode=display\">\nV = \\frac{1}{m}\\sum logD(x_i) + \\frac{1}{m} \\sum log(1-D(x_i^G)) \\\\\nwhere \\{x_1, ..., x_m\\}  from P_{data}(x), \\{x_1^G,...,x_m^G\\} from P_G(x)</script>","excerpt":"","more":"<h1 id=\"Generative-Adversarial-Network\"><a href=\"#Generative-Adversarial-Network\" class=\"headerlink\" title=\"Generative Adversarial Network\"></a>Generative Adversarial Network</h1><h2 id=\"Generater\"><a href=\"#Generater\" class=\"headerlink\" title=\"Generater\"></a>Generater</h2><ol>\n<li><p>Auto encoder</p>\n<p>input =&gt; nn encoder =&gt; code =&gt; nn decoder =&gt; output</p>\n<p>Output compared with input as close as possible</p>\n<p>[code =&gt; nn decoder =&gt; output] := a generater</p>\n</li>\n<li><p>VAE</p>\n<p>Auto-encoder Variational Bayes:</p>\n<p>input =&gt; nn encoder </p>\n<p>=&gt; {</p>\n<p>    code : [$m_i$],</p>\n<p>    variation : [$\\sigma_i$],</p>\n<p>    error : [$e_i$],</p>\n<p>} </p>\n<p>=&gt; {$c_i = exp(\\sigma_i) \\times e_i + m_i$}</p>\n<p>=&gt; nn decoder =&gt; output</p>\n<p>The goal is to monimize the expression as followed:</p>\n<script type=\"math/tex; mode=display\">\n\\sum(exp(\\sigma_i) - (1+\\sigma_i) + (m_i)^2)</script></li>\n</ol>\n<h2 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN\"></a>GAN</h2><p>(true or false)</p>\n<p>$P_{data}(x; \\theta) , P_G(x;\\theta)$</p>\n<ul>\n<li><p>Generator G</p>\n<ul>\n<li>G is a function, input z, output x</li>\n<li>Given a prior distribution $P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G</li>\n</ul>\n</li>\n<li><p>Discriminator D</p>\n<ul>\n<li>D is a function, input x, output scalar</li>\n<li>Evaluate the difference between $P<em>G(x)$ and $P</em>{data}(x)$</li>\n</ul>\n</li>\n<li><p>Function V(G, D)</p>\n<script type=\"math/tex; mode=display\">\nG^* = {arg} {min}_G {max}_D V(G,D)</script></li>\n</ul>\n<p>G*DGV$P_{data}$$P_G$GGD</p>\n<p>V</p>\n<script type=\"math/tex; mode=display\">\nV = E_{x~P_{data}}[logD(x)]+ E_{x~P_G}[log(1-D(x))] \\\\\n= \\int_x P_{data}(x)logD(x)dx +\\int_xP_G(x)log(1-D(X))dx \\\\\n= \\int_x[P_{data}(x)logD(x) + P_G(x)log(1-D(x))]dx</script><p>V</p>\n<script type=\"math/tex; mode=display\">\nP_{data}(x)logD(x) + P_G(x)log(1-D(x))</script><p>i.e. find D* maximizing: $f(D) = alog(D)+blog(1-D)$</p>\n<script type=\"math/tex; mode=display\">\n=> D^* = \\frac{a}{a+b} = \\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}</script><p></p>\n<script type=\"math/tex; mode=display\">\nmax_D V(G,D) = V(G, D^*) \\\\\n= -2log2 + \\int_x P_{data}(x) log\\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\ + \\int_x P_{data}(x) log\\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\\n= -2log2 + KL(P_{data}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\ \n+ KL(P_{G}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\\n= -2log2 + 2JSD(P_{data}(X||P_G(x))</script><p></p>\n<script type=\"math/tex; mode=display\">\nKL := KL divergence \\\\\nJSD(P||Q) = \\frac{1}{2}(KL(P||M) + KL(Q||M)), M= \\frac{P+Q}{2}</script><p>$max<em>D(G,D)$$P_G = P</em>{data}$</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><strong></strong></h3><ul>\n<li>Given $G_0$</li>\n<li>Find $D_0^*$ maximizing $V(G_0,D)$</li>\n<li>$\\theta_G \\leftarrow \\theta_G - \\eta \\partial V(G, D_0^*)/ \\partial \\theta_G $ =&gt; Obtain G1</li>\n<li>Find $D_1^*$ maximizing $V(G_1,D)$</li>\n<li></li>\n</ul>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p>mV</p>\n<script type=\"math/tex; mode=display\">\nV = \\frac{1}{m}\\sum logD(x_i) + \\frac{1}{m} \\sum log(1-D(x_i^G)) \\\\\nwhere \\{x_1, ..., x_m\\}  from P_{data}(x), \\{x_1^G,...,x_m^G\\} from P_G(x)</script>"},{"title":"Hands on Scrapy","date":"2017-06-21T18:00:27.000Z","_content":"\n# \n\n## \n\n```bash\nscrapy startproject <project_name> [project_dir]\n```\n\n\n\n```\n author.json\n runSpider.py\n scrapy.cfg\n projectname\n     __init__.py\n     items.py\n     middlewares.py\n     pipelines.py\n     settings.py      // \n     spiders          // \n         __init__.py\n         spider0.py\n         spider1.py\n```\n\n## \n\n\n\n```python\nfrom scrapy.spiders import CrawlSpider\nfrom scrapy.selector import Selector\nfrom scrapy.http import Request, FormRequest\n\nfrom tutorial.settings import *\n\nclass SampleSpider(CrawlSpider):\n    name = 'sampleSpider'\n    allowed_domains = ['sample.com']\n    start_url = 'https://sample.xxx.xx.x.x.x.xxx'\n\n    def __init__(self):\n        self.headers = HEADER\n    \n    def start_requests(self):\n        return [Request(\n            \"https://sample.com/signin\",\n            meta = {'cookiejar' : 1},\n            callback = self.post_login\n        )]\n\n    def post_login(self, response):\n        return [FormRequest(\n            'https://www.sample.com/login/',\n            method='POST',\n            meta={'cookiejar': response.meta['cookiejar']},\n            formdata = {\n                'email':'xxxx',\n                'password':'yyyy',\n            },\n            callback = self.after_login\n        )]\n\n    def after_login(self, response):\n        return [Request(\n            self.start_url,\n            meta={'cookiejar': response.meta['cookiejar']},\n            callback=self.parse,\n            errback=self.parse_err,\n        )]\n    \n    def parse(self, response):\n        # do something\n        pass\n\n    def parse_err(self, response):\n        print('eeeerrrrrrooooooorrrrrr!!!!!!')\n\n```\n\n## \n\n#### \n\n- CSS Selector\n- XPath\n\nCSSgoogle\n\n```python\nquery = 'h1.title::text'\nresponse.css(query).extract()[0]\nresponse.css(query).extract_first()\n# response.css(query).extract_first().strip() # strip\n```\n\n#### BeautifulSoup\n\njs\n\n#### lxml\n\nXMLHTML\n\n## Item\n\n\n\nItemLoader\n\n#### Item Pipeline\n\nItemItem Pipelinereturn Itempipeline\n\n- Item\n\n  ```python\n  from scrapy.exceptions import DropItem\n\n  class PricePipeline(object):\n\n      vat_factor = 1.15\n\n      def process_item(self, item, spider):\n          if item['price']:\n              if item['price_excludes_vat']:\n                  item['price'] = item['price'] * self.vat_factor\n              return item\n          else:\n              raise DropItem(\"Missing price in %s\" % item)\n  ```\n\n- JSON\n\n  ```python\n  import json\n\n  class JsonWriterPipeline(object):\n\n      def open_spider(self, spider):\n          self.file = open('items.jl', 'w')\n\n      def close_spider(self, spider):\n          self.file.close()\n\n      def process_item(self, item, spider):\n          line = json.dumps(dict(item)) + \"\\n\"\n          self.file.write(line)\n          return item\n  ```\n\n- MongoDB\n\n  ```python\n  import pymongo\n\n  class MongoPipeline(object):\n\n      collection_name = 'scrapy_items'\n\n      def __init__(self, mongo_uri, mongo_db):\n          self.mongo_uri = mongo_uri\n          self.mongo_db = mongo_db\n\n      @classmethod\n      def from_crawler(cls, crawler):\n          return cls(\n              mongo_uri=crawler.settings.get('MONGO_URI'),\n              mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')\n          )\n\n      def open_spider(self, spider):\n          self.client = pymongo.MongoClient(self.mongo_uri)\n          self.db = self.client[self.mongo_db]\n\n      def close_spider(self, spider):\n          self.client.close()\n\n      def process_item(self, item, spider):\n          self.db[self.collection_name].insert_one(dict(item))\n          return item\n  ```\n\n\n\n# \n\n## \n\n- POST\n\n  1. chrome\"network\"\n  2. network()\n  3. headersform data\n  4. (Request url)\n\n  \n\n  pilcookie\n\n- Cookie\n\n  1. network\n  2. headerscookies\n  3. cookiesRequest\n\n\n## CrawlSpider\n\nSpiderCrawSpiderparse\n\nCrawlSpiderRuleparsefollowcallback\n\ncallbackparseCrawlSpider","source":"_posts/Hands-on-Scrapy.md","raw":"---\ntitle: Hands on Scrapy\ndate: 2017-06-21 20:00:27\ncategories: [programming]\ntags: [scrapy, python, spider, crawl]\n---\n\n# \n\n## \n\n```bash\nscrapy startproject <project_name> [project_dir]\n```\n\n\n\n```\n author.json\n runSpider.py\n scrapy.cfg\n projectname\n     __init__.py\n     items.py\n     middlewares.py\n     pipelines.py\n     settings.py      // \n     spiders          // \n         __init__.py\n         spider0.py\n         spider1.py\n```\n\n## \n\n\n\n```python\nfrom scrapy.spiders import CrawlSpider\nfrom scrapy.selector import Selector\nfrom scrapy.http import Request, FormRequest\n\nfrom tutorial.settings import *\n\nclass SampleSpider(CrawlSpider):\n    name = 'sampleSpider'\n    allowed_domains = ['sample.com']\n    start_url = 'https://sample.xxx.xx.x.x.x.xxx'\n\n    def __init__(self):\n        self.headers = HEADER\n    \n    def start_requests(self):\n        return [Request(\n            \"https://sample.com/signin\",\n            meta = {'cookiejar' : 1},\n            callback = self.post_login\n        )]\n\n    def post_login(self, response):\n        return [FormRequest(\n            'https://www.sample.com/login/',\n            method='POST',\n            meta={'cookiejar': response.meta['cookiejar']},\n            formdata = {\n                'email':'xxxx',\n                'password':'yyyy',\n            },\n            callback = self.after_login\n        )]\n\n    def after_login(self, response):\n        return [Request(\n            self.start_url,\n            meta={'cookiejar': response.meta['cookiejar']},\n            callback=self.parse,\n            errback=self.parse_err,\n        )]\n    \n    def parse(self, response):\n        # do something\n        pass\n\n    def parse_err(self, response):\n        print('eeeerrrrrrooooooorrrrrr!!!!!!')\n\n```\n\n## \n\n#### \n\n- CSS Selector\n- XPath\n\nCSSgoogle\n\n```python\nquery = 'h1.title::text'\nresponse.css(query).extract()[0]\nresponse.css(query).extract_first()\n# response.css(query).extract_first().strip() # strip\n```\n\n#### BeautifulSoup\n\njs\n\n#### lxml\n\nXMLHTML\n\n## Item\n\n\n\nItemLoader\n\n#### Item Pipeline\n\nItemItem Pipelinereturn Itempipeline\n\n- Item\n\n  ```python\n  from scrapy.exceptions import DropItem\n\n  class PricePipeline(object):\n\n      vat_factor = 1.15\n\n      def process_item(self, item, spider):\n          if item['price']:\n              if item['price_excludes_vat']:\n                  item['price'] = item['price'] * self.vat_factor\n              return item\n          else:\n              raise DropItem(\"Missing price in %s\" % item)\n  ```\n\n- JSON\n\n  ```python\n  import json\n\n  class JsonWriterPipeline(object):\n\n      def open_spider(self, spider):\n          self.file = open('items.jl', 'w')\n\n      def close_spider(self, spider):\n          self.file.close()\n\n      def process_item(self, item, spider):\n          line = json.dumps(dict(item)) + \"\\n\"\n          self.file.write(line)\n          return item\n  ```\n\n- MongoDB\n\n  ```python\n  import pymongo\n\n  class MongoPipeline(object):\n\n      collection_name = 'scrapy_items'\n\n      def __init__(self, mongo_uri, mongo_db):\n          self.mongo_uri = mongo_uri\n          self.mongo_db = mongo_db\n\n      @classmethod\n      def from_crawler(cls, crawler):\n          return cls(\n              mongo_uri=crawler.settings.get('MONGO_URI'),\n              mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')\n          )\n\n      def open_spider(self, spider):\n          self.client = pymongo.MongoClient(self.mongo_uri)\n          self.db = self.client[self.mongo_db]\n\n      def close_spider(self, spider):\n          self.client.close()\n\n      def process_item(self, item, spider):\n          self.db[self.collection_name].insert_one(dict(item))\n          return item\n  ```\n\n\n\n# \n\n## \n\n- POST\n\n  1. chrome\"network\"\n  2. network()\n  3. headersform data\n  4. (Request url)\n\n  \n\n  pilcookie\n\n- Cookie\n\n  1. network\n  2. headerscookies\n  3. cookiesRequest\n\n\n## CrawlSpider\n\nSpiderCrawSpiderparse\n\nCrawlSpiderRuleparsefollowcallback\n\ncallbackparseCrawlSpider","slug":"Hands-on-Scrapy","published":1,"updated":"2017-06-22T14:15:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvpm000bpzm9rfxtzdm9","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">scrapy startproject &lt;project_name&gt; [project_dir]</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"> author.json</div><div class=\"line\"> runSpider.py</div><div class=\"line\"> scrapy.cfg</div><div class=\"line\"> projectname</div><div class=\"line\">     __init__.py</div><div class=\"line\">     items.py</div><div class=\"line\">     middlewares.py</div><div class=\"line\">     pipelines.py</div><div class=\"line\">     settings.py      // </div><div class=\"line\">     spiders          // </div><div class=\"line\">         __init__.py</div><div class=\"line\">         spider0.py</div><div class=\"line\">         spider1.py</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> scrapy.spiders <span class=\"keyword\">import</span> CrawlSpider</div><div class=\"line\"><span class=\"keyword\">from</span> scrapy.selector <span class=\"keyword\">import</span> Selector</div><div class=\"line\"><span class=\"keyword\">from</span> scrapy.http <span class=\"keyword\">import</span> Request, FormRequest</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">from</span> tutorial.settings <span class=\"keyword\">import</span> *</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SampleSpider</span><span class=\"params\">(CrawlSpider)</span>:</span></div><div class=\"line\">    name = <span class=\"string\">'sampleSpider'</span></div><div class=\"line\">    allowed_domains = [<span class=\"string\">'sample.com'</span>]</div><div class=\"line\">    start_url = <span class=\"string\">'https://sample.xxx.xx.x.x.x.xxx'</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.headers = HEADER</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">start_requests</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> [Request(</div><div class=\"line\">            <span class=\"string\">\"https://sample.com/signin\"</span>,</div><div class=\"line\">            meta = &#123;<span class=\"string\">'cookiejar'</span> : <span class=\"number\">1</span>&#125;,</div><div class=\"line\">            callback = self.post_login</div><div class=\"line\">        )]</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">post_login</span><span class=\"params\">(self, response)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> [FormRequest(</div><div class=\"line\">            <span class=\"string\">'https://www.sample.com/login/'</span>,</div><div class=\"line\">            method=<span class=\"string\">'POST'</span>,</div><div class=\"line\">            meta=&#123;<span class=\"string\">'cookiejar'</span>: response.meta[<span class=\"string\">'cookiejar'</span>]&#125;,</div><div class=\"line\">            formdata = &#123;</div><div class=\"line\">                <span class=\"string\">'email'</span>:<span class=\"string\">'xxxx'</span>,</div><div class=\"line\">                <span class=\"string\">'password'</span>:<span class=\"string\">'yyyy'</span>,</div><div class=\"line\">            &#125;,</div><div class=\"line\">            callback = self.after_login</div><div class=\"line\">        )]</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">after_login</span><span class=\"params\">(self, response)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> [Request(</div><div class=\"line\">            self.start_url,</div><div class=\"line\">            meta=&#123;<span class=\"string\">'cookiejar'</span>: response.meta[<span class=\"string\">'cookiejar'</span>]&#125;,</div><div class=\"line\">            callback=self.parse,</div><div class=\"line\">            errback=self.parse_err,</div><div class=\"line\">        )]</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse</span><span class=\"params\">(self, response)</span>:</span></div><div class=\"line\">        <span class=\"comment\"># do something</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_err</span><span class=\"params\">(self, response)</span>:</span></div><div class=\"line\">        print(<span class=\"string\">'eeeerrrrrrooooooorrrrrr!!!!!!'</span>)</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><ul>\n<li>CSS Selector</li>\n<li>XPath</li>\n</ul>\n<p>CSSgoogle</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">query = <span class=\"string\">'h1.title::text'</span></div><div class=\"line\">response.css(query).extract()[<span class=\"number\">0</span>]</div><div class=\"line\">response.css(query).extract_first()</div><div class=\"line\"><span class=\"comment\"># response.css(query).extract_first().strip() # strip</span></div></pre></td></tr></table></figure>\n<h4 id=\"BeautifulSoup\"><a href=\"#BeautifulSoup\" class=\"headerlink\" title=\"BeautifulSoup\"></a>BeautifulSoup</h4><p>js</p>\n<h4 id=\"lxml\"><a href=\"#lxml\" class=\"headerlink\" title=\"lxml\"></a>lxml</h4><p>XMLHTML</p>\n<h2 id=\"Item\"><a href=\"#Item\" class=\"headerlink\" title=\"Item\"></a>Item</h2><p></p>\n<p>ItemLoader</p>\n<h4 id=\"Item-Pipeline\"><a href=\"#Item-Pipeline\" class=\"headerlink\" title=\"Item Pipeline\"></a>Item Pipeline</h4><p>ItemItem Pipelinereturn Itempipeline</p>\n<ul>\n<li><p>Item</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> scrapy.exceptions <span class=\"keyword\">import</span> DropItem</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PricePipeline</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\"></div><div class=\"line\">    vat_factor = <span class=\"number\">1.15</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span><span class=\"params\">(self, item, spider)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> item[<span class=\"string\">'price'</span>]:</div><div class=\"line\">            <span class=\"keyword\">if</span> item[<span class=\"string\">'price_excludes_vat'</span>]:</div><div class=\"line\">                item[<span class=\"string\">'price'</span>] = item[<span class=\"string\">'price'</span>] * self.vat_factor</div><div class=\"line\">            <span class=\"keyword\">return</span> item</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">raise</span> DropItem(<span class=\"string\">\"Missing price in %s\"</span> % item)</div></pre></td></tr></table></figure>\n</li>\n<li><p>JSON</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> json</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JsonWriterPipeline</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span><span class=\"params\">(self, spider)</span>:</span></div><div class=\"line\">        self.file = open(<span class=\"string\">'items.jl'</span>, <span class=\"string\">'w'</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span><span class=\"params\">(self, spider)</span>:</span></div><div class=\"line\">        self.file.close()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span><span class=\"params\">(self, item, spider)</span>:</span></div><div class=\"line\">        line = json.dumps(dict(item)) + <span class=\"string\">\"\\n\"</span></div><div class=\"line\">        self.file.write(line)</div><div class=\"line\">        <span class=\"keyword\">return</span> item</div></pre></td></tr></table></figure>\n</li>\n<li><p>MongoDB</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> pymongo</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MongoPipeline</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\"></div><div class=\"line\">    collection_name = <span class=\"string\">'scrapy_items'</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, mongo_uri, mongo_db)</span>:</span></div><div class=\"line\">        self.mongo_uri = mongo_uri</div><div class=\"line\">        self.mongo_db = mongo_db</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">    @classmethod</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">from_crawler</span><span class=\"params\">(cls, crawler)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> cls(</div><div class=\"line\">            mongo_uri=crawler.settings.get(<span class=\"string\">'MONGO_URI'</span>),</div><div class=\"line\">            mongo_db=crawler.settings.get(<span class=\"string\">'MONGO_DATABASE'</span>, <span class=\"string\">'items'</span>)</div><div class=\"line\">        )</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span><span class=\"params\">(self, spider)</span>:</span></div><div class=\"line\">        self.client = pymongo.MongoClient(self.mongo_uri)</div><div class=\"line\">        self.db = self.client[self.mongo_db]</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span><span class=\"params\">(self, spider)</span>:</span></div><div class=\"line\">        self.client.close()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span><span class=\"params\">(self, item, spider)</span>:</span></div><div class=\"line\">        self.db[self.collection_name].insert_one(dict(item))</div><div class=\"line\">        <span class=\"keyword\">return</span> item</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>POST</p>\n<ol>\n<li>chromenetwork</li>\n<li>network()</li>\n<li>headersform data</li>\n<li>(Request url)</li>\n</ol>\n<p></p>\n<p>pilcookie</p>\n</li>\n<li><p>Cookie</p>\n<ol>\n<li>network</li>\n<li>headerscookies</li>\n<li>cookiesRequest</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"CrawlSpider\"><a href=\"#CrawlSpider\" class=\"headerlink\" title=\"CrawlSpider\"></a>CrawlSpider</h2><p>SpiderCrawSpiderparse</p>\n<p>CrawlSpiderRuleparsefollowcallback</p>\n<p>callbackparseCrawlSpider</p>\n","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">scrapy startproject &lt;project_name&gt; [project_dir]</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"> author.json</div><div class=\"line\"> runSpider.py</div><div class=\"line\"> scrapy.cfg</div><div class=\"line\"> projectname</div><div class=\"line\">     __init__.py</div><div class=\"line\">     items.py</div><div class=\"line\">     middlewares.py</div><div class=\"line\">     pipelines.py</div><div class=\"line\">     settings.py      // </div><div class=\"line\">     spiders          // </div><div class=\"line\">         __init__.py</div><div class=\"line\">         spider0.py</div><div class=\"line\">         spider1.py</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div><div class=\"line\">33</div><div class=\"line\">34</div><div class=\"line\">35</div><div class=\"line\">36</div><div class=\"line\">37</div><div class=\"line\">38</div><div class=\"line\">39</div><div class=\"line\">40</div><div class=\"line\">41</div><div class=\"line\">42</div><div class=\"line\">43</div><div class=\"line\">44</div><div class=\"line\">45</div><div class=\"line\">46</div><div class=\"line\">47</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> scrapy.spiders <span class=\"keyword\">import</span> CrawlSpider</div><div class=\"line\"><span class=\"keyword\">from</span> scrapy.selector <span class=\"keyword\">import</span> Selector</div><div class=\"line\"><span class=\"keyword\">from</span> scrapy.http <span class=\"keyword\">import</span> Request, FormRequest</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">from</span> tutorial.settings <span class=\"keyword\">import</span> *</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SampleSpider</span><span class=\"params\">(CrawlSpider)</span>:</span></div><div class=\"line\">    name = <span class=\"string\">'sampleSpider'</span></div><div class=\"line\">    allowed_domains = [<span class=\"string\">'sample.com'</span>]</div><div class=\"line\">    start_url = <span class=\"string\">'https://sample.xxx.xx.x.x.x.xxx'</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        self.headers = HEADER</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">start_requests</span><span class=\"params\">(self)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> [Request(</div><div class=\"line\">            <span class=\"string\">\"https://sample.com/signin\"</span>,</div><div class=\"line\">            meta = &#123;<span class=\"string\">'cookiejar'</span> : <span class=\"number\">1</span>&#125;,</div><div class=\"line\">            callback = self.post_login</div><div class=\"line\">        )]</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">post_login</span><span class=\"params\">(self, response)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> [FormRequest(</div><div class=\"line\">            <span class=\"string\">'https://www.sample.com/login/'</span>,</div><div class=\"line\">            method=<span class=\"string\">'POST'</span>,</div><div class=\"line\">            meta=&#123;<span class=\"string\">'cookiejar'</span>: response.meta[<span class=\"string\">'cookiejar'</span>]&#125;,</div><div class=\"line\">            formdata = &#123;</div><div class=\"line\">                <span class=\"string\">'email'</span>:<span class=\"string\">'xxxx'</span>,</div><div class=\"line\">                <span class=\"string\">'password'</span>:<span class=\"string\">'yyyy'</span>,</div><div class=\"line\">            &#125;,</div><div class=\"line\">            callback = self.after_login</div><div class=\"line\">        )]</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">after_login</span><span class=\"params\">(self, response)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> [Request(</div><div class=\"line\">            self.start_url,</div><div class=\"line\">            meta=&#123;<span class=\"string\">'cookiejar'</span>: response.meta[<span class=\"string\">'cookiejar'</span>]&#125;,</div><div class=\"line\">            callback=self.parse,</div><div class=\"line\">            errback=self.parse_err,</div><div class=\"line\">        )]</div><div class=\"line\">    </div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse</span><span class=\"params\">(self, response)</span>:</span></div><div class=\"line\">        <span class=\"comment\"># do something</span></div><div class=\"line\">        <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_err</span><span class=\"params\">(self, response)</span>:</span></div><div class=\"line\">        print(<span class=\"string\">'eeeerrrrrrooooooorrrrrr!!!!!!'</span>)</div></pre></td></tr></table></figure>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><ul>\n<li>CSS Selector</li>\n<li>XPath</li>\n</ul>\n<p>CSSgoogle</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">query = <span class=\"string\">'h1.title::text'</span></div><div class=\"line\">response.css(query).extract()[<span class=\"number\">0</span>]</div><div class=\"line\">response.css(query).extract_first()</div><div class=\"line\"><span class=\"comment\"># response.css(query).extract_first().strip() # strip</span></div></pre></td></tr></table></figure>\n<h4 id=\"BeautifulSoup\"><a href=\"#BeautifulSoup\" class=\"headerlink\" title=\"BeautifulSoup\"></a>BeautifulSoup</h4><p>js</p>\n<h4 id=\"lxml\"><a href=\"#lxml\" class=\"headerlink\" title=\"lxml\"></a>lxml</h4><p>XMLHTML</p>\n<h2 id=\"Item\"><a href=\"#Item\" class=\"headerlink\" title=\"Item\"></a>Item</h2><p></p>\n<p>ItemLoader</p>\n<h4 id=\"Item-Pipeline\"><a href=\"#Item-Pipeline\" class=\"headerlink\" title=\"Item Pipeline\"></a>Item Pipeline</h4><p>ItemItem Pipelinereturn Itempipeline</p>\n<ul>\n<li><p>Item</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> scrapy.exceptions <span class=\"keyword\">import</span> DropItem</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PricePipeline</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\"></div><div class=\"line\">    vat_factor = <span class=\"number\">1.15</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span><span class=\"params\">(self, item, spider)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">if</span> item[<span class=\"string\">'price'</span>]:</div><div class=\"line\">            <span class=\"keyword\">if</span> item[<span class=\"string\">'price_excludes_vat'</span>]:</div><div class=\"line\">                item[<span class=\"string\">'price'</span>] = item[<span class=\"string\">'price'</span>] * self.vat_factor</div><div class=\"line\">            <span class=\"keyword\">return</span> item</div><div class=\"line\">        <span class=\"keyword\">else</span>:</div><div class=\"line\">            <span class=\"keyword\">raise</span> DropItem(<span class=\"string\">\"Missing price in %s\"</span> % item)</div></pre></td></tr></table></figure>\n</li>\n<li><p>JSON</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> json</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JsonWriterPipeline</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span><span class=\"params\">(self, spider)</span>:</span></div><div class=\"line\">        self.file = open(<span class=\"string\">'items.jl'</span>, <span class=\"string\">'w'</span>)</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span><span class=\"params\">(self, spider)</span>:</span></div><div class=\"line\">        self.file.close()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span><span class=\"params\">(self, item, spider)</span>:</span></div><div class=\"line\">        line = json.dumps(dict(item)) + <span class=\"string\">\"\\n\"</span></div><div class=\"line\">        self.file.write(line)</div><div class=\"line\">        <span class=\"keyword\">return</span> item</div></pre></td></tr></table></figure>\n</li>\n<li><p>MongoDB</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">import</span> pymongo</div><div class=\"line\"></div><div class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MongoPipeline</span><span class=\"params\">(object)</span>:</span></div><div class=\"line\"></div><div class=\"line\">    collection_name = <span class=\"string\">'scrapy_items'</span></div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span><span class=\"params\">(self, mongo_uri, mongo_db)</span>:</span></div><div class=\"line\">        self.mongo_uri = mongo_uri</div><div class=\"line\">        self.mongo_db = mongo_db</div><div class=\"line\"></div><div class=\"line\"><span class=\"meta\">    @classmethod</span></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">from_crawler</span><span class=\"params\">(cls, crawler)</span>:</span></div><div class=\"line\">        <span class=\"keyword\">return</span> cls(</div><div class=\"line\">            mongo_uri=crawler.settings.get(<span class=\"string\">'MONGO_URI'</span>),</div><div class=\"line\">            mongo_db=crawler.settings.get(<span class=\"string\">'MONGO_DATABASE'</span>, <span class=\"string\">'items'</span>)</div><div class=\"line\">        )</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span><span class=\"params\">(self, spider)</span>:</span></div><div class=\"line\">        self.client = pymongo.MongoClient(self.mongo_uri)</div><div class=\"line\">        self.db = self.client[self.mongo_db]</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span><span class=\"params\">(self, spider)</span>:</span></div><div class=\"line\">        self.client.close()</div><div class=\"line\"></div><div class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span><span class=\"params\">(self, item, spider)</span>:</span></div><div class=\"line\">        self.db[self.collection_name].insert_one(dict(item))</div><div class=\"line\">        <span class=\"keyword\">return</span> item</div></pre></td></tr></table></figure>\n</li>\n</ul>\n<p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>POST</p>\n<ol>\n<li>chromenetwork</li>\n<li>network()</li>\n<li>headersform data</li>\n<li>(Request url)</li>\n</ol>\n<p></p>\n<p>pilcookie</p>\n</li>\n<li><p>Cookie</p>\n<ol>\n<li>network</li>\n<li>headerscookies</li>\n<li>cookiesRequest</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"CrawlSpider\"><a href=\"#CrawlSpider\" class=\"headerlink\" title=\"CrawlSpider\"></a>CrawlSpider</h2><p>SpiderCrawSpiderparse</p>\n<p>CrawlSpiderRuleparsefollowcallback</p>\n<p>callbackparseCrawlSpider</p>\n"},{"title":"Hilbert space","date":"2017-02-11T12:10:06.000Z","_content":"\n#  Hilbert space\n\n## \n\nwiki:\n\n>********\n\n\n\n### \n\n- \n\n  \n\n- \n\n  \n\n- (complet)\n\n  \n\n- \n\n  \n\n### \n\n- \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n(( +   =  + ) +  = ) +  = \n\n## \n\n- \n\n  \n\n- \n\n- \n\n  L^2:\n\n  \n  $$\n  (f|g) = \\int{\\overline{f}g}\n  $$\n  .\n\n- \n\n  H^sW^(s,2)\n\n## \n\n- 1\n- \n- H\n\n## \n\n- (produit scalaire)\n\n  \n\n$$\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0\n$$\n","source":"_posts/Hilbert-space.md","raw":"---\ntitle: Hilbert space\ndate: 2017-02-11 13:10:06\ncategories: [math]\ntags: [Hilbert, math, analyse]\n---\n\n#  Hilbert space\n\n## \n\nwiki:\n\n>********\n\n\n\n### \n\n- \n\n  \n\n- \n\n  \n\n- (complet)\n\n  \n\n- \n\n  \n\n### \n\n- \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n(( +   =  + ) +  = ) +  = \n\n## \n\n- \n\n  \n\n- \n\n- \n\n  L^2:\n\n  \n  $$\n  (f|g) = \\int{\\overline{f}g}\n  $$\n  .\n\n- \n\n  H^sW^(s,2)\n\n## \n\n- 1\n- \n- H\n\n## \n\n- (produit scalaire)\n\n  \n\n$$\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0\n$$\n","slug":"Hilbert-space","published":1,"updated":"2017-02-11T12:57:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvpo000dpzm9mzhs3zhw","content":"<h1 id=\"-Hilbert-space\"><a href=\"#-Hilbert-space\" class=\"headerlink\" title=\" Hilbert space\"></a> Hilbert space</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>wiki:</p>\n<blockquote>\n<p><strong></strong><strong></strong></p>\n</blockquote>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p>(complet)</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n<p>(( +   =  + ) +  = ) +  = </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n<p>L^2:</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n(f|g) = \\int{\\overline{f}g}</script><p>.</p>\n</li>\n<li><p></p>\n<p>H^sW^(s,2)</p>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>1</li>\n<li></li>\n<li>H</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>(produit scalaire)</p>\n<p></p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0</script>","excerpt":"","more":"<h1 id=\"-Hilbert-space\"><a href=\"#-Hilbert-space\" class=\"headerlink\" title=\" Hilbert space\"></a> Hilbert space</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>wiki:</p>\n<blockquote>\n<p><strong></strong><strong></strong></p>\n</blockquote>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p>(complet)</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n<p>(( +   =  + ) +  = ) +  = </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n<p>L^2:</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n(f|g) = \\int{\\overline{f}g}</script><p>.</p>\n</li>\n<li><p></p>\n<p>H^sW^(s,2)</p>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>1</li>\n<li></li>\n<li>H</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>(produit scalaire)</p>\n<p></p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0</script>"},{"title":"ML CNN","date":"2016-12-14T09:34:43.000Z","_content":"\n\n\n(CNN)(RNN)\n\n# \n\n \n\n## \n\n\n$$\nx = [x_0,x_1,...,x_n]^T\n$$\n\n$$\nz = [z_0,z_1,...,z_m]^T\n$$\n\n$$\nW_{m \\times n}\n$$\n\n$$\nb = [b_0,b_1,...,b_m]^T\n$$\n\n$$\nW * x + b = z\n$$\n\n## \n\n****()\n\n\n\n\n\n1. sigmoid\n\n    sigmoid\n\n   \n   $$\n   f(x) = \\frac{1}{1+e^{-x}}\n   $$\n   R(0, 1)\n\n2. \n   $$\n   f(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n   $$\n   (-1,1)sigmoid\n\n","source":"_posts/ML-CNN.md","raw":"---\ntitle: ML CNN\ndate: 2016-12-14 10:34:43\ncategories: [programming, unfinished]\ntags: [machine-learning, programming, algo, CNN]\n---\n\n\n\n(CNN)(RNN)\n\n# \n\n \n\n## \n\n\n$$\nx = [x_0,x_1,...,x_n]^T\n$$\n\n$$\nz = [z_0,z_1,...,z_m]^T\n$$\n\n$$\nW_{m \\times n}\n$$\n\n$$\nb = [b_0,b_1,...,b_m]^T\n$$\n\n$$\nW * x + b = z\n$$\n\n## \n\n****()\n\n\n\n\n\n1. sigmoid\n\n    sigmoid\n\n   \n   $$\n   f(x) = \\frac{1}{1+e^{-x}}\n   $$\n   R(0, 1)\n\n2. \n   $$\n   f(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n   $$\n   (-1,1)sigmoid\n\n","slug":"ML-CNN","published":1,"updated":"2016-12-15T15:36:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvpq000gpzm9b898e6rw","content":"<p></p>\n<p>(CNN)(RNN)</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\nx = [x_0,x_1,...,x_n]^T</script><p></p>\n<script type=\"math/tex; mode=display\">\nz = [z_0,z_1,...,z_m]^T</script><p></p>\n<script type=\"math/tex; mode=display\">\nW_{m \\times n}</script><p></p>\n<script type=\"math/tex; mode=display\">\nb = [b_0,b_1,...,b_m]^T</script><p></p>\n<script type=\"math/tex; mode=display\">\nW * x + b = z</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong>()</p>\n<p></p>\n<p></p>\n<ol>\n<li><p>sigmoid</p>\n<p> sigmoid</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{1+e^{-x}}</script><p>R(0, 1)</p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}</script><p>(-1,1)sigmoid</p>\n</li>\n</ol>\n","excerpt":"","more":"<p></p>\n<p>(CNN)(RNN)</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<script type=\"math/tex; mode=display\">\nx = [x_0,x_1,...,x_n]^T</script><p></p>\n<script type=\"math/tex; mode=display\">\nz = [z_0,z_1,...,z_m]^T</script><p></p>\n<script type=\"math/tex; mode=display\">\nW_{m \\times n}</script><p></p>\n<script type=\"math/tex; mode=display\">\nb = [b_0,b_1,...,b_m]^T</script><p></p>\n<script type=\"math/tex; mode=display\">\nW * x + b = z</script><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong>()</p>\n<p></p>\n<p></p>\n<ol>\n<li><p>sigmoid</p>\n<p> sigmoid</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{1+e^{-x}}</script><p>R(0, 1)</p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}</script><p>(-1,1)sigmoid</p>\n</li>\n</ol>\n"},{"title":" Method of programming facing to exams","date":"2016-11-27T12:49:31.000Z","_content":"\n1. \n\n   \n\n2. \n\n   \n\n3. \n\n   ```Python\n   def merge(A, B):\n       # merge two small solved problems into one.\n       return merged\n\n   def divideConquer(S, divide, combine):\n       if len(S) == 1: return S\n       # divide a grand problems\n       L, R = divide(S)\n       A = divideConquer(L, divide, combine)\n       B = divideConquer(R, divide, combine)\n       return merge(A, B)\n   ```\n\n   \n\n4. \n\n   [](http://blog.csdn.net/littlethunder/article/details/26575417)\n\n   ```Python\n   def bag(n,c,w,v):  \n       res=[[-1 for j in range(c+1)] for i in range(n+1)]  \n       for j in range(c+1):  \n           res[0][j]=0  \n       for i in range(1,n+1):  \n           for j in range(1,c+1):  \n               res[i][j]=res[i-1][j]  \n               if j>=w[i-1] and res[i][j]<res[i-1][j-w[i-1]]+v[i-1]:  \n                   res[i][j]=res[i-1][j-w[i-1]]+v[i-1]  \n       return res  \n     \n   def show(n,c,w,res):  \n       print(':',res[n][c])  \n       x=[False for i in range(n)]  \n       j=c  \n       for i in range(1,n+1):  \n           if res[i][j]>res[i-1][j]:  \n               x[i-1]=True  \n               j-=w[i-1]  \n       print(':')  \n       for i in range(n):  \n           if x[i]:  \n               print('',i,',',end='')  \n       print('')  \n     \n   if __name__=='__main__':  \n       n=5  \n       c=10  \n       w=[2,2,6,5,4]  \n       v=[6,3,5,4,6]  \n       res=bag(n,c,w,v)  \n       show(n,c,w,res)\n   ```\n\n   ","source":"_posts/Method-of-programming-facing-to-exams.md","raw":"---\ntitle:  Method of programming facing to exams\ndate: 2016-11-27 13:49:31\ncategories: programming\ntags: [algo, programming]\n---\n\n1. \n\n   \n\n2. \n\n   \n\n3. \n\n   ```Python\n   def merge(A, B):\n       # merge two small solved problems into one.\n       return merged\n\n   def divideConquer(S, divide, combine):\n       if len(S) == 1: return S\n       # divide a grand problems\n       L, R = divide(S)\n       A = divideConquer(L, divide, combine)\n       B = divideConquer(R, divide, combine)\n       return merge(A, B)\n   ```\n\n   \n\n4. \n\n   [](http://blog.csdn.net/littlethunder/article/details/26575417)\n\n   ```Python\n   def bag(n,c,w,v):  \n       res=[[-1 for j in range(c+1)] for i in range(n+1)]  \n       for j in range(c+1):  \n           res[0][j]=0  \n       for i in range(1,n+1):  \n           for j in range(1,c+1):  \n               res[i][j]=res[i-1][j]  \n               if j>=w[i-1] and res[i][j]<res[i-1][j-w[i-1]]+v[i-1]:  \n                   res[i][j]=res[i-1][j-w[i-1]]+v[i-1]  \n       return res  \n     \n   def show(n,c,w,res):  \n       print(':',res[n][c])  \n       x=[False for i in range(n)]  \n       j=c  \n       for i in range(1,n+1):  \n           if res[i][j]>res[i-1][j]:  \n               x[i-1]=True  \n               j-=w[i-1]  \n       print(':')  \n       for i in range(n):  \n           if x[i]:  \n               print('',i,',',end='')  \n       print('')  \n     \n   if __name__=='__main__':  \n       n=5  \n       c=10  \n       w=[2,2,6,5,4]  \n       v=[6,3,5,4,6]  \n       res=bag(n,c,w,v)  \n       show(n,c,w,res)\n   ```\n\n   ","slug":"Method-of-programming-facing-to-exams","published":1,"updated":"2016-11-30T10:45:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvpt000jpzm9ha42dod1","content":"<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">merge</span><span class=\"params\">(A, B)</span>:</span></div><div class=\"line\">    <span class=\"comment\"># merge two small solved problems into one.</span></div><div class=\"line\">    <span class=\"keyword\">return</span> merged</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">divideConquer</span><span class=\"params\">(S, divide, combine)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">if</span> len(S) == <span class=\"number\">1</span>: <span class=\"keyword\">return</span> S</div><div class=\"line\">    <span class=\"comment\"># divide a grand problems</span></div><div class=\"line\">    L, R = divide(S)</div><div class=\"line\">    A = divideConquer(L, divide, combine)</div><div class=\"line\">    B = divideConquer(R, divide, combine)</div><div class=\"line\">    <span class=\"keyword\">return</span> merge(A, B)</div></pre></td></tr></table></figure>\n<p></p>\n</li>\n<li><p></p>\n<p><a href=\"http://blog.csdn.net/littlethunder/article/details/26575417\" target=\"_blank\" rel=\"external\"></a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bag</span><span class=\"params\">(n,c,w,v)</span>:</span>  </div><div class=\"line\">    res=[[<span class=\"number\">-1</span> <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(c+<span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n+<span class=\"number\">1</span>)]  </div><div class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(c+<span class=\"number\">1</span>):  </div><div class=\"line\">        res[<span class=\"number\">0</span>][j]=<span class=\"number\">0</span>  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </div><div class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,c+<span class=\"number\">1</span>):  </div><div class=\"line\">            res[i][j]=res[i<span class=\"number\">-1</span>][j]  </div><div class=\"line\">            <span class=\"keyword\">if</span> j&gt;=w[i<span class=\"number\">-1</span>] <span class=\"keyword\">and</span> res[i][j]&lt;res[i<span class=\"number\">-1</span>][j-w[i<span class=\"number\">-1</span>]]+v[i<span class=\"number\">-1</span>]:  </div><div class=\"line\">                res[i][j]=res[i<span class=\"number\">-1</span>][j-w[i<span class=\"number\">-1</span>]]+v[i<span class=\"number\">-1</span>]  </div><div class=\"line\">    <span class=\"keyword\">return</span> res  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">show</span><span class=\"params\">(n,c,w,res)</span>:</span>  </div><div class=\"line\">    print(<span class=\"string\">':'</span>,res[n][c])  </div><div class=\"line\">    x=[<span class=\"keyword\">False</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n)]  </div><div class=\"line\">    j=c  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </div><div class=\"line\">        <span class=\"keyword\">if</span> res[i][j]&gt;res[i<span class=\"number\">-1</span>][j]:  </div><div class=\"line\">            x[i<span class=\"number\">-1</span>]=<span class=\"keyword\">True</span>  </div><div class=\"line\">            j-=w[i<span class=\"number\">-1</span>]  </div><div class=\"line\">    print(<span class=\"string\">':'</span>)  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):  </div><div class=\"line\">        <span class=\"keyword\">if</span> x[i]:  </div><div class=\"line\">            print(<span class=\"string\">''</span>,i,<span class=\"string\">','</span>,end=<span class=\"string\">''</span>)  </div><div class=\"line\">    print(<span class=\"string\">''</span>)  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"keyword\">if</span> __name__==<span class=\"string\">'__main__'</span>:  </div><div class=\"line\">    n=<span class=\"number\">5</span>  </div><div class=\"line\">    c=<span class=\"number\">10</span>  </div><div class=\"line\">    w=[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">6</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>]  </div><div class=\"line\">    v=[<span class=\"number\">6</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">6</span>]  </div><div class=\"line\">    res=bag(n,c,w,v)  </div><div class=\"line\">    show(n,c,w,res)</div></pre></td></tr></table></figure>\n<p></p>\n</li>\n</ol>\n","excerpt":"","more":"<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">merge</span><span class=\"params\">(A, B)</span>:</span></div><div class=\"line\">    <span class=\"comment\"># merge two small solved problems into one.</span></div><div class=\"line\">    <span class=\"keyword\">return</span> merged</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">divideConquer</span><span class=\"params\">(S, divide, combine)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">if</span> len(S) == <span class=\"number\">1</span>: <span class=\"keyword\">return</span> S</div><div class=\"line\">    <span class=\"comment\"># divide a grand problems</span></div><div class=\"line\">    L, R = divide(S)</div><div class=\"line\">    A = divideConquer(L, divide, combine)</div><div class=\"line\">    B = divideConquer(R, divide, combine)</div><div class=\"line\">    <span class=\"keyword\">return</span> merge(A, B)</div></pre></td></tr></table></figure>\n<p></p>\n</li>\n<li><p></p>\n<p><a href=\"http://blog.csdn.net/littlethunder/article/details/26575417\"></a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bag</span><span class=\"params\">(n,c,w,v)</span>:</span>  </div><div class=\"line\">    res=[[<span class=\"number\">-1</span> <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(c+<span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n+<span class=\"number\">1</span>)]  </div><div class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(c+<span class=\"number\">1</span>):  </div><div class=\"line\">        res[<span class=\"number\">0</span>][j]=<span class=\"number\">0</span>  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </div><div class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,c+<span class=\"number\">1</span>):  </div><div class=\"line\">            res[i][j]=res[i<span class=\"number\">-1</span>][j]  </div><div class=\"line\">            <span class=\"keyword\">if</span> j&gt;=w[i<span class=\"number\">-1</span>] <span class=\"keyword\">and</span> res[i][j]&lt;res[i<span class=\"number\">-1</span>][j-w[i<span class=\"number\">-1</span>]]+v[i<span class=\"number\">-1</span>]:  </div><div class=\"line\">                res[i][j]=res[i<span class=\"number\">-1</span>][j-w[i<span class=\"number\">-1</span>]]+v[i<span class=\"number\">-1</span>]  </div><div class=\"line\">    <span class=\"keyword\">return</span> res  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">show</span><span class=\"params\">(n,c,w,res)</span>:</span>  </div><div class=\"line\">    print(<span class=\"string\">':'</span>,res[n][c])  </div><div class=\"line\">    x=[<span class=\"keyword\">False</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n)]  </div><div class=\"line\">    j=c  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </div><div class=\"line\">        <span class=\"keyword\">if</span> res[i][j]&gt;res[i<span class=\"number\">-1</span>][j]:  </div><div class=\"line\">            x[i<span class=\"number\">-1</span>]=<span class=\"keyword\">True</span>  </div><div class=\"line\">            j-=w[i<span class=\"number\">-1</span>]  </div><div class=\"line\">    print(<span class=\"string\">':'</span>)  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):  </div><div class=\"line\">        <span class=\"keyword\">if</span> x[i]:  </div><div class=\"line\">            print(<span class=\"string\">''</span>,i,<span class=\"string\">','</span>,end=<span class=\"string\">''</span>)  </div><div class=\"line\">    print(<span class=\"string\">''</span>)  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"keyword\">if</span> __name__==<span class=\"string\">'__main__'</span>:  </div><div class=\"line\">    n=<span class=\"number\">5</span>  </div><div class=\"line\">    c=<span class=\"number\">10</span>  </div><div class=\"line\">    w=[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">6</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>]  </div><div class=\"line\">    v=[<span class=\"number\">6</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">6</span>]  </div><div class=\"line\">    res=bag(n,c,w,v)  </div><div class=\"line\">    show(n,c,w,res)</div></pre></td></tr></table></figure>\n<p></p>\n</li>\n</ol>\n"},{"title":"MongoDB, Docker and Python","date":"2017-06-22T12:53:44.000Z","_content":"\n## \n\n\n\n- Docker\n- Python\n  - pymongo\n\n## Docker\n\n--rm-d\n\n27017mongodb\n\n```Bash\ndocker run --name my-mongo -it -p 27017:27017 mongo\n```\n\n\n\n```Shell\ndocker start my-mongo\n```\n\n## Python\n\n```python\nfrom pymongo import MongoClient\n\n# connection\nclient = MongoClient()\nclient.server_info()\ndb = client.test\n\n# loop cursor\ncursor = db.cars.find()\nfor doc in cursor:\n    print(doc)\n\n# or just find one\ndb.cars.find_one()\n```","source":"_posts/MongoDB-Docker-and-Python.md","raw":"---\ntitle: 'MongoDB, Docker and Python'\ndate: 2017-06-22 14:53:44\ncategories: [programming]\ntags: [mongo, mongodb, docker, python]\n---\n\n## \n\n\n\n- Docker\n- Python\n  - pymongo\n\n## Docker\n\n--rm-d\n\n27017mongodb\n\n```Bash\ndocker run --name my-mongo -it -p 27017:27017 mongo\n```\n\n\n\n```Shell\ndocker start my-mongo\n```\n\n## Python\n\n```python\nfrom pymongo import MongoClient\n\n# connection\nclient = MongoClient()\nclient.server_info()\ndb = client.test\n\n# loop cursor\ncursor = db.cars.find()\nfor doc in cursor:\n    print(doc)\n\n# or just find one\ndb.cars.find_one()\n```","slug":"MongoDB-Docker-and-Python","published":1,"updated":"2017-06-22T07:07:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvpv000opzm9namnozlq","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>Docker</li>\n<li>Python<ul>\n<li>pymongo</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Docker\"><a href=\"#Docker\" class=\"headerlink\" title=\"Docker\"></a>Docker</h2><p>rm-d</p>\n<p>27017mongodb</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name my-mongo -it -p 27017:27017 mongo</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker start my-mongo</div></pre></td></tr></table></figure>\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> pymongo <span class=\"keyword\">import</span> MongoClient</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># connection</span></div><div class=\"line\">client = MongoClient()</div><div class=\"line\">client.server_info()</div><div class=\"line\">db = client.test</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># loop cursor</span></div><div class=\"line\">cursor = db.cars.find()</div><div class=\"line\"><span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> cursor:</div><div class=\"line\">    print(doc)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># or just find one</span></div><div class=\"line\">db.cars.find_one()</div></pre></td></tr></table></figure>","excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>Docker</li>\n<li>Python<ul>\n<li>pymongo</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Docker\"><a href=\"#Docker\" class=\"headerlink\" title=\"Docker\"></a>Docker</h2><p>rm-d</p>\n<p>27017mongodb</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker run --name my-mongo -it -p 27017:27017 mongo</div></pre></td></tr></table></figure>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div></pre></td><td class=\"code\"><pre><div class=\"line\">docker start my-mongo</div></pre></td></tr></table></figure>\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"keyword\">from</span> pymongo <span class=\"keyword\">import</span> MongoClient</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># connection</span></div><div class=\"line\">client = MongoClient()</div><div class=\"line\">client.server_info()</div><div class=\"line\">db = client.test</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># loop cursor</span></div><div class=\"line\">cursor = db.cars.find()</div><div class=\"line\"><span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> cursor:</div><div class=\"line\">    print(doc)</div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># or just find one</span></div><div class=\"line\">db.cars.find_one()</div></pre></td></tr></table></figure>"},{"title":"Note of NLP","date":"2017-06-26T18:52:45.000Z","_content":"\n# NLP\n\n1. \"One-hot\" representation\n\n   \n   $$\n   [0,0,0,0,0,0,0,0,0,1,0,0,0]\n   $$\n\n2. Main idea of word2vec\n\n   Two algorithms\n\n   1. Skip-grams\n   2. Continuous bag of words (CBOW)\n\n   Two training methods\n\n   1. Hierarchical softmax\n   2. Negative sampling\n\n## \n\n>[Zeng et al. 2014] [Santos et al. 2015]\n>\n>[Miwa et al. 2016]  LSTMLong-Short Term Memory LSTM  SemEval-2010 Task 8 \n>\n>--__\n\nRNNNLP[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) [](http://www.csdn.net/article/2015-08-28/2825569)\n\nLSTM[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)  [LSTM](http://blog.csdn.net/jerr__y/article/details/58598296)\n\n[LSTMtensorflow](http://blog.csdn.net/jerr__y/article/details/61195257)\n\n### GAN ?\n\nACGANDiscriminator\n\nInfoGAN\n\nGAN","source":"_posts/Note-of-NLP.md","raw":"---\ntitle: Note of NLP\ndate: 2017-06-26 20:52:45\ncategories: [programming]\ntags: [nlp, machine-learning, deep-learning]\n---\n\n# NLP\n\n1. \"One-hot\" representation\n\n   \n   $$\n   [0,0,0,0,0,0,0,0,0,1,0,0,0]\n   $$\n\n2. Main idea of word2vec\n\n   Two algorithms\n\n   1. Skip-grams\n   2. Continuous bag of words (CBOW)\n\n   Two training methods\n\n   1. Hierarchical softmax\n   2. Negative sampling\n\n## \n\n>[Zeng et al. 2014] [Santos et al. 2015]\n>\n>[Miwa et al. 2016]  LSTMLong-Short Term Memory LSTM  SemEval-2010 Task 8 \n>\n>--__\n\nRNNNLP[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) [](http://www.csdn.net/article/2015-08-28/2825569)\n\nLSTM[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)  [LSTM](http://blog.csdn.net/jerr__y/article/details/58598296)\n\n[LSTMtensorflow](http://blog.csdn.net/jerr__y/article/details/61195257)\n\n### GAN ?\n\nACGANDiscriminator\n\nInfoGAN\n\nGAN","slug":"Note-of-NLP","published":1,"updated":"2017-06-28T09:13:58.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvq0000qpzm9qs5ujq1r","content":"<h1 id=\"NLP\"><a href=\"#NLP\" class=\"headerlink\" title=\"NLP\"></a>NLP</h1><ol>\n<li><p>One-hot representation</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n[0,0,0,0,0,0,0,0,0,1,0,0,0]</script></li>\n<li><p>Main idea of word2vec</p>\n<p>Two algorithms</p>\n<ol>\n<li>Skip-grams</li>\n<li>Continuous bag of words (CBOW)</li>\n</ol>\n<p>Two training methods</p>\n<ol>\n<li>Hierarchical softmax</li>\n<li>Negative sampling</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><blockquote>\n<p>[Zeng et al. 2014] [Santos et al. 2015]</p>\n<p>[Miwa et al. 2016]  LSTMLong-Short Term Memory LSTM  SemEval-2010 Task 8 </p>\n<p><em></em></p>\n</blockquote>\n<p>RNNNLP<a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\" target=\"_blank\" rel=\"external\">The Unreasonable Effectiveness of Recurrent Neural Networks</a> <a href=\"http://www.csdn.net/article/2015-08-28/2825569\" target=\"_blank\" rel=\"external\"></a></p>\n<p>LSTM<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\" target=\"_blank\" rel=\"external\">Understanding LSTM Networks</a>  <a href=\"http://blog.csdn.net/jerr__y/article/details/58598296\" target=\"_blank\" rel=\"external\">LSTM</a></p>\n<p><a href=\"http://blog.csdn.net/jerr__y/article/details/61195257\" target=\"_blank\" rel=\"external\">LSTMtensorflow</a></p>\n<h3 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN ?\"></a>GAN ?</h3><p>ACGANDiscriminator</p>\n<p>InfoGAN</p>\n<p>GAN</p>\n","excerpt":"","more":"<h1 id=\"NLP\"><a href=\"#NLP\" class=\"headerlink\" title=\"NLP\"></a>NLP</h1><ol>\n<li><p>One-hot representation</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n[0,0,0,0,0,0,0,0,0,1,0,0,0]</script></li>\n<li><p>Main idea of word2vec</p>\n<p>Two algorithms</p>\n<ol>\n<li>Skip-grams</li>\n<li>Continuous bag of words (CBOW)</li>\n</ol>\n<p>Two training methods</p>\n<ol>\n<li>Hierarchical softmax</li>\n<li>Negative sampling</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><blockquote>\n<p>[Zeng et al. 2014] [Santos et al. 2015]</p>\n<p>[Miwa et al. 2016]  LSTMLong-Short Term Memory LSTM  SemEval-2010 Task 8 </p>\n<p><em></em></p>\n</blockquote>\n<p>RNNNLP<a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a> <a href=\"http://www.csdn.net/article/2015-08-28/2825569\"></a></p>\n<p>LSTM<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>  <a href=\"http://blog.csdn.net/jerr__y/article/details/58598296\">LSTM</a></p>\n<p><a href=\"http://blog.csdn.net/jerr__y/article/details/61195257\">LSTMtensorflow</a></p>\n<h3 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN ?\"></a>GAN ?</h3><p>ACGANDiscriminator</p>\n<p>InfoGAN</p>\n<p>GAN</p>\n"},{"title":" Note of datamining","date":"2016-12-06T14:35:24.000Z","_content":"\n# \n\n\n\n1.  - data clearing\n2.  - data integration\n3.  - data transformation\n4.  - data mining\n5.  - pattern evaluation\n6.  - knowledge presentation\n\n# \n\n1. \n\n   age(X, \"20-29\") ^ income(X, \"20K-30K\") => buys(X, \"MP3\")\n\n   [support = 2%, confidence = 60%]\n\n2. \n\n   \n\n   - \n   - \n   - \n   - \n\n3. \n\n   \n\n   \n\n4. \n\n   ()\n\n   \n\n   \n\n5. \n\n   \n\n   \n\n# \n\n\n\n\n\n1. ;\n2. ;\n3. ;\n4. \n\n# \n\n","source":"_posts/Note-of-datamining.md","raw":"---\ntitle:  Note of datamining\ndate: 2016-12-6 15:35:24\ncategories: [programming, unfinished]\ntags: [datamining]\n---\n\n# \n\n\n\n1.  - data clearing\n2.  - data integration\n3.  - data transformation\n4.  - data mining\n5.  - pattern evaluation\n6.  - knowledge presentation\n\n# \n\n1. \n\n   age(X, \"20-29\") ^ income(X, \"20K-30K\") => buys(X, \"MP3\")\n\n   [support = 2%, confidence = 60%]\n\n2. \n\n   \n\n   - \n   - \n   - \n   - \n\n3. \n\n   \n\n   \n\n4. \n\n   ()\n\n   \n\n   \n\n5. \n\n   \n\n   \n\n# \n\n\n\n\n\n1. ;\n2. ;\n3. ;\n4. \n\n# \n\n","slug":"Note-of-datamining","published":1,"updated":"2016-12-06T21:04:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvq7000tpzm9un7kkhbo","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li> - data clearing</li>\n<li> - data integration</li>\n<li> - data transformation</li>\n<li> - data mining</li>\n<li> - pattern evaluation</li>\n<li> - knowledge presentation</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>age(X, 20-29) ^ income(X, 20K-30K) =&gt; buys(X, MP3)</p>\n<p>[support = 2%, confidence = 60%]</p>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>()</p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<ol>\n<li>;</li>\n<li>;</li>\n<li>;</li>\n<li></li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li> - data clearing</li>\n<li> - data integration</li>\n<li> - data transformation</li>\n<li> - data mining</li>\n<li> - pattern evaluation</li>\n<li> - knowledge presentation</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>age(X, 20-29) ^ income(X, 20K-30K) =&gt; buys(X, MP3)</p>\n<p>[support = 2%, confidence = 60%]</p>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>()</p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<ol>\n<li>;</li>\n<li>;</li>\n<li>;</li>\n<li></li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n"},{"title":" Note of learning Algo","date":"2016-11-27T11:38:32.000Z","_content":"\n# Data Structure\n\n{% post_link complexity How to calcul the complexity?  %} \n\n{% post_link compression How to make a compression?  %}\n\n1. The data : int, double, etc.\n2. The basic data structure\n   - Container\n   - Table \n   - Stack \n   - Queue \n   - List\n3. Tree\n   - Arbres binaires - \n     - ABR - \n   - Arbres n-aires\n4. Dictionary \n   - Hash table - Table de hachage - \n5. **Heap - Tas -  **\n   - \n   - \n6. Find-Union\n\n# Method of programming\n\n{% post_link Method-of-programming-facing-to-exams Savoir plus %}\n\n1. Echaustive / force brute - \n2. Try-error - Essai-erreur \n3. Glouton - \n4. Recursif - recursive - \n5. Divede merge - Diviser pour regner - \n6. Dynamic - Dynamique - \n\n# Graph\n\n{% post_link graph Savoir plus %}\n\n1. Traversal - parcours - \n   - BFS\n   - DFS\n2. Critical path method - plus court chemin\n   - Dijkstra\n   - Floyd\n   - Bellman-Ford\n3. Tree - arbre\n   - Prim\n   - Kruskal\n\n*backtracking\n\n*Branch and bound\n\n# Others\n\n1. \n   - \n   - fusion\n   - \n   - tas ","source":"_posts/Note-of-learning-Algo.md","raw":"---\ntitle:  Note of learning Algo\ndate: 2016-11-27 12:38:32\ncategories: programming\ntags: [algo, programming]\n---\n\n# Data Structure\n\n{% post_link complexity How to calcul the complexity?  %} \n\n{% post_link compression How to make a compression?  %}\n\n1. The data : int, double, etc.\n2. The basic data structure\n   - Container\n   - Table \n   - Stack \n   - Queue \n   - List\n3. Tree\n   - Arbres binaires - \n     - ABR - \n   - Arbres n-aires\n4. Dictionary \n   - Hash table - Table de hachage - \n5. **Heap - Tas -  **\n   - \n   - \n6. Find-Union\n\n# Method of programming\n\n{% post_link Method-of-programming-facing-to-exams Savoir plus %}\n\n1. Echaustive / force brute - \n2. Try-error - Essai-erreur \n3. Glouton - \n4. Recursif - recursive - \n5. Divede merge - Diviser pour regner - \n6. Dynamic - Dynamique - \n\n# Graph\n\n{% post_link graph Savoir plus %}\n\n1. Traversal - parcours - \n   - BFS\n   - DFS\n2. Critical path method - plus court chemin\n   - Dijkstra\n   - Floyd\n   - Bellman-Ford\n3. Tree - arbre\n   - Prim\n   - Kruskal\n\n*backtracking\n\n*Branch and bound\n\n# Others\n\n1. \n   - \n   - fusion\n   - \n   - tas ","slug":"Note-of-learning-Algo","published":1,"updated":"2016-11-30T10:56:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvql000vpzm9lze8mf54","content":"<h1 id=\"Data-Structure\"><a href=\"#Data-Structure\" class=\"headerlink\" title=\"Data Structure\"></a>Data Structure</h1><a href=\"/2016/11/27/complexity/\" title=\"How to calcul the complexity?\">How to calcul the complexity?</a> \n<a href=\"/2016/11/27/compression/\" title=\"How to make a compression?\">How to make a compression?</a>\n<ol>\n<li>The data : int, double, etc.</li>\n<li>The basic data structure<ul>\n<li>Container</li>\n<li>Table </li>\n<li>Stack </li>\n<li>Queue </li>\n<li>List</li>\n</ul>\n</li>\n<li>Tree<ul>\n<li>Arbres binaires - <ul>\n<li>ABR - </li>\n</ul>\n</li>\n<li>Arbres n-aires</li>\n</ul>\n</li>\n<li>Dictionary <ul>\n<li>Hash table - Table de hachage - </li>\n</ul>\n</li>\n<li><strong>Heap - Tas -  </strong><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li>Find-Union</li>\n</ol>\n<h1 id=\"Method-of-programming\"><a href=\"#Method-of-programming\" class=\"headerlink\" title=\"Method of programming\"></a>Method of programming</h1><a href=\"/2016/11/27/Method-of-programming-facing-to-exams/\" title=\"Savoir plus\">Savoir plus</a>\n<ol>\n<li>Echaustive / force brute - </li>\n<li>Try-error - Essai-erreur </li>\n<li>Glouton - </li>\n<li>Recursif - recursive - </li>\n<li>Divede merge - Diviser pour regner - </li>\n<li>Dynamic - Dynamique - </li>\n</ol>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><a href=\"/2016/11/27/graph/\" title=\"Savoir plus\">Savoir plus</a>\n<ol>\n<li>Traversal - parcours - <ul>\n<li>BFS</li>\n<li>DFS</li>\n</ul>\n</li>\n<li>Critical path method - plus court chemin<ul>\n<li>Dijkstra</li>\n<li>Floyd</li>\n<li>Bellman-Ford</li>\n</ul>\n</li>\n<li>Tree - arbre<ul>\n<li>Prim</li>\n<li>Kruskal</li>\n</ul>\n</li>\n</ol>\n<p>*backtracking</p>\n<p>*Branch and bound</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><ol>\n<li><ul>\n<li></li>\n<li>fusion</li>\n<li></li>\n<li>tas </li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Data-Structure\"><a href=\"#Data-Structure\" class=\"headerlink\" title=\"Data Structure\"></a>Data Structure</h1><a href=\"/2016/11/27/complexity/\" title=\"How to calcul the complexity?\">How to calcul the complexity?</a> \n<a href=\"/2016/11/27/compression/\" title=\"How to make a compression?\">How to make a compression?</a>\n<ol>\n<li>The data : int, double, etc.</li>\n<li>The basic data structure<ul>\n<li>Container</li>\n<li>Table </li>\n<li>Stack </li>\n<li>Queue </li>\n<li>List</li>\n</ul>\n</li>\n<li>Tree<ul>\n<li>Arbres binaires - <ul>\n<li>ABR - </li>\n</ul>\n</li>\n<li>Arbres n-aires</li>\n</ul>\n</li>\n<li>Dictionary <ul>\n<li>Hash table - Table de hachage - </li>\n</ul>\n</li>\n<li><strong>Heap - Tas -  </strong><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li>Find-Union</li>\n</ol>\n<h1 id=\"Method-of-programming\"><a href=\"#Method-of-programming\" class=\"headerlink\" title=\"Method of programming\"></a>Method of programming</h1><a href=\"/2016/11/27/Method-of-programming-facing-to-exams/\" title=\"Savoir plus\">Savoir plus</a>\n<ol>\n<li>Echaustive / force brute - </li>\n<li>Try-error - Essai-erreur </li>\n<li>Glouton - </li>\n<li>Recursif - recursive - </li>\n<li>Divede merge - Diviser pour regner - </li>\n<li>Dynamic - Dynamique - </li>\n</ol>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><a href=\"/2016/11/27/graph/\" title=\"Savoir plus\">Savoir plus</a>\n<ol>\n<li>Traversal - parcours - <ul>\n<li>BFS</li>\n<li>DFS</li>\n</ul>\n</li>\n<li>Critical path method - plus court chemin<ul>\n<li>Dijkstra</li>\n<li>Floyd</li>\n<li>Bellman-Ford</li>\n</ul>\n</li>\n<li>Tree - arbre<ul>\n<li>Prim</li>\n<li>Kruskal</li>\n</ul>\n</li>\n</ol>\n<p>*backtracking</p>\n<p>*Branch and bound</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><ol>\n<li><ul>\n<li></li>\n<li>fusion</li>\n<li></li>\n<li>tas </li>\n</ul>\n</li>\n</ol>\n"},{"title":"Note of knowledge graph","date":"2017-06-25T09:21:18.000Z","_content":"\n#  Knowledge graph\n\nGoogle\n\n\n\n\n\n## 1.  information extraction\n\n(entity)(relationship)\n\n1.  entity extraction\n   - \n     - liuKnn\n     - lin\n   - \n     - 2012lingfreebaseStanford NER\n     - whitelaw\n     - \n2.  relationship extraction","source":"_posts/Note-of-knowledge-graph.md","raw":"---\ntitle: Note of knowledge graph\ndate: 2017-06-25 11:21:18\ncategories: [programming]\ntags: [knowledge-graph, machine-learning, datamining]\n---\n\n#  Knowledge graph\n\nGoogle\n\n\n\n\n\n## 1.  information extraction\n\n(entity)(relationship)\n\n1.  entity extraction\n   - \n     - liuKnn\n     - lin\n   - \n     - 2012lingfreebaseStanford NER\n     - whitelaw\n     - \n2.  relationship extraction","slug":"Note-of-knowledge-graph","published":1,"updated":"2017-06-25T05:40:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvqr000zpzm91ojgviqw","content":"<h1 id=\"-Knowledge-graph\"><a href=\"#-Knowledge-graph\" class=\"headerlink\" title=\" Knowledge graph\"></a> Knowledge graph</h1><p>Google</p>\n<p></p>\n<p></p>\n<h2 id=\"1--information-extraction\"><a href=\"#1--information-extraction\" class=\"headerlink\" title=\"1.  information extraction\"></a>1.  information extraction</h2><p>(entity)(relationship)</p>\n<ol>\n<li> entity extraction<ul>\n<li><ul>\n<li>liuKnn</li>\n<li>lin</li>\n</ul>\n</li>\n<li><ul>\n<li>2012lingfreebaseStanford NER</li>\n<li>whitelaw</li>\n<li></li>\n</ul>\n</li>\n</ul>\n</li>\n<li> relationship extraction</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"-Knowledge-graph\"><a href=\"#-Knowledge-graph\" class=\"headerlink\" title=\" Knowledge graph\"></a> Knowledge graph</h1><p>Google</p>\n<p></p>\n<p></p>\n<h2 id=\"1--information-extraction\"><a href=\"#1--information-extraction\" class=\"headerlink\" title=\"1.  information extraction\"></a>1.  information extraction</h2><p>(entity)(relationship)</p>\n<ol>\n<li> entity extraction<ul>\n<li><ul>\n<li>liuKnn</li>\n<li>lin</li>\n</ul>\n</li>\n<li><ul>\n<li>2012lingfreebaseStanford NER</li>\n<li>whitelaw</li>\n<li></li>\n</ul>\n</li>\n</ul>\n</li>\n<li> relationship extraction</li>\n</ol>\n"},{"title":" Note of probability","date":"2016-11-30T18:35:53.000Z","_content":"\n\n\n\n\n# Part 1 \n\n{% post_link proba-ch1 Savoir plus  %}\n\n# Part 2 \n\n{% post_link proba-ch2 Savoir plus  %}\n\n# Part 3 \n\n{% post_link proba-ch3 Savoir plus  %}\n\n# Part 4 \n\n{% post_link proba-ch4 Savoir plus  %}\n\n# Part 5 \n\n{% post_link proba-ch5 Savoir plus  %}\n\n# Part 6 \n\n{% post_link proba-ch6 Savoir plus  %}\n","source":"_posts/Note-of-probability.md","raw":"---\ntitle:  Note of probability\ndate: 2016-11-30 19:35:53\ncategories: [math]\ntags: [math, probability]\n---\n\n\n\n\n\n# Part 1 \n\n{% post_link proba-ch1 Savoir plus  %}\n\n# Part 2 \n\n{% post_link proba-ch2 Savoir plus  %}\n\n# Part 3 \n\n{% post_link proba-ch3 Savoir plus  %}\n\n# Part 4 \n\n{% post_link proba-ch4 Savoir plus  %}\n\n# Part 5 \n\n{% post_link proba-ch5 Savoir plus  %}\n\n# Part 6 \n\n{% post_link proba-ch6 Savoir plus  %}\n","slug":"Note-of-probability","published":1,"updated":"2016-12-05T14:16:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvqv0012pzm9wd26j7z4","content":"<p></p>\n<p></p>\n<h1 id=\"Part-1-\"><a href=\"#Part-1-\" class=\"headerlink\" title=\"Part 1 \"></a>Part 1 </h1><a href=\"/2016/12/01/proba-ch1/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-2-\"><a href=\"#Part-2-\" class=\"headerlink\" title=\"Part 2 \"></a>Part 2 </h1><a href=\"/2016/12/01/proba-ch2/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-3-\"><a href=\"#Part-3-\" class=\"headerlink\" title=\"Part 3 \"></a>Part 3 </h1><a href=\"/2016/12/01/proba-ch3/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-4-\"><a href=\"#Part-4-\" class=\"headerlink\" title=\"Part 4 \"></a>Part 4 </h1><a href=\"/2016/12/01/proba-ch4/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-5-\"><a href=\"#Part-5-\" class=\"headerlink\" title=\"Part 5 \"></a>Part 5 </h1><a href=\"/2016/12/01/proba-ch5/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-6-\"><a href=\"#Part-6-\" class=\"headerlink\" title=\"Part 6 \"></a>Part 6 </h1><a href=\"/2016/12/02/proba-ch6/\" title=\"Savoir plus\">Savoir plus</a>\n","excerpt":"","more":"<p></p>\n<p></p>\n<h1 id=\"Part-1-\"><a href=\"#Part-1-\" class=\"headerlink\" title=\"Part 1 \"></a>Part 1 </h1><a href=\"/2016/12/01/proba-ch1/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-2-\"><a href=\"#Part-2-\" class=\"headerlink\" title=\"Part 2 \"></a>Part 2 </h1><a href=\"/2016/12/01/proba-ch2/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-3-\"><a href=\"#Part-3-\" class=\"headerlink\" title=\"Part 3 \"></a>Part 3 </h1><a href=\"/2016/12/01/proba-ch3/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-4-\"><a href=\"#Part-4-\" class=\"headerlink\" title=\"Part 4 \"></a>Part 4 </h1><a href=\"/2016/12/01/proba-ch4/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-5-\"><a href=\"#Part-5-\" class=\"headerlink\" title=\"Part 5 \"></a>Part 5 </h1><a href=\"/2016/12/01/proba-ch5/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-6-\"><a href=\"#Part-6-\" class=\"headerlink\" title=\"Part 6 \"></a>Part 6 </h1><a href=\"/2016/12/02/proba-ch6/\" title=\"Savoir plus\">Savoir plus</a>\n"},{"title":"Note of statistic","date":"2017-01-28T17:13:13.000Z","_content":"\n# \n\n### \n\n\n\n### Slutsky\n\nif\n$$\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c\n$$\nthen\n$$\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c\n$$\n\n# \n\n## un test de $\\chi^2$\n\n\n\n| Liste | a    | b    | c    |\n| ----- | ---- | ---- | ---- |\n| pi    | xx   | xx   | xx   |\n| npi   | xx   | xx   | xx   |\n| ni    | xx   | xx   | xx   |\n\n\n$$\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}\n$$\nn-1","source":"_posts/Note-of-statistic.md","raw":"---\ntitle: Note of statistic\ndate: 2017-01-28 18:13:13\ncategories: [math, unfinished]\ntags: [statistic, math]\n---\n\n# \n\n### \n\n\n\n### Slutsky\n\nif\n$$\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c\n$$\nthen\n$$\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c\n$$\n\n# \n\n## un test de $\\chi^2$\n\n\n\n| Liste | a    | b    | c    |\n| ----- | ---- | ---- | ---- |\n| pi    | xx   | xx   | xx   |\n| npi   | xx   | xx   | xx   |\n| ni    | xx   | xx   | xx   |\n\n\n$$\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}\n$$\nn-1","slug":"Note-of-statistic","published":1,"updated":"2017-01-28T18:02:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvqx0015pzm99vx0i946","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<h3 id=\"Slutsky\"><a href=\"#Slutsky\" class=\"headerlink\" title=\"Slutsky\"></a>Slutsky</h3><p>if</p>\n<script type=\"math/tex; mode=display\">\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c</script><p>then</p>\n<script type=\"math/tex; mode=display\">\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c</script><h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"un-test-de-chi-2\"><a href=\"#un-test-de-chi-2\" class=\"headerlink\" title=\"un test de $\\chi^2$\"></a>un test de $\\chi^2$</h2><p></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Liste</th>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>npi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>ni</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p></p>\n<script type=\"math/tex; mode=display\">\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}</script><p>n-1</p>\n","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<h3 id=\"Slutsky\"><a href=\"#Slutsky\" class=\"headerlink\" title=\"Slutsky\"></a>Slutsky</h3><p>if</p>\n<script type=\"math/tex; mode=display\">\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c</script><p>then</p>\n<script type=\"math/tex; mode=display\">\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c</script><h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"un-test-de-chi-2\"><a href=\"#un-test-de-chi-2\" class=\"headerlink\" title=\"un test de $\\chi^2$\"></a>un test de $\\chi^2$</h2><p></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Liste</th>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>npi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>ni</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p></p>\n<script type=\"math/tex; mode=display\">\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}</script><p>n-1</p>\n"},{"title":"OS notes","date":"2017-04-15T16:59:08.000Z","_content":"\n# Operating System\n\nThis is the note or keywords of a course in udacity.\n\n## Overview\n\n- Processes and process management\n- Threads and concurrency\n- resource management\n- OS services\n- OS support for distributed services\n- Data cendter and cloud\n\n## Introduction\n\n### OS Elements\n\nAbstractions\n\n- Process, thread, file, socket, memory pape\n\nMechanisms\n\n- Create, schedule, open, write, allocate\n\nPolicies\n\n- Least - recently used (LRU) etc.\n\n\n### System call\n\nTwo ways for a user process to execute a priviledged call.\n\n- User process calls hardware directly, and that will cause a trap, the kernel check if it is legal\n- User process executes system call.\n\nuser/kernel transitions are not cheap!\n\n### OS services\n\n- Scheduler => CPU\n- Mem manager\n- Block device driver\n- file system\n- ...\n\n### Linux Architecture\n\nUser interface : **Users** <= user mode\n\nLibrary interface : **Standards utility programs** (shell, editor, compilors) <= user mode\n\nSystem call interface : **Standard licrary** (open, close, read, write, fork) <= user mode\n\n**Linux operating system** <= kernel mode\n\n**Hardware**\n\n## Processes and Process Management\n\nA process:\n\n- state of execution\n  - Program counter\n  - stack\n- parts and temporary holding area\n  - Data, register\n- May require special hardware\n  - IO devices\n\nProcess == state of a program when executing.\n\n### Process Control Block (PCB)\n\na data structure storing status of a process\n\n- PCB created when process is created\n- Certain filds are updated when process state changes\n- other fields change too frequently\n\n### Context switch\n\nHot cache, cold cache\n\n### CPU scheduler\n\nOS must \n\n- preempt\n- schedule\n- dispatch\n\n### Multi Processes\n\nP1(web server), P2(Database)\n\nInter - process communication (IPC) : \n\n- Message - passing IPC\n\n\n- Shared memory IPC","source":"_posts/OS-notes.md","raw":"---\ntitle: OS notes\ndate: 2017-04-15 18:59:08\ncategories: [programming, unfinished]\ntags: [OS]\n---\n\n# Operating System\n\nThis is the note or keywords of a course in udacity.\n\n## Overview\n\n- Processes and process management\n- Threads and concurrency\n- resource management\n- OS services\n- OS support for distributed services\n- Data cendter and cloud\n\n## Introduction\n\n### OS Elements\n\nAbstractions\n\n- Process, thread, file, socket, memory pape\n\nMechanisms\n\n- Create, schedule, open, write, allocate\n\nPolicies\n\n- Least - recently used (LRU) etc.\n\n\n### System call\n\nTwo ways for a user process to execute a priviledged call.\n\n- User process calls hardware directly, and that will cause a trap, the kernel check if it is legal\n- User process executes system call.\n\nuser/kernel transitions are not cheap!\n\n### OS services\n\n- Scheduler => CPU\n- Mem manager\n- Block device driver\n- file system\n- ...\n\n### Linux Architecture\n\nUser interface : **Users** <= user mode\n\nLibrary interface : **Standards utility programs** (shell, editor, compilors) <= user mode\n\nSystem call interface : **Standard licrary** (open, close, read, write, fork) <= user mode\n\n**Linux operating system** <= kernel mode\n\n**Hardware**\n\n## Processes and Process Management\n\nA process:\n\n- state of execution\n  - Program counter\n  - stack\n- parts and temporary holding area\n  - Data, register\n- May require special hardware\n  - IO devices\n\nProcess == state of a program when executing.\n\n### Process Control Block (PCB)\n\na data structure storing status of a process\n\n- PCB created when process is created\n- Certain filds are updated when process state changes\n- other fields change too frequently\n\n### Context switch\n\nHot cache, cold cache\n\n### CPU scheduler\n\nOS must \n\n- preempt\n- schedule\n- dispatch\n\n### Multi Processes\n\nP1(web server), P2(Database)\n\nInter - process communication (IPC) : \n\n- Message - passing IPC\n\n\n- Shared memory IPC","slug":"OS-notes","published":1,"updated":"2017-04-16T18:40:56.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvqz0019pzm9oju9evg5","content":"<h1 id=\"Operating-System\"><a href=\"#Operating-System\" class=\"headerlink\" title=\"Operating System\"></a>Operating System</h1><p>This is the note or keywords of a course in udacity.</p>\n<h2 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h2><ul>\n<li>Processes and process management</li>\n<li>Threads and concurrency</li>\n<li>resource management</li>\n<li>OS services</li>\n<li>OS support for distributed services</li>\n<li>Data cendter and cloud</li>\n</ul>\n<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h3 id=\"OS-Elements\"><a href=\"#OS-Elements\" class=\"headerlink\" title=\"OS Elements\"></a>OS Elements</h3><p>Abstractions</p>\n<ul>\n<li>Process, thread, file, socket, memory pape</li>\n</ul>\n<p>Mechanisms</p>\n<ul>\n<li>Create, schedule, open, write, allocate</li>\n</ul>\n<p>Policies</p>\n<ul>\n<li>Least - recently used (LRU) etc.</li>\n</ul>\n<h3 id=\"System-call\"><a href=\"#System-call\" class=\"headerlink\" title=\"System call\"></a>System call</h3><p>Two ways for a user process to execute a priviledged call.</p>\n<ul>\n<li>User process calls hardware directly, and that will cause a trap, the kernel check if it is legal</li>\n<li>User process executes system call.</li>\n</ul>\n<p>user/kernel transitions are not cheap!</p>\n<h3 id=\"OS-services\"><a href=\"#OS-services\" class=\"headerlink\" title=\"OS services\"></a>OS services</h3><ul>\n<li>Scheduler =&gt; CPU</li>\n<li>Mem manager</li>\n<li>Block device driver</li>\n<li>file system</li>\n<li></li>\n</ul>\n<h3 id=\"Linux-Architecture\"><a href=\"#Linux-Architecture\" class=\"headerlink\" title=\"Linux Architecture\"></a>Linux Architecture</h3><p>User interface : <strong>Users</strong> &lt;= user mode</p>\n<p>Library interface : <strong>Standards utility programs</strong> (shell, editor, compilors) &lt;= user mode</p>\n<p>System call interface : <strong>Standard licrary</strong> (open, close, read, write, fork) &lt;= user mode</p>\n<p><strong>Linux operating system</strong> &lt;= kernel mode</p>\n<p><strong>Hardware</strong></p>\n<h2 id=\"Processes-and-Process-Management\"><a href=\"#Processes-and-Process-Management\" class=\"headerlink\" title=\"Processes and Process Management\"></a>Processes and Process Management</h2><p>A process:</p>\n<ul>\n<li>state of execution<ul>\n<li>Program counter</li>\n<li>stack</li>\n</ul>\n</li>\n<li>parts and temporary holding area<ul>\n<li>Data, register</li>\n</ul>\n</li>\n<li>May require special hardware<ul>\n<li>IO devices</li>\n</ul>\n</li>\n</ul>\n<p>Process == state of a program when executing.</p>\n<h3 id=\"Process-Control-Block-PCB\"><a href=\"#Process-Control-Block-PCB\" class=\"headerlink\" title=\"Process Control Block (PCB)\"></a>Process Control Block (PCB)</h3><p>a data structure storing status of a process</p>\n<ul>\n<li>PCB created when process is created</li>\n<li>Certain filds are updated when process state changes</li>\n<li>other fields change too frequently</li>\n</ul>\n<h3 id=\"Context-switch\"><a href=\"#Context-switch\" class=\"headerlink\" title=\"Context switch\"></a>Context switch</h3><p>Hot cache, cold cache</p>\n<h3 id=\"CPU-scheduler\"><a href=\"#CPU-scheduler\" class=\"headerlink\" title=\"CPU scheduler\"></a>CPU scheduler</h3><p>OS must </p>\n<ul>\n<li>preempt</li>\n<li>schedule</li>\n<li>dispatch</li>\n</ul>\n<h3 id=\"Multi-Processes\"><a href=\"#Multi-Processes\" class=\"headerlink\" title=\"Multi Processes\"></a>Multi Processes</h3><p>P1(web server), P2(Database)</p>\n<p>Inter - process communication (IPC) : </p>\n<ul>\n<li>Message - passing IPC</li>\n</ul>\n<ul>\n<li>Shared memory IPC</li>\n</ul>\n","excerpt":"","more":"<h1 id=\"Operating-System\"><a href=\"#Operating-System\" class=\"headerlink\" title=\"Operating System\"></a>Operating System</h1><p>This is the note or keywords of a course in udacity.</p>\n<h2 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h2><ul>\n<li>Processes and process management</li>\n<li>Threads and concurrency</li>\n<li>resource management</li>\n<li>OS services</li>\n<li>OS support for distributed services</li>\n<li>Data cendter and cloud</li>\n</ul>\n<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h3 id=\"OS-Elements\"><a href=\"#OS-Elements\" class=\"headerlink\" title=\"OS Elements\"></a>OS Elements</h3><p>Abstractions</p>\n<ul>\n<li>Process, thread, file, socket, memory pape</li>\n</ul>\n<p>Mechanisms</p>\n<ul>\n<li>Create, schedule, open, write, allocate</li>\n</ul>\n<p>Policies</p>\n<ul>\n<li>Least - recently used (LRU) etc.</li>\n</ul>\n<h3 id=\"System-call\"><a href=\"#System-call\" class=\"headerlink\" title=\"System call\"></a>System call</h3><p>Two ways for a user process to execute a priviledged call.</p>\n<ul>\n<li>User process calls hardware directly, and that will cause a trap, the kernel check if it is legal</li>\n<li>User process executes system call.</li>\n</ul>\n<p>user/kernel transitions are not cheap!</p>\n<h3 id=\"OS-services\"><a href=\"#OS-services\" class=\"headerlink\" title=\"OS services\"></a>OS services</h3><ul>\n<li>Scheduler =&gt; CPU</li>\n<li>Mem manager</li>\n<li>Block device driver</li>\n<li>file system</li>\n<li></li>\n</ul>\n<h3 id=\"Linux-Architecture\"><a href=\"#Linux-Architecture\" class=\"headerlink\" title=\"Linux Architecture\"></a>Linux Architecture</h3><p>User interface : <strong>Users</strong> &lt;= user mode</p>\n<p>Library interface : <strong>Standards utility programs</strong> (shell, editor, compilors) &lt;= user mode</p>\n<p>System call interface : <strong>Standard licrary</strong> (open, close, read, write, fork) &lt;= user mode</p>\n<p><strong>Linux operating system</strong> &lt;= kernel mode</p>\n<p><strong>Hardware</strong></p>\n<h2 id=\"Processes-and-Process-Management\"><a href=\"#Processes-and-Process-Management\" class=\"headerlink\" title=\"Processes and Process Management\"></a>Processes and Process Management</h2><p>A process:</p>\n<ul>\n<li>state of execution<ul>\n<li>Program counter</li>\n<li>stack</li>\n</ul>\n</li>\n<li>parts and temporary holding area<ul>\n<li>Data, register</li>\n</ul>\n</li>\n<li>May require special hardware<ul>\n<li>IO devices</li>\n</ul>\n</li>\n</ul>\n<p>Process == state of a program when executing.</p>\n<h3 id=\"Process-Control-Block-PCB\"><a href=\"#Process-Control-Block-PCB\" class=\"headerlink\" title=\"Process Control Block (PCB)\"></a>Process Control Block (PCB)</h3><p>a data structure storing status of a process</p>\n<ul>\n<li>PCB created when process is created</li>\n<li>Certain filds are updated when process state changes</li>\n<li>other fields change too frequently</li>\n</ul>\n<h3 id=\"Context-switch\"><a href=\"#Context-switch\" class=\"headerlink\" title=\"Context switch\"></a>Context switch</h3><p>Hot cache, cold cache</p>\n<h3 id=\"CPU-scheduler\"><a href=\"#CPU-scheduler\" class=\"headerlink\" title=\"CPU scheduler\"></a>CPU scheduler</h3><p>OS must </p>\n<ul>\n<li>preempt</li>\n<li>schedule</li>\n<li>dispatch</li>\n</ul>\n<h3 id=\"Multi-Processes\"><a href=\"#Multi-Processes\" class=\"headerlink\" title=\"Multi Processes\"></a>Multi Processes</h3><p>P1(web server), P2(Database)</p>\n<p>Inter - process communication (IPC) : </p>\n<ul>\n<li>Message - passing IPC</li>\n</ul>\n<ul>\n<li>Shared memory IPC</li>\n</ul>\n"},{"title":" QuadTree","date":"2016-12-13T17:45:37.000Z","_content":"\nECP\n\n\n\n \n\n```Python\n# =_=\n\"\"\"\n3-------2       \n|       |\n|       |\n|       |\n0-------1\n\n=>\n3---7---2\n|   |   |\n8---4---6\n|   |   |\n0---5---1\n\n=>\n...\n\"\"\"\n```\n\nO(logn)\n\n\n\npythonparaview= =\n\n![QTree](http://oi4yiqiop.bkt.clouddn.com/QTree.png?imageMogr2/thumbnail/!50p)\n\n","source":"_posts/QuadTree.md","raw":"---\ntitle:  QuadTree\ndate: 2016-12-13 18:45:37\ncategories: [programming]\ntags: [algo, data-structure]\n---\n\nECP\n\n\n\n \n\n```Python\n# =_=\n\"\"\"\n3-------2       \n|       |\n|       |\n|       |\n0-------1\n\n=>\n3---7---2\n|   |   |\n8---4---6\n|   |   |\n0---5---1\n\n=>\n...\n\"\"\"\n```\n\nO(logn)\n\n\n\npythonparaview= =\n\n![QTree](http://oi4yiqiop.bkt.clouddn.com/QTree.png?imageMogr2/thumbnail/!50p)\n\n","slug":"QuadTree","published":1,"updated":"2016-12-13T21:20:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvr1001dpzm9whneu765","content":"<p>ECP</p>\n<p></p>\n<p> </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># =_=</span></div><div class=\"line\"><span class=\"string\">\"\"\"</span></div><div class=\"line\">3-------2       </div><div class=\"line\">|       |</div><div class=\"line\">|       |</div><div class=\"line\">|       |</div><div class=\"line\">0-------1</div><div class=\"line\"></div><div class=\"line\">=&gt;</div><div class=\"line\">3---7---2</div><div class=\"line\">|   |   |</div><div class=\"line\">8---4---6</div><div class=\"line\">|   |   |</div><div class=\"line\">0---5---1</div><div class=\"line\"></div><div class=\"line\">=&gt;</div><div class=\"line\">...</div><div class=\"line\">\"\"\"</div></pre></td></tr></table></figure>\n<p>O(logn)</p>\n<p>pythonparaview= =</p>\n<p><img src=\"http://oi4yiqiop.bkt.clouddn.com/QTree.png?imageMogr2/thumbnail/!50p\" alt=\"QTree\"></p>\n","excerpt":"","more":"<p>ECP</p>\n<p></p>\n<p> </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># =_=</span></div><div class=\"line\"><span class=\"string\">\"\"\"</div><div class=\"line\">3-------2       </div><div class=\"line\">|       |</div><div class=\"line\">|       |</div><div class=\"line\">|       |</div><div class=\"line\">0-------1</div><div class=\"line\"></div><div class=\"line\">=&gt;</div><div class=\"line\">3---7---2</div><div class=\"line\">|   |   |</div><div class=\"line\">8---4---6</div><div class=\"line\">|   |   |</div><div class=\"line\">0---5---1</div><div class=\"line\"></div><div class=\"line\">=&gt;</div><div class=\"line\">...</div><div class=\"line\">\"\"\"</span></div></pre></td></tr></table></figure>\n<p>O(logn)</p>\n<p>pythonparaview= =</p>\n<p><img src=\"http://oi4yiqiop.bkt.clouddn.com/QTree.png?imageMogr2/thumbnail/!50p\" alt=\"QTree\"></p>\n"},{"title":"Sobolev space","date":"2017-02-11T13:37:53.000Z","_content":"\n#  Sobolev space\n\n## \n\nwiki\n\n>p  1fkLp\n\nC1(11)\n\n## \n\n$$\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p\n$$\n\n$W^{k,p}$\n\n## $H^k$\n\n\n$$\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}\n$$\n\n\n$$\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}\n$$\n","source":"_posts/Sobolev-space.md","raw":"---\ntitle: Sobolev space\ndate: 2017-02-11 14:37:53\ncategories: [math, unfinished]\ntags: [Sobolev, analyse, math, EDP]\n---\n\n#  Sobolev space\n\n## \n\nwiki\n\n>p  1fkLp\n\nC1(11)\n\n## \n\n$$\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p\n$$\n\n$W^{k,p}$\n\n## $H^k$\n\n\n$$\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}\n$$\n\n\n$$\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}\n$$\n","slug":"Sobolev-space","published":1,"updated":"2017-02-11T16:48:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvr3001hpzm9ijp0gil4","content":"<h1 id=\"-Sobolev-space\"><a href=\"#-Sobolev-space\" class=\"headerlink\" title=\" Sobolev space\"></a> Sobolev space</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>wiki</p>\n<blockquote>\n<p>p  1fkLp</p>\n</blockquote>\n<p>C1(11)</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><script type=\"math/tex; mode=display\">\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p</script><p>$W^{k,p}$</p>\n<h2 id=\"H-k\"><a href=\"#H-k\" class=\"headerlink\" title=\"$H^k$\"></a>$H^k$</h2><p></p>\n<script type=\"math/tex; mode=display\">\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}</script><p></p>\n<script type=\"math/tex; mode=display\">\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}</script>","excerpt":"","more":"<h1 id=\"-Sobolev-space\"><a href=\"#-Sobolev-space\" class=\"headerlink\" title=\" Sobolev space\"></a> Sobolev space</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>wiki</p>\n<blockquote>\n<p>p  1fkLp</p>\n</blockquote>\n<p>C1(11)</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><script type=\"math/tex; mode=display\">\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p</script><p>$W^{k,p}$</p>\n<h2 id=\"H-k\"><a href=\"#H-k\" class=\"headerlink\" title=\"$H^k$\"></a>$H^k$</h2><p></p>\n<script type=\"math/tex; mode=display\">\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}</script><p></p>\n<script type=\"math/tex; mode=display\">\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}</script>"},{"title":"Relation Classification via Attention Model ","date":"2017-12-17T07:00:00.000Z","_content":"\n## Relation Classification via Attention Model\n\n[1]Attentionattentionattention\n\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n### 1. Attention\n\n#### 1.1 \n\nAttentionNLPBahdanau[2]attentionattentionNLP\n\n####1.2 Recurrent Models of Visual Attention \n\nRNNattentionAttention\n\n#### 1.3 Attention-based RNN in NLP\n\n[1]EncoderDecoderSeq2seqEncoderDecoder\n\nDecoder\n\n<img src=\"http://img.blog.csdn.net/20170806205924785?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbXBrX25vMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\" width=\"30%\">\n\n[3]attentionRNN\n\n#### 1.4 Attention-based CNN in NLP\n\n[4]CNNattentioncnn3CNNattention\n\n- ABCNN-1: attentionattentionattention feature mapfeature map\n- ABCNN-2: attentionattention.\n- ABCNN-3: ABCNN-1 + ABCNN-2\n\n### 2. Relation Classification \n\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n#### \t2.1 Classification Objective\n\nL2\n$$\n\\delta_{\\theta}(S,y) = ||\\frac{w^O}{|w^O|} - W_y^L||_{L^2} \\\\\nS:\\text{Sentence}, y:\\text{Output relation}, w^O: \\text{Network output}, W^L:\\text{Relation embedding}\n$$\n\n$$\n\\mathcal{L} = [\\delta_\\theta(S,y) + (1-\\delta_\\theta(S, \\hat{y}^-))] + \\beta||\\theta||^2 \\\\\n\\hat{y}^- : \\text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\\\\n\\hat{y}^- = argmax_{y'\\in \\mathcal{Y},y'\\ne y}(\\delta(S, y'))\n$$\n$\\beta$\n\n#### 2.2 Input Representation \n\ne1,e2\n$$\nS = (w_1,w_2,...,w_n) \\\\\ne_1 := w_p, e_2 := w_t . p,t\\in [1,n], p\\ne t\n$$\nword position embeddingsiEmbedding\n$$\nw_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T\n$$\nkinput representation\n$$\nz_i = [(w_{i - (k-1)/2}^M)^T,...,(w_{i + (k-1)/2}^M)^T]^T\n$$\n\n#### 2.3 Input Attention Mechanism\n\n<img src=\"https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg\" width=\"70%\">\n\nattention$A_{i,i}^j=f(e_j,w_i)$wiej f \n$$\n\\alpha_i^j = \\frac{exp(A_{i,i}^j)}{\\sum_{i'=1}^{n}{exp(A_{i',i}^j)}}\n$$\nj=1,2 :\n\n- \n  $$\n  r_i = z_i \\frac{\\alpha_i^1 + \\alpha_i^2}{2}\n  $$\n\n- \n  $$\n  r_i = [(z_i \\alpha_i^1)^T, (z_i \\alpha_i^2)^T]^T\n  $$\n\n- \n  $$\n  r_i = z_i \\frac{\\alpha_i^1 - \\alpha_i^2}{2}\n  $$\n\n\n\n\n$R = [r_1, r_2,,r_n]$\n\n#### 2.4 Convolutional Max-Pooling with Secondary Attention\n\nRdc:\n$$\nR^* = tanh(W_fR+B_f), \\text{where the siaze of Wf is } d^c \\times k(d^w+2d^p)\n$$\nR*WL\n$$\nG = R^{*T}UW^L, \\\\U :\\text{weighting matrix learnt by the network}\n$$\n\nsoftmaxGattention pooling matrix Ap:\n$$\nA_{i,j}^p = \\frac{exp(G_{i,j})}{\\sum_{i'=1}^n{exp(G_{i',j})}}\n$$\nApR*attention\n$$\nw_i^O = max_j(R^*A^p)_{i,j}\n$$\n\n### 3. \n\n[1]attentionSem-Eval-2010 Task 8\n\n\n\n- \n- \n- \n\nAttentionpytorch[](https://github.com/lawlietAi/relation-classification-via-attention-model)\n\n## Reference\n\n\\*https://zhuanlan.zhihu.com/p/22867750\n\n[1] Wang, L., Cao, Z., Melo, G. D., & Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. *Meeting of the Association for Computational Linguistics* (pp.1298-1307).\n\n[2] Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. *Computer Science*.\n\n[3] Luong, M. T., Pham, H., & Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. *Computer Science*.\n\n[4] Yin, W., Schtze, H., Xiang, B., & Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. *Computer Science*.","source":"_posts/[2017.12.17]Relation-Classification-via-Attention-Model.md","raw":"---\ntitle: Relation Classification via Attention Model \ndate: 2017-12-17 08:00:00\ncategories: [research]\ntags: [relation-classification, attention, relation-extraction]\n---\n\n## Relation Classification via Attention Model\n\n[1]Attentionattentionattention\n\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n### 1. Attention\n\n#### 1.1 \n\nAttentionNLPBahdanau[2]attentionattentionNLP\n\n####1.2 Recurrent Models of Visual Attention \n\nRNNattentionAttention\n\n#### 1.3 Attention-based RNN in NLP\n\n[1]EncoderDecoderSeq2seqEncoderDecoder\n\nDecoder\n\n<img src=\"http://img.blog.csdn.net/20170806205924785?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbXBrX25vMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\" width=\"30%\">\n\n[3]attentionRNN\n\n#### 1.4 Attention-based CNN in NLP\n\n[4]CNNattentioncnn3CNNattention\n\n- ABCNN-1: attentionattentionattention feature mapfeature map\n- ABCNN-2: attentionattention.\n- ABCNN-3: ABCNN-1 + ABCNN-2\n\n### 2. Relation Classification \n\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n#### \t2.1 Classification Objective\n\nL2\n$$\n\\delta_{\\theta}(S,y) = ||\\frac{w^O}{|w^O|} - W_y^L||_{L^2} \\\\\nS:\\text{Sentence}, y:\\text{Output relation}, w^O: \\text{Network output}, W^L:\\text{Relation embedding}\n$$\n\n$$\n\\mathcal{L} = [\\delta_\\theta(S,y) + (1-\\delta_\\theta(S, \\hat{y}^-))] + \\beta||\\theta||^2 \\\\\n\\hat{y}^- : \\text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\\\\n\\hat{y}^- = argmax_{y'\\in \\mathcal{Y},y'\\ne y}(\\delta(S, y'))\n$$\n$\\beta$\n\n#### 2.2 Input Representation \n\ne1,e2\n$$\nS = (w_1,w_2,...,w_n) \\\\\ne_1 := w_p, e_2 := w_t . p,t\\in [1,n], p\\ne t\n$$\nword position embeddingsiEmbedding\n$$\nw_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T\n$$\nkinput representation\n$$\nz_i = [(w_{i - (k-1)/2}^M)^T,...,(w_{i + (k-1)/2}^M)^T]^T\n$$\n\n#### 2.3 Input Attention Mechanism\n\n<img src=\"https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg\" width=\"70%\">\n\nattention$A_{i,i}^j=f(e_j,w_i)$wiej f \n$$\n\\alpha_i^j = \\frac{exp(A_{i,i}^j)}{\\sum_{i'=1}^{n}{exp(A_{i',i}^j)}}\n$$\nj=1,2 :\n\n- \n  $$\n  r_i = z_i \\frac{\\alpha_i^1 + \\alpha_i^2}{2}\n  $$\n\n- \n  $$\n  r_i = [(z_i \\alpha_i^1)^T, (z_i \\alpha_i^2)^T]^T\n  $$\n\n- \n  $$\n  r_i = z_i \\frac{\\alpha_i^1 - \\alpha_i^2}{2}\n  $$\n\n\n\n\n$R = [r_1, r_2,,r_n]$\n\n#### 2.4 Convolutional Max-Pooling with Secondary Attention\n\nRdc:\n$$\nR^* = tanh(W_fR+B_f), \\text{where the siaze of Wf is } d^c \\times k(d^w+2d^p)\n$$\nR*WL\n$$\nG = R^{*T}UW^L, \\\\U :\\text{weighting matrix learnt by the network}\n$$\n\nsoftmaxGattention pooling matrix Ap:\n$$\nA_{i,j}^p = \\frac{exp(G_{i,j})}{\\sum_{i'=1}^n{exp(G_{i',j})}}\n$$\nApR*attention\n$$\nw_i^O = max_j(R^*A^p)_{i,j}\n$$\n\n### 3. \n\n[1]attentionSem-Eval-2010 Task 8\n\n\n\n- \n- \n- \n\nAttentionpytorch[](https://github.com/lawlietAi/relation-classification-via-attention-model)\n\n## Reference\n\n\\*https://zhuanlan.zhihu.com/p/22867750\n\n[1] Wang, L., Cao, Z., Melo, G. D., & Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. *Meeting of the Association for Computational Linguistics* (pp.1298-1307).\n\n[2] Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. *Computer Science*.\n\n[3] Luong, M. T., Pham, H., & Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. *Computer Science*.\n\n[4] Yin, W., Schtze, H., Xiang, B., & Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. *Computer Science*.","slug":"[2017.12.17]Relation-Classification-via-Attention-Model","published":1,"updated":"2018-01-27T11:09:43.612Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvr4001lpzm9cpb3h9gb","content":"<h2 id=\"Relation-Classification-via-Attention-Model\"><a href=\"#Relation-Classification-via-Attention-Model\" class=\"headerlink\" title=\"Relation Classification via Attention Model\"></a>Relation Classification via Attention Model</h2><p>[1]Attentionattentionattention</p>\n<p><img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\"></p>\n<h3 id=\"1-Attention\"><a href=\"#1-Attention\" class=\"headerlink\" title=\"1. Attention\"></a>1. Attention</h3><h4 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h4><p>AttentionNLPBahdanau[2]attentionattentionNLP</p>\n<h4 id=\"1-2-Recurrent-Models-of-Visual-Attention\"><a href=\"#1-2-Recurrent-Models-of-Visual-Attention\" class=\"headerlink\" title=\"1.2 Recurrent Models of Visual Attention\"></a>1.2 Recurrent Models of Visual Attention</h4><p>RNNattentionAttention</p>\n<h4 id=\"1-3-Attention-based-RNN-in-NLP\"><a href=\"#1-3-Attention-based-RNN-in-NLP\" class=\"headerlink\" title=\"1.3 Attention-based RNN in NLP\"></a>1.3 Attention-based RNN in NLP</h4><p>[1]EncoderDecoderSeq2seqEncoderDecoder</p>\n<p>Decoder</p>\n<p><img src=\"http://img.blog.csdn.net/20170806205924785?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbXBrX25vMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\" width=\"30%\"></p>\n<p>[3]attentionRNN</p>\n<h4 id=\"1-4-Attention-based-CNN-in-NLP\"><a href=\"#1-4-Attention-based-CNN-in-NLP\" class=\"headerlink\" title=\"1.4 Attention-based CNN in NLP\"></a>1.4 Attention-based CNN in NLP</h4><p>[4]CNNattentioncnn3CNNattention</p>\n<ul>\n<li>ABCNN-1: attentionattentionattention feature mapfeature map</li>\n<li>ABCNN-2: attentionattention.</li>\n<li>ABCNN-3: ABCNN-1 + ABCNN-2</li>\n</ul>\n<h3 id=\"2-Relation-Classification\"><a href=\"#2-Relation-Classification\" class=\"headerlink\" title=\"2. Relation Classification\"></a>2. Relation Classification</h3><p><img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\"></p>\n<h4 id=\"2-1-Classification-Objective\"><a href=\"#2-1-Classification-Objective\" class=\"headerlink\" title=\"2.1 Classification Objective\"></a>2.1 Classification Objective</h4><p>L2</p>\n<script type=\"math/tex; mode=display\">\n\\delta_{\\theta}(S,y) = ||\\frac{w^O}{|w^O|} - W_y^L||_{L^2} \\\\\nS:\\text{Sentence}, y:\\text{Output relation}, w^O: \\text{Network output}, W^L:\\text{Relation embedding}</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{L} = [\\delta_\\theta(S,y) + (1-\\delta_\\theta(S, \\hat{y}^-))] + \\beta||\\theta||^2 \\\\\n\\hat{y}^- : \\text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\\\\n\\hat{y}^- = argmax_{y'\\in \\mathcal{Y},y'\\ne y}(\\delta(S, y'))</script><p>$\\beta$</p>\n<h4 id=\"2-2-Input-Representation\"><a href=\"#2-2-Input-Representation\" class=\"headerlink\" title=\"2.2 Input Representation\"></a>2.2 Input Representation</h4><p>e1,e2</p>\n<script type=\"math/tex; mode=display\">\nS = (w_1,w_2,...,w_n) \\\\\ne_1 := w_p, e_2 := w_t . p,t\\in [1,n], p\\ne t</script><p>word position embeddingsiEmbedding</p>\n<script type=\"math/tex; mode=display\">\nw_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T</script><p>kinput representation</p>\n<script type=\"math/tex; mode=display\">\nz_i = [(w_{i - (k-1)/2}^M)^T,...,(w_{i + (k-1)/2}^M)^T]^T</script><h4 id=\"2-3-Input-Attention-Mechanism\"><a href=\"#2-3-Input-Attention-Mechanism\" class=\"headerlink\" title=\"2.3 Input Attention Mechanism\"></a>2.3 Input Attention Mechanism</h4><p><img src=\"https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg\" width=\"70%\"></p>\n<p>attention$A_{i,i}^j=f(e_j,w_i)$wiej f </p>\n<script type=\"math/tex; mode=display\">\n\\alpha_i^j = \\frac{exp(A_{i,i}^j)}{\\sum_{i'=1}^{n}{exp(A_{i',i}^j)}}</script><p>j=1,2 :</p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nr_i = z_i \\frac{\\alpha_i^1 + \\alpha_i^2}{2}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nr_i = [(z_i \\alpha_i^1)^T, (z_i \\alpha_i^2)^T]^T</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nr_i = z_i \\frac{\\alpha_i^1 - \\alpha_i^2}{2}</script></li>\n</ul>\n<p>$R = [r_1, r_2,,r_n]$</p>\n<h4 id=\"2-4-Convolutional-Max-Pooling-with-Secondary-Attention\"><a href=\"#2-4-Convolutional-Max-Pooling-with-Secondary-Attention\" class=\"headerlink\" title=\"2.4 Convolutional Max-Pooling with Secondary Attention\"></a>2.4 Convolutional Max-Pooling with Secondary Attention</h4><p>Rdc:</p>\n<script type=\"math/tex; mode=display\">\nR^* = tanh(W_fR+B_f), \\text{where the siaze of Wf is } d^c \\times k(d^w+2d^p)</script><p>R*WL</p>\n<script type=\"math/tex; mode=display\">\nG = R^{*T}UW^L, \\\\U :\\text{weighting matrix learnt by the network}</script><p>softmaxGattention pooling matrix Ap:</p>\n<script type=\"math/tex; mode=display\">\nA_{i,j}^p = \\frac{exp(G_{i,j})}{\\sum_{i'=1}^n{exp(G_{i',j})}}</script><p>ApR*attention</p>\n<script type=\"math/tex; mode=display\">\nw_i^O = max_j(R^*A^p)_{i,j}</script><h3 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h3><p>[1]attentionSem-Eval-2010 Task 8</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p>Attentionpytorch<a href=\"https://github.com/lawlietAi/relation-classification-via-attention-model\" target=\"_blank\" rel=\"external\"></a></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>*<a href=\"https://zhuanlan.zhihu.com/p/22867750\" target=\"_blank\" rel=\"external\">https://zhuanlan.zhihu.com/p/22867750</a></p>\n<p>[1] Wang, L., Cao, Z., Melo, G. D., &amp; Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. <em>Meeting of the Association for Computational Linguistics</em> (pp.1298-1307).</p>\n<p>[2] Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <em>Computer Science</em>.</p>\n<p>[3] Luong, M. T., Pham, H., &amp; Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. <em>Computer Science</em>.</p>\n<p>[4] Yin, W., Schtze, H., Xiang, B., &amp; Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. <em>Computer Science</em>.</p>\n","excerpt":"","more":"<h2 id=\"Relation-Classification-via-Attention-Model\"><a href=\"#Relation-Classification-via-Attention-Model\" class=\"headerlink\" title=\"Relation Classification via Attention Model\"></a>Relation Classification via Attention Model</h2><p>[1]Attentionattentionattention</p>\n<p><img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\"></p>\n<h3 id=\"1-Attention\"><a href=\"#1-Attention\" class=\"headerlink\" title=\"1. Attention\"></a>1. Attention</h3><h4 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h4><p>AttentionNLPBahdanau[2]attentionattentionNLP</p>\n<h4 id=\"1-2-Recurrent-Models-of-Visual-Attention\"><a href=\"#1-2-Recurrent-Models-of-Visual-Attention\" class=\"headerlink\" title=\"1.2 Recurrent Models of Visual Attention\"></a>1.2 Recurrent Models of Visual Attention</h4><p>RNNattentionAttention</p>\n<h4 id=\"1-3-Attention-based-RNN-in-NLP\"><a href=\"#1-3-Attention-based-RNN-in-NLP\" class=\"headerlink\" title=\"1.3 Attention-based RNN in NLP\"></a>1.3 Attention-based RNN in NLP</h4><p>[1]EncoderDecoderSeq2seqEncoderDecoder</p>\n<p>Decoder</p>\n<p><img src=\"http://img.blog.csdn.net/20170806205924785?watermark/2/text/aHR0cDovL2Jsb2cuY3Nkbi5uZXQvbXBrX25vMQ==/font/5a6L5L2T/fontsize/400/fill/I0JBQkFCMA==/dissolve/70/gravity/Center\" width=\"30%\"></p>\n<p>[3]attentionRNN</p>\n<h4 id=\"1-4-Attention-based-CNN-in-NLP\"><a href=\"#1-4-Attention-based-CNN-in-NLP\" class=\"headerlink\" title=\"1.4 Attention-based CNN in NLP\"></a>1.4 Attention-based CNN in NLP</h4><p>[4]CNNattentioncnn3CNNattention</p>\n<ul>\n<li>ABCNN-1: attentionattentionattention feature mapfeature map</li>\n<li>ABCNN-2: attentionattention.</li>\n<li>ABCNN-3: ABCNN-1 + ABCNN-2</li>\n</ul>\n<h3 id=\"2-Relation-Classification\"><a href=\"#2-Relation-Classification\" class=\"headerlink\" title=\"2. Relation Classification\"></a>2. Relation Classification</h3><p><img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\"></p>\n<h4 id=\"2-1-Classification-Objective\"><a href=\"#2-1-Classification-Objective\" class=\"headerlink\" title=\"2.1 Classification Objective\"></a>2.1 Classification Objective</h4><p>L2</p>\n<script type=\"math/tex; mode=display\">\n\\delta_{\\theta}(S,y) = ||\\frac{w^O}{|w^O|} - W_y^L||_{L^2} \\\\\nS:\\text{Sentence}, y:\\text{Output relation}, w^O: \\text{Network output}, W^L:\\text{Relation embedding}</script><p></p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{L} = [\\delta_\\theta(S,y) + (1-\\delta_\\theta(S, \\hat{y}^-))] + \\beta||\\theta||^2 \\\\\n\\hat{y}^- : \\text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\\\\n\\hat{y}^- = argmax_{y'\\in \\mathcal{Y},y'\\ne y}(\\delta(S, y'))</script><p>$\\beta$</p>\n<h4 id=\"2-2-Input-Representation\"><a href=\"#2-2-Input-Representation\" class=\"headerlink\" title=\"2.2 Input Representation\"></a>2.2 Input Representation</h4><p>e1,e2</p>\n<script type=\"math/tex; mode=display\">\nS = (w_1,w_2,...,w_n) \\\\\ne_1 := w_p, e_2 := w_t . p,t\\in [1,n], p\\ne t</script><p>word position embeddingsiEmbedding</p>\n<script type=\"math/tex; mode=display\">\nw_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T</script><p>kinput representation</p>\n<script type=\"math/tex; mode=display\">\nz_i = [(w_{i - (k-1)/2}^M)^T,...,(w_{i + (k-1)/2}^M)^T]^T</script><h4 id=\"2-3-Input-Attention-Mechanism\"><a href=\"#2-3-Input-Attention-Mechanism\" class=\"headerlink\" title=\"2.3 Input Attention Mechanism\"></a>2.3 Input Attention Mechanism</h4><p><img src=\"https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg\" width=\"70%\"></p>\n<p>attention$A_{i,i}^j=f(e_j,w_i)$wiej f </p>\n<script type=\"math/tex; mode=display\">\n\\alpha_i^j = \\frac{exp(A_{i,i}^j)}{\\sum_{i'=1}^{n}{exp(A_{i',i}^j)}}</script><p>j=1,2 :</p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nr_i = z_i \\frac{\\alpha_i^1 + \\alpha_i^2}{2}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nr_i = [(z_i \\alpha_i^1)^T, (z_i \\alpha_i^2)^T]^T</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nr_i = z_i \\frac{\\alpha_i^1 - \\alpha_i^2}{2}</script></li>\n</ul>\n<p>$R = [r_1, r_2,,r_n]$</p>\n<h4 id=\"2-4-Convolutional-Max-Pooling-with-Secondary-Attention\"><a href=\"#2-4-Convolutional-Max-Pooling-with-Secondary-Attention\" class=\"headerlink\" title=\"2.4 Convolutional Max-Pooling with Secondary Attention\"></a>2.4 Convolutional Max-Pooling with Secondary Attention</h4><p>Rdc:</p>\n<script type=\"math/tex; mode=display\">\nR^* = tanh(W_fR+B_f), \\text{where the siaze of Wf is } d^c \\times k(d^w+2d^p)</script><p>R*WL</p>\n<script type=\"math/tex; mode=display\">\nG = R^{*T}UW^L, \\\\U :\\text{weighting matrix learnt by the network}</script><p>softmaxGattention pooling matrix Ap:</p>\n<script type=\"math/tex; mode=display\">\nA_{i,j}^p = \\frac{exp(G_{i,j})}{\\sum_{i'=1}^n{exp(G_{i',j})}}</script><p>ApR*attention</p>\n<script type=\"math/tex; mode=display\">\nw_i^O = max_j(R^*A^p)_{i,j}</script><h3 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h3><p>[1]attentionSem-Eval-2010 Task 8</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p>Attentionpytorch<a href=\"https://github.com/lawlietAi/relation-classification-via-attention-model\"></a></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>*<a href=\"https://zhuanlan.zhihu.com/p/22867750\">https://zhuanlan.zhihu.com/p/22867750</a></p>\n<p>[1] Wang, L., Cao, Z., Melo, G. D., &amp; Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. <em>Meeting of the Association for Computational Linguistics</em> (pp.1298-1307).</p>\n<p>[2] Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <em>Computer Science</em>.</p>\n<p>[3] Luong, M. T., Pham, H., &amp; Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. <em>Computer Science</em>.</p>\n<p>[4] Yin, W., Schtze, H., Xiang, B., &amp; Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. <em>Computer Science</em>.</p>\n"},{"title":" Entity resolution","date":"2017-12-10T07:00:00.000Z","_content":"\n## 1. Entity resolution\n\n###1.1 Sequence labeling\n\nMLNamed Entity RecognitionSequence labelingnlpsequence labelingRNN-CRF\n\n- Embedding layer\n- Bi-directional RNN (usually LSTM) layer\n- Tanh hidden layer\n- CRF layer\n\nsequence labelingnamed entity recognitionevent recognitionseq labeling\n\n#### 1.1.1 Attention \n\n> [1] RNN-CRF  attention  attention \n>\n> [2] BiLSTM-CRF  attention \n>\n>                        from paperweekly\n\n#### 1.1.2  \n\n\n\n- [Deep Active Learning for Named Entity Recognition](https://openreview.net/forum?id=ry018WZAZ)[7]\n\n  ICLR 2018paperactive learningCNN-CNN-LSTMNERseq labeling25%state-of-the-art\n\n  paperseq labelingdecoderLSTMCRFLSTMCRFactive learningseq labeling\n\n- Semi-supervised sequence tagging with bidirectional language models[4]\n\n  LM embedding RNN-CRF \n\n   NER  RNN-CRF \n\n### 1.2 Relation extraction\n\npipeline\n\npipelineentity\n\n[9]LSTM-RNNword sequencebidirectional sequential LSTM-RNNsTree Structures bidirectional tree- structured LSTM-RNNs\n\n![LSTM-RNNs](https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg)\n\npaperjoint\n\n[7] encoder-decoder  bi-lstm  encoderlstm  decoder BIEM++pipeline F1  0.5\n\nsoftmax\n\n## 2. Others\n\n\n\n1. Ngram2vec[5]\n\n    word2vec  ngram [https://github.com/zhezhaoa/ngram2vec/](http://link.zhihu.com/?target=https%3A//github.com/zhezhaoa/ngram2vec/)\n\n2. [AutoML](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html)\n\n   googlereinforcement learning\n\n3. Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]\n\n   meta learning4mnistconv netpretrained\n\n## Reference\n\n[1] Rei, M., Crichton, G. K., & Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. *arXiv preprint arXiv:1611.04361*.\n\n[2] Mortensen, A. B. D., & Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.\n\n[3] Yang, Z., Salakhutdinov, R., & Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. *arXiv preprint arXiv:1703.06345*.\n\n[4] Peters, M. E., Ammar, W., Bhagavatula, C., & Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. *arXiv preprint arXiv:1705.00108*.\n\n[5] Zhao, Z., Liu, T., Li, S., Li, B., & Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In *Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing* (pp. 244-253).\n\n[6] Sinha, A., Sarkar, M., Mukherjee, A., & Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. *arXiv preprint arXiv:1704.04959*.\n\n[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, & Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.\n\n[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., & Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. *arXiv preprint arXiv:1706.05075*.\n\n[9] Miwa, M., & Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. *arXiv preprint arXiv:1601.00770*.","source":"_posts/[2017.12.10]Entity-resolution.md","raw":"---\ntitle:  Entity resolution\ndate: 2017-12-10 08:00:00\ncategories: [research]\ntags: [entity-resolution, sequence-labeling, relation-extraction, LSTM, RNN]\n---\n\n## 1. Entity resolution\n\n###1.1 Sequence labeling\n\nMLNamed Entity RecognitionSequence labelingnlpsequence labelingRNN-CRF\n\n- Embedding layer\n- Bi-directional RNN (usually LSTM) layer\n- Tanh hidden layer\n- CRF layer\n\nsequence labelingnamed entity recognitionevent recognitionseq labeling\n\n#### 1.1.1 Attention \n\n> [1] RNN-CRF  attention  attention \n>\n> [2] BiLSTM-CRF  attention \n>\n>                        from paperweekly\n\n#### 1.1.2  \n\n\n\n- [Deep Active Learning for Named Entity Recognition](https://openreview.net/forum?id=ry018WZAZ)[7]\n\n  ICLR 2018paperactive learningCNN-CNN-LSTMNERseq labeling25%state-of-the-art\n\n  paperseq labelingdecoderLSTMCRFLSTMCRFactive learningseq labeling\n\n- Semi-supervised sequence tagging with bidirectional language models[4]\n\n  LM embedding RNN-CRF \n\n   NER  RNN-CRF \n\n### 1.2 Relation extraction\n\npipeline\n\npipelineentity\n\n[9]LSTM-RNNword sequencebidirectional sequential LSTM-RNNsTree Structures bidirectional tree- structured LSTM-RNNs\n\n![LSTM-RNNs](https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg)\n\npaperjoint\n\n[7] encoder-decoder  bi-lstm  encoderlstm  decoder BIEM++pipeline F1  0.5\n\nsoftmax\n\n## 2. Others\n\n\n\n1. Ngram2vec[5]\n\n    word2vec  ngram [https://github.com/zhezhaoa/ngram2vec/](http://link.zhihu.com/?target=https%3A//github.com/zhezhaoa/ngram2vec/)\n\n2. [AutoML](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html)\n\n   googlereinforcement learning\n\n3. Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]\n\n   meta learning4mnistconv netpretrained\n\n## Reference\n\n[1] Rei, M., Crichton, G. K., & Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. *arXiv preprint arXiv:1611.04361*.\n\n[2] Mortensen, A. B. D., & Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.\n\n[3] Yang, Z., Salakhutdinov, R., & Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. *arXiv preprint arXiv:1703.06345*.\n\n[4] Peters, M. E., Ammar, W., Bhagavatula, C., & Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. *arXiv preprint arXiv:1705.00108*.\n\n[5] Zhao, Z., Liu, T., Li, S., Li, B., & Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In *Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing* (pp. 244-253).\n\n[6] Sinha, A., Sarkar, M., Mukherjee, A., & Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. *arXiv preprint arXiv:1704.04959*.\n\n[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, & Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.\n\n[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., & Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. *arXiv preprint arXiv:1706.05075*.\n\n[9] Miwa, M., & Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. *arXiv preprint arXiv:1601.00770*.","slug":"[2017.12.10]Entity-resolution","published":1,"updated":"2018-01-27T11:07:30.139Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvr6001opzm9nmea0n24","content":"<h2 id=\"1-Entity-resolution\"><a href=\"#1-Entity-resolution\" class=\"headerlink\" title=\"1. Entity resolution\"></a>1. Entity resolution</h2><h3 id=\"1-1-Sequence-labeling\"><a href=\"#1-1-Sequence-labeling\" class=\"headerlink\" title=\"1.1 Sequence labeling\"></a>1.1 Sequence labeling</h3><p>MLNamed Entity RecognitionSequence labelingnlpsequence labelingRNN-CRF</p>\n<ul>\n<li>Embedding layer</li>\n<li>Bi-directional RNN (usually LSTM) layer</li>\n<li>Tanh hidden layer</li>\n<li>CRF layer</li>\n</ul>\n<p>sequence labelingnamed entity recognitionevent recognitionseq labeling</p>\n<h4 id=\"1-1-1-Attention\"><a href=\"#1-1-1-Attention\" class=\"headerlink\" title=\"1.1.1 Attention\"></a>1.1.1 Attention</h4><blockquote>\n<p>[1] RNN-CRF  attention  attention </p>\n<p>[2] BiLSTM-CRF  attention </p>\n<p>                       from paperweekly</p>\n</blockquote>\n<h4 id=\"1-1-2-\"><a href=\"#1-1-2-\" class=\"headerlink\" title=\"1.1.2 \"></a>1.1.2 </h4><p></p>\n<ul>\n<li><p><a href=\"https://openreview.net/forum?id=ry018WZAZ\" target=\"_blank\" rel=\"external\">Deep Active Learning for Named Entity Recognition</a>[7]</p>\n<p>ICLR 2018paperactive learningCNN-CNN-LSTMNERseq labeling25%state-of-the-art</p>\n<p>paperseq labelingdecoderLSTMCRFLSTMCRFactive learningseq labeling</p>\n</li>\n<li><p>Semi-supervised sequence tagging with bidirectional language models[4]</p>\n<p>LM embedding RNN-CRF </p>\n<p> NER  RNN-CRF </p>\n</li>\n</ul>\n<h3 id=\"1-2-Relation-extraction\"><a href=\"#1-2-Relation-extraction\" class=\"headerlink\" title=\"1.2 Relation extraction\"></a>1.2 Relation extraction</h3><p>pipeline</p>\n<p>pipelineentity</p>\n<p>[9]LSTM-RNNword sequencebidirectional sequential LSTM-RNNsTree Structures bidirectional tree- structured LSTM-RNNs</p>\n<p><img src=\"https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg\" alt=\"LSTM-RNNs\"></p>\n<p>paperjoint</p>\n<p>[7] encoder-decoder  bi-lstm  encoderlstm  decoder BIEM++pipeline F1  0.5</p>\n<p>softmax</p>\n<h2 id=\"2-Others\"><a href=\"#2-Others\" class=\"headerlink\" title=\"2. Others\"></a>2. Others</h2><p></p>\n<ol>\n<li><p>Ngram2vec[5]</p>\n<p> word2vec  ngram <a href=\"http://link.zhihu.com/?target=https%3A//github.com/zhezhaoa/ngram2vec/\" target=\"_blank\" rel=\"external\">https://github.com/zhezhaoa/ngram2vec/</a></p>\n</li>\n<li><p><a href=\"https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html\" target=\"_blank\" rel=\"external\">AutoML</a></p>\n<p>googlereinforcement learning</p>\n</li>\n<li><p>Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]</p>\n<p>meta learning4mnistconv netpretrained</p>\n</li>\n</ol>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] Rei, M., Crichton, G. K., &amp; Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. <em>arXiv preprint arXiv:1611.04361</em>.</p>\n<p>[2] Mortensen, A. B. D., &amp; Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.</p>\n<p>[3] Yang, Z., Salakhutdinov, R., &amp; Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. <em>arXiv preprint arXiv:1703.06345</em>.</p>\n<p>[4] Peters, M. E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. <em>arXiv preprint arXiv:1705.00108</em>.</p>\n<p>[5] Zhao, Z., Liu, T., Li, S., Li, B., &amp; Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In <em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em> (pp. 244-253).</p>\n<p>[6] Sinha, A., Sarkar, M., Mukherjee, A., &amp; Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. <em>arXiv preprint arXiv:1704.04959</em>.</p>\n<p>[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, &amp; Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.</p>\n<p>[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., &amp; Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. <em>arXiv preprint arXiv:1706.05075</em>.</p>\n<p>[9] Miwa, M., &amp; Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. <em>arXiv preprint arXiv:1601.00770</em>.</p>\n","excerpt":"","more":"<h2 id=\"1-Entity-resolution\"><a href=\"#1-Entity-resolution\" class=\"headerlink\" title=\"1. Entity resolution\"></a>1. Entity resolution</h2><h3 id=\"1-1-Sequence-labeling\"><a href=\"#1-1-Sequence-labeling\" class=\"headerlink\" title=\"1.1 Sequence labeling\"></a>1.1 Sequence labeling</h3><p>MLNamed Entity RecognitionSequence labelingnlpsequence labelingRNN-CRF</p>\n<ul>\n<li>Embedding layer</li>\n<li>Bi-directional RNN (usually LSTM) layer</li>\n<li>Tanh hidden layer</li>\n<li>CRF layer</li>\n</ul>\n<p>sequence labelingnamed entity recognitionevent recognitionseq labeling</p>\n<h4 id=\"1-1-1-Attention\"><a href=\"#1-1-1-Attention\" class=\"headerlink\" title=\"1.1.1 Attention\"></a>1.1.1 Attention</h4><blockquote>\n<p>[1] RNN-CRF  attention  attention </p>\n<p>[2] BiLSTM-CRF  attention </p>\n<p>                       from paperweekly</p>\n</blockquote>\n<h4 id=\"1-1-2-\"><a href=\"#1-1-2-\" class=\"headerlink\" title=\"1.1.2 \"></a>1.1.2 </h4><p></p>\n<ul>\n<li><p><a href=\"https://openreview.net/forum?id=ry018WZAZ\">Deep Active Learning for Named Entity Recognition</a>[7]</p>\n<p>ICLR 2018paperactive learningCNN-CNN-LSTMNERseq labeling25%state-of-the-art</p>\n<p>paperseq labelingdecoderLSTMCRFLSTMCRFactive learningseq labeling</p>\n</li>\n<li><p>Semi-supervised sequence tagging with bidirectional language models[4]</p>\n<p>LM embedding RNN-CRF </p>\n<p> NER  RNN-CRF </p>\n</li>\n</ul>\n<h3 id=\"1-2-Relation-extraction\"><a href=\"#1-2-Relation-extraction\" class=\"headerlink\" title=\"1.2 Relation extraction\"></a>1.2 Relation extraction</h3><p>pipeline</p>\n<p>pipelineentity</p>\n<p>[9]LSTM-RNNword sequencebidirectional sequential LSTM-RNNsTree Structures bidirectional tree- structured LSTM-RNNs</p>\n<p><img src=\"https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg\" alt=\"LSTM-RNNs\"></p>\n<p>paperjoint</p>\n<p>[7] encoder-decoder  bi-lstm  encoderlstm  decoder BIEM++pipeline F1  0.5</p>\n<p>softmax</p>\n<h2 id=\"2-Others\"><a href=\"#2-Others\" class=\"headerlink\" title=\"2. Others\"></a>2. Others</h2><p></p>\n<ol>\n<li><p>Ngram2vec[5]</p>\n<p> word2vec  ngram <a href=\"http://link.zhihu.com/?target=https%3A//github.com/zhezhaoa/ngram2vec/\">https://github.com/zhezhaoa/ngram2vec/</a></p>\n</li>\n<li><p><a href=\"https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html\">AutoML</a></p>\n<p>googlereinforcement learning</p>\n</li>\n<li><p>Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]</p>\n<p>meta learning4mnistconv netpretrained</p>\n</li>\n</ol>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] Rei, M., Crichton, G. K., &amp; Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. <em>arXiv preprint arXiv:1611.04361</em>.</p>\n<p>[2] Mortensen, A. B. D., &amp; Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.</p>\n<p>[3] Yang, Z., Salakhutdinov, R., &amp; Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. <em>arXiv preprint arXiv:1703.06345</em>.</p>\n<p>[4] Peters, M. E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. <em>arXiv preprint arXiv:1705.00108</em>.</p>\n<p>[5] Zhao, Z., Liu, T., Li, S., Li, B., &amp; Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In <em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em> (pp. 244-253).</p>\n<p>[6] Sinha, A., Sarkar, M., Mukherjee, A., &amp; Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. <em>arXiv preprint arXiv:1704.04959</em>.</p>\n<p>[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, &amp; Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.</p>\n<p>[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., &amp; Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. <em>arXiv preprint arXiv:1706.05075</em>.</p>\n<p>[9] Miwa, M., &amp; Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. <em>arXiv preprint arXiv:1601.00770</em>.</p>\n"},{"title":" relation extraction ","date":"2018-01-14T07:00:00.000Z","_content":"\n##  relation extraction \n\n****Distant supervision relation extraction [1] dynamic-transition matrix distant supervision  relation extraction [2]negative pattern[3] relation extraction  Multi-instance Multi-label \n\n### 1. Problem of distant supervision\n\nDistant supervision  \\<e1, r, e2\\> \\<subj, r, obj\\> e1  e2  r \n\n\\<DonaldTrump, born-in, New York\\>Donald Trump was born in New YorkDonaldTrump worked in New Yorkborn-in\n\n### 2. Approaches to this problems\n\n-  \n  - dynamic-transition matrix [1]\n-  \n  - [2]\n  - Multi-instance learning[3],  attention  at-least-one-assumption\n\n\n\n#### 2.1 Learning with dynamic-transition matrix [1]\n\n[1]  dynamic-transition matrix Distant supervision dynamic-transition matrix  curriculum learning  relation extraction  state-of-the-art\n\n![overview](overview.png)\n\nTransition matrix T n*nnT $T_{ij}$ p( j| i ) i j \n\n    = \n\npredicted observed  timeRE  entityRE(NYT)  state-of-art\n\n#### 2.2 Reducing Wrong Labels [2] \n\nFreebase      \n\n<img src=\"wrong_label_reduction.png\" width=\"70%\">\n\nNegPat(r)rnegative patternirelationiiNegPat relation DS 1\n\n####2.3 Multi-instance Multi-label Learning [3]\n\n entities  entities  born in is the president of \n\n\n\n Multi-instance Multi-label   relation extraction \n\n### 3. Conclusion \n\n[1] relation extraction \n\n## References\n\n\\*[ | Learning with Noise: Supervised Relation Extraction](https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg)\n\n[1] Luo, Bingfeng, et al. \"Learning with noise: enhance distantly supervised relation extraction with dynamic transition matrix.\" *arXiv preprint arXiv:1705.03995* (2017).\n\n[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. \"Reducing wrong labels in distant supervision for relation extraction.\" *Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1*. Association for Computational Linguistics, 2012.\n\n[3] Surdeanu, Mihai, et al. \"Multi-instance multi-label learning for relation extraction.\" *Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning*. Association for Computational Linguistics, 2012.","source":"_posts/[2018.1.14]Models-for-relation-extraction.md","raw":"---\ntitle:  relation extraction \ndate: 2018-01-14 08:00:00\ncategories: [research]\ntags: [relation-extraction, distant-supervision]\n---\n\n##  relation extraction \n\n****Distant supervision relation extraction [1] dynamic-transition matrix distant supervision  relation extraction [2]negative pattern[3] relation extraction  Multi-instance Multi-label \n\n### 1. Problem of distant supervision\n\nDistant supervision  \\<e1, r, e2\\> \\<subj, r, obj\\> e1  e2  r \n\n\\<DonaldTrump, born-in, New York\\>Donald Trump was born in New YorkDonaldTrump worked in New Yorkborn-in\n\n### 2. Approaches to this problems\n\n-  \n  - dynamic-transition matrix [1]\n-  \n  - [2]\n  - Multi-instance learning[3],  attention  at-least-one-assumption\n\n\n\n#### 2.1 Learning with dynamic-transition matrix [1]\n\n[1]  dynamic-transition matrix Distant supervision dynamic-transition matrix  curriculum learning  relation extraction  state-of-the-art\n\n![overview](overview.png)\n\nTransition matrix T n*nnT $T_{ij}$ p( j| i ) i j \n\n    = \n\npredicted observed  timeRE  entityRE(NYT)  state-of-art\n\n#### 2.2 Reducing Wrong Labels [2] \n\nFreebase      \n\n<img src=\"wrong_label_reduction.png\" width=\"70%\">\n\nNegPat(r)rnegative patternirelationiiNegPat relation DS 1\n\n####2.3 Multi-instance Multi-label Learning [3]\n\n entities  entities  born in is the president of \n\n\n\n Multi-instance Multi-label   relation extraction \n\n### 3. Conclusion \n\n[1] relation extraction \n\n## References\n\n\\*[ | Learning with Noise: Supervised Relation Extraction](https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg)\n\n[1] Luo, Bingfeng, et al. \"Learning with noise: enhance distantly supervised relation extraction with dynamic transition matrix.\" *arXiv preprint arXiv:1705.03995* (2017).\n\n[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. \"Reducing wrong labels in distant supervision for relation extraction.\" *Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1*. Association for Computational Linguistics, 2012.\n\n[3] Surdeanu, Mihai, et al. \"Multi-instance multi-label learning for relation extraction.\" *Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning*. Association for Computational Linguistics, 2012.","slug":"[2018.1.14]Models-for-relation-extraction","published":1,"updated":"2018-01-27T11:17:23.317Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvr9001spzm9jr61qiyr","content":"<h2 id=\"-relation-extraction-\"><a href=\"#-relation-extraction-\" class=\"headerlink\" title=\" relation extraction \"></a> relation extraction </h2><p><strong></strong>Distant supervision relation extraction [1] dynamic-transition matrix distant supervision  relation extraction [2]negative pattern[3] relation extraction  Multi-instance Multi-label </p>\n<h3 id=\"1-Problem-of-distant-supervision\"><a href=\"#1-Problem-of-distant-supervision\" class=\"headerlink\" title=\"1. Problem of distant supervision\"></a>1. Problem of distant supervision</h3><p>Distant supervision  \\<e1, r,=\"\" e2\\=\"\"> \\<subj, r,=\"\" obj\\=\"\"> e1  e2  r </subj,></e1,></p>\n<p>\\<donaldtrump, born-in,=\"\" new=\"\" york\\=\"\">Donald Trump was born in New YorkDonaldTrump worked in New Yorkborn-in</donaldtrump,></p>\n<h3 id=\"2-Approaches-to-this-problems\"><a href=\"#2-Approaches-to-this-problems\" class=\"headerlink\" title=\"2. Approaches to this problems\"></a>2. Approaches to this problems</h3><ul>\n<li><ul>\n<li>dynamic-transition matrix [1]</li>\n</ul>\n</li>\n<li><ul>\n<li>[2]</li>\n<li>Multi-instance learning[3],  attention  at-least-one-assumption</li>\n</ul>\n</li>\n</ul>\n<p></p>\n<h4 id=\"2-1-Learning-with-dynamic-transition-matrix-1\"><a href=\"#2-1-Learning-with-dynamic-transition-matrix-1\" class=\"headerlink\" title=\"2.1 Learning with dynamic-transition matrix [1]\"></a>2.1 Learning with dynamic-transition matrix [1]</h4><p>[1]  dynamic-transition matrix Distant supervision dynamic-transition matrix  curriculum learning  relation extraction  state-of-the-art</p>\n<p><img src=\"overview.png\" alt=\"overview\"></p>\n<p>Transition matrix T n*nnT $T_{ij}$ p( j| i ) i j </p>\n<p>    = </p>\n<p>predicted observed  timeRE  entityRE(NYT)  state-of-art</p>\n<h4 id=\"2-2-Reducing-Wrong-Labels-2\"><a href=\"#2-2-Reducing-Wrong-Labels-2\" class=\"headerlink\" title=\"2.2 Reducing Wrong Labels [2]\"></a>2.2 Reducing Wrong Labels [2]</h4><p>Freebase      </p>\n<p><img src=\"wrong_label_reduction.png\" width=\"70%\"></p>\n<p>NegPat(r)rnegative patternirelationiiNegPat relation DS 1</p>\n<h4 id=\"2-3-Multi-instance-Multi-label-Learning-3\"><a href=\"#2-3-Multi-instance-Multi-label-Learning-3\" class=\"headerlink\" title=\"2.3 Multi-instance Multi-label Learning [3]\"></a>2.3 Multi-instance Multi-label Learning [3]</h4><p> entities  entities  born in is the president of </p>\n<p></p>\n<p> Multi-instance Multi-label   relation extraction </p>\n<h3 id=\"3-Conclusion\"><a href=\"#3-Conclusion\" class=\"headerlink\" title=\"3. Conclusion\"></a>3. Conclusion</h3><p>[1] relation extraction </p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p>*<a href=\"https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg\" target=\"_blank\" rel=\"external\"> | Learning with Noise: Supervised Relation Extraction</a></p>\n<p>[1] Luo, Bingfeng, et al. Learning with noise: enhance distantly supervised relation extraction with dynamic transition matrix. <em>arXiv preprint arXiv:1705.03995</em> (2017).</p>\n<p>[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. Reducing wrong labels in distant supervision for relation extraction. <em>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1</em>. Association for Computational Linguistics, 2012.</p>\n<p>[3] Surdeanu, Mihai, et al. Multi-instance multi-label learning for relation extraction. <em>Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</em>. Association for Computational Linguistics, 2012.</p>\n","excerpt":"","more":"<h2 id=\"-relation-extraction-\"><a href=\"#-relation-extraction-\" class=\"headerlink\" title=\" relation extraction \"></a> relation extraction </h2><p><strong></strong>Distant supervision relation extraction [1] dynamic-transition matrix distant supervision  relation extraction [2]negative pattern[3] relation extraction  Multi-instance Multi-label </p>\n<h3 id=\"1-Problem-of-distant-supervision\"><a href=\"#1-Problem-of-distant-supervision\" class=\"headerlink\" title=\"1. Problem of distant supervision\"></a>1. Problem of distant supervision</h3><p>Distant supervision  \\<e1, r, e2\\> \\<subj, r, obj\\> e1  e2  r </p>\n<p>\\<DonaldTrump, born-in, New York\\>Donald Trump was born in New YorkDonaldTrump worked in New Yorkborn-in</p>\n<h3 id=\"2-Approaches-to-this-problems\"><a href=\"#2-Approaches-to-this-problems\" class=\"headerlink\" title=\"2. Approaches to this problems\"></a>2. Approaches to this problems</h3><ul>\n<li><ul>\n<li>dynamic-transition matrix [1]</li>\n</ul>\n</li>\n<li><ul>\n<li>[2]</li>\n<li>Multi-instance learning[3],  attention  at-least-one-assumption</li>\n</ul>\n</li>\n</ul>\n<p></p>\n<h4 id=\"2-1-Learning-with-dynamic-transition-matrix-1\"><a href=\"#2-1-Learning-with-dynamic-transition-matrix-1\" class=\"headerlink\" title=\"2.1 Learning with dynamic-transition matrix [1]\"></a>2.1 Learning with dynamic-transition matrix [1]</h4><p>[1]  dynamic-transition matrix Distant supervision dynamic-transition matrix  curriculum learning  relation extraction  state-of-the-art</p>\n<p><img src=\"overview.png\" alt=\"overview\"></p>\n<p>Transition matrix T n*nnT $T_{ij}$ p( j| i ) i j </p>\n<p>    = </p>\n<p>predicted observed  timeRE  entityRE(NYT)  state-of-art</p>\n<h4 id=\"2-2-Reducing-Wrong-Labels-2\"><a href=\"#2-2-Reducing-Wrong-Labels-2\" class=\"headerlink\" title=\"2.2 Reducing Wrong Labels [2]\"></a>2.2 Reducing Wrong Labels [2]</h4><p>Freebase      </p>\n<p><img src=\"wrong_label_reduction.png\" width=\"70%\"></p>\n<p>NegPat(r)rnegative patternirelationiiNegPat relation DS 1</p>\n<h4 id=\"2-3-Multi-instance-Multi-label-Learning-3\"><a href=\"#2-3-Multi-instance-Multi-label-Learning-3\" class=\"headerlink\" title=\"2.3 Multi-instance Multi-label Learning [3]\"></a>2.3 Multi-instance Multi-label Learning [3]</h4><p> entities  entities  born in is the president of </p>\n<p></p>\n<p> Multi-instance Multi-label   relation extraction </p>\n<h3 id=\"3-Conclusion\"><a href=\"#3-Conclusion\" class=\"headerlink\" title=\"3. Conclusion\"></a>3. Conclusion</h3><p>[1] relation extraction </p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p>*<a href=\"https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg\"> | Learning with Noise: Supervised Relation Extraction</a></p>\n<p>[1] Luo, Bingfeng, et al. Learning with noise: enhance distantly supervised relation extraction with dynamic transition matrix. <em>arXiv preprint arXiv:1705.03995</em> (2017).</p>\n<p>[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. Reducing wrong labels in distant supervision for relation extraction. <em>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1</em>. Association for Computational Linguistics, 2012.</p>\n<p>[3] Surdeanu, Mihai, et al. Multi-instance multi-label learning for relation extraction. <em>Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</em>. Association for Computational Linguistics, 2012.</p>\n"},{"title":"Event detection and co-reference with minimal supervision ","date":"2018-01-21T07:00:00.000Z","_content":"\n## Event detection and co-reference with minimal supervision [1]\n\n****ACErich EREFreebase\n\n### 1. Introduction\n\n<img src='overview.png' width='70%'>\n\nMSEPMinimally Supervised Event Pipeline Event examples  Example vectorsMSEP\n\n\n\n- Event detection \n- Co-reference problem. Co-reference problem\n\neevent detection e co-reference problem e1e2\n\n1. 2. semantic role labeling  representationSRLembedding\n\nevent mentionevent ontology co-reference \n\n\n\n### 2. The MSEP System\n\n#### 2.1 Structured Vector Representation \n\n\n\n![basic](basic_event.png)\n\n**Basic event vector representation**\n\n![basic](augmented_event.png)\n\n**Augmented event vector representation**+ ESA\n\n#### 2.2 Event Mention Detection\n\n Event type representation \n\n\n$$\nS(e_1, e_2) = \\frac{vec(e_1)  vec(e_2)}{||vec(e_1)||||vec(e_2)||} \\\\\n= \\frac{\\sum_a{vec(a_1)  vec(a_2)}}{\\sqrt{\\sum_a{||vec(a_1)||^2}  \\sum_a{||vec(a_2)||^2}}}\n$$\n e1 e2 a  a \n\n#### 2.3 Event co-reference\n\n$S(e_1, e_2)$\n\n$agnet_{sub}, agnet_{obj}$$Set_{conflict}$\n\nk+1\n$$\ne_p = argmax_{e\\in \\{e_1,...,e_k\\} e \\notin Set_{conflit}} {S(e_p, e_{k+1})}\n$$\n$S(e_p, e_{k+1})$\n\n### 3. Vector Representation\n\n embedding \n\n- Explicit Semantic Analysis\n- Brown Cluster\n- Word2Vec\n- Dependency-Based Embedding\n\n### 4. Semantic Role Labeling\n\n Semantic Role Labeling  Semantic Role Labeling\n\n[2]RNN-CRF\n\n- Embedding layer\n- Bi-directional RNN (usually LSTM) layer\n- Tanh hidden layer\n- CRF layer\n\nAttention\n\nLTP Semantic Role Labeling \n\n### 5. Conclusion\n\nevent\n\n\n\n## Bibliography\n\n[1] Peng, H., Song, Y., & Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In *EMNLP* (pp. 392-402).\n\n[2] Zhou, J., & Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In *ACL (1)* (pp. 1127-1137).","source":"_posts/[2018.1.21]Event-detection-and-co-referentce.md","raw":"---\ntitle: Event detection and co-reference with minimal supervision \ndate: 2018-01-21 08:00:00\ncategories: [research]\ntags: [event-detection, co-reference]\n---\n\n## Event detection and co-reference with minimal supervision [1]\n\n****ACErich EREFreebase\n\n### 1. Introduction\n\n<img src='overview.png' width='70%'>\n\nMSEPMinimally Supervised Event Pipeline Event examples  Example vectorsMSEP\n\n\n\n- Event detection \n- Co-reference problem. Co-reference problem\n\neevent detection e co-reference problem e1e2\n\n1. 2. semantic role labeling  representationSRLembedding\n\nevent mentionevent ontology co-reference \n\n\n\n### 2. The MSEP System\n\n#### 2.1 Structured Vector Representation \n\n\n\n![basic](basic_event.png)\n\n**Basic event vector representation**\n\n![basic](augmented_event.png)\n\n**Augmented event vector representation**+ ESA\n\n#### 2.2 Event Mention Detection\n\n Event type representation \n\n\n$$\nS(e_1, e_2) = \\frac{vec(e_1)  vec(e_2)}{||vec(e_1)||||vec(e_2)||} \\\\\n= \\frac{\\sum_a{vec(a_1)  vec(a_2)}}{\\sqrt{\\sum_a{||vec(a_1)||^2}  \\sum_a{||vec(a_2)||^2}}}\n$$\n e1 e2 a  a \n\n#### 2.3 Event co-reference\n\n$S(e_1, e_2)$\n\n$agnet_{sub}, agnet_{obj}$$Set_{conflict}$\n\nk+1\n$$\ne_p = argmax_{e\\in \\{e_1,...,e_k\\} e \\notin Set_{conflit}} {S(e_p, e_{k+1})}\n$$\n$S(e_p, e_{k+1})$\n\n### 3. Vector Representation\n\n embedding \n\n- Explicit Semantic Analysis\n- Brown Cluster\n- Word2Vec\n- Dependency-Based Embedding\n\n### 4. Semantic Role Labeling\n\n Semantic Role Labeling  Semantic Role Labeling\n\n[2]RNN-CRF\n\n- Embedding layer\n- Bi-directional RNN (usually LSTM) layer\n- Tanh hidden layer\n- CRF layer\n\nAttention\n\nLTP Semantic Role Labeling \n\n### 5. Conclusion\n\nevent\n\n\n\n## Bibliography\n\n[1] Peng, H., Song, Y., & Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In *EMNLP* (pp. 392-402).\n\n[2] Zhou, J., & Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In *ACL (1)* (pp. 1127-1137).","slug":"[2018.1.21]Event-detection-and-co-referentce","published":1,"updated":"2018-01-27T11:18:29.654Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvra001wpzm94r7d8x0r","content":"<h2 id=\"Event-detection-and-co-reference-with-minimal-supervision-1\"><a href=\"#Event-detection-and-co-reference-with-minimal-supervision-1\" class=\"headerlink\" title=\"Event detection and co-reference with minimal supervision [1]\"></a>Event detection and co-reference with minimal supervision [1]</h2><p><strong></strong>ACErich EREFreebase</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p><img src=\"overview.png\" width=\"70%\"></p>\n<p>MSEPMinimally Supervised Event Pipeline Event examples  Example vectorsMSEP</p>\n<p></p>\n<ul>\n<li>Event detection </li>\n<li>Co-reference problem. Co-reference problem</li>\n</ul>\n<p>eevent detection e co-reference problem e1e2</p>\n<p>1. 2. semantic role labeling  representationSRLembedding</p>\n<p>event mentionevent ontology co-reference </p>\n<h3 id=\"2-The-MSEP-System\"><a href=\"#2-The-MSEP-System\" class=\"headerlink\" title=\"2. The MSEP System\"></a>2. The MSEP System</h3><h4 id=\"2-1-Structured-Vector-Representation\"><a href=\"#2-1-Structured-Vector-Representation\" class=\"headerlink\" title=\"2.1 Structured Vector Representation\"></a>2.1 Structured Vector Representation</h4><p></p>\n<p><img src=\"basic_event.png\" alt=\"basic\"></p>\n<p><strong>Basic event vector representation</strong></p>\n<p><img src=\"augmented_event.png\" alt=\"basic\"></p>\n<p><strong>Augmented event vector representation</strong>+ ESA</p>\n<h4 id=\"2-2-Event-Mention-Detection\"><a href=\"#2-2-Event-Mention-Detection\" class=\"headerlink\" title=\"2.2 Event Mention Detection\"></a>2.2 Event Mention Detection</h4><p> Event type representation </p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nS(e_1, e_2) = \\frac{vec(e_1)  vec(e_2)}{||vec(e_1)||||vec(e_2)||} \\\\\n= \\frac{\\sum_a{vec(a_1)  vec(a_2)}}{\\sqrt{\\sum_a{||vec(a_1)||^2}  \\sum_a{||vec(a_2)||^2}}}</script><p> e1 e2 a  a </p>\n<h4 id=\"2-3-Event-co-reference\"><a href=\"#2-3-Event-co-reference\" class=\"headerlink\" title=\"2.3 Event co-reference\"></a>2.3 Event co-reference</h4><p>$S(e_1, e_2)$</p>\n<p>$agnet<em>{sub}, agnet</em>{obj}$$Set_{conflict}$</p>\n<p>k+1</p>\n<script type=\"math/tex; mode=display\">\ne_p = argmax_{e\\in \\{e_1,...,e_k\\} e \\notin Set_{conflit}} {S(e_p, e_{k+1})}</script><p>$S(e<em>p, e</em>{k+1})$</p>\n<h3 id=\"3-Vector-Representation\"><a href=\"#3-Vector-Representation\" class=\"headerlink\" title=\"3. Vector Representation\"></a>3. Vector Representation</h3><p> embedding </p>\n<ul>\n<li>Explicit Semantic Analysis</li>\n<li>Brown Cluster</li>\n<li>Word2Vec</li>\n<li>Dependency-Based Embedding</li>\n</ul>\n<h3 id=\"4-Semantic-Role-Labeling\"><a href=\"#4-Semantic-Role-Labeling\" class=\"headerlink\" title=\"4. Semantic Role Labeling\"></a>4. Semantic Role Labeling</h3><p> Semantic Role Labeling  Semantic Role Labeling</p>\n<p>[2]RNN-CRF</p>\n<ul>\n<li>Embedding layer</li>\n<li>Bi-directional RNN (usually LSTM) layer</li>\n<li>Tanh hidden layer</li>\n<li>CRF layer</li>\n</ul>\n<p>Attention</p>\n<p>LTP Semantic Role Labeling </p>\n<h3 id=\"5-Conclusion\"><a href=\"#5-Conclusion\" class=\"headerlink\" title=\"5. Conclusion\"></a>5. Conclusion</h3><p>event</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[1] Peng, H., Song, Y., &amp; Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In <em>EMNLP</em> (pp. 392-402).</p>\n<p>[2] Zhou, J., &amp; Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In <em>ACL (1)</em> (pp. 1127-1137).</p>\n","excerpt":"","more":"<h2 id=\"Event-detection-and-co-reference-with-minimal-supervision-1\"><a href=\"#Event-detection-and-co-reference-with-minimal-supervision-1\" class=\"headerlink\" title=\"Event detection and co-reference with minimal supervision [1]\"></a>Event detection and co-reference with minimal supervision [1]</h2><p><strong></strong>ACErich EREFreebase</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p><img src='overview.png' width='70%'></p>\n<p>MSEPMinimally Supervised Event Pipeline Event examples  Example vectorsMSEP</p>\n<p></p>\n<ul>\n<li>Event detection </li>\n<li>Co-reference problem. Co-reference problem</li>\n</ul>\n<p>eevent detection e co-reference problem e1e2</p>\n<p>1. 2. semantic role labeling  representationSRLembedding</p>\n<p>event mentionevent ontology co-reference </p>\n<h3 id=\"2-The-MSEP-System\"><a href=\"#2-The-MSEP-System\" class=\"headerlink\" title=\"2. The MSEP System\"></a>2. The MSEP System</h3><h4 id=\"2-1-Structured-Vector-Representation\"><a href=\"#2-1-Structured-Vector-Representation\" class=\"headerlink\" title=\"2.1 Structured Vector Representation\"></a>2.1 Structured Vector Representation</h4><p></p>\n<p><img src=\"basic_event.png\" alt=\"basic\"></p>\n<p><strong>Basic event vector representation</strong></p>\n<p><img src=\"augmented_event.png\" alt=\"basic\"></p>\n<p><strong>Augmented event vector representation</strong>+ ESA</p>\n<h4 id=\"2-2-Event-Mention-Detection\"><a href=\"#2-2-Event-Mention-Detection\" class=\"headerlink\" title=\"2.2 Event Mention Detection\"></a>2.2 Event Mention Detection</h4><p> Event type representation </p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nS(e_1, e_2) = \\frac{vec(e_1)  vec(e_2)}{||vec(e_1)||||vec(e_2)||} \\\\\n= \\frac{\\sum_a{vec(a_1)  vec(a_2)}}{\\sqrt{\\sum_a{||vec(a_1)||^2}  \\sum_a{||vec(a_2)||^2}}}</script><p> e1 e2 a  a </p>\n<h4 id=\"2-3-Event-co-reference\"><a href=\"#2-3-Event-co-reference\" class=\"headerlink\" title=\"2.3 Event co-reference\"></a>2.3 Event co-reference</h4><p>$S(e_1, e_2)$</p>\n<p>$agnet<em>{sub}, agnet</em>{obj}$$Set_{conflict}$</p>\n<p>k+1</p>\n<script type=\"math/tex; mode=display\">\ne_p = argmax_{e\\in \\{e_1,...,e_k\\} e \\notin Set_{conflit}} {S(e_p, e_{k+1})}</script><p>$S(e<em>p, e</em>{k+1})$</p>\n<h3 id=\"3-Vector-Representation\"><a href=\"#3-Vector-Representation\" class=\"headerlink\" title=\"3. Vector Representation\"></a>3. Vector Representation</h3><p> embedding </p>\n<ul>\n<li>Explicit Semantic Analysis</li>\n<li>Brown Cluster</li>\n<li>Word2Vec</li>\n<li>Dependency-Based Embedding</li>\n</ul>\n<h3 id=\"4-Semantic-Role-Labeling\"><a href=\"#4-Semantic-Role-Labeling\" class=\"headerlink\" title=\"4. Semantic Role Labeling\"></a>4. Semantic Role Labeling</h3><p> Semantic Role Labeling  Semantic Role Labeling</p>\n<p>[2]RNN-CRF</p>\n<ul>\n<li>Embedding layer</li>\n<li>Bi-directional RNN (usually LSTM) layer</li>\n<li>Tanh hidden layer</li>\n<li>CRF layer</li>\n</ul>\n<p>Attention</p>\n<p>LTP Semantic Role Labeling </p>\n<h3 id=\"5-Conclusion\"><a href=\"#5-Conclusion\" class=\"headerlink\" title=\"5. Conclusion\"></a>5. Conclusion</h3><p>event</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[1] Peng, H., Song, Y., &amp; Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In <em>EMNLP</em> (pp. 392-402).</p>\n<p>[2] Zhou, J., &amp; Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In <em>ACL (1)</em> (pp. 1127-1137).</p>\n"},{"title":"A convolution BiLSTM neural network model for chinese event extraction ","date":"2018-01-29T07:00:00.000Z","_content":"\n## A convolution BiLSTM neural network model for chinese event extraction\n\n****NLP \\[1\\]LSTMCNNLSTM\n\n### 1. Introduction\n\nAutomatic Content ExtractionACE\n\n- \n- \n\n********\n\nS1Intel****\n\nIntel\n\n state-of-the-art [2-4] ********\n\nS2****1994\n\nS3****\n\nS2\n\nS3\n\n[2, 3]NLP\n\nChen et al. [5] LSTMLSTM POSNER\n\n### 2. Trigger Labeling \n\n#### 2.1 Language Specific Issues\n\n\n\n- \n- \n\n BIOBIOLSTM\n\n![trigger-labeling](trigger_labeling.png)\n\n awtctCNNb  734 bP\n\n#### 2.2 Word-Based Method\n\n**LSTM Network**  nlpLSTMLSTM\n\n**CNN**  nlp\n\nn{w1, w2, ... , wn}wtwt  map   cwtwt\n\n73\n\n**Output Layer**  BiLSTMCNNtcwt \\[ht; cwt\\]softmaxwt\n\n\n#### 2.3 Character-Based Method\n\nCharacter-embeddinginput layer\n\n![character](character.png)\n\n### 3. Argument Labeling\n\n\n\n#### 3.1 Input Layer\n\npipelineword embeddings embeddingBiLSTMCNN\n\n- \n- NONE\n- \n- NONE ACENLP**1. embed2. \n  BiLSTMCNN\n\n#### 3.2 Output Layer\n\n ACE  S4\n\nS7*******Bob******Joe*****\n\nCNNBiLSTM\n\nBiLSTMhN\n\nCNN softmax\n\n### 4. Conclusion\n\n[1]LSTMACE 2005BiLSTM+CRF[1]\n\n## Bibliography\n\n\\[1\\] Zeng, Y., Yang, H., Feng, Y., Wang, Z., & Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In *Natural Language Understanding and Intelligent Applications* (pp. 275-287). Springer, Cham.\n\n\\[2\\] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529544. Citeseer (2012)\n\n\\[3\\] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)\n\n[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 7382 (2013)\n\n[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)","source":"_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction.md","raw":"---\ntitle: A convolution BiLSTM neural network model for chinese event extraction \ndate: 2018-01-29 08:00:00\ncategories: [research]\ntags: [convolution, BiLSTM, event-extraction]\n---\n\n## A convolution BiLSTM neural network model for chinese event extraction\n\n****NLP \\[1\\]LSTMCNNLSTM\n\n### 1. Introduction\n\nAutomatic Content ExtractionACE\n\n- \n- \n\n********\n\nS1Intel****\n\nIntel\n\n state-of-the-art [2-4] ********\n\nS2****1994\n\nS3****\n\nS2\n\nS3\n\n[2, 3]NLP\n\nChen et al. [5] LSTMLSTM POSNER\n\n### 2. Trigger Labeling \n\n#### 2.1 Language Specific Issues\n\n\n\n- \n- \n\n BIOBIOLSTM\n\n![trigger-labeling](trigger_labeling.png)\n\n awtctCNNb  734 bP\n\n#### 2.2 Word-Based Method\n\n**LSTM Network**  nlpLSTMLSTM\n\n**CNN**  nlp\n\nn{w1, w2, ... , wn}wtwt  map   cwtwt\n\n73\n\n**Output Layer**  BiLSTMCNNtcwt \\[ht; cwt\\]softmaxwt\n\n\n#### 2.3 Character-Based Method\n\nCharacter-embeddinginput layer\n\n![character](character.png)\n\n### 3. Argument Labeling\n\n\n\n#### 3.1 Input Layer\n\npipelineword embeddings embeddingBiLSTMCNN\n\n- \n- NONE\n- \n- NONE ACENLP**1. embed2. \n  BiLSTMCNN\n\n#### 3.2 Output Layer\n\n ACE  S4\n\nS7*******Bob******Joe*****\n\nCNNBiLSTM\n\nBiLSTMhN\n\nCNN softmax\n\n### 4. Conclusion\n\n[1]LSTMACE 2005BiLSTM+CRF[1]\n\n## Bibliography\n\n\\[1\\] Zeng, Y., Yang, H., Feng, Y., Wang, Z., & Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In *Natural Language Understanding and Intelligent Applications* (pp. 275-287). Springer, Cham.\n\n\\[2\\] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529544. Citeseer (2012)\n\n\\[3\\] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)\n\n[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 7382 (2013)\n\n[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)","slug":"[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction","published":1,"updated":"2018-03-03T20:17:22.105Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrc001zpzm9j6m6iv54","content":"<h2 id=\"A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction\"><a href=\"#A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction\" class=\"headerlink\" title=\"A convolution BiLSTM neural network model for chinese event extraction\"></a>A convolution BiLSTM neural network model for chinese event extraction</h2><p><strong></strong>NLP [1]LSTMCNNLSTM</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>Automatic Content ExtractionACE</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p><strong></strong><strong></strong></p>\n<p>S1Intel<strong></strong></p>\n<p>Intel</p>\n<p> state-of-the-art [2-4] <strong></strong><strong></strong></p>\n<p>S2<strong></strong>1994</p>\n<p>S3<strong></strong></p>\n<p>S2</p>\n<p>S3</p>\n<p>[2, 3]NLP</p>\n<p>Chen et al. [5] LSTMLSTM POSNER</p>\n<h3 id=\"2-Trigger-Labeling\"><a href=\"#2-Trigger-Labeling\" class=\"headerlink\" title=\"2. Trigger Labeling\"></a>2. Trigger Labeling</h3><h4 id=\"2-1-Language-Specific-Issues\"><a href=\"#2-1-Language-Specific-Issues\" class=\"headerlink\" title=\"2.1 Language Specific Issues\"></a>2.1 Language Specific Issues</h4><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p> BIOBIOLSTM</p>\n<p><img src=\"trigger_labeling.png\" alt=\"trigger-labeling\"></p>\n<p> awtctCNNb  734 bP</p>\n<h4 id=\"2-2-Word-Based-Method\"><a href=\"#2-2-Word-Based-Method\" class=\"headerlink\" title=\"2.2 Word-Based Method\"></a>2.2 Word-Based Method</h4><p><strong>LSTM Network</strong>  nlpLSTMLSTM</p>\n<p><strong>CNN</strong>  nlp</p>\n<p>n{w1, w2,  , wn}wtwt  map   cwtwt</p>\n<p>73</p>\n<p><strong>Output Layer</strong>  BiLSTMCNNtcwt [ht; cwt]softmaxwt<br></p>\n<h4 id=\"2-3-Character-Based-Method\"><a href=\"#2-3-Character-Based-Method\" class=\"headerlink\" title=\"2.3 Character-Based Method\"></a>2.3 Character-Based Method</h4><p>Character-embeddinginput layer</p>\n<p><img src=\"character.png\" alt=\"character\"></p>\n<h3 id=\"3-Argument-Labeling\"><a href=\"#3-Argument-Labeling\" class=\"headerlink\" title=\"3. Argument Labeling\"></a>3. Argument Labeling</h3><p></p>\n<h4 id=\"3-1-Input-Layer\"><a href=\"#3-1-Input-Layer\" class=\"headerlink\" title=\"3.1 Input Layer\"></a>3.1 Input Layer</h4><p>pipelineword embeddings embeddingBiLSTMCNN</p>\n<ul>\n<li></li>\n<li>NONE</li>\n<li></li>\n<li>NONE ACENLP<em></em>1. embed2. <br>BiLSTMCNN</li>\n</ul>\n<h4 id=\"3-2-Output-Layer\"><a href=\"#3-2-Output-Layer\" class=\"headerlink\" title=\"3.2 Output Layer\"></a>3.2 Output Layer</h4><p> ACE  S4</p>\n<p>S7<strong></strong><em></em><em>Bob</em><strong></strong><em>Joe</em><strong></strong></p>\n<p>CNNBiLSTM</p>\n<p>BiLSTMhN</p>\n<p>CNN softmax</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>[1]LSTMACE 2005BiLSTM+CRF[1]</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[1] Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.</p>\n<p>[2] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529544. Citeseer (2012)</p>\n<p>[3] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)</p>\n<p>[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 7382 (2013)</p>\n<p>[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)</p>\n","excerpt":"","more":"<h2 id=\"A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction\"><a href=\"#A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction\" class=\"headerlink\" title=\"A convolution BiLSTM neural network model for chinese event extraction\"></a>A convolution BiLSTM neural network model for chinese event extraction</h2><p><strong></strong>NLP [1]LSTMCNNLSTM</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>Automatic Content ExtractionACE</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p><strong></strong><strong></strong></p>\n<p>S1Intel<strong></strong></p>\n<p>Intel</p>\n<p> state-of-the-art [2-4] <strong></strong><strong></strong></p>\n<p>S2<strong></strong>1994</p>\n<p>S3<strong></strong></p>\n<p>S2</p>\n<p>S3</p>\n<p>[2, 3]NLP</p>\n<p>Chen et al. [5] LSTMLSTM POSNER</p>\n<h3 id=\"2-Trigger-Labeling\"><a href=\"#2-Trigger-Labeling\" class=\"headerlink\" title=\"2. Trigger Labeling\"></a>2. Trigger Labeling</h3><h4 id=\"2-1-Language-Specific-Issues\"><a href=\"#2-1-Language-Specific-Issues\" class=\"headerlink\" title=\"2.1 Language Specific Issues\"></a>2.1 Language Specific Issues</h4><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p> BIOBIOLSTM</p>\n<p><img src=\"trigger_labeling.png\" alt=\"trigger-labeling\"></p>\n<p> awtctCNNb  734 bP</p>\n<h4 id=\"2-2-Word-Based-Method\"><a href=\"#2-2-Word-Based-Method\" class=\"headerlink\" title=\"2.2 Word-Based Method\"></a>2.2 Word-Based Method</h4><p><strong>LSTM Network</strong>  nlpLSTMLSTM</p>\n<p><strong>CNN</strong>  nlp</p>\n<p>n{w1, w2,  , wn}wtwt  map   cwtwt</p>\n<p>73</p>\n<p><strong>Output Layer</strong>  BiLSTMCNNtcwt [ht; cwt]softmaxwt<br></p>\n<h4 id=\"2-3-Character-Based-Method\"><a href=\"#2-3-Character-Based-Method\" class=\"headerlink\" title=\"2.3 Character-Based Method\"></a>2.3 Character-Based Method</h4><p>Character-embeddinginput layer</p>\n<p><img src=\"character.png\" alt=\"character\"></p>\n<h3 id=\"3-Argument-Labeling\"><a href=\"#3-Argument-Labeling\" class=\"headerlink\" title=\"3. Argument Labeling\"></a>3. Argument Labeling</h3><p></p>\n<h4 id=\"3-1-Input-Layer\"><a href=\"#3-1-Input-Layer\" class=\"headerlink\" title=\"3.1 Input Layer\"></a>3.1 Input Layer</h4><p>pipelineword embeddings embeddingBiLSTMCNN</p>\n<ul>\n<li></li>\n<li>NONE</li>\n<li></li>\n<li>NONE ACENLP<em></em>1. embed2. <br>BiLSTMCNN</li>\n</ul>\n<h4 id=\"3-2-Output-Layer\"><a href=\"#3-2-Output-Layer\" class=\"headerlink\" title=\"3.2 Output Layer\"></a>3.2 Output Layer</h4><p> ACE  S4</p>\n<p>S7<strong></strong><em></em><em>Bob</em><strong></strong><em>Joe</em><strong></strong></p>\n<p>CNNBiLSTM</p>\n<p>BiLSTMhN</p>\n<p>CNN softmax</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>[1]LSTMACE 2005BiLSTM+CRF[1]</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[1] Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.</p>\n<p>[2] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529544. Citeseer (2012)</p>\n<p>[3] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)</p>\n<p>[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 7382 (2013)</p>\n<p>[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)</p>\n"},{"title":"Overcoming Limited Supervision in Relation Extraction ","date":"2018-01-04T07:00:00.000Z","_content":"\nOvercoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach[1]distributional approachpattern-based approach\n\n![illustration](illustration.png)\n\n### 1. Introduction\n\n#### 1.1 Weakly Supervised Learning\n\nseed\n\n\n\n1. \n2. \n3. \n\n#### 1.2 Co-training strategy\n\nco-training[2]\n\nco-training\n\n#### 1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)\n\nREPEL\n\n### 2. Problem definition\n\n\n\n $(e_h, e_t)$$(e_h, e_t, r)$\n\nDRseed$ \\{(e_h^{r(k)}, e_t^{r(k)}, r)\\} _{k=1}^{N_r} $$ \\{(e_h^{r(i)}, e_t^{r(i)}, r)\\} _{i=1}^M $$ r \\in R $$ \\{(e_h^{r(i)}, e_t^{r(i)})\\} _{i=1}^{M_r} $\n\n### 3. REPEL Framework\n\n\n\n\n\n\n$$\nmax_{P,D}O = max_{P,D}\\{O_p + O_d + \\lambda O_i\\}\n$$\nPDOpOdOi\n\n\n\n#### 3.1 Pattern Module\n\nrK\n\npath-based patternmeta pattern\n\n$\\pi$\n$$\nR(\\pi)=\\frac{|G(\\pi)\\cap S_{pair}|}{|G(\\pi)|}\n$$\n$G(\\pi)$$\\pi$$S_{pair}$seedR$\\pi$seedseed\n$$\nO_p = \\sum_{\\pi \\in P}R(\\pi)\n$$\n\n\n- seed\n- RK\n\n#### 3.2 Distributional Module\n\n\n\new\n$$\nP(w|e) =\\frac{exp(x_e*c_w)}{Z}\n$$\n$x_e$ $c_w$word embeddingZ\n$$\nO_{text} = \\sum_{w,e}n_{w,e}log(P(w|e))\n$$\n$n_{w,e}$\n\n\n$$\nL_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2\n$$\n$(x_{e_h} - x_{e_t})$$y_r$r$L_D$1\n$$\nO_{seed} = \\sum_{f\\in S_{pair}} \\sum_{f'\\in(e'_h,e'_t)} {min\\{1, L_D(f|r) - L_D(f'|r)\\}}\n$$\n$(e'_h,e'_t)$$L_D(f'|r)$\n\nOd\n$$\nO_d = O_{text} + \\eta O_{seed}\n$$\n$\\eta$\n\n#### 3.3 Modeling the Module Interaction\n\n$$\nO_i = E_{f\\in G(P)}[L_D(f|r)]\n$$\n\nE\n\nOiPOiG(P)LD\n\n### 4. The Joint Optimization Problem\n\n![algo](algo.png)\n\n\n\nseed$S_{pair}$$G(P)$Eqn.11\n$$\nmax_D \\{ O_d + \\lambda O_i \\} = max_D \\{ O_d + \\lambda E_{f \\in G(P)}[L_D(f|r)] \\}\n$$\n$S_{pair}$Eqn.12\n$$\nmax_P \\{ O_p + \\lambda O_i \\} = max_P \\{ \\sum_{\\pi \\in P}(R(\\pi) + \\lambda E_{f \\in G(\\pi)}[L_D(f|r)]) \\}\n$$\n\n\n### 5. Conclusion\n\n\n\n## Reference\n\n\\*https://zhuanlan.zhihu.com/p/32364723\n\n[1] Qu, M., Ren, X., Zhang, Y., & Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. *arXiv preprint arXiv:1711.03226*.\n\n[2] Blum, Avrim, and Tom Mitchell. \"Combining labeled and unlabeled data with co-training.\" *Proceedings of the eleventh annual conference on Computational learning theory*. ACM, 1998.\n\n","source":"_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction.md","raw":"---\ntitle: Overcoming Limited Supervision in Relation Extraction \ndate: 2018-01-04 08:00:00\ncategories: [research]\ntags: [relation-extraction, limited-supervision, weak-supervision]\n---\n\nOvercoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach[1]distributional approachpattern-based approach\n\n![illustration](illustration.png)\n\n### 1. Introduction\n\n#### 1.1 Weakly Supervised Learning\n\nseed\n\n\n\n1. \n2. \n3. \n\n#### 1.2 Co-training strategy\n\nco-training[2]\n\nco-training\n\n#### 1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)\n\nREPEL\n\n### 2. Problem definition\n\n\n\n $(e_h, e_t)$$(e_h, e_t, r)$\n\nDRseed$ \\{(e_h^{r(k)}, e_t^{r(k)}, r)\\} _{k=1}^{N_r} $$ \\{(e_h^{r(i)}, e_t^{r(i)}, r)\\} _{i=1}^M $$ r \\in R $$ \\{(e_h^{r(i)}, e_t^{r(i)})\\} _{i=1}^{M_r} $\n\n### 3. REPEL Framework\n\n\n\n\n\n\n$$\nmax_{P,D}O = max_{P,D}\\{O_p + O_d + \\lambda O_i\\}\n$$\nPDOpOdOi\n\n\n\n#### 3.1 Pattern Module\n\nrK\n\npath-based patternmeta pattern\n\n$\\pi$\n$$\nR(\\pi)=\\frac{|G(\\pi)\\cap S_{pair}|}{|G(\\pi)|}\n$$\n$G(\\pi)$$\\pi$$S_{pair}$seedR$\\pi$seedseed\n$$\nO_p = \\sum_{\\pi \\in P}R(\\pi)\n$$\n\n\n- seed\n- RK\n\n#### 3.2 Distributional Module\n\n\n\new\n$$\nP(w|e) =\\frac{exp(x_e*c_w)}{Z}\n$$\n$x_e$ $c_w$word embeddingZ\n$$\nO_{text} = \\sum_{w,e}n_{w,e}log(P(w|e))\n$$\n$n_{w,e}$\n\n\n$$\nL_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2\n$$\n$(x_{e_h} - x_{e_t})$$y_r$r$L_D$1\n$$\nO_{seed} = \\sum_{f\\in S_{pair}} \\sum_{f'\\in(e'_h,e'_t)} {min\\{1, L_D(f|r) - L_D(f'|r)\\}}\n$$\n$(e'_h,e'_t)$$L_D(f'|r)$\n\nOd\n$$\nO_d = O_{text} + \\eta O_{seed}\n$$\n$\\eta$\n\n#### 3.3 Modeling the Module Interaction\n\n$$\nO_i = E_{f\\in G(P)}[L_D(f|r)]\n$$\n\nE\n\nOiPOiG(P)LD\n\n### 4. The Joint Optimization Problem\n\n![algo](algo.png)\n\n\n\nseed$S_{pair}$$G(P)$Eqn.11\n$$\nmax_D \\{ O_d + \\lambda O_i \\} = max_D \\{ O_d + \\lambda E_{f \\in G(P)}[L_D(f|r)] \\}\n$$\n$S_{pair}$Eqn.12\n$$\nmax_P \\{ O_p + \\lambda O_i \\} = max_P \\{ \\sum_{\\pi \\in P}(R(\\pi) + \\lambda E_{f \\in G(\\pi)}[L_D(f|r)]) \\}\n$$\n\n\n### 5. Conclusion\n\n\n\n## Reference\n\n\\*https://zhuanlan.zhihu.com/p/32364723\n\n[1] Qu, M., Ren, X., Zhang, Y., & Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. *arXiv preprint arXiv:1711.03226*.\n\n[2] Blum, Avrim, and Tom Mitchell. \"Combining labeled and unlabeled data with co-training.\" *Proceedings of the eleventh annual conference on Computational learning theory*. ACM, 1998.\n\n","slug":"[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction","published":1,"updated":"2018-01-27T11:14:18.400Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrd0022pzm9qy2f3wli","content":"<p>Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach[1]distributional approachpattern-based approach</p>\n<p><img src=\"illustration.png\" alt=\"illustration\"></p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><h4 id=\"1-1-Weakly-Supervised-Learning\"><a href=\"#1-1-Weakly-Supervised-Learning\" class=\"headerlink\" title=\"1.1 Weakly Supervised Learning\"></a>1.1 Weakly Supervised Learning</h4><p>seed</p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<h4 id=\"1-2-Co-training-strategy\"><a href=\"#1-2-Co-training-strategy\" class=\"headerlink\" title=\"1.2 Co-training strategy\"></a>1.2 Co-training strategy</h4><p>co-training[2]</p>\n<p>co-training</p>\n<h4 id=\"1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding\"><a href=\"#1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding\" class=\"headerlink\" title=\"1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)\"></a>1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)</h4><p>REPEL</p>\n<h3 id=\"2-Problem-definition\"><a href=\"#2-Problem-definition\" class=\"headerlink\" title=\"2. Problem definition\"></a>2. Problem definition</h3><p></p>\n<p> $(e_h, e_t)$$(e_h, e_t, r)$</p>\n<p>DRseed$ {(e<em>h^{r(k)}, e_t^{r(k)}, r)} </em>{k=1}^{N<em>r} $$ {(e_h^{r(i)}, e_t^{r(i)}, r)} </em>{i=1}^M $$ r \\in R $$ {(e<em>h^{r(i)}, e_t^{r(i)})} </em>{i=1}^{M_r} $</p>\n<h3 id=\"3-REPEL-Framework\"><a href=\"#3-REPEL-Framework\" class=\"headerlink\" title=\"3. REPEL Framework\"></a>3. REPEL Framework</h3><p></p>\n<p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nmax_{P,D}O = max_{P,D}\\{O_p + O_d + \\lambda O_i\\}</script><p>PDOpOdOi</p>\n<p></p>\n<h4 id=\"3-1-Pattern-Module\"><a href=\"#3-1-Pattern-Module\" class=\"headerlink\" title=\"3.1 Pattern Module\"></a>3.1 Pattern Module</h4><p>rK</p>\n<p>path-based patternmeta pattern</p>\n<p>$\\pi$</p>\n<script type=\"math/tex; mode=display\">\nR(\\pi)=\\frac{|G(\\pi)\\cap S_{pair}|}{|G(\\pi)|}</script><p>$G(\\pi)$$\\pi$$S_{pair}$seedR$\\pi$seedseed</p>\n<script type=\"math/tex; mode=display\">\nO_p = \\sum_{\\pi \\in P}R(\\pi)</script><p></p>\n<ul>\n<li>seed</li>\n<li>RK</li>\n</ul>\n<h4 id=\"3-2-Distributional-Module\"><a href=\"#3-2-Distributional-Module\" class=\"headerlink\" title=\"3.2 Distributional Module\"></a>3.2 Distributional Module</h4><p></p>\n<p>ew</p>\n<script type=\"math/tex; mode=display\">\nP(w|e) =\\frac{exp(x_e*c_w)}{Z}</script><p>$x_e$ $c_w$word embeddingZ</p>\n<script type=\"math/tex; mode=display\">\nO_{text} = \\sum_{w,e}n_{w,e}log(P(w|e))</script><p>$n_{w,e}$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nL_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2</script><p>$(x<em>{e_h} - x</em>{e_t})$$y_r$r$L_D$1</p>\n<script type=\"math/tex; mode=display\">\nO_{seed} = \\sum_{f\\in S_{pair}} \\sum_{f'\\in(e'_h,e'_t)} {min\\{1, L_D(f|r) - L_D(f'|r)\\}}</script><p>$(e_h,e_t)$$L_D(f|r)$</p>\n<p>Od</p>\n<script type=\"math/tex; mode=display\">\nO_d = O_{text} + \\eta O_{seed}</script><p>$\\eta$</p>\n<h4 id=\"3-3-Modeling-the-Module-Interaction\"><a href=\"#3-3-Modeling-the-Module-Interaction\" class=\"headerlink\" title=\"3.3 Modeling the Module Interaction\"></a>3.3 Modeling the Module Interaction</h4><script type=\"math/tex; mode=display\">\nO_i = E_{f\\in G(P)}[L_D(f|r)]</script><p>E</p>\n<p>OiPOiG(P)LD</p>\n<h3 id=\"4-The-Joint-Optimization-Problem\"><a href=\"#4-The-Joint-Optimization-Problem\" class=\"headerlink\" title=\"4. The Joint Optimization Problem\"></a>4. The Joint Optimization Problem</h3><p><img src=\"algo.png\" alt=\"algo\"></p>\n<p></p>\n<p>seed$S_{pair}$$G(P)$Eqn.11</p>\n<script type=\"math/tex; mode=display\">\nmax_D \\{ O_d + \\lambda O_i \\} = max_D \\{ O_d + \\lambda E_{f \\in G(P)}[L_D(f|r)] \\}</script><p>$S_{pair}$Eqn.12</p>\n<script type=\"math/tex; mode=display\">\nmax_P \\{ O_p + \\lambda O_i \\} = max_P \\{ \\sum_{\\pi \\in P}(R(\\pi) + \\lambda E_{f \\in G(\\pi)}[L_D(f|r)]) \\}</script><p></p>\n<h3 id=\"5-Conclusion\"><a href=\"#5-Conclusion\" class=\"headerlink\" title=\"5. Conclusion\"></a>5. Conclusion</h3><p></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>*<a href=\"https://zhuanlan.zhihu.com/p/32364723\" target=\"_blank\" rel=\"external\">https://zhuanlan.zhihu.com/p/32364723</a></p>\n<p>[1] Qu, M., Ren, X., Zhang, Y., &amp; Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. <em>arXiv preprint arXiv:1711.03226</em>.</p>\n<p>[2] Blum, Avrim, and Tom Mitchell. Combining labeled and unlabeled data with co-training. <em>Proceedings of the eleventh annual conference on Computational learning theory</em>. ACM, 1998.</p>\n","excerpt":"","more":"<p>Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach[1]distributional approachpattern-based approach</p>\n<p><img src=\"illustration.png\" alt=\"illustration\"></p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><h4 id=\"1-1-Weakly-Supervised-Learning\"><a href=\"#1-1-Weakly-Supervised-Learning\" class=\"headerlink\" title=\"1.1 Weakly Supervised Learning\"></a>1.1 Weakly Supervised Learning</h4><p>seed</p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<h4 id=\"1-2-Co-training-strategy\"><a href=\"#1-2-Co-training-strategy\" class=\"headerlink\" title=\"1.2 Co-training strategy\"></a>1.2 Co-training strategy</h4><p>co-training[2]</p>\n<p>co-training</p>\n<h4 id=\"1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding\"><a href=\"#1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding\" class=\"headerlink\" title=\"1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)\"></a>1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)</h4><p>REPEL</p>\n<h3 id=\"2-Problem-definition\"><a href=\"#2-Problem-definition\" class=\"headerlink\" title=\"2. Problem definition\"></a>2. Problem definition</h3><p></p>\n<p> $(e_h, e_t)$$(e_h, e_t, r)$</p>\n<p>DRseed$ {(e<em>h^{r(k)}, e_t^{r(k)}, r)} </em>{k=1}^{N<em>r} $$ {(e_h^{r(i)}, e_t^{r(i)}, r)} </em>{i=1}^M $$ r \\in R $$ {(e<em>h^{r(i)}, e_t^{r(i)})} </em>{i=1}^{M_r} $</p>\n<h3 id=\"3-REPEL-Framework\"><a href=\"#3-REPEL-Framework\" class=\"headerlink\" title=\"3. REPEL Framework\"></a>3. REPEL Framework</h3><p></p>\n<p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nmax_{P,D}O = max_{P,D}\\{O_p + O_d + \\lambda O_i\\}</script><p>PDOpOdOi</p>\n<p></p>\n<h4 id=\"3-1-Pattern-Module\"><a href=\"#3-1-Pattern-Module\" class=\"headerlink\" title=\"3.1 Pattern Module\"></a>3.1 Pattern Module</h4><p>rK</p>\n<p>path-based patternmeta pattern</p>\n<p>$\\pi$</p>\n<script type=\"math/tex; mode=display\">\nR(\\pi)=\\frac{|G(\\pi)\\cap S_{pair}|}{|G(\\pi)|}</script><p>$G(\\pi)$$\\pi$$S_{pair}$seedR$\\pi$seedseed</p>\n<script type=\"math/tex; mode=display\">\nO_p = \\sum_{\\pi \\in P}R(\\pi)</script><p></p>\n<ul>\n<li>seed</li>\n<li>RK</li>\n</ul>\n<h4 id=\"3-2-Distributional-Module\"><a href=\"#3-2-Distributional-Module\" class=\"headerlink\" title=\"3.2 Distributional Module\"></a>3.2 Distributional Module</h4><p></p>\n<p>ew</p>\n<script type=\"math/tex; mode=display\">\nP(w|e) =\\frac{exp(x_e*c_w)}{Z}</script><p>$x_e$ $c_w$word embeddingZ</p>\n<script type=\"math/tex; mode=display\">\nO_{text} = \\sum_{w,e}n_{w,e}log(P(w|e))</script><p>$n_{w,e}$</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nL_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2</script><p>$(x<em>{e_h} - x</em>{e_t})$$y_r$r$L_D$1</p>\n<script type=\"math/tex; mode=display\">\nO_{seed} = \\sum_{f\\in S_{pair}} \\sum_{f'\\in(e'_h,e'_t)} {min\\{1, L_D(f|r) - L_D(f'|r)\\}}</script><p>$(e_h,e_t)$$L_D(f|r)$</p>\n<p>Od</p>\n<script type=\"math/tex; mode=display\">\nO_d = O_{text} + \\eta O_{seed}</script><p>$\\eta$</p>\n<h4 id=\"3-3-Modeling-the-Module-Interaction\"><a href=\"#3-3-Modeling-the-Module-Interaction\" class=\"headerlink\" title=\"3.3 Modeling the Module Interaction\"></a>3.3 Modeling the Module Interaction</h4><script type=\"math/tex; mode=display\">\nO_i = E_{f\\in G(P)}[L_D(f|r)]</script><p>E</p>\n<p>OiPOiG(P)LD</p>\n<h3 id=\"4-The-Joint-Optimization-Problem\"><a href=\"#4-The-Joint-Optimization-Problem\" class=\"headerlink\" title=\"4. The Joint Optimization Problem\"></a>4. The Joint Optimization Problem</h3><p><img src=\"algo.png\" alt=\"algo\"></p>\n<p></p>\n<p>seed$S_{pair}$$G(P)$Eqn.11</p>\n<script type=\"math/tex; mode=display\">\nmax_D \\{ O_d + \\lambda O_i \\} = max_D \\{ O_d + \\lambda E_{f \\in G(P)}[L_D(f|r)] \\}</script><p>$S_{pair}$Eqn.12</p>\n<script type=\"math/tex; mode=display\">\nmax_P \\{ O_p + \\lambda O_i \\} = max_P \\{ \\sum_{\\pi \\in P}(R(\\pi) + \\lambda E_{f \\in G(\\pi)}[L_D(f|r)]) \\}</script><p></p>\n<h3 id=\"5-Conclusion\"><a href=\"#5-Conclusion\" class=\"headerlink\" title=\"5. Conclusion\"></a>5. Conclusion</h3><p></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>*<a href=\"https://zhuanlan.zhihu.com/p/32364723\">https://zhuanlan.zhihu.com/p/32364723</a></p>\n<p>[1] Qu, M., Ren, X., Zhang, Y., &amp; Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. <em>arXiv preprint arXiv:1711.03226</em>.</p>\n<p>[2] Blum, Avrim, and Tom Mitchell. Combining labeled and unlabeled data with co-training. <em>Proceedings of the eleventh annual conference on Computational learning theory</em>. ACM, 1998.</p>\n"},{"title":"Open-World Knowledge Graph Completion ","date":"2018-02-26T07:00:00.000Z","_content":"\n## Open-World Knowledge Graph Completion\n\n****\\[1\\]Closed-World KGC KG KG Open-World KGC  KGConMaskattention\n\n### 1. Introduction\n\nKG $(h,r,t)$ h: head entity, t: tail entity, r: relationKG DBPediaConceptNet KGWikipediaDBPedia4605\n\nKnowledge Graph Completion (KGC)\n\n#### Closed-World KGC\n\nKG $G=(E,R,T)$  $E,R,T$ Closed-World KGC $ T' = \\{ <h,r,t>|h \\in E, r \\in R, t \\in E, <h,r,t> \\notin T \\}$  $G$.\n\nClosed-World KGC  $G$  $G$ \n\nClosed-World KGCTranE $h+r=t$  Embedding \n\nKGKG\n\n#### Open-World KGC\n\nKG $G=(E,R,T)$  $E,R,T$ Open-World KGC  ![G](https://www.zhihu.com/equation?tex=G) $T' =\\{<h,r,t>|h\\in E^i,r\\in R, t\\in E^i,<h,r,t>\\notin T\\}$  $E^i$ G\n\nClosed-Worldembedding\n\nentity description\n\n1. Closed-world KGCembedding ()Open-World KGCword embeddingentity embeddingword embeddingentities\n2. Open-World KGC\n\n### 2. Closed-World KGC \n\n Closed-World KGC (RL)TransE \\[2\\]. \n$$\nh+r = t\n$$\nhhead entityttail entityr\n\nTransEloss function\n$$\n\\mathcal{L(T)} = \\sum_{<h,r,t>\\in T} [\\gamma + E(<h,r,t>) - E(<h',r',t'>)]_+\n$$\n $T$ $E(<h,r,t>) = ||h+r-t||_{L_n}$energy function$<h,r,t>$G$<h',r',t'>$ $T$ $<h,r,t>$\n\nTransEClosed-World KGC\n\n### 3. ConMask for Open-World KGC\n\n\n\n****\\<Ameen Sayani, residence, ? \\>KGAmeen Sayani\n\n****\"... **Ameen Sayani** was introduced to All India Radio, **Bombay**, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years ...\" \n\n****Bombay (or Mumbai)\n\nAmeen SayaniAmeen SayaniAll India RadioBombayAmeen SayaniBombayBombayMumbai\n\n\n\n1. \n2. \n3. \n\nConMask\n\n1. **Relationship-dependent content masking** -- \n2. **Target fusion** -- embedding\n3. **Target entity resolution** -- KG2embedding\n\n<img src=\"illustration.png\" width=\"60%\">\n\nConMaskConMaskConMaskFCNword-embeddingembeddingKG\n\n#### 3.1 Relationship-dependent content masking \n\nConMaskcontent-maskingattentionRNN\\[3\\]attention\n\n\n$$\n\\tau(\\phi(e), \\psi(r)) = W_{\\phi(e)} \\circ f_w(W_{\\phi(e)}, W_{\\psi(r)})\n$$\n $e$ $r$ , $\\phi$ description function$\\psi$ name mapping function $W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding $W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding$\\circ$ row-wise product$f_w$ \n\n$f_w$ Maximal Word-Relationship Weights(MWRW)cos:\n$$\nf_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max_j(\\frac{\\sum_m^k{W_{\\phi(e)[i,m]} W_{\\psi(r)[j,m]}}}{\\sqrt{\\sum_m^k{W^2_{\\phi(e)[i,m]}}}\\sqrt{\\sum_m^k{W^2_{\\psi(e)[j,m]}}}})\n$$\nspousemarriedmarriedspouseMWRWindicator wordbarack obamamarried\n\nword $k_m$  Maximal Context-Relationship Weights (MCRW)\n$$\nf_w^{MCRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max(f_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i-k_m:i]})\n$$\n<img src=\"MWRW.png\">\n\n#### 3.2 Target Fusion\n\nembedding$\\xi$Conetent Masking $\\tau$ \n\n<img src=\"arch.png\">\n\n**Semantic Averaging**\n\nembeddingTarget fusiontarget fusion\n\nembedding$\\eta(W) = \\frac{1}{k_l}\\sum_i^{k_i}W_i$\n\n#### 3.3 Loss function\n\n list-wise ranking loss function (Shi and Weninger 2017) partial list-wise ranking loss function$E^+$head entitytail entity$E^-$ \n$$\n\\mathcal{L}(h, r, t) =  \\begin{cases}\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h_+,r,t,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c > 0.5; \\\\\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h,r,t_+,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c \\le 0.5; .\n\\end{cases}\n$$\n$p_c$ $[0,1]$0.5tail entity0.5head entityhead entitytail entity50%$S$,  softmax normalized output of ConMask\n$$\nS(h,r,t,E^+) = \\begin{cases}\n\\sum_{e \\in E^\\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} & \\text{if } p_c > 0.5 \\\\\n\\sum_{e \\in E^\\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} & \\text{if } p_c \\le 0.5 \\\\\n\\end{cases}\n$$\n\n### 4. Results\n\nConMaskClosed-WorldConMaskTransETransR\n\nConMask\n\n## Bibliographies\n\nhttps://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178\n\nhttps://github.com/bxshi/ConMask\n\n\\[1\\] Shi, Baoxu, and Tim Weninger. \"Open-World Knowledge Graph Completion.\" *arXiv preprint arXiv:1711.03438* (2017).\n\n\\[2\\] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In *Advances in neural information processing systems* (pp. 2787-2795).\n\n\\[3\\] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., & Bengio, Y. (2015). Attention-based models for speech recognition. In *Advances in neural information processing systems* (pp. 577-585).","source":"_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion.md","raw":"---\ntitle: Open-World Knowledge Graph Completion \ndate: 2018-02-26 08:00:00\ncategories: [research]\ntags: [KGC, CNN, knowledge-graph]\n---\n\n## Open-World Knowledge Graph Completion\n\n****\\[1\\]Closed-World KGC KG KG Open-World KGC  KGConMaskattention\n\n### 1. Introduction\n\nKG $(h,r,t)$ h: head entity, t: tail entity, r: relationKG DBPediaConceptNet KGWikipediaDBPedia4605\n\nKnowledge Graph Completion (KGC)\n\n#### Closed-World KGC\n\nKG $G=(E,R,T)$  $E,R,T$ Closed-World KGC $ T' = \\{ <h,r,t>|h \\in E, r \\in R, t \\in E, <h,r,t> \\notin T \\}$  $G$.\n\nClosed-World KGC  $G$  $G$ \n\nClosed-World KGCTranE $h+r=t$  Embedding \n\nKGKG\n\n#### Open-World KGC\n\nKG $G=(E,R,T)$  $E,R,T$ Open-World KGC  ![G](https://www.zhihu.com/equation?tex=G) $T' =\\{<h,r,t>|h\\in E^i,r\\in R, t\\in E^i,<h,r,t>\\notin T\\}$  $E^i$ G\n\nClosed-Worldembedding\n\nentity description\n\n1. Closed-world KGCembedding ()Open-World KGCword embeddingentity embeddingword embeddingentities\n2. Open-World KGC\n\n### 2. Closed-World KGC \n\n Closed-World KGC (RL)TransE \\[2\\]. \n$$\nh+r = t\n$$\nhhead entityttail entityr\n\nTransEloss function\n$$\n\\mathcal{L(T)} = \\sum_{<h,r,t>\\in T} [\\gamma + E(<h,r,t>) - E(<h',r',t'>)]_+\n$$\n $T$ $E(<h,r,t>) = ||h+r-t||_{L_n}$energy function$<h,r,t>$G$<h',r',t'>$ $T$ $<h,r,t>$\n\nTransEClosed-World KGC\n\n### 3. ConMask for Open-World KGC\n\n\n\n****\\<Ameen Sayani, residence, ? \\>KGAmeen Sayani\n\n****\"... **Ameen Sayani** was introduced to All India Radio, **Bombay**, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years ...\" \n\n****Bombay (or Mumbai)\n\nAmeen SayaniAmeen SayaniAll India RadioBombayAmeen SayaniBombayBombayMumbai\n\n\n\n1. \n2. \n3. \n\nConMask\n\n1. **Relationship-dependent content masking** -- \n2. **Target fusion** -- embedding\n3. **Target entity resolution** -- KG2embedding\n\n<img src=\"illustration.png\" width=\"60%\">\n\nConMaskConMaskConMaskFCNword-embeddingembeddingKG\n\n#### 3.1 Relationship-dependent content masking \n\nConMaskcontent-maskingattentionRNN\\[3\\]attention\n\n\n$$\n\\tau(\\phi(e), \\psi(r)) = W_{\\phi(e)} \\circ f_w(W_{\\phi(e)}, W_{\\psi(r)})\n$$\n $e$ $r$ , $\\phi$ description function$\\psi$ name mapping function $W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding $W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding$\\circ$ row-wise product$f_w$ \n\n$f_w$ Maximal Word-Relationship Weights(MWRW)cos:\n$$\nf_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max_j(\\frac{\\sum_m^k{W_{\\phi(e)[i,m]} W_{\\psi(r)[j,m]}}}{\\sqrt{\\sum_m^k{W^2_{\\phi(e)[i,m]}}}\\sqrt{\\sum_m^k{W^2_{\\psi(e)[j,m]}}}})\n$$\nspousemarriedmarriedspouseMWRWindicator wordbarack obamamarried\n\nword $k_m$  Maximal Context-Relationship Weights (MCRW)\n$$\nf_w^{MCRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max(f_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i-k_m:i]})\n$$\n<img src=\"MWRW.png\">\n\n#### 3.2 Target Fusion\n\nembedding$\\xi$Conetent Masking $\\tau$ \n\n<img src=\"arch.png\">\n\n**Semantic Averaging**\n\nembeddingTarget fusiontarget fusion\n\nembedding$\\eta(W) = \\frac{1}{k_l}\\sum_i^{k_i}W_i$\n\n#### 3.3 Loss function\n\n list-wise ranking loss function (Shi and Weninger 2017) partial list-wise ranking loss function$E^+$head entitytail entity$E^-$ \n$$\n\\mathcal{L}(h, r, t) =  \\begin{cases}\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h_+,r,t,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c > 0.5; \\\\\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h,r,t_+,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c \\le 0.5; .\n\\end{cases}\n$$\n$p_c$ $[0,1]$0.5tail entity0.5head entityhead entitytail entity50%$S$,  softmax normalized output of ConMask\n$$\nS(h,r,t,E^+) = \\begin{cases}\n\\sum_{e \\in E^\\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} & \\text{if } p_c > 0.5 \\\\\n\\sum_{e \\in E^\\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} & \\text{if } p_c \\le 0.5 \\\\\n\\end{cases}\n$$\n\n### 4. Results\n\nConMaskClosed-WorldConMaskTransETransR\n\nConMask\n\n## Bibliographies\n\nhttps://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178\n\nhttps://github.com/bxshi/ConMask\n\n\\[1\\] Shi, Baoxu, and Tim Weninger. \"Open-World Knowledge Graph Completion.\" *arXiv preprint arXiv:1711.03438* (2017).\n\n\\[2\\] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In *Advances in neural information processing systems* (pp. 2787-2795).\n\n\\[3\\] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., & Bengio, Y. (2015). Attention-based models for speech recognition. In *Advances in neural information processing systems* (pp. 577-585).","slug":"[2018.2.26]Open-World-Knowledge-Graph-Completion","published":1,"updated":"2018-03-03T20:21:16.156Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvre0026pzm9e01tr9vh","content":"<h2 id=\"Open-World-Knowledge-Graph-Completion\"><a href=\"#Open-World-Knowledge-Graph-Completion\" class=\"headerlink\" title=\"Open-World Knowledge Graph Completion\"></a>Open-World Knowledge Graph Completion</h2><p><strong></strong>[1]Closed-World KGC KG KG Open-World KGC  KGConMaskattention</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>KG $(h,r,t)$ h: head entity, t: tail entity, r: relationKG DBPediaConceptNet KGWikipediaDBPedia4605</p>\n<p>Knowledge Graph Completion (KGC)</p>\n<h4 id=\"Closed-World-KGC\"><a href=\"#Closed-World-KGC\" class=\"headerlink\" title=\"Closed-World KGC\"></a>Closed-World KGC</h4><p>KG $G=(E,R,T)$  $E,R,T$ Closed-World KGC $ T = { <h,r,t>|h \\in E, r \\in R, t \\in E, <h,r,t> \\notin T }$  $G$.</h,r,t></h,r,t></p>\n<p>Closed-World KGC  $G$  $G$ </p>\n<p>Closed-World KGCTranE $h+r=t$  Embedding </p>\n<p>KGKG</p>\n<h4 id=\"Open-World-KGC\"><a href=\"#Open-World-KGC\" class=\"headerlink\" title=\"Open-World KGC\"></a>Open-World KGC</h4><p>KG $G=(E,R,T)$  $E,R,T$ Open-World KGC  <img src=\"https://www.zhihu.com/equation?tex=G\" alt=\"G\"> $T ={<h,r,t>|h\\in E^i,r\\in R, t\\in E^i,<h,r,t>\\notin T}$  $E^i$ G</h,r,t></h,r,t></p>\n<p>Closed-Worldembedding</p>\n<p>entity description</p>\n<ol>\n<li>Closed-world KGCembedding ()Open-World KGCword embeddingentity embeddingword embeddingentities</li>\n<li>Open-World KGC</li>\n</ol>\n<h3 id=\"2-Closed-World-KGC\"><a href=\"#2-Closed-World-KGC\" class=\"headerlink\" title=\"2. Closed-World KGC\"></a>2. Closed-World KGC</h3><p> Closed-World KGC (RL)TransE [2]. </p>\n<script type=\"math/tex; mode=display\">\nh+r = t</script><p>hhead entityttail entityr</p>\n<p>TransEloss function</p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{L(T)} = \\sum_{<h,r,t>\\in T} [\\gamma + E(<h,r,t>) - E(<h',r',t'>)]_+</script><p> $T$ $E(<h,r,t>) = ||h+r-t||_{L_n}$energy function$<h,r,t>$G$&lt;h,r,t&gt;$ $T$ $<h,r,t>$</h,r,t></h,r,t></h,r,t></p>\n<p>TransEClosed-World KGC</p>\n<h3 id=\"3-ConMask-for-Open-World-KGC\"><a href=\"#3-ConMask-for-Open-World-KGC\" class=\"headerlink\" title=\"3. ConMask for Open-World KGC\"></a>3. ConMask for Open-World KGC</h3><p></p>\n<p><strong></strong>\\<ameen sayani,=\"\" residence,=\"\" ?=\"\" \\=\"\">KGAmeen Sayani</ameen></p>\n<p><strong></strong> <strong>Ameen Sayani</strong> was introduced to All India Radio, <strong>Bombay</strong>, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years  </p>\n<p><strong></strong>Bombay (or Mumbai)</p>\n<p>Ameen SayaniAmeen SayaniAll India RadioBombayAmeen SayaniBombayBombayMumbai</p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<p>ConMask</p>\n<ol>\n<li><strong>Relationship-dependent content masking</strong>  </li>\n<li><strong>Target fusion</strong>  embedding</li>\n<li><strong>Target entity resolution</strong>  KG2embedding</li>\n</ol>\n<p><img src=\"illustration.png\" width=\"60%\"></p>\n<p>ConMaskConMaskConMaskFCNword-embeddingembeddingKG</p>\n<h4 id=\"3-1-Relationship-dependent-content-masking\"><a href=\"#3-1-Relationship-dependent-content-masking\" class=\"headerlink\" title=\"3.1 Relationship-dependent content masking\"></a>3.1 Relationship-dependent content masking</h4><p>ConMaskcontent-maskingattentionRNN[3]attention</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\tau(\\phi(e), \\psi(r)) = W_{\\phi(e)} \\circ f_w(W_{\\phi(e)}, W_{\\psi(r)})</script><p> $e$ $r$ , $\\phi$ description function$\\psi$ name mapping function $W<em>{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding $W</em>{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding$\\circ$ row-wise product$f_w$ </p>\n<p>$f_w$ Maximal Word-Relationship Weights(MWRW)cos:</p>\n<script type=\"math/tex; mode=display\">\nf_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max_j(\\frac{\\sum_m^k{W_{\\phi(e)[i,m]} W_{\\psi(r)[j,m]}}}{\\sqrt{\\sum_m^k{W^2_{\\phi(e)[i,m]}}}\\sqrt{\\sum_m^k{W^2_{\\psi(e)[j,m]}}}})</script><p>spousemarriedmarriedspouseMWRWindicator wordbarack obamamarried</p>\n<p>word $k_m$  Maximal Context-Relationship Weights (MCRW)</p>\n<script type=\"math/tex; mode=display\">\nf_w^{MCRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max(f_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i-k_m:i]})</script><p><img src=\"MWRW.png\"></p>\n<h4 id=\"3-2-Target-Fusion\"><a href=\"#3-2-Target-Fusion\" class=\"headerlink\" title=\"3.2 Target Fusion\"></a>3.2 Target Fusion</h4><p>embedding$\\xi$Conetent Masking $\\tau$ </p>\n<p><img src=\"arch.png\"></p>\n<p><strong>Semantic Averaging</strong></p>\n<p>embeddingTarget fusiontarget fusion</p>\n<p>embedding$\\eta(W) = \\frac{1}{k_l}\\sum_i^{k_i}W_i$</p>\n<h4 id=\"3-3-Loss-function\"><a href=\"#3-3-Loss-function\" class=\"headerlink\" title=\"3.3 Loss function\"></a>3.3 Loss function</h4><p> list-wise ranking loss function (Shi and Weninger 2017) partial list-wise ranking loss function$E^+$head entitytail entity$E^-$ </p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{L}(h, r, t) =  \\begin{cases}\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h_+,r,t,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c > 0.5; \\\\\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h,r,t_+,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c \\le 0.5; .\n\\end{cases}</script><p>$p_c$ $[0,1]$0.5tail entity0.5head entityhead entitytail entity50%$S$,  softmax normalized output of ConMask</p>\n<script type=\"math/tex; mode=display\">\nS(h,r,t,E^+) = \\begin{cases}\n\\sum_{e \\in E^\\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} & \\text{if } p_c > 0.5 \\\\\n\\sum_{e \\in E^\\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} & \\text{if } p_c \\le 0.5 \\\\\n\\end{cases}</script><h3 id=\"4-Results\"><a href=\"#4-Results\" class=\"headerlink\" title=\"4. Results\"></a>4. Results</h3><p>ConMaskClosed-WorldConMaskTransETransR</p>\n<p>ConMask</p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p><a href=\"https://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178\" target=\"_blank\" rel=\"external\">https://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178</a></p>\n<p><a href=\"https://github.com/bxshi/ConMask\" target=\"_blank\" rel=\"external\">https://github.com/bxshi/ConMask</a></p>\n<p>[1] Shi, Baoxu, and Tim Weninger. Open-World Knowledge Graph Completion. <em>arXiv preprint arXiv:1711.03438</em> (2017).</p>\n<p>[2] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).</p>\n<p>[3] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., &amp; Bengio, Y. (2015). Attention-based models for speech recognition. In <em>Advances in neural information processing systems</em> (pp. 577-585).</p>\n","excerpt":"","more":"<h2 id=\"Open-World-Knowledge-Graph-Completion\"><a href=\"#Open-World-Knowledge-Graph-Completion\" class=\"headerlink\" title=\"Open-World Knowledge Graph Completion\"></a>Open-World Knowledge Graph Completion</h2><p><strong></strong>[1]Closed-World KGC KG KG Open-World KGC  KGConMaskattention</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>KG $(h,r,t)$ h: head entity, t: tail entity, r: relationKG DBPediaConceptNet KGWikipediaDBPedia4605</p>\n<p>Knowledge Graph Completion (KGC)</p>\n<h4 id=\"Closed-World-KGC\"><a href=\"#Closed-World-KGC\" class=\"headerlink\" title=\"Closed-World KGC\"></a>Closed-World KGC</h4><p>KG $G=(E,R,T)$  $E,R,T$ Closed-World KGC $ T = { <h,r,t>|h \\in E, r \\in R, t \\in E, <h,r,t> \\notin T }$  $G$.</p>\n<p>Closed-World KGC  $G$  $G$ </p>\n<p>Closed-World KGCTranE $h+r=t$  Embedding </p>\n<p>KGKG</p>\n<h4 id=\"Open-World-KGC\"><a href=\"#Open-World-KGC\" class=\"headerlink\" title=\"Open-World KGC\"></a>Open-World KGC</h4><p>KG $G=(E,R,T)$  $E,R,T$ Open-World KGC  <img src=\"https://www.zhihu.com/equation?tex=G\" alt=\"G\"> $T ={<h,r,t>|h\\in E^i,r\\in R, t\\in E^i,<h,r,t>\\notin T}$  $E^i$ G</p>\n<p>Closed-Worldembedding</p>\n<p>entity description</p>\n<ol>\n<li>Closed-world KGCembedding ()Open-World KGCword embeddingentity embeddingword embeddingentities</li>\n<li>Open-World KGC</li>\n</ol>\n<h3 id=\"2-Closed-World-KGC\"><a href=\"#2-Closed-World-KGC\" class=\"headerlink\" title=\"2. Closed-World KGC\"></a>2. Closed-World KGC</h3><p> Closed-World KGC (RL)TransE [2]. </p>\n<script type=\"math/tex; mode=display\">\nh+r = t</script><p>hhead entityttail entityr</p>\n<p>TransEloss function</p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{L(T)} = \\sum_{<h,r,t>\\in T} [\\gamma + E(<h,r,t>) - E(<h',r',t'>)]_+</script><p> $T$ $E(<h,r,t>) = ||h+r-t||_{L_n}$energy function$<h,r,t>$G$&lt;h,r,t&gt;$ $T$ $<h,r,t>$</p>\n<p>TransEClosed-World KGC</p>\n<h3 id=\"3-ConMask-for-Open-World-KGC\"><a href=\"#3-ConMask-for-Open-World-KGC\" class=\"headerlink\" title=\"3. ConMask for Open-World KGC\"></a>3. ConMask for Open-World KGC</h3><p></p>\n<p><strong></strong>\\<Ameen Sayani, residence, ? \\>KGAmeen Sayani</p>\n<p><strong></strong> <strong>Ameen Sayani</strong> was introduced to All India Radio, <strong>Bombay</strong>, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years  </p>\n<p><strong></strong>Bombay (or Mumbai)</p>\n<p>Ameen SayaniAmeen SayaniAll India RadioBombayAmeen SayaniBombayBombayMumbai</p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<p>ConMask</p>\n<ol>\n<li><strong>Relationship-dependent content masking</strong>  </li>\n<li><strong>Target fusion</strong>  embedding</li>\n<li><strong>Target entity resolution</strong>  KG2embedding</li>\n</ol>\n<p><img src=\"illustration.png\" width=\"60%\"></p>\n<p>ConMaskConMaskConMaskFCNword-embeddingembeddingKG</p>\n<h4 id=\"3-1-Relationship-dependent-content-masking\"><a href=\"#3-1-Relationship-dependent-content-masking\" class=\"headerlink\" title=\"3.1 Relationship-dependent content masking\"></a>3.1 Relationship-dependent content masking</h4><p>ConMaskcontent-maskingattentionRNN[3]attention</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\tau(\\phi(e), \\psi(r)) = W_{\\phi(e)} \\circ f_w(W_{\\phi(e)}, W_{\\psi(r)})</script><p> $e$ $r$ , $\\phi$ description function$\\psi$ name mapping function $W<em>{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding $W</em>{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding$\\circ$ row-wise product$f_w$ </p>\n<p>$f_w$ Maximal Word-Relationship Weights(MWRW)cos:</p>\n<script type=\"math/tex; mode=display\">\nf_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max_j(\\frac{\\sum_m^k{W_{\\phi(e)[i,m]} W_{\\psi(r)[j,m]}}}{\\sqrt{\\sum_m^k{W^2_{\\phi(e)[i,m]}}}\\sqrt{\\sum_m^k{W^2_{\\psi(e)[j,m]}}}})</script><p>spousemarriedmarriedspouseMWRWindicator wordbarack obamamarried</p>\n<p>word $k_m$  Maximal Context-Relationship Weights (MCRW)</p>\n<script type=\"math/tex; mode=display\">\nf_w^{MCRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max(f_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i-k_m:i]})</script><p><img src=\"MWRW.png\"></p>\n<h4 id=\"3-2-Target-Fusion\"><a href=\"#3-2-Target-Fusion\" class=\"headerlink\" title=\"3.2 Target Fusion\"></a>3.2 Target Fusion</h4><p>embedding$\\xi$Conetent Masking $\\tau$ </p>\n<p><img src=\"arch.png\"></p>\n<p><strong>Semantic Averaging</strong></p>\n<p>embeddingTarget fusiontarget fusion</p>\n<p>embedding$\\eta(W) = \\frac{1}{k_l}\\sum_i^{k_i}W_i$</p>\n<h4 id=\"3-3-Loss-function\"><a href=\"#3-3-Loss-function\" class=\"headerlink\" title=\"3.3 Loss function\"></a>3.3 Loss function</h4><p> list-wise ranking loss function (Shi and Weninger 2017) partial list-wise ranking loss function$E^+$head entitytail entity$E^-$ </p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{L}(h, r, t) =  \\begin{cases}\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h_+,r,t,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c > 0.5; \\\\\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h,r,t_+,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c \\le 0.5; .\n\\end{cases}</script><p>$p_c$ $[0,1]$0.5tail entity0.5head entityhead entitytail entity50%$S$,  softmax normalized output of ConMask</p>\n<script type=\"math/tex; mode=display\">\nS(h,r,t,E^+) = \\begin{cases}\n\\sum_{e \\in E^\\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} & \\text{if } p_c > 0.5 \\\\\n\\sum_{e \\in E^\\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} & \\text{if } p_c \\le 0.5 \\\\\n\\end{cases}</script><h3 id=\"4-Results\"><a href=\"#4-Results\" class=\"headerlink\" title=\"4. Results\"></a>4. Results</h3><p>ConMaskClosed-WorldConMaskTransETransR</p>\n<p>ConMask</p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p><a href=\"https://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178\">https://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178</a></p>\n<p><a href=\"https://github.com/bxshi/ConMask\">https://github.com/bxshi/ConMask</a></p>\n<p>[1] Shi, Baoxu, and Tim Weninger. Open-World Knowledge Graph Completion. <em>arXiv preprint arXiv:1711.03438</em> (2017).</p>\n<p>[2] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).</p>\n<p>[3] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., &amp; Bengio, Y. (2015). Attention-based models for speech recognition. In <em>Advances in neural information processing systems</em> (pp. 577-585).</p>\n"},{"title":"Nested LSTMs ","date":"2018-02-05T07:00:00.000Z","_content":"\n## Nested LSTMs\n\n**** Nested LSTMs LSTMLSTMRNNNested LSTMLSTMNLSTMLSTMLSTMNLSTM$c_t^{outer} = f_t \\odot c_{t-1} + i_t \\odot g_t$ $(f_t \\odot c_{t-1}, i_t \\odot g_t)$ LSTMNLSTM $c_t^{outer} = h_t^{inner}$Nested LSTM  LSTM NLSTM  LSTMNested LSTM  LSTM\n\n### 1. Introduction\n\nnlp\n\n#### single-layer LSTM\n\n<img src=\"singleLSTM.png\" width=\"90%\">\n\nRNNHochreiter1991Bengio1994RNNHochreiterSchmidhuber1997LSTMLSTM\n\n#### Stacked LSTMs\n\n<img src=\"StackedLSTM.png\" width=\"60%\">\n\n LSTM  LSTM LSTM\n\nLSTM   \n\n#### Nested LSTMs\n\n NLSTM LSTM  LSTM NLSTM Stacked LSTM Stacked LSTM Nested LSTM NLSTM \n\n### 2. Model of Nested LSTMs\n\nLSTM Nested LSTM gate\n\n<img src=\"NestedLSTM.png\" width=\"80%\">\n\n#### The architecture\n\n LSTM \n$$\ni_t = \\sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\\\\nf_t = \\sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\\\\nc_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\\\\no_t = \\sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\\\\nh_t = o_t \\odot \\sigma_h(c_t)\n$$\nNested LSTM  $c_t = m_t(f_t\\odot c_{t1}, i_t \\odot g_t)$  LSTM  $c_t$  m  t inner memory $c_t$  $m_{t+1}$ LSTM  Nested LSTM Nested LSTM \n\nNLSTM \n$$\n\\tilde{h}_{t-1} = f_t \\odot c_{t-1} \\\\\n\\tilde{x}_t = i_t \\odot \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c)\n$$\n$c_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) =  \\tilde{h}_{t-1} + \\tilde{x}_t $ LSTM\n\n<img src=\"ComputationalGraph.png\">\n\n*LSTMStacked LSTM  Nested LSTM hcd*\n$$\n\\widetilde{i}_t = \\widetilde{\\sigma}_i (\\widetilde{x}_t \\widetilde{W}_{xi} + \\widetilde{h}_{t-1} \\widetilde{W}_{hi} + \\widetilde{b}_i) \\\\\n\\widetilde{f}_t = \\widetilde{\\sigma}_t (\\widetilde{x}_t \\widetilde{W}_{xf} + \\widetilde{h}_{t-1} \\widetilde{W}_{hf} + \\widetilde{b}_i) \\\\\n\\widetilde{c}_t = \\widetilde{f}_t \\odot \\widetilde{c}_{c-1} + \\widetilde{\\sigma}_c (\\widetilde{x}_t \\widetilde{W}_{xc} + \\widetilde{h}_{t-1} \\widetilde{W}_{hc} + \\widetilde{b}_c) \\\\\n\\widetilde{o_t} = \\widetilde{\\sigma}_o (\\widetilde{x}_t \\widetilde{W}_{xo} + \\widetilde{h}_{t-1} \\widetilde{W}_{ho} + \\widetilde{b}_o) \\\\\n\\widetilde{h}_t = \\widetilde{o}_t \\odot \\widetilde{\\sigma}_h(\\widetilde{c}_t)\n$$\n LSTM  $ c_t = \\tilde{h}_{t} $ \n\n### 3. Experiments\n\n[1]\n\n### 4. Conclusion\n\nNested LSTMNLSTMLSTM NLSTM\n\n[1]Nested LSTM Stacked LSTMsingle-layer LSTMStacked LSTM LSTM \n\n[NLSTMTensorflow](https://github.com/hannw/nlstm)\n\n[NLSTMKeras](https://github.com/titu1994/Nested-LSTM)\n\n\n\n## Bibliographies\n\nhttp://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&type=title\n\n[1] Moniz, Joel Ruben Antony, and David Krueger. \"Nested LSTMs.\" *Asian Conference on Machine Learning*. 2017.\n\n[2] Hochreiter, Sepp, and Jrgen Schmidhuber. \"Long short-term memory.\" *Neural computation* 9.8 (1997): 1735-1780.\n\n","source":"_posts/[2018.2.5]Nested-LSTMs.md","raw":"---\ntitle: Nested LSTMs \ndate: 2018-02-05 08:00:00\ncategories: [research]\ntags: [LSTM, RNN]\n---\n\n## Nested LSTMs\n\n**** Nested LSTMs LSTMLSTMRNNNested LSTMLSTMNLSTMLSTMLSTMNLSTM$c_t^{outer} = f_t \\odot c_{t-1} + i_t \\odot g_t$ $(f_t \\odot c_{t-1}, i_t \\odot g_t)$ LSTMNLSTM $c_t^{outer} = h_t^{inner}$Nested LSTM  LSTM NLSTM  LSTMNested LSTM  LSTM\n\n### 1. Introduction\n\nnlp\n\n#### single-layer LSTM\n\n<img src=\"singleLSTM.png\" width=\"90%\">\n\nRNNHochreiter1991Bengio1994RNNHochreiterSchmidhuber1997LSTMLSTM\n\n#### Stacked LSTMs\n\n<img src=\"StackedLSTM.png\" width=\"60%\">\n\n LSTM  LSTM LSTM\n\nLSTM   \n\n#### Nested LSTMs\n\n NLSTM LSTM  LSTM NLSTM Stacked LSTM Stacked LSTM Nested LSTM NLSTM \n\n### 2. Model of Nested LSTMs\n\nLSTM Nested LSTM gate\n\n<img src=\"NestedLSTM.png\" width=\"80%\">\n\n#### The architecture\n\n LSTM \n$$\ni_t = \\sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\\\\nf_t = \\sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\\\\nc_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\\\\no_t = \\sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\\\\nh_t = o_t \\odot \\sigma_h(c_t)\n$$\nNested LSTM  $c_t = m_t(f_t\\odot c_{t1}, i_t \\odot g_t)$  LSTM  $c_t$  m  t inner memory $c_t$  $m_{t+1}$ LSTM  Nested LSTM Nested LSTM \n\nNLSTM \n$$\n\\tilde{h}_{t-1} = f_t \\odot c_{t-1} \\\\\n\\tilde{x}_t = i_t \\odot \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c)\n$$\n$c_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) =  \\tilde{h}_{t-1} + \\tilde{x}_t $ LSTM\n\n<img src=\"ComputationalGraph.png\">\n\n*LSTMStacked LSTM  Nested LSTM hcd*\n$$\n\\widetilde{i}_t = \\widetilde{\\sigma}_i (\\widetilde{x}_t \\widetilde{W}_{xi} + \\widetilde{h}_{t-1} \\widetilde{W}_{hi} + \\widetilde{b}_i) \\\\\n\\widetilde{f}_t = \\widetilde{\\sigma}_t (\\widetilde{x}_t \\widetilde{W}_{xf} + \\widetilde{h}_{t-1} \\widetilde{W}_{hf} + \\widetilde{b}_i) \\\\\n\\widetilde{c}_t = \\widetilde{f}_t \\odot \\widetilde{c}_{c-1} + \\widetilde{\\sigma}_c (\\widetilde{x}_t \\widetilde{W}_{xc} + \\widetilde{h}_{t-1} \\widetilde{W}_{hc} + \\widetilde{b}_c) \\\\\n\\widetilde{o_t} = \\widetilde{\\sigma}_o (\\widetilde{x}_t \\widetilde{W}_{xo} + \\widetilde{h}_{t-1} \\widetilde{W}_{ho} + \\widetilde{b}_o) \\\\\n\\widetilde{h}_t = \\widetilde{o}_t \\odot \\widetilde{\\sigma}_h(\\widetilde{c}_t)\n$$\n LSTM  $ c_t = \\tilde{h}_{t} $ \n\n### 3. Experiments\n\n[1]\n\n### 4. Conclusion\n\nNested LSTMNLSTMLSTM NLSTM\n\n[1]Nested LSTM Stacked LSTMsingle-layer LSTMStacked LSTM LSTM \n\n[NLSTMTensorflow](https://github.com/hannw/nlstm)\n\n[NLSTMKeras](https://github.com/titu1994/Nested-LSTM)\n\n\n\n## Bibliographies\n\nhttp://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&type=title\n\n[1] Moniz, Joel Ruben Antony, and David Krueger. \"Nested LSTMs.\" *Asian Conference on Machine Learning*. 2017.\n\n[2] Hochreiter, Sepp, and Jrgen Schmidhuber. \"Long short-term memory.\" *Neural computation* 9.8 (1997): 1735-1780.\n\n","slug":"[2018.2.5]Nested-LSTMs","published":1,"updated":"2018-03-03T20:21:18.918Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrf0029pzm91lfdtp9v","content":"<h2 id=\"Nested-LSTMs\"><a href=\"#Nested-LSTMs\" class=\"headerlink\" title=\"Nested LSTMs\"></a>Nested LSTMs</h2><p><strong></strong> Nested LSTMs LSTMLSTMRNNNested LSTMLSTMNLSTMLSTMLSTMNLSTM$c<em>t^{outer} = f_t \\odot c</em>{t-1} + i<em>t \\odot g_t$ $(f_t \\odot c</em>{t-1}, i_t \\odot g_t)$ LSTMNLSTM $c_t^{outer} = h_t^{inner}$Nested LSTM  LSTM NLSTM  LSTMNested LSTM  LSTM</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>nlp</p>\n<h4 id=\"single-layer-LSTM\"><a href=\"#single-layer-LSTM\" class=\"headerlink\" title=\"single-layer LSTM\"></a>single-layer LSTM</h4><p><img src=\"singleLSTM.png\" width=\"90%\"></p>\n<p>RNNHochreiter1991Bengio1994RNNHochreiterSchmidhuber1997LSTMLSTM</p>\n<h4 id=\"Stacked-LSTMs\"><a href=\"#Stacked-LSTMs\" class=\"headerlink\" title=\"Stacked LSTMs\"></a>Stacked LSTMs</h4><p><img src=\"StackedLSTM.png\" width=\"60%\"></p>\n<p> LSTM  LSTM LSTM</p>\n<p>LSTM   </p>\n<h4 id=\"Nested-LSTMs-1\"><a href=\"#Nested-LSTMs-1\" class=\"headerlink\" title=\"Nested LSTMs\"></a>Nested LSTMs</h4><p> NLSTM LSTM  LSTM NLSTM Stacked LSTM Stacked LSTM Nested LSTM NLSTM </p>\n<h3 id=\"2-Model-of-Nested-LSTMs\"><a href=\"#2-Model-of-Nested-LSTMs\" class=\"headerlink\" title=\"2. Model of Nested LSTMs\"></a>2. Model of Nested LSTMs</h3><p>LSTM Nested LSTM gate</p>\n<p><img src=\"NestedLSTM.png\" width=\"80%\"></p>\n<h4 id=\"The-architecture\"><a href=\"#The-architecture\" class=\"headerlink\" title=\"The architecture\"></a>The architecture</h4><p> LSTM </p>\n<script type=\"math/tex; mode=display\">\ni_t = \\sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\\\\nf_t = \\sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\\\\nc_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\\\\no_t = \\sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\\\\nh_t = o_t \\odot \\sigma_h(c_t)</script><p>Nested LSTM  $c<em>t = m_t(f_t\\odot c</em>{t1}, i<em>t \\odot g_t)$  LSTM  $c_t$  m  t inner memory $c_t$  $m</em>{t+1}$ LSTM  Nested LSTM Nested LSTM </p>\n<p>NLSTM </p>\n<script type=\"math/tex; mode=display\">\n\\tilde{h}_{t-1} = f_t \\odot c_{t-1} \\\\\n\\tilde{x}_t = i_t \\odot \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c)</script><p>$c<em>t = f_t \\odot c</em>{c-1} + \\sigma<em>c (x_t W</em>{xc} + h<em>{t-1} W</em>{hc} + b<em>c) =  \\tilde{h}</em>{t-1} + \\tilde{x}_t $ LSTM</p>\n<p><img src=\"ComputationalGraph.png\"></p>\n<p><em>LSTMStacked LSTM  Nested LSTM hcd</em></p>\n<script type=\"math/tex; mode=display\">\n\\widetilde{i}_t = \\widetilde{\\sigma}_i (\\widetilde{x}_t \\widetilde{W}_{xi} + \\widetilde{h}_{t-1} \\widetilde{W}_{hi} + \\widetilde{b}_i) \\\\\n\\widetilde{f}_t = \\widetilde{\\sigma}_t (\\widetilde{x}_t \\widetilde{W}_{xf} + \\widetilde{h}_{t-1} \\widetilde{W}_{hf} + \\widetilde{b}_i) \\\\\n\\widetilde{c}_t = \\widetilde{f}_t \\odot \\widetilde{c}_{c-1} + \\widetilde{\\sigma}_c (\\widetilde{x}_t \\widetilde{W}_{xc} + \\widetilde{h}_{t-1} \\widetilde{W}_{hc} + \\widetilde{b}_c) \\\\\n\\widetilde{o_t} = \\widetilde{\\sigma}_o (\\widetilde{x}_t \\widetilde{W}_{xo} + \\widetilde{h}_{t-1} \\widetilde{W}_{ho} + \\widetilde{b}_o) \\\\\n\\widetilde{h}_t = \\widetilde{o}_t \\odot \\widetilde{\\sigma}_h(\\widetilde{c}_t)</script><p> LSTM  $ c<em>t = \\tilde{h}</em>{t} $ </p>\n<h3 id=\"3-Experiments\"><a href=\"#3-Experiments\" class=\"headerlink\" title=\"3. Experiments\"></a>3. Experiments</h3><p>[1]</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>Nested LSTMNLSTMLSTM NLSTM</p>\n<p>[1]Nested LSTM Stacked LSTMsingle-layer LSTMStacked LSTM LSTM </p>\n<p><a href=\"https://github.com/hannw/nlstm\" target=\"_blank\" rel=\"external\">NLSTMTensorflow</a></p>\n<p><a href=\"https://github.com/titu1994/Nested-LSTM\" target=\"_blank\" rel=\"external\">NLSTMKeras</a></p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p><a href=\"http://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title\" target=\"_blank\" rel=\"external\">http://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title</a></p>\n<p>[1] Moniz, Joel Ruben Antony, and David Krueger. Nested LSTMs. <em>Asian Conference on Machine Learning</em>. 2017.</p>\n<p>[2] Hochreiter, Sepp, and Jrgen Schmidhuber. Long short-term memory. <em>Neural computation</em> 9.8 (1997): 1735-1780.</p>\n","excerpt":"","more":"<h2 id=\"Nested-LSTMs\"><a href=\"#Nested-LSTMs\" class=\"headerlink\" title=\"Nested LSTMs\"></a>Nested LSTMs</h2><p><strong></strong> Nested LSTMs LSTMLSTMRNNNested LSTMLSTMNLSTMLSTMLSTMNLSTM$c<em>t^{outer} = f_t \\odot c</em>{t-1} + i<em>t \\odot g_t$ $(f_t \\odot c</em>{t-1}, i_t \\odot g_t)$ LSTMNLSTM $c_t^{outer} = h_t^{inner}$Nested LSTM  LSTM NLSTM  LSTMNested LSTM  LSTM</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>nlp</p>\n<h4 id=\"single-layer-LSTM\"><a href=\"#single-layer-LSTM\" class=\"headerlink\" title=\"single-layer LSTM\"></a>single-layer LSTM</h4><p><img src=\"singleLSTM.png\" width=\"90%\"></p>\n<p>RNNHochreiter1991Bengio1994RNNHochreiterSchmidhuber1997LSTMLSTM</p>\n<h4 id=\"Stacked-LSTMs\"><a href=\"#Stacked-LSTMs\" class=\"headerlink\" title=\"Stacked LSTMs\"></a>Stacked LSTMs</h4><p><img src=\"StackedLSTM.png\" width=\"60%\"></p>\n<p> LSTM  LSTM LSTM</p>\n<p>LSTM   </p>\n<h4 id=\"Nested-LSTMs-1\"><a href=\"#Nested-LSTMs-1\" class=\"headerlink\" title=\"Nested LSTMs\"></a>Nested LSTMs</h4><p> NLSTM LSTM  LSTM NLSTM Stacked LSTM Stacked LSTM Nested LSTM NLSTM </p>\n<h3 id=\"2-Model-of-Nested-LSTMs\"><a href=\"#2-Model-of-Nested-LSTMs\" class=\"headerlink\" title=\"2. Model of Nested LSTMs\"></a>2. Model of Nested LSTMs</h3><p>LSTM Nested LSTM gate</p>\n<p><img src=\"NestedLSTM.png\" width=\"80%\"></p>\n<h4 id=\"The-architecture\"><a href=\"#The-architecture\" class=\"headerlink\" title=\"The architecture\"></a>The architecture</h4><p> LSTM </p>\n<script type=\"math/tex; mode=display\">\ni_t = \\sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\\\\nf_t = \\sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\\\\nc_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\\\\no_t = \\sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\\\\nh_t = o_t \\odot \\sigma_h(c_t)</script><p>Nested LSTM  $c<em>t = m_t(f_t\\odot c</em>{t1}, i<em>t \\odot g_t)$  LSTM  $c_t$  m  t inner memory $c_t$  $m</em>{t+1}$ LSTM  Nested LSTM Nested LSTM </p>\n<p>NLSTM </p>\n<script type=\"math/tex; mode=display\">\n\\tilde{h}_{t-1} = f_t \\odot c_{t-1} \\\\\n\\tilde{x}_t = i_t \\odot \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c)</script><p>$c<em>t = f_t \\odot c</em>{c-1} + \\sigma<em>c (x_t W</em>{xc} + h<em>{t-1} W</em>{hc} + b<em>c) =  \\tilde{h}</em>{t-1} + \\tilde{x}_t $ LSTM</p>\n<p><img src=\"ComputationalGraph.png\"></p>\n<p><em>LSTMStacked LSTM  Nested LSTM hcd</em></p>\n<script type=\"math/tex; mode=display\">\n\\widetilde{i}_t = \\widetilde{\\sigma}_i (\\widetilde{x}_t \\widetilde{W}_{xi} + \\widetilde{h}_{t-1} \\widetilde{W}_{hi} + \\widetilde{b}_i) \\\\\n\\widetilde{f}_t = \\widetilde{\\sigma}_t (\\widetilde{x}_t \\widetilde{W}_{xf} + \\widetilde{h}_{t-1} \\widetilde{W}_{hf} + \\widetilde{b}_i) \\\\\n\\widetilde{c}_t = \\widetilde{f}_t \\odot \\widetilde{c}_{c-1} + \\widetilde{\\sigma}_c (\\widetilde{x}_t \\widetilde{W}_{xc} + \\widetilde{h}_{t-1} \\widetilde{W}_{hc} + \\widetilde{b}_c) \\\\\n\\widetilde{o_t} = \\widetilde{\\sigma}_o (\\widetilde{x}_t \\widetilde{W}_{xo} + \\widetilde{h}_{t-1} \\widetilde{W}_{ho} + \\widetilde{b}_o) \\\\\n\\widetilde{h}_t = \\widetilde{o}_t \\odot \\widetilde{\\sigma}_h(\\widetilde{c}_t)</script><p> LSTM  $ c<em>t = \\tilde{h}</em>{t} $ </p>\n<h3 id=\"3-Experiments\"><a href=\"#3-Experiments\" class=\"headerlink\" title=\"3. Experiments\"></a>3. Experiments</h3><p>[1]</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>Nested LSTMNLSTMLSTM NLSTM</p>\n<p>[1]Nested LSTM Stacked LSTMsingle-layer LSTMStacked LSTM LSTM </p>\n<p><a href=\"https://github.com/hannw/nlstm\">NLSTMTensorflow</a></p>\n<p><a href=\"https://github.com/titu1994/Nested-LSTM\">NLSTMKeras</a></p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p><a href=\"http://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title\">http://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title</a></p>\n<p>[1] Moniz, Joel Ruben Antony, and David Krueger. Nested LSTMs. <em>Asian Conference on Machine Learning</em>. 2017.</p>\n<p>[2] Hochreiter, Sepp, and Jrgen Schmidhuber. Long short-term memory. <em>Neural computation</em> 9.8 (1997): 1735-1780.</p>\n"},{"title":" complexity","date":"2016-11-27T09:52:05.000Z","_content":"\n#  - Calcul the complexity\n\n\n\nThere, we only discuss the time complexity.\n\n##  - Normal\n\n1. Single operation - O(1)\n\n2. Loop\n\n   ```Python\n   def fun(n):\n   \tfor i in range(n):\n      \t\tpass\n   ```\n\n   ```python\n   def fun(n):\n   \twhile i < n :\n       \ti += 1\n   ```\n\n    O(n)\n\n   ```python\n   def fun(n):\n       while i < n :\n           i *= 2\n   ```\n\n    O(logn)\n\n   Etc.\n\n   ##  - Recursion\n   1.  \n\n       \n\n       ex:\n\n       T(n) = 2*T(n/2) + O(n)\n\n        T(n) = kn^2\n\n       \n\n       \n\n   2.  \n\n          \n\n          ex:\n\n          T(n) = T(n-1) + O(1)\n\n          T(1) = O(1)\n\n          T(n) = T(n-1) + O(1) = T(n-1) + 2 * O(1) =  = n*O(1) = O(n)\n\n   3.  \n\n          \n\n          T(n) = aT(n/b) +f(n)\n\n          \n\n   4.  \n\n          ","source":"_posts/complexity.md","raw":"---\ntitle:  complexity\ndate: 2016-11-27 10:52:05\ncategories: programming\ntags: [algo, programming, complexity]\n---\n\n#  - Calcul the complexity\n\n\n\nThere, we only discuss the time complexity.\n\n##  - Normal\n\n1. Single operation - O(1)\n\n2. Loop\n\n   ```Python\n   def fun(n):\n   \tfor i in range(n):\n      \t\tpass\n   ```\n\n   ```python\n   def fun(n):\n   \twhile i < n :\n       \ti += 1\n   ```\n\n    O(n)\n\n   ```python\n   def fun(n):\n       while i < n :\n           i *= 2\n   ```\n\n    O(logn)\n\n   Etc.\n\n   ##  - Recursion\n   1.  \n\n       \n\n       ex:\n\n       T(n) = 2*T(n/2) + O(n)\n\n        T(n) = kn^2\n\n       \n\n       \n\n   2.  \n\n          \n\n          ex:\n\n          T(n) = T(n-1) + O(1)\n\n          T(1) = O(1)\n\n          T(n) = T(n-1) + O(1) = T(n-1) + 2 * O(1) =  = n*O(1) = O(n)\n\n   3.  \n\n          \n\n          T(n) = aT(n/b) +f(n)\n\n          \n\n   4.  \n\n          ","slug":"complexity","published":1,"updated":"2016-11-30T10:43:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrh002dpzm9npdzxhoq","content":"<h1 id=\"-Calcul-the-complexity\"><a href=\"#-Calcul-the-complexity\" class=\"headerlink\" title=\" - Calcul the complexity\"></a> - Calcul the complexity</h1><p></p>\n<p>There, we only discuss the time complexity.</p>\n<h2 id=\"-Normal\"><a href=\"#-Normal\" class=\"headerlink\" title=\" - Normal\"></a> - Normal</h2><ol>\n<li><p>Single operation - O(1)</p>\n</li>\n<li><p>Loop</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):</div><div class=\"line\">   \t\t<span class=\"keyword\">pass</span></div></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">\t<span class=\"keyword\">while</span> i &lt; n :</div><div class=\"line\">    \ti += <span class=\"number\">1</span></div></pre></td></tr></table></figure>\n<p> O(n)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">while</span> i &lt; n :</div><div class=\"line\">        i *= <span class=\"number\">2</span></div></pre></td></tr></table></figure>\n<p> O(logn)</p>\n<p>Etc.</p>\n<h2 id=\"-Recursion\"><a href=\"#-Recursion\" class=\"headerlink\" title=\" - Recursion\"></a> - Recursion</h2><ol>\n<li><p></p>\n<p></p>\n<p>ex:</p>\n<p>T(n) = 2*T(n/2) + O(n)</p>\n<p> T(n) = kn^2</p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>   </p>\n<p>   ex:</p>\n<p>   T(n) = T(n-1) + O(1)</p>\n<p>   T(1) = O(1)</p>\n<p>   T(n) = T(n-1) + O(1) = T(n-1) + 2 <em> O(1) =  = n</em>O(1) = O(n)</p>\n</li>\n<li><p></p>\n<p>   </p>\n<p>   T(n) = aT(n/b) +f(n)</p>\n<p>   </p>\n</li>\n<li><p></p>\n<p>   </p>\n</li>\n</ol>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"-Calcul-the-complexity\"><a href=\"#-Calcul-the-complexity\" class=\"headerlink\" title=\" - Calcul the complexity\"></a> - Calcul the complexity</h1><p></p>\n<p>There, we only discuss the time complexity.</p>\n<h2 id=\"-Normal\"><a href=\"#-Normal\" class=\"headerlink\" title=\" - Normal\"></a> - Normal</h2><ol>\n<li><p>Single operation - O(1)</p>\n</li>\n<li><p>Loop</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):</div><div class=\"line\">   \t\t<span class=\"keyword\">pass</span></div></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">\t<span class=\"keyword\">while</span> i &lt; n :</div><div class=\"line\">    \ti += <span class=\"number\">1</span></div></pre></td></tr></table></figure>\n<p> O(n)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">while</span> i &lt; n :</div><div class=\"line\">        i *= <span class=\"number\">2</span></div></pre></td></tr></table></figure>\n<p> O(logn)</p>\n<p>Etc.</p>\n<h2 id=\"-Recursion\"><a href=\"#-Recursion\" class=\"headerlink\" title=\" - Recursion\"></a> - Recursion</h2><ol>\n<li><p></p>\n<p></p>\n<p>ex:</p>\n<p>T(n) = 2*T(n/2) + O(n)</p>\n<p> T(n) = kn^2</p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>   </p>\n<p>   ex:</p>\n<p>   T(n) = T(n-1) + O(1)</p>\n<p>   T(1) = O(1)</p>\n<p>   T(n) = T(n-1) + O(1) = T(n-1) + 2 <em> O(1) =  = n</em>O(1) = O(n)</p>\n</li>\n<li><p></p>\n<p>   </p>\n<p>   T(n) = aT(n/b) +f(n)</p>\n<p>   </p>\n</li>\n<li><p></p>\n<p>   </p>\n</li>\n</ol>\n</li>\n</ol>\n"},{"title":" compression","date":"2016-11-27T13:22:11.000Z","_content":"\n1. Run length encoding\n\n   ex:\n\n   0101  0,101  \"3 pixels are color '0'\"\n\n   1101  1,101  \"6 pixels are color '1'\"\n\n   You can also define other signification like:\n\n   1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.\n\n2. Huffman\n\n   Defined in wiki\n\n   Normally we supppose higher number with \"1\".\n\n   ex:\n\n                           (1)\n\n                      0/       \\1\n\n               a(0.45)     (0.55)\n\n                                0/     \\1\n\n                        b(0.25)    c(0.30)\n\n3. Lempel-Ziv\n\n   Encode:\n\n   - Origin: ababcbab...\n   - Init: a:0, b:1, c:2\n   - Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6...\n   - Result: 01324...\n\n   Decode: pass\n\n   ","source":"_posts/compression.md","raw":"---\ntitle:  compression\ndate: 2016-11-27 14:22:11\ncategories: programming\ntags: [algo, compression, programming]\n---\n\n1. Run length encoding\n\n   ex:\n\n   0101  0,101  \"3 pixels are color '0'\"\n\n   1101  1,101  \"6 pixels are color '1'\"\n\n   You can also define other signification like:\n\n   1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.\n\n2. Huffman\n\n   Defined in wiki\n\n   Normally we supppose higher number with \"1\".\n\n   ex:\n\n                           (1)\n\n                      0/       \\1\n\n               a(0.45)     (0.55)\n\n                                0/     \\1\n\n                        b(0.25)    c(0.30)\n\n3. Lempel-Ziv\n\n   Encode:\n\n   - Origin: ababcbab...\n   - Init: a:0, b:1, c:2\n   - Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6...\n   - Result: 01324...\n\n   Decode: pass\n\n   ","slug":"compression","published":1,"updated":"2016-11-30T10:46:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrj002fpzm9cnzuzfrn","content":"<ol>\n<li><p>Run length encoding</p>\n<p>ex:</p>\n<p>0101  0,101  3 pixels are color 0</p>\n<p>1101  1,101  6 pixels are color 1</p>\n<p>You can also define other signification like:</p>\n<p>1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.</p>\n</li>\n<li><p>Huffman</p>\n<p>Defined in wiki</p>\n<p>Normally we supppose higher number with 1.</p>\n<p>ex:</p>\n<p>                        (1)</p>\n<p>                   0/       \\1</p>\n<p>            a(0.45)     (0.55)</p>\n<p>                             0/     \\1</p>\n<p>                     b(0.25)    c(0.30)</p>\n</li>\n<li><p>Lempel-Ziv</p>\n<p>Encode:</p>\n<ul>\n<li>Origin: ababcbab</li>\n<li>Init: a:0, b:1, c:2</li>\n<li>Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6</li>\n<li>Result: 01324</li>\n</ul>\n<p>Decode: pass</p>\n<p></p>\n</li>\n</ol>\n","excerpt":"","more":"<ol>\n<li><p>Run length encoding</p>\n<p>ex:</p>\n<p>0101  0,101  3 pixels are color 0</p>\n<p>1101  1,101  6 pixels are color 1</p>\n<p>You can also define other signification like:</p>\n<p>1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.</p>\n</li>\n<li><p>Huffman</p>\n<p>Defined in wiki</p>\n<p>Normally we supppose higher number with 1.</p>\n<p>ex:</p>\n<p>                        (1)</p>\n<p>                   0/       \\1</p>\n<p>            a(0.45)     (0.55)</p>\n<p>                             0/     \\1</p>\n<p>                     b(0.25)    c(0.30)</p>\n</li>\n<li><p>Lempel-Ziv</p>\n<p>Encode:</p>\n<ul>\n<li>Origin: ababcbab</li>\n<li>Init: a:0, b:1, c:2</li>\n<li>Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6</li>\n<li>Result: 01324</li>\n</ul>\n<p>Decode: pass</p>\n<p></p>\n</li>\n</ol>\n"},{"title":"-","date":"2016-12-26T13:56:57.000Z","_content":"\n# \n\n\n\n1. \n\n   \n\n2. \n\n   \n\n      \t\n\n:\n\n1. ()()\n2.  \n3. () \n4. \n5.  \n\n# \n\n1. \n\n   - \n\n     \n\n2. \n\n   \n   $$\n   I(s_1,,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}\n   $$\n   A\n   $$\n   E(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,,s_m) }\n   $$\n   E(A)Sj\n   $$\n   I(s_{1j},,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}\n   $$\n   A:\n   $$\n   Gain(A) =I(s_1,,s_m)- E(A)\n   $$\n   Gain(A)A\n\n   Gain\n\n3. \n\n   1. \n\n      \n\n   2. \n\n      \n\n      (MDL)\n\n      \n\n4. \n\n   \"if...else...\"\n\n5. \n\n#  \n\n\n\n\n\n\n\n1. \n\n   XH\n   $$\n   P(H|X) = \\frac{P(X|H)P(H)}{P(X)}\n   $$\n\n2. \n\n   \n\n   1. nX={x1,,xn}n(A1,,An)\n\n   2. m(C1,,Cm)XCi\n      $$\n      P(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)\n      $$\n      \n      $$\n      P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}\n      $$\n\n   3. P(X|Ci)P(Ci)P(Ci)P(X|Ci)\n\n   4. P(X|Ci)\n      $$\n      P(X|C_i) = \\prod{P(x_k|C_i)}\n      $$\n      P(xk|Ci)\n\n      - Ak\n        $$\n        P(x_k|Ci)=\\frac{s_{ik}}{s_i}\n        $$\n        sikCiAkvksiCi\n\n      - Ak\n        $$\n        P(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}\n        $$\n        $g(x_k,\\mu_{C_i},\\sigma_{C_i})$Ak\n\n   5. XX\n\n3. \n\n   \n\n   \n\n   - \n\n     \n\n     \n\n     \n\n   - (CPT)\n\n     ZCPTP(Z|parent(Z))\n\n     LunCancerFamilyHistorySmoker\n\n|             | FH, S | FH, ~S | ~FH, S | ~FH, ~S |\n| ----------- | ----- | ------ | ------ | ------- |\n| LungCancer  | 0.8   | 0.5    | 0.7    | 0.1     |\n| ~LungCancer | 0.2   | 0.5    | 0.3    | 0.9     |\n\n\n\n$$\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}\n$$\n\n4. \n\n   \n\n   1. \n      $$\n      \\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}\n      $$\n      \n      SXdp\n\n      YiUip\n\n   2. \n      $$\n      w_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}\n      $$\n      l\n\n   3. \n\n      wijk011.\n\n# \n\n1. \n\n   ()()\n\n   \n\n   \n\n   \n\n   \n\n   \n\n2. \n\n   \n\n   - \n   - ()\n   - \n   - \n\n   01.\n\n   A={a0,a1,a2}I0, I1, I20A=a0I11.\n\n   \n\n3. \n\n   \n\n   \n\n   ()\n\n   ```python\n   # sumxf(x)\n   def sum(f(x), x):\n       pass\n\n   # \n   init();\n\n   while !conditions:           # \n       for X in samples:\n           for each layer:      # \n               O[j] = 1 / (1 + exp( - I[j]))\n               I[j] = sum(w[i][j]O[i], i) + theta[j]\n           for each unit of output layer as j:    # j\n               Err[j] = O[j] * (1 - O[j]) * (T[j] - O[j])\n           for each unit of hidden layer as j:    # j\n               Err[j] = O[j] * (1 - O[j]) * sum(Err[k] * w[i][j][k], k)\n           for each w[i][j] in the network:       # networkwij\n               delta_w[i][j] = (l) * Err[j] * O[i]     # (l)01\n               w[i][j] += delta_w[i][j]\n           for each theta[j] in the network:      # networkthetaij\n               delta_theta[j] = (l) * Err[j]\n               v[i] = theta[j] + delta_theta[j]\n           \n   ```\n\n   \n\n# \n\n\n\n# \n\n\n\n1. k-\n\n   \n\n2. \n\n3. \n\n4. \n\n5. \n\n# \n\n1. \n\n   \n\n2. \n\n   \n   $$\n   Y = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3\n   $$\n   \n   $$\n   X_1 = X;X_2 = X^2 ; X_3 = X^3\n   $$\n   \n\n3. \n\n   \n\n# \n\nkbaggingboosting()()","source":"_posts/datamining-class-pred.md","raw":"---\ntitle: -\ndate: 2016-12-26 14:56:57\ncategories: [programming]\ntags: [datamining, programming, classification, prediction]\n---\n\n# \n\n\n\n1. \n\n   \n\n2. \n\n   \n\n      \t\n\n:\n\n1. ()()\n2.  \n3. () \n4. \n5.  \n\n# \n\n1. \n\n   - \n\n     \n\n2. \n\n   \n   $$\n   I(s_1,,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}\n   $$\n   A\n   $$\n   E(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,,s_m) }\n   $$\n   E(A)Sj\n   $$\n   I(s_{1j},,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}\n   $$\n   A:\n   $$\n   Gain(A) =I(s_1,,s_m)- E(A)\n   $$\n   Gain(A)A\n\n   Gain\n\n3. \n\n   1. \n\n      \n\n   2. \n\n      \n\n      (MDL)\n\n      \n\n4. \n\n   \"if...else...\"\n\n5. \n\n#  \n\n\n\n\n\n\n\n1. \n\n   XH\n   $$\n   P(H|X) = \\frac{P(X|H)P(H)}{P(X)}\n   $$\n\n2. \n\n   \n\n   1. nX={x1,,xn}n(A1,,An)\n\n   2. m(C1,,Cm)XCi\n      $$\n      P(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)\n      $$\n      \n      $$\n      P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}\n      $$\n\n   3. P(X|Ci)P(Ci)P(Ci)P(X|Ci)\n\n   4. P(X|Ci)\n      $$\n      P(X|C_i) = \\prod{P(x_k|C_i)}\n      $$\n      P(xk|Ci)\n\n      - Ak\n        $$\n        P(x_k|Ci)=\\frac{s_{ik}}{s_i}\n        $$\n        sikCiAkvksiCi\n\n      - Ak\n        $$\n        P(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}\n        $$\n        $g(x_k,\\mu_{C_i},\\sigma_{C_i})$Ak\n\n   5. XX\n\n3. \n\n   \n\n   \n\n   - \n\n     \n\n     \n\n     \n\n   - (CPT)\n\n     ZCPTP(Z|parent(Z))\n\n     LunCancerFamilyHistorySmoker\n\n|             | FH, S | FH, ~S | ~FH, S | ~FH, ~S |\n| ----------- | ----- | ------ | ------ | ------- |\n| LungCancer  | 0.8   | 0.5    | 0.7    | 0.1     |\n| ~LungCancer | 0.2   | 0.5    | 0.3    | 0.9     |\n\n\n\n$$\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}\n$$\n\n4. \n\n   \n\n   1. \n      $$\n      \\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}\n      $$\n      \n      SXdp\n\n      YiUip\n\n   2. \n      $$\n      w_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}\n      $$\n      l\n\n   3. \n\n      wijk011.\n\n# \n\n1. \n\n   ()()\n\n   \n\n   \n\n   \n\n   \n\n   \n\n2. \n\n   \n\n   - \n   - ()\n   - \n   - \n\n   01.\n\n   A={a0,a1,a2}I0, I1, I20A=a0I11.\n\n   \n\n3. \n\n   \n\n   \n\n   ()\n\n   ```python\n   # sumxf(x)\n   def sum(f(x), x):\n       pass\n\n   # \n   init();\n\n   while !conditions:           # \n       for X in samples:\n           for each layer:      # \n               O[j] = 1 / (1 + exp( - I[j]))\n               I[j] = sum(w[i][j]O[i], i) + theta[j]\n           for each unit of output layer as j:    # j\n               Err[j] = O[j] * (1 - O[j]) * (T[j] - O[j])\n           for each unit of hidden layer as j:    # j\n               Err[j] = O[j] * (1 - O[j]) * sum(Err[k] * w[i][j][k], k)\n           for each w[i][j] in the network:       # networkwij\n               delta_w[i][j] = (l) * Err[j] * O[i]     # (l)01\n               w[i][j] += delta_w[i][j]\n           for each theta[j] in the network:      # networkthetaij\n               delta_theta[j] = (l) * Err[j]\n               v[i] = theta[j] + delta_theta[j]\n           \n   ```\n\n   \n\n# \n\n\n\n# \n\n\n\n1. k-\n\n   \n\n2. \n\n3. \n\n4. \n\n5. \n\n# \n\n1. \n\n   \n\n2. \n\n   \n   $$\n   Y = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3\n   $$\n   \n   $$\n   X_1 = X;X_2 = X^2 ; X_3 = X^3\n   $$\n   \n\n3. \n\n   \n\n# \n\nkbaggingboosting()()","slug":"datamining-class-pred","published":1,"updated":"2016-12-26T15:52:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrl002jpzm9ay5clz3r","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p>       </p>\n</li>\n</ol>\n<p>:</p>\n<ol>\n<li>()()</li>\n<li> </li>\n<li>() </li>\n<li></li>\n<li> </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<ul>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nI(s_1,,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}</script><p>A</p>\n<script type=\"math/tex; mode=display\">\nE(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,,s_m) }</script><p>E(A)Sj</p>\n<script type=\"math/tex; mode=display\">\nI(s_{1j},,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}</script><p>A:</p>\n<script type=\"math/tex; mode=display\">\nGain(A) =I(s_1,,s_m)- E(A)</script><p>Gain(A)A</p>\n<p>Gain</p>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p>(MDL)</p>\n<p></p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<p>ifelse</p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<p></p>\n<ol>\n<li><p></p>\n<p>XH</p>\n<script type=\"math/tex; mode=display\">\nP(H|X) = \\frac{P(X|H)P(H)}{P(X)}</script></li>\n<li><p></p>\n<p></p>\n<ol>\n<li><p>nX={x1,,xn}n(A1,,An)</p>\n</li>\n<li><p>m(C1,,Cm)XCi</p>\n<script type=\"math/tex; mode=display\">\nP(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)</script><p></p>\n<script type=\"math/tex; mode=display\">\nP(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}</script></li>\n<li><p>P(X|Ci)P(Ci)P(Ci)P(X|Ci)</p>\n</li>\n<li><p>P(X|Ci)</p>\n<script type=\"math/tex; mode=display\">\nP(X|C_i) = \\prod{P(x_k|C_i)}</script><p>P(xk|Ci)</p>\n<ul>\n<li><p>Ak</p>\n<script type=\"math/tex; mode=display\">\nP(x_k|Ci)=\\frac{s_{ik}}{s_i}</script><p>sikCiAkvksiCi</p>\n</li>\n<li><p>Ak</p>\n<script type=\"math/tex; mode=display\">\nP(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}</script><p>$g(x<em>k,\\mu</em>{C<em>i},\\sigma</em>{C_i})$Ak</p>\n</li>\n</ul>\n</li>\n<li><p>XX</p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n<ul>\n<li><p></p>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p>(CPT)</p>\n<p>ZCPTP(Z|parent(Z))</p>\n<p>LunCancerFamilyHistorySmoker</p>\n</li>\n</ul>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>FH, S</th>\n<th>FH, ~S</th>\n<th>~FH, S</th>\n<th>~FH, ~S</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>LungCancer</td>\n<td>0.8</td>\n<td>0.5</td>\n<td>0.7</td>\n<td>0.1</td>\n</tr>\n<tr>\n<td>~LungCancer</td>\n<td>0.2</td>\n<td>0.5</td>\n<td>0.3</td>\n<td>0.9</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p></p>\n<script type=\"math/tex; mode=display\">\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}</script><ol>\n<li><p></p>\n<p></p>\n<ol>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}</script><p><br>SXdp</p>\n<p>YiUip</p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nw_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}</script><p>l</p>\n</li>\n<li><p></p>\n<p>wijk011.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>()()</p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li></li>\n<li>()</li>\n<li></li>\n<li></li>\n</ul>\n<p>01.</p>\n<p>A={a0,a1,a2}I0, I1, I20A=a0I11.</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n<p>()</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># sumxf(x)</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sum</span><span class=\"params\">(f<span class=\"params\">(x)</span>, x)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">init();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span> !conditions:           <span class=\"comment\"># </span></div><div class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> samples:</div><div class=\"line\">        <span class=\"keyword\">for</span> each layer:      <span class=\"comment\"># </span></div><div class=\"line\">            O[j] = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + exp( - I[j]))</div><div class=\"line\">            I[j] = sum(w[i][j]O[i], i) + theta[j]</div><div class=\"line\">        <span class=\"keyword\">for</span> each unit of output layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># j</span></div><div class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * (T[j] - O[j])</div><div class=\"line\">        <span class=\"keyword\">for</span> each unit of hidden layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># j</span></div><div class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * sum(Err[k] * w[i][j][k], k)</div><div class=\"line\">        <span class=\"keyword\">for</span> each w[i][j] <span class=\"keyword\">in</span> the network:       <span class=\"comment\"># networkwij</span></div><div class=\"line\">            delta_w[i][j] = (l) * Err[j] * O[i]     <span class=\"comment\"># (l)01</span></div><div class=\"line\">            w[i][j] += delta_w[i][j]</div><div class=\"line\">        <span class=\"keyword\">for</span> each theta[j] <span class=\"keyword\">in</span> the network:      <span class=\"comment\"># networkthetaij</span></div><div class=\"line\">            delta_theta[j] = (l) * Err[j]</div><div class=\"line\">            v[i] = theta[j] + delta_theta[j]</div></pre></td></tr></table></figure>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li><p>k-</p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nY = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3</script><p></p>\n<script type=\"math/tex; mode=display\">\nX_1 = X;X_2 = X^2 ; X_3 = X^3</script><p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>kbaggingboosting()()</p>\n","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p>       </p>\n</li>\n</ol>\n<p>:</p>\n<ol>\n<li>()()</li>\n<li> </li>\n<li>() </li>\n<li></li>\n<li> </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<ul>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nI(s_1,,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}</script><p>A</p>\n<script type=\"math/tex; mode=display\">\nE(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,,s_m) }</script><p>E(A)Sj</p>\n<script type=\"math/tex; mode=display\">\nI(s_{1j},,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}</script><p>A:</p>\n<script type=\"math/tex; mode=display\">\nGain(A) =I(s_1,,s_m)- E(A)</script><p>Gain(A)A</p>\n<p>Gain</p>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p>(MDL)</p>\n<p></p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<p>ifelse</p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<p></p>\n<ol>\n<li><p></p>\n<p>XH</p>\n<script type=\"math/tex; mode=display\">\nP(H|X) = \\frac{P(X|H)P(H)}{P(X)}</script></li>\n<li><p></p>\n<p></p>\n<ol>\n<li><p>nX={x1,,xn}n(A1,,An)</p>\n</li>\n<li><p>m(C1,,Cm)XCi</p>\n<script type=\"math/tex; mode=display\">\nP(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)</script><p></p>\n<script type=\"math/tex; mode=display\">\nP(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}</script></li>\n<li><p>P(X|Ci)P(Ci)P(Ci)P(X|Ci)</p>\n</li>\n<li><p>P(X|Ci)</p>\n<script type=\"math/tex; mode=display\">\nP(X|C_i) = \\prod{P(x_k|C_i)}</script><p>P(xk|Ci)</p>\n<ul>\n<li><p>Ak</p>\n<script type=\"math/tex; mode=display\">\nP(x_k|Ci)=\\frac{s_{ik}}{s_i}</script><p>sikCiAkvksiCi</p>\n</li>\n<li><p>Ak</p>\n<script type=\"math/tex; mode=display\">\nP(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}</script><p>$g(x<em>k,\\mu</em>{C<em>i},\\sigma</em>{C_i})$Ak</p>\n</li>\n</ul>\n</li>\n<li><p>XX</p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n<ul>\n<li><p></p>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p>(CPT)</p>\n<p>ZCPTP(Z|parent(Z))</p>\n<p>LunCancerFamilyHistorySmoker</p>\n</li>\n</ul>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>FH, S</th>\n<th>FH, ~S</th>\n<th>~FH, S</th>\n<th>~FH, ~S</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>LungCancer</td>\n<td>0.8</td>\n<td>0.5</td>\n<td>0.7</td>\n<td>0.1</td>\n</tr>\n<tr>\n<td>~LungCancer</td>\n<td>0.2</td>\n<td>0.5</td>\n<td>0.3</td>\n<td>0.9</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p></p>\n<script type=\"math/tex; mode=display\">\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}</script><ol>\n<li><p></p>\n<p></p>\n<ol>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}</script><p><br>SXdp</p>\n<p>YiUip</p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nw_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}</script><p>l</p>\n</li>\n<li><p></p>\n<p>wijk011.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>()()</p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li></li>\n<li>()</li>\n<li></li>\n<li></li>\n</ul>\n<p>01.</p>\n<p>A={a0,a1,a2}I0, I1, I20A=a0I11.</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n<p>()</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># sumxf(x)</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sum</span><span class=\"params\">(f<span class=\"params\">(x)</span>, x)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># </span></div><div class=\"line\">init();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span> !conditions:           <span class=\"comment\"># </span></div><div class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> samples:</div><div class=\"line\">        <span class=\"keyword\">for</span> each layer:      <span class=\"comment\"># </span></div><div class=\"line\">            O[j] = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + exp( - I[j]))</div><div class=\"line\">            I[j] = sum(w[i][j]O[i], i) + theta[j]</div><div class=\"line\">        <span class=\"keyword\">for</span> each unit of output layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># j</span></div><div class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * (T[j] - O[j])</div><div class=\"line\">        <span class=\"keyword\">for</span> each unit of hidden layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># j</span></div><div class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * sum(Err[k] * w[i][j][k], k)</div><div class=\"line\">        <span class=\"keyword\">for</span> each w[i][j] <span class=\"keyword\">in</span> the network:       <span class=\"comment\"># networkwij</span></div><div class=\"line\">            delta_w[i][j] = (l) * Err[j] * O[i]     <span class=\"comment\"># (l)01</span></div><div class=\"line\">            w[i][j] += delta_w[i][j]</div><div class=\"line\">        <span class=\"keyword\">for</span> each theta[j] <span class=\"keyword\">in</span> the network:      <span class=\"comment\"># networkthetaij</span></div><div class=\"line\">            delta_theta[j] = (l) * Err[j]</div><div class=\"line\">            v[i] = theta[j] + delta_theta[j]</div></pre></td></tr></table></figure>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li><p>k-</p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nY = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3</script><p></p>\n<script type=\"math/tex; mode=display\">\nX_1 = X;X_2 = X^2 ; X_3 = X^3</script><p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>kbaggingboosting()()</p>\n"},{"title":"-","date":"2016-12-06T21:05:57.000Z","_content":"\n\n\n \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  ()\n\n  - \n  - \n  - \n  - \n\n# \n\n1. \n   - \n   - \n   - \n   - \n   - \n   - \n     - \n     - \n\n   \n\n2. \n\n   - Bin  \n   - \n   - \n   -   \n\n\n# \n\n1. \n\n   \n\n   - \"custom_id\", \"cum_num\" \n\n   - \n\n     \n     $$\n     r_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}\n     $$\n\n   - \n\n2. \n\n   1. bin\n\n   2. \n\n   3. \n\n   4. (1020100)4\n\n      -   \n\n      - \n        $$\n        v' = \\frac{v - \\bar{v}}{\\sigma}\n        $$\n\n      - \n        $$\n        v' = \\frac{v}{10^j}\n        $$\n\n   5. \n\n# \n\n \n\n1. \n\n   \n\n   \n\n2. \n\n3. \n\n   - \n   - \n\n4. \n\n   - \n   - \n   - \n   - \n\n5. \n\n   - bin\n   - \n   - \n   - \n   - \n\n# \n\n ","source":"_posts/datamining-pretreatment.md","raw":"---\ntitle: -\ndate: 2016-12-06 22:05:57\ncategories: programming\ntags: [datamining, programming]\n---\n\n\n\n \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  ()\n\n  - \n  - \n  - \n  - \n\n# \n\n1. \n   - \n   - \n   - \n   - \n   - \n   - \n     - \n     - \n\n   \n\n2. \n\n   - Bin  \n   - \n   - \n   -   \n\n\n# \n\n1. \n\n   \n\n   - \"custom_id\", \"cum_num\" \n\n   - \n\n     \n     $$\n     r_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}\n     $$\n\n   - \n\n2. \n\n   1. bin\n\n   2. \n\n   3. \n\n   4. (1020100)4\n\n      -   \n\n      - \n        $$\n        v' = \\frac{v - \\bar{v}}{\\sigma}\n        $$\n\n      - \n        $$\n        v' = \\frac{v}{10^j}\n        $$\n\n   5. \n\n# \n\n \n\n1. \n\n   \n\n   \n\n2. \n\n3. \n\n   - \n   - \n\n4. \n\n   - \n   - \n   - \n   - \n\n5. \n\n   - bin\n   - \n   - \n   - \n   - \n\n# \n\n ","slug":"datamining-pretreatment","published":1,"updated":"2016-12-08T20:29:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrm002lpzm9lve9z3sy","content":"<p></p>\n<p> </p>\n<ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>()</p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ul>\n<p></p>\n</li>\n<li><p></p>\n<ul>\n<li>Bin  </li>\n<li></li>\n<li></li>\n<li>  </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p></p>\n<ul>\n<li><p>custom_id, cum_num </p>\n</li>\n<li><p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nr_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}</script></li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ol>\n<li><p>bin</p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>(1020100)4</p>\n<ul>\n<li><p>  </p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nv' = \\frac{v - \\bar{v}}{\\sigma}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nv' = \\frac{v}{10^j}</script></li>\n</ul>\n</li>\n<li><p></p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n<ol>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>bin</li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n","excerpt":"","more":"<p></p>\n<p> </p>\n<ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>()</p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ul>\n<p></p>\n</li>\n<li><p></p>\n<ul>\n<li>Bin  </li>\n<li></li>\n<li></li>\n<li>  </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p></p>\n<ul>\n<li><p>custom_id, cum_num </p>\n</li>\n<li><p></p>\n<p></p>\n<script type=\"math/tex; mode=display\">\nr_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}</script></li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ol>\n<li><p>bin</p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>(1020100)4</p>\n<ul>\n<li><p>  </p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nv' = \\frac{v - \\bar{v}}{\\sigma}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nv' = \\frac{v}{10^j}</script></li>\n</ul>\n</li>\n<li><p></p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n<ol>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>bin</li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n"},{"title":"-","date":"2016-12-08T20:31:50.000Z","_content":"\n# \n\n1.    \n\n      ()\n\n      :() \n\n      roll up: \n\n      drill down: \n\n2.    \n\n      \n\n      ()()()\n\n      \n\n      1. \n\n         \n\n      2. \n\n         :()  \n\n      \n\n      1. \n\n         \n\n      2. \n\n      \n\n3.    \n\n      \n\n      1. \n\n      2. AOI\n\n         \n\n      3. \n\n         \n\n      4. \n\n      5. AOI\n\n          \n\n4.    \n\n      1. \n         1. \n\n         2. \n\n            ()\n\n         3. \n         4. \n         5. \n\n      2. t_weight - \n\n      3. d_weight - \n\n5.    \n\n      1. \n\n         1. \n         2. \n         3. \n\n      2. \n\n         ()\n\n         Q1,Q2,Q3\n\n         M\n\n         MinimumMaximum\n\n         - IQR = Q3 - Q1\n         - Minimum, Q3, M, Q1, Maximum\n\n         n-1.","source":"_posts/datamining-qualitative-induction.md","raw":"---\ntitle: -\ndate: 2016-12-08 21:31:50\ncategories: [programming]\ntags: [datamining, qualitative-induction, programming]\n---\n\n# \n\n1.    \n\n      ()\n\n      :() \n\n      roll up: \n\n      drill down: \n\n2.    \n\n      \n\n      ()()()\n\n      \n\n      1. \n\n         \n\n      2. \n\n         :()  \n\n      \n\n      1. \n\n         \n\n      2. \n\n      \n\n3.    \n\n      \n\n      1. \n\n      2. AOI\n\n         \n\n      3. \n\n         \n\n      4. \n\n      5. AOI\n\n          \n\n4.    \n\n      1. \n         1. \n\n         2. \n\n            ()\n\n         3. \n         4. \n         5. \n\n      2. t_weight - \n\n      3. d_weight - \n\n5.    \n\n      1. \n\n         1. \n         2. \n         3. \n\n      2. \n\n         ()\n\n         Q1,Q2,Q3\n\n         M\n\n         MinimumMaximum\n\n         - IQR = Q3 - Q1\n         - Minimum, Q3, M, Q1, Maximum\n\n         n-1.","slug":"datamining-qualitative-induction","published":1,"updated":"2016-12-23T06:55:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvro002opzm9lqoc7amw","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>()</p>\n<p>:() </p>\n<p>roll up: </p>\n<p>drill down: </p>\n</li>\n<li><p></p>\n<p></p>\n<p>()()()</p>\n<p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>:()  </p>\n</li>\n</ol>\n<p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<ol>\n<li><p></p>\n</li>\n<li><p>AOI</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>AOI</p>\n<p> </p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<ol>\n<li><p></p>\n</li>\n<li><p></p>\n<p>()</p>\n</li>\n<li><p></p>\n</li>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p>t_weight - </p>\n</li>\n<li><p>d_weight - </p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p></p>\n<p>()</p>\n<p>Q1,Q2,Q3</p>\n<p>M</p>\n<p>MinimumMaximum</p>\n<ul>\n<li>IQR = Q3 - Q1</li>\n<li>Minimum, Q3, M, Q1, Maximum</li>\n</ul>\n<p>n-1.</p>\n</li>\n</ol>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>()</p>\n<p>:() </p>\n<p>roll up: </p>\n<p>drill down: </p>\n</li>\n<li><p></p>\n<p></p>\n<p>()()()</p>\n<p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>:()  </p>\n</li>\n</ol>\n<p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<ol>\n<li><p></p>\n</li>\n<li><p>AOI</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>AOI</p>\n<p> </p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<ol>\n<li><p></p>\n</li>\n<li><p></p>\n<p>()</p>\n</li>\n<li><p></p>\n</li>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p>t_weight - </p>\n</li>\n<li><p>d_weight - </p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p></p>\n<p>()</p>\n<p>Q1,Q2,Q3</p>\n<p>M</p>\n<p>MinimumMaximum</p>\n<ul>\n<li>IQR = Q3 - Q1</li>\n<li>Minimum, Q3, M, Q1, Maximum</li>\n</ul>\n<p>n-1.</p>\n</li>\n</ol>\n</li>\n</ol>\n"},{"title":" graph","date":"2016-11-27T13:42:24.000Z","_content":"\n# The symbols\n\nIn graph thery, a graph G = (V, E) is a collection of points.\n\nV, called vertices and lines connecting some subset of them\n\nE, called edges, is contained by V  V\n\nUnion-Find\n\n# Others\n\nwiki\n\n[](https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA)\n\n\n\n>- [](https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95)(D.A)\n>- [](https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95)(K.A)\n>- [](https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95)(P.A)\n>- [](https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F)(TSA)\n>- [](https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84)(CPA)\n>- [](https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)([BFS](https://zh.wikipedia.org/wiki/BFS)'s A)\n>- [](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)([DFS](https://zh.wikipedia.org/wiki/DFS)'s A)\n\n","source":"_posts/graph.md","raw":"---\ntitle:  graph\ndate: 2016-11-27 14:42:24\ncategories: [programming]\ntags: [graph, algo, programming]\n---\n\n# The symbols\n\nIn graph thery, a graph G = (V, E) is a collection of points.\n\nV, called vertices and lines connecting some subset of them\n\nE, called edges, is contained by V  V\n\nUnion-Find\n\n# Others\n\nwiki\n\n[](https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA)\n\n\n\n>- [](https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95)(D.A)\n>- [](https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95)(K.A)\n>- [](https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95)(P.A)\n>- [](https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F)(TSA)\n>- [](https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84)(CPA)\n>- [](https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)([BFS](https://zh.wikipedia.org/wiki/BFS)'s A)\n>- [](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)([DFS](https://zh.wikipedia.org/wiki/DFS)'s A)\n\n","slug":"graph","published":1,"updated":"2017-02-11T12:08:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrp002rpzm9hg9vqse1","content":"<h1 id=\"The-symbols\"><a href=\"#The-symbols\" class=\"headerlink\" title=\"The symbols\"></a>The symbols</h1><p>In graph thery, a graph G = (V, E) is a collection of points.</p>\n<p>V, called vertices and lines connecting some subset of them</p>\n<p>E, called edges, is contained by V  V</p>\n<p>Union-Find</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><p>wiki</p>\n<p><a href=\"https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA\" target=\"_blank\" rel=\"external\"></a></p>\n<p></p>\n<blockquote>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"external\"></a>(D.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"external\"></a>(K.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"external\"></a>(P.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F\" target=\"_blank\" rel=\"external\"></a>(TSA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84\" target=\"_blank\" rel=\"external\"></a>(CPA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\" target=\"_blank\" rel=\"external\"></a>(<a href=\"https://zh.wikipedia.org/wiki/BFS\" target=\"_blank\" rel=\"external\">BFS</a>s A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\" target=\"_blank\" rel=\"external\"></a>(<a href=\"https://zh.wikipedia.org/wiki/DFS\" target=\"_blank\" rel=\"external\">DFS</a>s A)</li>\n</ul>\n</blockquote>\n","excerpt":"","more":"<h1 id=\"The-symbols\"><a href=\"#The-symbols\" class=\"headerlink\" title=\"The symbols\"></a>The symbols</h1><p>In graph thery, a graph G = (V, E) is a collection of points.</p>\n<p>V, called vertices and lines connecting some subset of them</p>\n<p>E, called edges, is contained by V  V</p>\n<p>Union-Find</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><p>wiki</p>\n<p><a href=\"https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA\"></a></p>\n<p></p>\n<blockquote>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95\"></a>(D.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95\"></a>(K.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95\"></a>(P.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F\"></a>(TSA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84\"></a>(CPA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\"></a>(<a href=\"https://zh.wikipedia.org/wiki/BFS\">BFS</a>s A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\"></a>(<a href=\"https://zh.wikipedia.org/wiki/DFS\">DFS</a>s A)</li>\n</ul>\n</blockquote>\n"},{"title":"hexo hexo with latex","date":"2016-11-30T21:19:02.000Z","_content":"\nhexohexomarkdownlatexmarkdownMarkdown\n\nGoogle[HexoMathJax](http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/)[hexo-renderer-kramed](https://github.com/sun11/hexo-renderer-kramed)fork hexo-renderer-marked MathJax\n\n\n\n\n\n```\n$ npm uninstall hexo-renderer-marked --save\n$ npm install hexo-renderer-kramed --save\n```\n\n\n\n","source":"_posts/hexo-with-latex.md","raw":"---\ntitle: hexo hexo with latex\ndate: 2016-11-30 22:19:02\ncategories: other\ntags: [hexo, latex, mathjax, marked]\n---\n\nhexohexomarkdownlatexmarkdownMarkdown\n\nGoogle[HexoMathJax](http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/)[hexo-renderer-kramed](https://github.com/sun11/hexo-renderer-kramed)fork hexo-renderer-marked MathJax\n\n\n\n\n\n```\n$ npm uninstall hexo-renderer-marked --save\n$ npm install hexo-renderer-kramed --save\n```\n\n\n\n","slug":"hexo-with-latex","published":1,"updated":"2016-11-30T21:45:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrq002upzm9fvw9l715","content":"<p>hexohexomarkdownlatexmarkdownMarkdown</p>\n<p>Google<a href=\"http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/\" target=\"_blank\" rel=\"external\">HexoMathJax</a><a href=\"https://github.com/sun11/hexo-renderer-kramed\" target=\"_blank\" rel=\"external\">hexo-renderer-kramed</a>fork hexo-renderer-marked MathJax</p>\n<p></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ npm uninstall hexo-renderer-marked --save</div><div class=\"line\">$ npm install hexo-renderer-kramed --save</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n","excerpt":"","more":"<p>hexohexomarkdownlatexmarkdownMarkdown</p>\n<p>Google<a href=\"http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/\">HexoMathJax</a><a href=\"https://github.com/sun11/hexo-renderer-kramed\">hexo-renderer-kramed</a>fork hexo-renderer-marked MathJax</p>\n<p></p>\n<p></p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ npm uninstall hexo-renderer-marked --save</div><div class=\"line\">$ npm install hexo-renderer-kramed --save</div></pre></td></tr></table></figure>\n<p></p>\n<p></p>\n"},{"title":"learning OS and building LorriOS","date":"2016-12-28T14:00:08.000Z","_content":"\ntoy OS?()toy os\n\nDayN\n\n----\n\nOS\n\n[](https://github.com/codeurJue/lorriOS)\n\n# Day1:\n\n30\n\nwinos xlinuxos xharibote.binmyos.img\n\n```shell\n# makefile\nmkdir -p /tmp/floppy\nmount -o loop myos.img /tmp/floppy -o fat=12 # mac\nsleep 1\ncp haribote.bin /tmp/floppy\nsleep 1\numount /tmp/floppy\n```\n\nOs x mountubuntuwin\n\n\\*Docker\n\n# Day2:\n\nORANGE'S\n\nxv6MITunixOS\n\nmacweb30winlinuxlinux= =\n\n# Day3:\n\nORANGEmacfreedos\n\n\n\n3216\n\n- GDT\n\n   GDT(Global Descriptor Table)GDTLGDTGDTR\n\n- Selector\n\n   GDTR\n\n- LDT\n\n   LDT(Local Descriptor Table)GDTGDTTIGDTGDTLDT\n\n\n\n1. GDTLDT\n2. \n3. GDT\n4. LDT\n5. \n\n\n\n\n\n# Day4:\n\n### \n\nIA324\n\n- LEVEL 0: \n- LEVEL 1, 2: \n- LEVEL 3: \n\nCPL(current privilege level)DPL(descriptor privilege level)RPL(requested privilege level)\n\nCPLcsss01CPLCPL\n\nDPL\n\nRPL01\n\nCPLRPLDPL\n\n### \n\njmpcall\n\n\n\n- \n- TSS\n- TSS\n\n\n\n-  Call gate\n-  Interrupt gate\n-  Trap gate\n-  Task gate\n\n# Day5:\n\n### \n\nint 15h \n\n\n\n32os\n\nPagingDemopushpoppushret\n\n\n\n### \n\nIDTIDT\n\n- \n- \n- \n\n# Day6:\n\n= =\n\n\n\n\n\n**GDTTSS**\n\n1. GDTLDTGDTGDT\n2. \n3. GDTTSSGDTTSS\n\n**GDTTSS**\n\n1. \n\n   \n\n2. \n\n   process.hglobal.c\n\n   \n\n   GDTLDTprotect.c\n\n3. GDTTSS\n\n   TSSprotect.h\n\n   GDTTSSprotect.c\n\n   TSStrkernel.asm\n\n****\n\n\n\n=> GDTTSSLDTTSS\n\n=> \n\n=>  ring0 -> ring1\n\n### \n\norangeminixtask_table\n\n1.  (proto.h)\n2. task_table (global.c)\n3. (++) (process.h)\n4. ","source":"_posts/learning-OS-and-building-LorriOS.md","raw":"---\ntitle: learning OS and building LorriOS\ndate: 2016-12-28 15:00:08\ncategories: [programming, unfinished]\ntags: [OS, kernel]\n---\n\ntoy OS?()toy os\n\nDayN\n\n----\n\nOS\n\n[](https://github.com/codeurJue/lorriOS)\n\n# Day1:\n\n30\n\nwinos xlinuxos xharibote.binmyos.img\n\n```shell\n# makefile\nmkdir -p /tmp/floppy\nmount -o loop myos.img /tmp/floppy -o fat=12 # mac\nsleep 1\ncp haribote.bin /tmp/floppy\nsleep 1\numount /tmp/floppy\n```\n\nOs x mountubuntuwin\n\n\\*Docker\n\n# Day2:\n\nORANGE'S\n\nxv6MITunixOS\n\nmacweb30winlinuxlinux= =\n\n# Day3:\n\nORANGEmacfreedos\n\n\n\n3216\n\n- GDT\n\n   GDT(Global Descriptor Table)GDTLGDTGDTR\n\n- Selector\n\n   GDTR\n\n- LDT\n\n   LDT(Local Descriptor Table)GDTGDTTIGDTGDTLDT\n\n\n\n1. GDTLDT\n2. \n3. GDT\n4. LDT\n5. \n\n\n\n\n\n# Day4:\n\n### \n\nIA324\n\n- LEVEL 0: \n- LEVEL 1, 2: \n- LEVEL 3: \n\nCPL(current privilege level)DPL(descriptor privilege level)RPL(requested privilege level)\n\nCPLcsss01CPLCPL\n\nDPL\n\nRPL01\n\nCPLRPLDPL\n\n### \n\njmpcall\n\n\n\n- \n- TSS\n- TSS\n\n\n\n-  Call gate\n-  Interrupt gate\n-  Trap gate\n-  Task gate\n\n# Day5:\n\n### \n\nint 15h \n\n\n\n32os\n\nPagingDemopushpoppushret\n\n\n\n### \n\nIDTIDT\n\n- \n- \n- \n\n# Day6:\n\n= =\n\n\n\n\n\n**GDTTSS**\n\n1. GDTLDTGDTGDT\n2. \n3. GDTTSSGDTTSS\n\n**GDTTSS**\n\n1. \n\n   \n\n2. \n\n   process.hglobal.c\n\n   \n\n   GDTLDTprotect.c\n\n3. GDTTSS\n\n   TSSprotect.h\n\n   GDTTSSprotect.c\n\n   TSStrkernel.asm\n\n****\n\n\n\n=> GDTTSSLDTTSS\n\n=> \n\n=>  ring0 -> ring1\n\n### \n\norangeminixtask_table\n\n1.  (proto.h)\n2. task_table (global.c)\n3. (++) (process.h)\n4. ","slug":"learning-OS-and-building-LorriOS","published":1,"updated":"2017-04-17T15:12:41.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrr002ypzm9mcvij53s","content":"<p>toy OS?()toy os</p>\n<p>DayN</p>\n<hr>\n<p>OS</p>\n<p><a href=\"https://github.com/codeurJue/lorriOS\" target=\"_blank\" rel=\"external\"></a></p>\n<h1 id=\"Day1\"><a href=\"#Day1\" class=\"headerlink\" title=\"Day1:\"></a>Day1:</h1><p>30</p>\n<p>winos xlinuxos xharibote.binmyos.img</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"># makefile</div><div class=\"line\">mkdir -p /tmp/floppy</div><div class=\"line\">mount -o loop myos.img /tmp/floppy -o fat=12 # mac</div><div class=\"line\">sleep 1</div><div class=\"line\">cp haribote.bin /tmp/floppy</div><div class=\"line\">sleep 1</div><div class=\"line\">umount /tmp/floppy</div></pre></td></tr></table></figure>\n<p>Os x mountubuntuwin</p>\n<p>*Docker</p>\n<h1 id=\"Day2\"><a href=\"#Day2\" class=\"headerlink\" title=\"Day2:\"></a>Day2:</h1><p>ORANGES</p>\n<p>xv6MITunixOS</p>\n<p>macweb30winlinuxlinux= =</p>\n<h1 id=\"Day3\"><a href=\"#Day3\" class=\"headerlink\" title=\"Day3:\"></a>Day3:</h1><p>ORANGEmacfreedos</p>\n<p></p>\n<p>3216</p>\n<ul>\n<li><p>GDT</p>\n<p> GDT(Global Descriptor Table)GDTLGDTGDTR</p>\n</li>\n<li><p>Selector</p>\n<p> GDTR</p>\n</li>\n<li><p>LDT</p>\n<p> LDT(Local Descriptor Table)GDTGDTTIGDTGDTLDT</p>\n</li>\n</ul>\n<p></p>\n<ol>\n<li>GDTLDT</li>\n<li></li>\n<li>GDT</li>\n<li>LDT</li>\n<li></li>\n</ol>\n<p></p>\n<p></p>\n<h1 id=\"Day4\"><a href=\"#Day4\" class=\"headerlink\" title=\"Day4:\"></a>Day4:</h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IA324</p>\n<ul>\n<li>LEVEL 0: </li>\n<li>LEVEL 1, 2: </li>\n<li>LEVEL 3: </li>\n</ul>\n<p>CPL(current privilege level)DPL(descriptor privilege level)RPL(requested privilege level)</p>\n<p>CPLcsss01CPLCPL</p>\n<p>DPL</p>\n<p>RPL01</p>\n<p>CPLRPLDPL</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>jmpcall</p>\n<p></p>\n<ul>\n<li></li>\n<li>TSS</li>\n<li>TSS</li>\n</ul>\n<p></p>\n<ul>\n<li> Call gate</li>\n<li> Interrupt gate</li>\n<li> Trap gate</li>\n<li> Task gate</li>\n</ul>\n<h1 id=\"Day5\"><a href=\"#Day5\" class=\"headerlink\" title=\"Day5:\"></a>Day5:</h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>int 15h </p>\n<p></p>\n<p>32os</p>\n<p>PagingDemopushpoppushret</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IDTIDT</p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h1 id=\"Day6\"><a href=\"#Day6\" class=\"headerlink\" title=\"Day6:\"></a>Day6:</h1><p>= =</p>\n<p></p>\n<p></p>\n<p><strong>GDTTSS</strong></p>\n<ol>\n<li>GDTLDTGDTGDT</li>\n<li></li>\n<li>GDTTSSGDTTSS</li>\n</ol>\n<p><strong>GDTTSS</strong></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>process.hglobal.c</p>\n<p></p>\n<p>GDTLDTprotect.c</p>\n</li>\n<li><p>GDTTSS</p>\n<p>TSSprotect.h</p>\n<p>GDTTSSprotect.c</p>\n<p>TSStrkernel.asm</p>\n</li>\n</ol>\n<p><strong></strong></p>\n<p></p>\n<p>=&gt; GDTTSSLDTTSS</p>\n<p>=&gt; </p>\n<p>=&gt;  ring0 -&gt; ring1</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>orangeminixtask_table</p>\n<ol>\n<li> (proto.h)</li>\n<li>task_table (global.c)</li>\n<li>(++) (process.h)</li>\n<li></li>\n</ol>\n","excerpt":"","more":"<p>toy OS?()toy os</p>\n<p>DayN</p>\n<hr>\n<p>OS</p>\n<p><a href=\"https://github.com/codeurJue/lorriOS\"></a></p>\n<h1 id=\"Day1\"><a href=\"#Day1\" class=\"headerlink\" title=\"Day1:\"></a>Day1:</h1><p>30</p>\n<p>winos xlinuxos xharibote.binmyos.img</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"># makefile</div><div class=\"line\">mkdir -p /tmp/floppy</div><div class=\"line\">mount -o loop myos.img /tmp/floppy -o fat=12 # mac</div><div class=\"line\">sleep 1</div><div class=\"line\">cp haribote.bin /tmp/floppy</div><div class=\"line\">sleep 1</div><div class=\"line\">umount /tmp/floppy</div></pre></td></tr></table></figure>\n<p>Os x mountubuntuwin</p>\n<p>*Docker</p>\n<h1 id=\"Day2\"><a href=\"#Day2\" class=\"headerlink\" title=\"Day2:\"></a>Day2:</h1><p>ORANGES</p>\n<p>xv6MITunixOS</p>\n<p>macweb30winlinuxlinux= =</p>\n<h1 id=\"Day3\"><a href=\"#Day3\" class=\"headerlink\" title=\"Day3:\"></a>Day3:</h1><p>ORANGEmacfreedos</p>\n<p></p>\n<p>3216</p>\n<ul>\n<li><p>GDT</p>\n<p> GDT(Global Descriptor Table)GDTLGDTGDTR</p>\n</li>\n<li><p>Selector</p>\n<p> GDTR</p>\n</li>\n<li><p>LDT</p>\n<p> LDT(Local Descriptor Table)GDTGDTTIGDTGDTLDT</p>\n</li>\n</ul>\n<p></p>\n<ol>\n<li>GDTLDT</li>\n<li></li>\n<li>GDT</li>\n<li>LDT</li>\n<li></li>\n</ol>\n<p></p>\n<p></p>\n<h1 id=\"Day4\"><a href=\"#Day4\" class=\"headerlink\" title=\"Day4:\"></a>Day4:</h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IA324</p>\n<ul>\n<li>LEVEL 0: </li>\n<li>LEVEL 1, 2: </li>\n<li>LEVEL 3: </li>\n</ul>\n<p>CPL(current privilege level)DPL(descriptor privilege level)RPL(requested privilege level)</p>\n<p>CPLcsss01CPLCPL</p>\n<p>DPL</p>\n<p>RPL01</p>\n<p>CPLRPLDPL</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>jmpcall</p>\n<p></p>\n<ul>\n<li></li>\n<li>TSS</li>\n<li>TSS</li>\n</ul>\n<p></p>\n<ul>\n<li> Call gate</li>\n<li> Interrupt gate</li>\n<li> Trap gate</li>\n<li> Task gate</li>\n</ul>\n<h1 id=\"Day5\"><a href=\"#Day5\" class=\"headerlink\" title=\"Day5:\"></a>Day5:</h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>int 15h </p>\n<p></p>\n<p>32os</p>\n<p>PagingDemopushpoppushret</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IDTIDT</p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h1 id=\"Day6\"><a href=\"#Day6\" class=\"headerlink\" title=\"Day6:\"></a>Day6:</h1><p>= =</p>\n<p></p>\n<p></p>\n<p><strong>GDTTSS</strong></p>\n<ol>\n<li>GDTLDTGDTGDT</li>\n<li></li>\n<li>GDTTSSGDTTSS</li>\n</ol>\n<p><strong>GDTTSS</strong></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>process.hglobal.c</p>\n<p></p>\n<p>GDTLDTprotect.c</p>\n</li>\n<li><p>GDTTSS</p>\n<p>TSSprotect.h</p>\n<p>GDTTSSprotect.c</p>\n<p>TSStrkernel.asm</p>\n</li>\n</ol>\n<p><strong></strong></p>\n<p></p>\n<p>=&gt; GDTTSSLDTTSS</p>\n<p>=&gt; </p>\n<p>=&gt;  ring0 -&gt; ring1</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>orangeminixtask_table</p>\n<ol>\n<li> (proto.h)</li>\n<li>task_table (global.c)</li>\n<li>(++) (process.h)</li>\n<li></li>\n</ol>\n"},{"title":"machine learning","date":"2016-12-12T21:04:47.000Z","_content":"\n# \n\n\n\n# \n\n[](http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&utm_medium=relatedPosts)","source":"_posts/machine-learning.md","raw":"---\ntitle: machine learning\ndate: 2016-12-12 22:04:47\ncategories: [programming, unfinished]\ntags: [machine-learning]\n---\n\n# \n\n\n\n# \n\n[](http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&utm_medium=relatedPosts)","slug":"machine-learning","published":1,"updated":"2016-12-12T21:07:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrs0031pzm9yz184apm","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><a href=\"http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&amp;utm_medium=relatedPosts\" target=\"_blank\" rel=\"external\"></a></p>\n","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><a href=\"http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&amp;utm_medium=relatedPosts\"></a></p>\n"},{"title":"","date":"2016-12-10T16:48:37.000Z","_content":"\nThis is the note of learning \"Management of the firm\", with the book of GESTION (ecole centrale paris).\n\n# The firm and the management\n\n## the firm\n\n1. the definition of the firm\n\n   - The company is an economic entity or a place of creation of value\n   - It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.\n   - It uses (destroys) resources (mobilized from partners)\n   - it generates positive or negative externalities on its environment\n2. the different types of resources used by the company\n\n   - The work, provided by employees who sell their working time\n   - Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:\n     1. Tangible resources ()\n     2. Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands\n     3. the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment\n3. the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)\n\n   - Design or R&D\n   - Manufacturing or production\n   - Marketing / sales\n   - Finance\n\n\n4. the importance of the company's relations with its partners in the framework of contracts and with its stakeholders more generally.\n\n   - The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the company's share capital\n   - With the sectoral communities (suppliers, distributors ...), economic (financiers, prescribers, ...) and social (legislation, populations);\n\n\n## The management\n\n1. the definitions of management\n\n   - Manages a planning / organization function and a control function (animation and evaluation) of the activity.\n   - POCCC: prevoir, organiser, commander, coordonner, controle\n\n2. the difference between the operational mode and the strategic management mode\n\n   - manage operationally :\n\n     to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.\n\n   - manage strategically:\n\n     to make sure that you do the right things (doing the right thing)\n\n     That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the company's balance sheet (stock).\n\n# Marketing\n\n**Things important:**\n\n- PESTEL:\n  - Policy, especially government stability and regulations.\n  - Economic, in particular state of the economic situation and economic situation\n  - Sociocultural, particularly demography and changing lifestyles.\n  - Technological, in particular public and private R&D expenditure.\n  - Ecological, in particular legislation on the protection of the environment\n  - Legal, in particular the law of competition and the law of labor.\n\n- SWOT model: \n  - Strengths - Internal\n  - Weaknesses - Internal\n  - Opportunities - External\n  - Threats - External\n\n- Marketing mix ()\n\n  4P => 4C: \n\n  - Product => Consumer wants and needs\n  - Price => Cost\n  - Promotion => communication\n  - Place (distribution) => Convenience\n\n1. the definition of marketing\n\n   - Aggregate of methods to adapt its offer to changing demand\n     - Assess and anticipate relevant changes \n     - Understand customers' needs and desires\n     - Act on supply and its perception\n   - But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.\n\n\n2. The difference between marketing and sales\n\n   - The marketing aims to facilitate and accompany the act of sale,\n\n   - The marketing Collects / Synthesizes Customer and Market Information\n\n   - The marketing helps to define offers (products / services) adapted to the customers\n\n   - The sales representative is in charge of the act of sale and the relationship with customers\n\n     Marketing provides elements for sales support.\n\n3. The distinction between strategic and operational marketing\n\n   - Strategic marketing is devoted to the conception of the offer: \n\n     It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.\n\n   - Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.\n\n4. Market segmentation\n\n   The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups\n\n# Strategy\n\n**things important:**\n\n- Tools and Analysis Methods\n\n| Level              | Internal Analysis                        | External Analysis                        |\n| ------------------ | ---------------------------------------- | ---------------------------------------- |\n| Corporate strategy | <p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p> | PESTEL                                   |\n| Business strategy  | <p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p> | <p>Porters 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p> |\n\n- **Porters 5 forces mode**\n\n  - Suppliers                ->     induxtry competitors\n  - Potential entrants ->\n  - Buyers                     ->\n  - Substitutes             ->\n\n- Strategic group map\n\n  Something like that below:\n\n  ^(high)\n\n  |            O\n\n  |                                                   O\n\n  |(low)>(high)\n\n- Product life circle (PLC)\n\n  1. market development\n  2. growth\n  3. maturity\n  4. decline\n\n- Key success factors\n\n  The factors we must have to compete in a market.\n\n  The rule of the game common to all players\n\n  The necessary conditions to compete in a market.\n\n  1. Segnentation \n  2. DAS ()\n  3. Stracgical activities areas\n\n- **Value chain analysis**\n\n| Support activities     |\n| ---------------------- |\n| Firm infrastructure    |\n| HR                     |\n| Technology Development |\n| Procurement            |\n\n  **Primary activities:**\n\n| Inbound logistics | Outbound logistics | Operations | Marketing | Service | Design |\n| ----------------- | ------------------ | ---------- | --------- | ------- | ------ |\n|                 |                  |          |         |       |      |\n\n- BCG matrix\n\n  market growth\n\n  ^(high)\n\n  |                       **Star**                                    **?**\n\n  |\n\n  |                        **Cow**                                   **Dog**()\n\n  |                                                \n\n  |(low)(high)>(low) market share\n\n1. Definition of strategy\n\n   A firms theory about how to excel in the game it is playing\n\n   A firms theory about how to create a unique position in the markets and industries within which it is operating\n\n2. Competitive advantage: doing different things\n\n3. Resource-based view (internal analysis)\n\n   - Human \n   - Physical \n   - Financial \n   - Organizational \n\n# Development of the firm\n\nGrowth orientations:\n\n1. Integration  \n2. Diversification  \n3. International strategies  \n\nModes of growth:\n\n1. Internal = organic growth\n   - Based on own funds\n   - Slower\n2. External\n   - Rapid market share, or competency gain\n   - Accelerator to grow internationally\n\n# Organizational structure\n\n1. Simple structure\n\n   Owner/Director -> Employees\n\n   - Taylorism\n   - Fayol\n\n2. Complex structure\n\n   - Functional\n\n     Ex: Finance, R&D, Communication, IT\n\n     - Advantages:\n\n        Specialization\n\n        Accumulation of experience\n\n     - Disadvantages:\n\n        Coordination and collaboration\n\n   - Divisional\n\n     \n\n     - Advantages\n\n        Coordination between functions\n\n        Responsibility of results better defined\n\n     - Disadvantages\n\n        Problem of reinventing the wheel\n\n        Internal competition\n\n   - Staff and line\n\n     staff\n\n     - Advantages:\n\n        Specialized expertise\n\n     - Disadvantages:\n\n        Conflict between staff and line\n\n   - Matrix \n\n     \n\n     - Advantages\n\n        Specialization and coordination are facilitated\n\n     - Disadvantages\n\n        Each employee has two bosses  \n\n        Decision making\n","source":"_posts/management-of-the-firm.md","raw":"---\ntitle: \ndate: 2016-12-10 17:48:37\ncategories: other\ntags: [management, firm]\n---\n\nThis is the note of learning \"Management of the firm\", with the book of GESTION (ecole centrale paris).\n\n# The firm and the management\n\n## the firm\n\n1. the definition of the firm\n\n   - The company is an economic entity or a place of creation of value\n   - It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.\n   - It uses (destroys) resources (mobilized from partners)\n   - it generates positive or negative externalities on its environment\n2. the different types of resources used by the company\n\n   - The work, provided by employees who sell their working time\n   - Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:\n     1. Tangible resources ()\n     2. Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands\n     3. the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment\n3. the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)\n\n   - Design or R&D\n   - Manufacturing or production\n   - Marketing / sales\n   - Finance\n\n\n4. the importance of the company's relations with its partners in the framework of contracts and with its stakeholders more generally.\n\n   - The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the company's share capital\n   - With the sectoral communities (suppliers, distributors ...), economic (financiers, prescribers, ...) and social (legislation, populations);\n\n\n## The management\n\n1. the definitions of management\n\n   - Manages a planning / organization function and a control function (animation and evaluation) of the activity.\n   - POCCC: prevoir, organiser, commander, coordonner, controle\n\n2. the difference between the operational mode and the strategic management mode\n\n   - manage operationally :\n\n     to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.\n\n   - manage strategically:\n\n     to make sure that you do the right things (doing the right thing)\n\n     That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the company's balance sheet (stock).\n\n# Marketing\n\n**Things important:**\n\n- PESTEL:\n  - Policy, especially government stability and regulations.\n  - Economic, in particular state of the economic situation and economic situation\n  - Sociocultural, particularly demography and changing lifestyles.\n  - Technological, in particular public and private R&D expenditure.\n  - Ecological, in particular legislation on the protection of the environment\n  - Legal, in particular the law of competition and the law of labor.\n\n- SWOT model: \n  - Strengths - Internal\n  - Weaknesses - Internal\n  - Opportunities - External\n  - Threats - External\n\n- Marketing mix ()\n\n  4P => 4C: \n\n  - Product => Consumer wants and needs\n  - Price => Cost\n  - Promotion => communication\n  - Place (distribution) => Convenience\n\n1. the definition of marketing\n\n   - Aggregate of methods to adapt its offer to changing demand\n     - Assess and anticipate relevant changes \n     - Understand customers' needs and desires\n     - Act on supply and its perception\n   - But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.\n\n\n2. The difference between marketing and sales\n\n   - The marketing aims to facilitate and accompany the act of sale,\n\n   - The marketing Collects / Synthesizes Customer and Market Information\n\n   - The marketing helps to define offers (products / services) adapted to the customers\n\n   - The sales representative is in charge of the act of sale and the relationship with customers\n\n     Marketing provides elements for sales support.\n\n3. The distinction between strategic and operational marketing\n\n   - Strategic marketing is devoted to the conception of the offer: \n\n     It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.\n\n   - Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.\n\n4. Market segmentation\n\n   The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups\n\n# Strategy\n\n**things important:**\n\n- Tools and Analysis Methods\n\n| Level              | Internal Analysis                        | External Analysis                        |\n| ------------------ | ---------------------------------------- | ---------------------------------------- |\n| Corporate strategy | <p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p> | PESTEL                                   |\n| Business strategy  | <p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p> | <p>Porters 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p> |\n\n- **Porters 5 forces mode**\n\n  - Suppliers                ->     induxtry competitors\n  - Potential entrants ->\n  - Buyers                     ->\n  - Substitutes             ->\n\n- Strategic group map\n\n  Something like that below:\n\n  ^(high)\n\n  |            O\n\n  |                                                   O\n\n  |(low)>(high)\n\n- Product life circle (PLC)\n\n  1. market development\n  2. growth\n  3. maturity\n  4. decline\n\n- Key success factors\n\n  The factors we must have to compete in a market.\n\n  The rule of the game common to all players\n\n  The necessary conditions to compete in a market.\n\n  1. Segnentation \n  2. DAS ()\n  3. Stracgical activities areas\n\n- **Value chain analysis**\n\n| Support activities     |\n| ---------------------- |\n| Firm infrastructure    |\n| HR                     |\n| Technology Development |\n| Procurement            |\n\n  **Primary activities:**\n\n| Inbound logistics | Outbound logistics | Operations | Marketing | Service | Design |\n| ----------------- | ------------------ | ---------- | --------- | ------- | ------ |\n|                 |                  |          |         |       |      |\n\n- BCG matrix\n\n  market growth\n\n  ^(high)\n\n  |                       **Star**                                    **?**\n\n  |\n\n  |                        **Cow**                                   **Dog**()\n\n  |                                                \n\n  |(low)(high)>(low) market share\n\n1. Definition of strategy\n\n   A firms theory about how to excel in the game it is playing\n\n   A firms theory about how to create a unique position in the markets and industries within which it is operating\n\n2. Competitive advantage: doing different things\n\n3. Resource-based view (internal analysis)\n\n   - Human \n   - Physical \n   - Financial \n   - Organizational \n\n# Development of the firm\n\nGrowth orientations:\n\n1. Integration  \n2. Diversification  \n3. International strategies  \n\nModes of growth:\n\n1. Internal = organic growth\n   - Based on own funds\n   - Slower\n2. External\n   - Rapid market share, or competency gain\n   - Accelerator to grow internationally\n\n# Organizational structure\n\n1. Simple structure\n\n   Owner/Director -> Employees\n\n   - Taylorism\n   - Fayol\n\n2. Complex structure\n\n   - Functional\n\n     Ex: Finance, R&D, Communication, IT\n\n     - Advantages:\n\n        Specialization\n\n        Accumulation of experience\n\n     - Disadvantages:\n\n        Coordination and collaboration\n\n   - Divisional\n\n     \n\n     - Advantages\n\n        Coordination between functions\n\n        Responsibility of results better defined\n\n     - Disadvantages\n\n        Problem of reinventing the wheel\n\n        Internal competition\n\n   - Staff and line\n\n     staff\n\n     - Advantages:\n\n        Specialized expertise\n\n     - Disadvantages:\n\n        Conflict between staff and line\n\n   - Matrix \n\n     \n\n     - Advantages\n\n        Specialization and coordination are facilitated\n\n     - Disadvantages\n\n        Each employee has two bosses  \n\n        Decision making\n","slug":"management-of-the-firm","published":1,"updated":"2016-12-13T21:26:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvru0036pzm9769rghce","content":"<p>This is the note of learning Management of the firm, with the book of GESTION (ecole centrale paris).</p>\n<h1 id=\"The-firm-and-the-management\"><a href=\"#The-firm-and-the-management\" class=\"headerlink\" title=\"The firm and the management\"></a>The firm and the management</h1><h2 id=\"the-firm\"><a href=\"#the-firm\" class=\"headerlink\" title=\"the firm\"></a>the firm</h2><ol>\n<li><p>the definition of the firm</p>\n<ul>\n<li>The company is an economic entity or a place of creation of value</li>\n<li>It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.</li>\n<li>It uses (destroys) resources (mobilized from partners)</li>\n<li>it generates positive or negative externalities on its environment</li>\n</ul>\n</li>\n<li><p>the different types of resources used by the company</p>\n<ul>\n<li>The work, provided by employees who sell their working time</li>\n<li>Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:<ol>\n<li>Tangible resources ()</li>\n<li>Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands</li>\n<li>the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)</p>\n<ul>\n<li>Design or R&amp;D</li>\n<li>Manufacturing or production</li>\n<li>Marketing / sales</li>\n<li>Finance</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>the importance of the companys relations with its partners in the framework of contracts and with its stakeholders more generally.</p>\n<ul>\n<li>The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the companys share capital</li>\n<li>With the sectoral communities (suppliers, distributors ), economic (financiers, prescribers, ) and social (legislation, populations);</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"The-management\"><a href=\"#The-management\" class=\"headerlink\" title=\"The management\"></a>The management</h2><ol>\n<li><p>the definitions of management</p>\n<ul>\n<li>Manages a planning / organization function and a control function (animation and evaluation) of the activity.</li>\n<li>POCCC: prevoir, organiser, commander, coordonner, controle</li>\n</ul>\n</li>\n<li><p>the difference between the operational mode and the strategic management mode</p>\n<ul>\n<li><p>manage operationally :</p>\n<p>to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.</p>\n</li>\n<li><p>manage strategically:</p>\n<p>to make sure that you do the right things (doing the right thing)</p>\n<p>That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the companys balance sheet (stock).</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Marketing\"><a href=\"#Marketing\" class=\"headerlink\" title=\"Marketing\"></a>Marketing</h1><p><strong>Things important:</strong></p>\n<ul>\n<li><p>PESTEL:</p>\n<ul>\n<li>Policy, especially government stability and regulations.</li>\n<li>Economic, in particular state of the economic situation and economic situation</li>\n<li>Sociocultural, particularly demography and changing lifestyles.</li>\n<li>Technological, in particular public and private R&amp;D expenditure.</li>\n<li>Ecological, in particular legislation on the protection of the environment</li>\n<li>Legal, in particular the law of competition and the law of labor.</li>\n</ul>\n</li>\n<li><p>SWOT model: </p>\n<ul>\n<li>Strengths - Internal</li>\n<li>Weaknesses - Internal</li>\n<li>Opportunities - External</li>\n<li>Threats - External</li>\n</ul>\n</li>\n<li><p>Marketing mix ()</p>\n<p>4P =&gt; 4C: </p>\n<ul>\n<li>Product =&gt; Consumer wants and needs</li>\n<li>Price =&gt; Cost</li>\n<li>Promotion =&gt; communication</li>\n<li>Place (distribution) =&gt; Convenience</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li><p>the definition of marketing</p>\n<ul>\n<li>Aggregate of methods to adapt its offer to changing demand<ul>\n<li>Assess and anticipate relevant changes </li>\n<li>Understand customers needs and desires</li>\n<li>Act on supply and its perception</li>\n</ul>\n</li>\n<li>But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>The difference between marketing and sales</p>\n<ul>\n<li><p>The marketing aims to facilitate and accompany the act of sale,</p>\n</li>\n<li><p>The marketing Collects / Synthesizes Customer and Market Information</p>\n</li>\n<li><p>The marketing helps to define offers (products / services) adapted to the customers</p>\n</li>\n<li><p>The sales representative is in charge of the act of sale and the relationship with customers</p>\n<p>Marketing provides elements for sales support.</p>\n</li>\n</ul>\n</li>\n<li><p>The distinction between strategic and operational marketing</p>\n<ul>\n<li><p>Strategic marketing is devoted to the conception of the offer: </p>\n<p>It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.</p>\n</li>\n<li><p>Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.</p>\n</li>\n</ul>\n</li>\n<li><p>Market segmentation</p>\n<p>The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups</p>\n</li>\n</ol>\n<h1 id=\"Strategy\"><a href=\"#Strategy\" class=\"headerlink\" title=\"Strategy\"></a>Strategy</h1><p><strong>things important:</strong></p>\n<ul>\n<li>Tools and Analysis Methods</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Level</th>\n<th>Internal Analysis</th>\n<th>External Analysis</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Corporate strategy</td>\n<td><p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p></td>\n<td>PESTEL</td>\n</tr>\n<tr>\n<td>Business strategy</td>\n<td><p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p></td>\n<td><p>Porters 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p><strong>Porters 5 forces mode</strong></p>\n<ul>\n<li>Suppliers                -&gt;     induxtry competitors</li>\n<li>Potential entrants -&gt;</li>\n<li>Buyers                     -&gt;</li>\n<li>Substitutes             -&gt;</li>\n</ul>\n</li>\n<li><p>Strategic group map</p>\n<p>Something like that below:</p>\n<p>^(high)</p>\n<p>|            O</p>\n<p>|                                                   O</p>\n<p>|(low)&gt;(high)</p>\n</li>\n<li><p>Product life circle (PLC)</p>\n<ol>\n<li>market development</li>\n<li>growth</li>\n<li>maturity</li>\n<li>decline</li>\n</ol>\n</li>\n<li><p>Key success factors</p>\n<p>The factors we must have to compete in a market.</p>\n<p>The rule of the game common to all players</p>\n<p>The necessary conditions to compete in a market.</p>\n<ol>\n<li>Segnentation </li>\n<li>DAS ()</li>\n<li>Stracgical activities areas</li>\n</ol>\n</li>\n<li><p><strong>Value chain analysis</strong></p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Support activities</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Firm infrastructure</td>\n</tr>\n<tr>\n<td>HR</td>\n</tr>\n<tr>\n<td>Technology Development</td>\n</tr>\n<tr>\n<td>Procurement</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>  <strong>Primary activities:</strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Inbound logistics</th>\n<th>Outbound logistics</th>\n<th>Operations</th>\n<th>Marketing</th>\n<th>Service</th>\n<th>Design</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p>BCG matrix</p>\n<p>market growth</p>\n<p>^(high)</p>\n<p>|                       <strong>Star</strong>                                    <strong>?</strong></p>\n<p>|</p>\n<p>|                        <strong>Cow</strong>                                   <strong>Dog</strong>()</p>\n<p>|                                                </p>\n<p>|(low)(high)&gt;(low) market share</p>\n</li>\n</ul>\n<ol>\n<li><p>Definition of strategy</p>\n<p>A firms theory about how to excel in the game it is playing</p>\n<p>A firms theory about how to create a unique position in the markets and industries within which it is operating</p>\n</li>\n<li><p>Competitive advantage: doing different things</p>\n</li>\n<li><p>Resource-based view (internal analysis)</p>\n<ul>\n<li>Human </li>\n<li>Physical </li>\n<li>Financial </li>\n<li>Organizational </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Development-of-the-firm\"><a href=\"#Development-of-the-firm\" class=\"headerlink\" title=\"Development of the firm\"></a>Development of the firm</h1><p>Growth orientations:</p>\n<ol>\n<li>Integration  </li>\n<li>Diversification  </li>\n<li>International strategies  </li>\n</ol>\n<p>Modes of growth:</p>\n<ol>\n<li>Internal = organic growth<ul>\n<li>Based on own funds</li>\n<li>Slower</li>\n</ul>\n</li>\n<li>External<ul>\n<li>Rapid market share, or competency gain</li>\n<li>Accelerator to grow internationally</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Organizational-structure\"><a href=\"#Organizational-structure\" class=\"headerlink\" title=\"Organizational structure\"></a>Organizational structure</h1><ol>\n<li><p>Simple structure</p>\n<p>Owner/Director -&gt; Employees</p>\n<ul>\n<li>Taylorism</li>\n<li>Fayol</li>\n</ul>\n</li>\n<li><p>Complex structure</p>\n<ul>\n<li><p>Functional</p>\n<p>Ex: Finance, R&amp;D, Communication, IT</p>\n<ul>\n<li><p>Advantages:</p>\n<p> Specialization</p>\n<p> Accumulation of experience</p>\n</li>\n<li><p>Disadvantages:</p>\n<p> Coordination and collaboration</p>\n</li>\n</ul>\n</li>\n<li><p>Divisional</p>\n<p></p>\n<ul>\n<li><p>Advantages</p>\n<p> Coordination between functions</p>\n<p> Responsibility of results better defined</p>\n</li>\n<li><p>Disadvantages</p>\n<p> Problem of reinventing the wheel</p>\n<p> Internal competition</p>\n</li>\n</ul>\n</li>\n<li><p>Staff and line</p>\n<p>staff</p>\n<ul>\n<li><p>Advantages:</p>\n<p> Specialized expertise</p>\n</li>\n<li><p>Disadvantages:</p>\n<p> Conflict between staff and line</p>\n</li>\n</ul>\n</li>\n<li><p>Matrix </p>\n<p></p>\n<ul>\n<li><p>Advantages</p>\n<p> Specialization and coordination are facilitated</p>\n</li>\n<li><p>Disadvantages</p>\n<p> Each employee has two bosses  </p>\n<p> Decision making</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<p>This is the note of learning Management of the firm, with the book of GESTION (ecole centrale paris).</p>\n<h1 id=\"The-firm-and-the-management\"><a href=\"#The-firm-and-the-management\" class=\"headerlink\" title=\"The firm and the management\"></a>The firm and the management</h1><h2 id=\"the-firm\"><a href=\"#the-firm\" class=\"headerlink\" title=\"the firm\"></a>the firm</h2><ol>\n<li><p>the definition of the firm</p>\n<ul>\n<li>The company is an economic entity or a place of creation of value</li>\n<li>It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.</li>\n<li>It uses (destroys) resources (mobilized from partners)</li>\n<li>it generates positive or negative externalities on its environment</li>\n</ul>\n</li>\n<li><p>the different types of resources used by the company</p>\n<ul>\n<li>The work, provided by employees who sell their working time</li>\n<li>Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:<ol>\n<li>Tangible resources ()</li>\n<li>Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands</li>\n<li>the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)</p>\n<ul>\n<li>Design or R&amp;D</li>\n<li>Manufacturing or production</li>\n<li>Marketing / sales</li>\n<li>Finance</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>the importance of the companys relations with its partners in the framework of contracts and with its stakeholders more generally.</p>\n<ul>\n<li>The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the companys share capital</li>\n<li>With the sectoral communities (suppliers, distributors ), economic (financiers, prescribers, ) and social (legislation, populations);</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"The-management\"><a href=\"#The-management\" class=\"headerlink\" title=\"The management\"></a>The management</h2><ol>\n<li><p>the definitions of management</p>\n<ul>\n<li>Manages a planning / organization function and a control function (animation and evaluation) of the activity.</li>\n<li>POCCC: prevoir, organiser, commander, coordonner, controle</li>\n</ul>\n</li>\n<li><p>the difference between the operational mode and the strategic management mode</p>\n<ul>\n<li><p>manage operationally :</p>\n<p>to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.</p>\n</li>\n<li><p>manage strategically:</p>\n<p>to make sure that you do the right things (doing the right thing)</p>\n<p>That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the companys balance sheet (stock).</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Marketing\"><a href=\"#Marketing\" class=\"headerlink\" title=\"Marketing\"></a>Marketing</h1><p><strong>Things important:</strong></p>\n<ul>\n<li><p>PESTEL:</p>\n<ul>\n<li>Policy, especially government stability and regulations.</li>\n<li>Economic, in particular state of the economic situation and economic situation</li>\n<li>Sociocultural, particularly demography and changing lifestyles.</li>\n<li>Technological, in particular public and private R&amp;D expenditure.</li>\n<li>Ecological, in particular legislation on the protection of the environment</li>\n<li>Legal, in particular the law of competition and the law of labor.</li>\n</ul>\n</li>\n<li><p>SWOT model: </p>\n<ul>\n<li>Strengths - Internal</li>\n<li>Weaknesses - Internal</li>\n<li>Opportunities - External</li>\n<li>Threats - External</li>\n</ul>\n</li>\n<li><p>Marketing mix ()</p>\n<p>4P =&gt; 4C: </p>\n<ul>\n<li>Product =&gt; Consumer wants and needs</li>\n<li>Price =&gt; Cost</li>\n<li>Promotion =&gt; communication</li>\n<li>Place (distribution) =&gt; Convenience</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li><p>the definition of marketing</p>\n<ul>\n<li>Aggregate of methods to adapt its offer to changing demand<ul>\n<li>Assess and anticipate relevant changes </li>\n<li>Understand customers needs and desires</li>\n<li>Act on supply and its perception</li>\n</ul>\n</li>\n<li>But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>The difference between marketing and sales</p>\n<ul>\n<li><p>The marketing aims to facilitate and accompany the act of sale,</p>\n</li>\n<li><p>The marketing Collects / Synthesizes Customer and Market Information</p>\n</li>\n<li><p>The marketing helps to define offers (products / services) adapted to the customers</p>\n</li>\n<li><p>The sales representative is in charge of the act of sale and the relationship with customers</p>\n<p>Marketing provides elements for sales support.</p>\n</li>\n</ul>\n</li>\n<li><p>The distinction between strategic and operational marketing</p>\n<ul>\n<li><p>Strategic marketing is devoted to the conception of the offer: </p>\n<p>It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.</p>\n</li>\n<li><p>Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.</p>\n</li>\n</ul>\n</li>\n<li><p>Market segmentation</p>\n<p>The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups</p>\n</li>\n</ol>\n<h1 id=\"Strategy\"><a href=\"#Strategy\" class=\"headerlink\" title=\"Strategy\"></a>Strategy</h1><p><strong>things important:</strong></p>\n<ul>\n<li>Tools and Analysis Methods</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Level</th>\n<th>Internal Analysis</th>\n<th>External Analysis</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Corporate strategy</td>\n<td><p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p></td>\n<td>PESTEL</td>\n</tr>\n<tr>\n<td>Business strategy</td>\n<td><p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p></td>\n<td><p>Porters 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p><strong>Porters 5 forces mode</strong></p>\n<ul>\n<li>Suppliers                -&gt;     induxtry competitors</li>\n<li>Potential entrants -&gt;</li>\n<li>Buyers                     -&gt;</li>\n<li>Substitutes             -&gt;</li>\n</ul>\n</li>\n<li><p>Strategic group map</p>\n<p>Something like that below:</p>\n<p>^(high)</p>\n<p>|            O</p>\n<p>|                                                   O</p>\n<p>|(low)&gt;(high)</p>\n</li>\n<li><p>Product life circle (PLC)</p>\n<ol>\n<li>market development</li>\n<li>growth</li>\n<li>maturity</li>\n<li>decline</li>\n</ol>\n</li>\n<li><p>Key success factors</p>\n<p>The factors we must have to compete in a market.</p>\n<p>The rule of the game common to all players</p>\n<p>The necessary conditions to compete in a market.</p>\n<ol>\n<li>Segnentation </li>\n<li>DAS ()</li>\n<li>Stracgical activities areas</li>\n</ol>\n</li>\n<li><p><strong>Value chain analysis</strong></p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Support activities</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Firm infrastructure</td>\n</tr>\n<tr>\n<td>HR</td>\n</tr>\n<tr>\n<td>Technology Development</td>\n</tr>\n<tr>\n<td>Procurement</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>  <strong>Primary activities:</strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Inbound logistics</th>\n<th>Outbound logistics</th>\n<th>Operations</th>\n<th>Marketing</th>\n<th>Service</th>\n<th>Design</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p>BCG matrix</p>\n<p>market growth</p>\n<p>^(high)</p>\n<p>|                       <strong>Star</strong>                                    <strong>?</strong></p>\n<p>|</p>\n<p>|                        <strong>Cow</strong>                                   <strong>Dog</strong>()</p>\n<p>|                                                </p>\n<p>|(low)(high)&gt;(low) market share</p>\n</li>\n</ul>\n<ol>\n<li><p>Definition of strategy</p>\n<p>A firms theory about how to excel in the game it is playing</p>\n<p>A firms theory about how to create a unique position in the markets and industries within which it is operating</p>\n</li>\n<li><p>Competitive advantage: doing different things</p>\n</li>\n<li><p>Resource-based view (internal analysis)</p>\n<ul>\n<li>Human </li>\n<li>Physical </li>\n<li>Financial </li>\n<li>Organizational </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Development-of-the-firm\"><a href=\"#Development-of-the-firm\" class=\"headerlink\" title=\"Development of the firm\"></a>Development of the firm</h1><p>Growth orientations:</p>\n<ol>\n<li>Integration  </li>\n<li>Diversification  </li>\n<li>International strategies  </li>\n</ol>\n<p>Modes of growth:</p>\n<ol>\n<li>Internal = organic growth<ul>\n<li>Based on own funds</li>\n<li>Slower</li>\n</ul>\n</li>\n<li>External<ul>\n<li>Rapid market share, or competency gain</li>\n<li>Accelerator to grow internationally</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Organizational-structure\"><a href=\"#Organizational-structure\" class=\"headerlink\" title=\"Organizational structure\"></a>Organizational structure</h1><ol>\n<li><p>Simple structure</p>\n<p>Owner/Director -&gt; Employees</p>\n<ul>\n<li>Taylorism</li>\n<li>Fayol</li>\n</ul>\n</li>\n<li><p>Complex structure</p>\n<ul>\n<li><p>Functional</p>\n<p>Ex: Finance, R&amp;D, Communication, IT</p>\n<ul>\n<li><p>Advantages:</p>\n<p> Specialization</p>\n<p> Accumulation of experience</p>\n</li>\n<li><p>Disadvantages:</p>\n<p> Coordination and collaboration</p>\n</li>\n</ul>\n</li>\n<li><p>Divisional</p>\n<p></p>\n<ul>\n<li><p>Advantages</p>\n<p> Coordination between functions</p>\n<p> Responsibility of results better defined</p>\n</li>\n<li><p>Disadvantages</p>\n<p> Problem of reinventing the wheel</p>\n<p> Internal competition</p>\n</li>\n</ul>\n</li>\n<li><p>Staff and line</p>\n<p>staff</p>\n<ul>\n<li><p>Advantages:</p>\n<p> Specialized expertise</p>\n</li>\n<li><p>Disadvantages:</p>\n<p> Conflict between staff and line</p>\n</li>\n</ul>\n</li>\n<li><p>Matrix </p>\n<p></p>\n<ul>\n<li><p>Advantages</p>\n<p> Specialization and coordination are facilitated</p>\n</li>\n<li><p>Disadvantages</p>\n<p> Each employee has two bosses  </p>\n<p> Decision making</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n"},{"title":"participe prsent et grondif","date":"2016-12-06T11:31:56.000Z","_content":"\n# (le participe prsent)\n\n## 1. \n\n\n-ons-ant \n\n- faire : nous faisons \n\n\n- etre-etant \n- savoir-sachant\n\n## 2. \n1. qui\n   - L'tranger cherche  trouver quelqu'un **connaissant** (=qui conaisse)  la fois franais et l'anglais.\n2. \n   - **Voyant**(=Comme elle voit) que tout le monde est dej assis,elle va vite  sa place.\n   - **Ayant**(=Comme il a) mal  la tete,il dcide de rester au lit.\n\n## 3. \n### I. \n\n1. \n   - Ses yeux **brillants** disent la convoitises. \n   - Je l'ai trouv toute **tremblante**. \n\n2. \n\n   - Une seance **payante** (=o l'on paie) \n   - une collation **soupante** (=si copieuse qu'elle tient lieu de souper) \n\n   \n\n3. \n\n|        |        |\n| ---------- | --------- |\n| provoquant | provocant |\n| fatiguant  | fatigant  |\n| vaquant    | vacant    |\n| naviguant  | navigant  |\n\n\n### II. \n\n\n\n1. qui\n   - C'est un film **captivant** les spectateurs. \n   - Je le vois **lisant**. \n2. \n   - **Prenant** l'escabeau, il s'offoree d'atteindre le dernier rayon. \n   - **Croyant** le bureau vide, il entra. \n3. \n   - Le train repartit, **courant** vers le Midi. \n4. \n   - Midi **sonnant**, on se met  table. \n\n\n\n\n# (le grondif)\n\n## 1. \n\n\nen \n\n- faire : en faisant\n\nayanttanten\n\n## 2. \n1. \n   - N'oubliez pas de fermer la port **en sortant**.\n   - Ne lis pas **en mangeant**. \n2. \n   - Elle arriva **en courant**. \n3. \n   - **En se levant** plus tot le matin, il n'arrivera pas en retard. \n4. \n   - **En voyant** critiquant, il n'avait nulle intention de nous dcourager. \n5. \n   - **En voyant** son embarras, l'agent se fit plus aimable. \n\n**\\***\n\nalleren\n\n- Sa vue va **en s'affaiblissant**. \n\n## 3. \n\n1. Tous + \n2. Rien que + \n\n\n\n\n\n# \n\n## \n\n\n\n## \n\n1. \n\n\\*\n\n- La fortune vient **en dormant**. \n\n\n2. \n\n","source":"_posts/participe-present-et-gerondif.md","raw":"---\ntitle: participe prsent et grondif\ndate: 2016-12-06 12:31:56\ncategories: francais\ntags: [francais, language]\n---\n\n# (le participe prsent)\n\n## 1. \n\n\n-ons-ant \n\n- faire : nous faisons \n\n\n- etre-etant \n- savoir-sachant\n\n## 2. \n1. qui\n   - L'tranger cherche  trouver quelqu'un **connaissant** (=qui conaisse)  la fois franais et l'anglais.\n2. \n   - **Voyant**(=Comme elle voit) que tout le monde est dej assis,elle va vite  sa place.\n   - **Ayant**(=Comme il a) mal  la tete,il dcide de rester au lit.\n\n## 3. \n### I. \n\n1. \n   - Ses yeux **brillants** disent la convoitises. \n   - Je l'ai trouv toute **tremblante**. \n\n2. \n\n   - Une seance **payante** (=o l'on paie) \n   - une collation **soupante** (=si copieuse qu'elle tient lieu de souper) \n\n   \n\n3. \n\n|        |        |\n| ---------- | --------- |\n| provoquant | provocant |\n| fatiguant  | fatigant  |\n| vaquant    | vacant    |\n| naviguant  | navigant  |\n\n\n### II. \n\n\n\n1. qui\n   - C'est un film **captivant** les spectateurs. \n   - Je le vois **lisant**. \n2. \n   - **Prenant** l'escabeau, il s'offoree d'atteindre le dernier rayon. \n   - **Croyant** le bureau vide, il entra. \n3. \n   - Le train repartit, **courant** vers le Midi. \n4. \n   - Midi **sonnant**, on se met  table. \n\n\n\n\n# (le grondif)\n\n## 1. \n\n\nen \n\n- faire : en faisant\n\nayanttanten\n\n## 2. \n1. \n   - N'oubliez pas de fermer la port **en sortant**.\n   - Ne lis pas **en mangeant**. \n2. \n   - Elle arriva **en courant**. \n3. \n   - **En se levant** plus tot le matin, il n'arrivera pas en retard. \n4. \n   - **En voyant** critiquant, il n'avait nulle intention de nous dcourager. \n5. \n   - **En voyant** son embarras, l'agent se fit plus aimable. \n\n**\\***\n\nalleren\n\n- Sa vue va **en s'affaiblissant**. \n\n## 3. \n\n1. Tous + \n2. Rien que + \n\n\n\n\n\n# \n\n## \n\n\n\n## \n\n1. \n\n\\*\n\n- La fortune vient **en dormant**. \n\n\n2. \n\n","slug":"participe-present-et-gerondif","published":1,"updated":"2016-12-13T21:28:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrv0039pzm9g9rbtp6g","content":"<h1 id=\"-le-participe-present\"><a href=\"#-le-participe-present\" class=\"headerlink\" title=\"(le participe prsent)\"></a>(le participe prsent)</h1><h2 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<p>-ons-ant </p>\n<ul>\n<li>faire : nous faisons </li>\n</ul>\n<p></p>\n<ul>\n<li>etre-etant </li>\n<li>savoir-sachant</li>\n</ul>\n<h2 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h2><ol>\n<li>qui<ul>\n<li>Ltranger cherche  trouver quelquun <strong>connaissant</strong> (=qui conaisse)  la fois franais et langlais.</li>\n</ul>\n</li>\n<li><ul>\n<li><strong>Voyant</strong>(=Comme elle voit) que tout le monde est dej assis,elle va vite  sa place.</li>\n<li><strong>Ayant</strong>(=Comme il a) mal  la tete,il dcide de rester au lit.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h2><h3 id=\"I-\"><a href=\"#I-\" class=\"headerlink\" title=\"I. \"></a>I. </h3><p></p>\n<ol>\n<li><p></p>\n<ul>\n<li>Ses yeux <strong>brillants</strong> disent la convoitises. </li>\n<li>Je lai trouv toute <strong>tremblante</strong>. </li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>Une seance <strong>payante</strong> (=o lon paie) </li>\n<li>une collation <strong>soupante</strong> (=si copieuse quelle tient lieu de souper) </li>\n</ul>\n<p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>provoquant</td>\n<td>provocant</td>\n</tr>\n<tr>\n<td>fatiguant</td>\n<td>fatigant</td>\n</tr>\n<tr>\n<td>vaquant</td>\n<td>vacant</td>\n</tr>\n<tr>\n<td>naviguant</td>\n<td>navigant</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"II-\"><a href=\"#II-\" class=\"headerlink\" title=\"II. \"></a>II. </h3><p></p>\n<ol>\n<li>qui<ul>\n<li>Cest un film <strong>captivant</strong> les spectateurs. </li>\n<li>Je le vois <strong>lisant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>Prenant</strong> lescabeau, il sofforee datteindre le dernier rayon. </li>\n<li><strong>Croyant</strong> le bureau vide, il entra. </li>\n</ul>\n</li>\n<li><ul>\n<li>Le train repartit, <strong>courant</strong> vers le Midi. </li>\n</ul>\n</li>\n<li><ul>\n<li>Midi <strong>sonnant</strong>, on se met  table. </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"-le-gerondif\"><a href=\"#-le-gerondif\" class=\"headerlink\" title=\"(le grondif)\"></a>(le grondif)</h1><h2 id=\"1--1\"><a href=\"#1--1\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<p>en </p>\n<ul>\n<li>faire : en faisant</li>\n</ul>\n<p>ayanttanten</p>\n<h2 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h2><ol>\n<li><ul>\n<li>Noubliez pas de fermer la port <strong>en sortant</strong>.</li>\n<li>Ne lis pas <strong>en mangeant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li>Elle arriva <strong>en courant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En se levant</strong> plus tot le matin, il narrivera pas en retard. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En voyant</strong> critiquant, il navait nulle intention de nous dcourager. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En voyant</strong> son embarras, lagent se fit plus aimable. </li>\n</ul>\n</li>\n</ol>\n<p><strong>*</strong></p>\n<p>alleren</p>\n<ul>\n<li>Sa vue va <strong>en saffaiblissant</strong>. </li>\n</ul>\n<h2 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h2><ol>\n<li>Tous + </li>\n<li>Rien que + </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li></li>\n</ol>\n<p>*</p>\n<ul>\n<li>La fortune vient <strong>en dormant</strong>. </li>\n</ul>\n<ol>\n<li></li>\n</ol>\n","excerpt":"","more":"<h1 id=\"-le-participe-present\"><a href=\"#-le-participe-present\" class=\"headerlink\" title=\"(le participe prsent)\"></a>(le participe prsent)</h1><h2 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<p>-ons-ant </p>\n<ul>\n<li>faire : nous faisons </li>\n</ul>\n<p></p>\n<ul>\n<li>etre-etant </li>\n<li>savoir-sachant</li>\n</ul>\n<h2 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h2><ol>\n<li>qui<ul>\n<li>Ltranger cherche  trouver quelquun <strong>connaissant</strong> (=qui conaisse)  la fois franais et langlais.</li>\n</ul>\n</li>\n<li><ul>\n<li><strong>Voyant</strong>(=Comme elle voit) que tout le monde est dej assis,elle va vite  sa place.</li>\n<li><strong>Ayant</strong>(=Comme il a) mal  la tete,il dcide de rester au lit.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h2><h3 id=\"I-\"><a href=\"#I-\" class=\"headerlink\" title=\"I. \"></a>I. </h3><p></p>\n<ol>\n<li><p></p>\n<ul>\n<li>Ses yeux <strong>brillants</strong> disent la convoitises. </li>\n<li>Je lai trouv toute <strong>tremblante</strong>. </li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>Une seance <strong>payante</strong> (=o lon paie) </li>\n<li>une collation <strong>soupante</strong> (=si copieuse quelle tient lieu de souper) </li>\n</ul>\n<p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>provoquant</td>\n<td>provocant</td>\n</tr>\n<tr>\n<td>fatiguant</td>\n<td>fatigant</td>\n</tr>\n<tr>\n<td>vaquant</td>\n<td>vacant</td>\n</tr>\n<tr>\n<td>naviguant</td>\n<td>navigant</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"II-\"><a href=\"#II-\" class=\"headerlink\" title=\"II. \"></a>II. </h3><p></p>\n<ol>\n<li>qui<ul>\n<li>Cest un film <strong>captivant</strong> les spectateurs. </li>\n<li>Je le vois <strong>lisant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>Prenant</strong> lescabeau, il sofforee datteindre le dernier rayon. </li>\n<li><strong>Croyant</strong> le bureau vide, il entra. </li>\n</ul>\n</li>\n<li><ul>\n<li>Le train repartit, <strong>courant</strong> vers le Midi. </li>\n</ul>\n</li>\n<li><ul>\n<li>Midi <strong>sonnant</strong>, on se met  table. </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"-le-gerondif\"><a href=\"#-le-gerondif\" class=\"headerlink\" title=\"(le grondif)\"></a>(le grondif)</h1><h2 id=\"1--1\"><a href=\"#1--1\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<p>en </p>\n<ul>\n<li>faire : en faisant</li>\n</ul>\n<p>ayanttanten</p>\n<h2 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h2><ol>\n<li><ul>\n<li>Noubliez pas de fermer la port <strong>en sortant</strong>.</li>\n<li>Ne lis pas <strong>en mangeant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li>Elle arriva <strong>en courant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En se levant</strong> plus tot le matin, il narrivera pas en retard. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En voyant</strong> critiquant, il navait nulle intention de nous dcourager. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En voyant</strong> son embarras, lagent se fit plus aimable. </li>\n</ul>\n</li>\n</ol>\n<p><strong>*</strong></p>\n<p>alleren</p>\n<ul>\n<li>Sa vue va <strong>en saffaiblissant</strong>. </li>\n</ul>\n<h2 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h2><ol>\n<li>Tous + </li>\n<li>Rien que + </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li></li>\n</ol>\n<p>*</p>\n<ul>\n<li>La fortune vient <strong>en dormant</strong>. </li>\n</ul>\n<ol>\n<li></li>\n</ol>\n"},{"title":"proba-ch1 ","date":"2016-12-01T11:17:29.000Z","_content":"\n- \n\n\n$$\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}\n$$\n\n- An\n\n$$\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- An\n\n$$\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- \n- \n\n$$\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})\n$$\n\n- (Equation de partition)\n\n$$\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}\n$$\n\n- (de Bay)\n\n$$\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}\n$$\n\n- \n\n- \n\n  P({wn}) = pnpnP\n\n- \n  $$\n  E[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}\n  $$\n\n- \n\n$$\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)\n$$\n\n- \n\n  - Loi discrete uniforme\n\n  - $$\n    \\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}\n    $$\n\n    $$\n    E[X] = \\frac{n+1}{2}\n    $$\n\n  - Loi de Bernoulli\n\n    $$\n    P(X=1) = p, t P(X=0) = 1-p\n    $$\n    $$\n    E[N] = p, Var(N) = p(1-p)\n    $$\n\n  - Loi binomiale \n    $$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Loi geometrique \n    $$\n    P(N=n) = P^n(1-p),$$$$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Distribution de Poisson\n    $$\n    P(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},\n    $$\n    $$\n    E[X] = \\lambda, Var(X) = \\lambda\n    $$\n","source":"_posts/proba-ch1.md","raw":"---\ntitle: proba-ch1 \ndate: 2016-12-01 12:17:29\ncategories: math\ntags: [probability, math]\n---\n\n- \n\n\n$$\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}\n$$\n\n- An\n\n$$\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- An\n\n$$\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- \n- \n\n$$\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})\n$$\n\n- (Equation de partition)\n\n$$\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}\n$$\n\n- (de Bay)\n\n$$\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}\n$$\n\n- \n\n- \n\n  P({wn}) = pnpnP\n\n- \n  $$\n  E[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}\n  $$\n\n- \n\n$$\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)\n$$\n\n- \n\n  - Loi discrete uniforme\n\n  - $$\n    \\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}\n    $$\n\n    $$\n    E[X] = \\frac{n+1}{2}\n    $$\n\n  - Loi de Bernoulli\n\n    $$\n    P(X=1) = p, t P(X=0) = 1-p\n    $$\n    $$\n    E[N] = p, Var(N) = p(1-p)\n    $$\n\n  - Loi binomiale \n    $$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Loi geometrique \n    $$\n    P(N=n) = P^n(1-p),$$$$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Distribution de Poisson\n    $$\n    P(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},\n    $$\n    $$\n    E[X] = \\lambda, Var(X) = \\lambda\n    $$\n","slug":"proba-ch1","published":1,"updated":"2016-12-01T11:19:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrx003dpzm9axm4jfox","content":"<ul>\n<li></li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}</script><ul>\n<li>An</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}</script><ul>\n<li>An</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}</script><ul>\n<li></li>\n<li></li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})</script><ul>\n<li>(Equation de partition)</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}</script><ul>\n<li>(de Bay)</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}</script><ul>\n<li><p></p>\n</li>\n<li><p></p>\n<p>P({wn}) = pnpnP</p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}</script></li>\n<li><p></p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)</script><ul>\n<li><p></p>\n<ul>\n<li><p>Loi discrete uniforme</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}</script><script type=\"math/tex; mode=display\">\nE[X] = \\frac{n+1}{2}</script></li>\n<li><p>Loi de Bernoulli</p>\n<script type=\"math/tex; mode=display\">\nP(X=1) = p, t P(X=0) = 1-p</script><script type=\"math/tex; mode=display\">\nE[N] = p, Var(N) = p(1-p)</script></li>\n<li><p>Loi binomiale </p>\n<script type=\"math/tex; mode=display\">\nE[N] = np, Var(N) = np(1-p)</script></li>\n<li><p>Loi geometrique </p>\n<script type=\"math/tex; mode=display\">\nP(N=n) = P^n(1-p),$$</script><p>E[N] = np, Var(N) = np(1-p)<br>$$</p>\n</li>\n<li><p>Distribution de Poisson</p>\n<script type=\"math/tex; mode=display\">\nP(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},</script><script type=\"math/tex; mode=display\">\nE[X] = \\lambda, Var(X) = \\lambda</script></li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<ul>\n<li></li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}</script><ul>\n<li>An</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}</script><ul>\n<li>An</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}</script><ul>\n<li></li>\n<li></li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})</script><ul>\n<li>(Equation de partition)</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}</script><ul>\n<li>(de Bay)</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}</script><ul>\n<li><p></p>\n</li>\n<li><p></p>\n<p>P({wn}) = pnpnP</p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}</script></li>\n<li><p></p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)</script><ul>\n<li><p></p>\n<ul>\n<li><p>Loi discrete uniforme</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}</script><script type=\"math/tex; mode=display\">\nE[X] = \\frac{n+1}{2}</script></li>\n<li><p>Loi de Bernoulli</p>\n<script type=\"math/tex; mode=display\">\nP(X=1) = p, t P(X=0) = 1-p</script><script type=\"math/tex; mode=display\">\nE[N] = p, Var(N) = p(1-p)</script></li>\n<li><p>Loi binomiale </p>\n<script type=\"math/tex; mode=display\">\nE[N] = np, Var(N) = np(1-p)</script></li>\n<li><p>Loi geometrique </p>\n<script type=\"math/tex; mode=display\">\nP(N=n) = P^n(1-p),$$</script><p>E[N] = np, Var(N) = np(1-p)<br>$$</p>\n</li>\n<li><p>Distribution de Poisson</p>\n<script type=\"math/tex; mode=display\">\nP(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},</script><script type=\"math/tex; mode=display\">\nE[X] = \\lambda, Var(X) = \\lambda</script></li>\n</ul>\n</li>\n</ul>\n"},{"title":"proba-ch2 ","date":"2016-12-01T11:17:33.000Z","_content":"\n- \n\n$$\n\\pi-system\n$$\n\n- R\n\n  -  la fonction de repartition\n    $$\n    F:x\\xrightarrow{}F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] }{f(t).\\lambda(dt)}\n    $$\n\n  - \n\n    F\n    $$\n    (i) F \\\\(ii)F \\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}\n    $$\n\n  - \n    $$\n    P(\\{x\\}) = F(x) - F(x-)\n    $$\n\n- R^N\n\n  - \n  $$\n    F:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )\n  $$\n\n  - \n    $$\n    P(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}\n    $$\n\n- \n\n  - \n    $$\n    Soit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}\n    $$\n    X\n\n  -  tribu engendree par X\n    $$\n    X^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)\n    $$\n\n- loi\n\n  - \n    $$\n    \\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))\n    $$\n\n- \n\n  - \n    $$\n    E[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}\n    $$\n\n  - \n    $$\n    (X_n)_{n\\in N} \n    $$\n\n    - XnX\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n    - FatouXn\n      $$\n      E[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}\n      $$\n\n    - convergence dominee: limXn = X p.s Z in L1|Xn|<=Z\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n  - (Inegalite de Markov)\n\n    Xadmettant un moment d'ordre 1, a>0\n    $$\n    P(|X| \\geq a) \\leq \\frac{E[|X|]}{a}\n    $$\n\n  - \n    $$\n    E[h(X)] = \\int_E{h(x)P_X(dx)}\n    $$\n\n  - \n  $$\n  un\\ moment\\ d'ordre\\ n: \\int_\\Omega{|X|^ndP} < \\infty\n  $$\n\n  - 0<p<qLqLp\n\n  - \n\n    - $$\n      Var(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}\n      $$\n\n    - XVar(X) = 0\n\n  - \n    $$\n    E[h(X)] = \\int_E{h(x)f_X(dx)}\n    $$\n    \n    $$\n    P(X \\in A) = E[1_{\\{X\\in A\\}}] = \\int_A{f_X(dx)}\n    $$\n\n- Vecteurs aleatoires\n\n  X = (X1,,XN) \n\n  - \n    $$\n    Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]\n    $$\n\n    - \n      $$\n      Cov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)\n      $$\n\n  - \n    $$\n    \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1\n    $$\n\n  - \n    $$\n    \\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)\n    $$\n\n  - \n\n- \n\n  \n\n  - XY\n\n    1. AB\n    $$\n      P(X \\in A, Y\\in B) = P(X\\in A)\n    $$\n\n    2. fg\n    $$\n      E[f(X)g(Y)] = E[f(X)] E[g(Y)]\n    $$\n\n    3. fgf(X)g(Y)\n\n  - \n    $$\n    \\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.\n    $$\n    $$\n    \\text{XY} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\n    P_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)\n    $$\n\n  - XY\n    $$\n    \\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)\n    $$\n\n  - (X,Y)lebesgueXY\n    $$\n    \\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)\n    $$\n\n  - XY admettant un moment d'ordre 1, \n\n  - $$\n    E[XY]=E[X]E[Y]\n    $$\n\n  - XY admettant un moment d'ordre 2, Cov(X,Y)=0, \n\n  - $$\n    Var(X+Y) =Var(X) + Var(Y)\n    $$\n\n    \n","source":"_posts/proba-ch2.md","raw":"---\ntitle: proba-ch2 \ndate: 2016-12-01 12:17:33\ncategories: math\ntags: [probability, math, aleatoire]\n---\n\n- \n\n$$\n\\pi-system\n$$\n\n- R\n\n  -  la fonction de repartition\n    $$\n    F:x\\xrightarrow{}F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] }{f(t).\\lambda(dt)}\n    $$\n\n  - \n\n    F\n    $$\n    (i) F \\\\(ii)F \\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}\n    $$\n\n  - \n    $$\n    P(\\{x\\}) = F(x) - F(x-)\n    $$\n\n- R^N\n\n  - \n  $$\n    F:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )\n  $$\n\n  - \n    $$\n    P(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}\n    $$\n\n- \n\n  - \n    $$\n    Soit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}\n    $$\n    X\n\n  -  tribu engendree par X\n    $$\n    X^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)\n    $$\n\n- loi\n\n  - \n    $$\n    \\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))\n    $$\n\n- \n\n  - \n    $$\n    E[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}\n    $$\n\n  - \n    $$\n    (X_n)_{n\\in N} \n    $$\n\n    - XnX\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n    - FatouXn\n      $$\n      E[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}\n      $$\n\n    - convergence dominee: limXn = X p.s Z in L1|Xn|<=Z\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n  - (Inegalite de Markov)\n\n    Xadmettant un moment d'ordre 1, a>0\n    $$\n    P(|X| \\geq a) \\leq \\frac{E[|X|]}{a}\n    $$\n\n  - \n    $$\n    E[h(X)] = \\int_E{h(x)P_X(dx)}\n    $$\n\n  - \n  $$\n  un\\ moment\\ d'ordre\\ n: \\int_\\Omega{|X|^ndP} < \\infty\n  $$\n\n  - 0<p<qLqLp\n\n  - \n\n    - $$\n      Var(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}\n      $$\n\n    - XVar(X) = 0\n\n  - \n    $$\n    E[h(X)] = \\int_E{h(x)f_X(dx)}\n    $$\n    \n    $$\n    P(X \\in A) = E[1_{\\{X\\in A\\}}] = \\int_A{f_X(dx)}\n    $$\n\n- Vecteurs aleatoires\n\n  X = (X1,,XN) \n\n  - \n    $$\n    Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]\n    $$\n\n    - \n      $$\n      Cov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)\n      $$\n\n  - \n    $$\n    \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1\n    $$\n\n  - \n    $$\n    \\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)\n    $$\n\n  - \n\n- \n\n  \n\n  - XY\n\n    1. AB\n    $$\n      P(X \\in A, Y\\in B) = P(X\\in A)\n    $$\n\n    2. fg\n    $$\n      E[f(X)g(Y)] = E[f(X)] E[g(Y)]\n    $$\n\n    3. fgf(X)g(Y)\n\n  - \n    $$\n    \\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.\n    $$\n    $$\n    \\text{XY} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\n    P_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)\n    $$\n\n  - XY\n    $$\n    \\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)\n    $$\n\n  - (X,Y)lebesgueXY\n    $$\n    \\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)\n    $$\n\n  - XY admettant un moment d'ordre 1, \n\n  - $$\n    E[XY]=E[X]E[Y]\n    $$\n\n  - XY admettant un moment d'ordre 2, Cov(X,Y)=0, \n\n  - $$\n    Var(X+Y) =Var(X) + Var(Y)\n    $$\n\n    \n","slug":"proba-ch2","published":1,"updated":"2016-12-01T13:44:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvry003fpzm9jgrppbjf","content":"<ul>\n<li></li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\pi-system</script><ul>\n<li><p>R</p>\n<ul>\n<li><p> la fonction de repartition</p>\n<script type=\"math/tex; mode=display\">\nF:x\\xrightarrow{}F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] }{f(t).\\lambda(dt)}</script></li>\n<li><p></p>\n<p>F</p>\n<script type=\"math/tex; mode=display\">\n(i) F \\\\(ii)F \\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nP(\\{x\\}) = F(x) - F(x-)</script></li>\n</ul>\n</li>\n<li><p>R^N</p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nF:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nP(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}</script></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nSoit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}</script><p>X</p>\n</li>\n<li><p> tribu engendree par X</p>\n<script type=\"math/tex; mode=display\">\nX^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)</script></li>\n</ul>\n</li>\n<li><p>loi</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\n\\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))</script></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n(X_n)_{n\\in N} </script><ul>\n<li><p>XnX</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]</script></li>\n<li><p>FatouXn</p>\n<script type=\"math/tex; mode=display\">\nE[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}</script></li>\n<li><p>convergence dominee: limXn = X p.s Z in L1|Xn|&lt;=Z</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]</script></li>\n</ul>\n</li>\n<li><p>(Inegalite de Markov)</p>\n<p>Xadmettant un moment dordre 1, a&gt;0</p>\n<script type=\"math/tex; mode=display\">\nP(|X| \\geq a) \\leq \\frac{E[|X|]}{a}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[h(X)] = \\int_E{h(x)P_X(dx)}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nun\\ moment\\ d'ordre\\ n: \\int_\\Omega{|X|^ndP} < \\infty</script></li>\n<li><p>0&lt;p&lt;qLqLp</p>\n</li>\n<li><p></p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\nVar(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}</script></li>\n<li><p>XVar(X) = 0</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[h(X)] = \\int_E{h(x)f_X(dx)}</script><p></p>\n<script type=\"math/tex; mode=display\">\nP(X \\in A) = E[1_{\\{X\\in A\\}}] = \\int_A{f_X(dx)}</script></li>\n</ul>\n</li>\n<li><p>Vecteurs aleatoires</p>\n<p>X = (X1,,XN) </p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nCov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]</script><ul>\n<li><script type=\"math/tex; mode=display\">\nCov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)</script></li>\n</ul>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)</script></li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li><p>XY</p>\n<ol>\n<li><p>AB</p>\n<script type=\"math/tex; mode=display\">\nP(X \\in A, Y\\in B) = P(X\\in A)</script></li>\n<li><p>fg</p>\n<script type=\"math/tex; mode=display\">\nE[f(X)g(Y)] = E[f(X)] E[g(Y)]</script></li>\n<li><p>fgf(X)g(Y)</p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.</script><script type=\"math/tex; mode=display\">\n\\text{XY} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\nP_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)</script></li>\n<li><p>XY</p>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)</script></li>\n<li><p>(X,Y)lebesgueXY</p>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)</script></li>\n<li><p>XY admettant un moment dordre 1, </p>\n</li>\n<li><script type=\"math/tex; mode=display\">\nE[XY]=E[X]E[Y]</script></li>\n<li><p>XY admettant un moment dordre 2, Cov(X,Y)=0, </p>\n</li>\n<li><script type=\"math/tex; mode=display\">\nVar(X+Y) =Var(X) + Var(Y)</script><p></p>\n</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<ul>\n<li></li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\pi-system</script><ul>\n<li><p>R</p>\n<ul>\n<li><p> la fonction de repartition</p>\n<script type=\"math/tex; mode=display\">\nF:x\\xrightarrow{}F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] }{f(t).\\lambda(dt)}</script></li>\n<li><p></p>\n<p>F</p>\n<script type=\"math/tex; mode=display\">\n(i) F \\\\(ii)F \\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nP(\\{x\\}) = F(x) - F(x-)</script></li>\n</ul>\n</li>\n<li><p>R^N</p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nF:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nP(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}</script></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nSoit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}</script><p>X</p>\n</li>\n<li><p> tribu engendree par X</p>\n<script type=\"math/tex; mode=display\">\nX^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)</script></li>\n</ul>\n</li>\n<li><p>loi</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\n\\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))</script></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n(X_n)_{n\\in N} </script><ul>\n<li><p>XnX</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]</script></li>\n<li><p>FatouXn</p>\n<script type=\"math/tex; mode=display\">\nE[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}</script></li>\n<li><p>convergence dominee: limXn = X p.s Z in L1|Xn|&lt;=Z</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]</script></li>\n</ul>\n</li>\n<li><p>(Inegalite de Markov)</p>\n<p>Xadmettant un moment dordre 1, a&gt;0</p>\n<script type=\"math/tex; mode=display\">\nP(|X| \\geq a) \\leq \\frac{E[|X|]}{a}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[h(X)] = \\int_E{h(x)P_X(dx)}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nun\\ moment\\ d'ordre\\ n: \\int_\\Omega{|X|^ndP} < \\infty</script></li>\n<li><p>0&lt;p&lt;qLqLp</p>\n</li>\n<li><p></p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\nVar(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}</script></li>\n<li><p>XVar(X) = 0</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[h(X)] = \\int_E{h(x)f_X(dx)}</script><p></p>\n<script type=\"math/tex; mode=display\">\nP(X \\in A) = E[1_{\\{X\\in A\\}}] = \\int_A{f_X(dx)}</script></li>\n</ul>\n</li>\n<li><p>Vecteurs aleatoires</p>\n<p>X = (X1,,XN) </p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nCov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]</script><ul>\n<li><script type=\"math/tex; mode=display\">\nCov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)</script></li>\n</ul>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)</script></li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li><p>XY</p>\n<ol>\n<li><p>AB</p>\n<script type=\"math/tex; mode=display\">\nP(X \\in A, Y\\in B) = P(X\\in A)</script></li>\n<li><p>fg</p>\n<script type=\"math/tex; mode=display\">\nE[f(X)g(Y)] = E[f(X)] E[g(Y)]</script></li>\n<li><p>fgf(X)g(Y)</p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.</script><script type=\"math/tex; mode=display\">\n\\text{XY} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\nP_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)</script></li>\n<li><p>XY</p>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)</script></li>\n<li><p>(X,Y)lebesgueXY</p>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)</script></li>\n<li><p>XY admettant un moment dordre 1, </p>\n</li>\n<li><script type=\"math/tex; mode=display\">\nE[XY]=E[X]E[Y]</script></li>\n<li><p>XY admettant un moment dordre 2, Cov(X,Y)=0, </p>\n</li>\n<li><script type=\"math/tex; mode=display\">\nVar(X+Y) =Var(X) + Var(Y)</script><p></p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"proba-ch3 ","date":"2016-12-01T13:54:10.000Z","_content":"\n1. \n\n    f=0\n\n   1. loi uniforme\n      $$\n      f(x)=\\frac{1}{b-a} si\\ x \\in [a,b]\n      $$\n\n   2. loi exponentielle\n      $$\n      f(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\n      E[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2\n      $$\n\n   3. Loi de weibull\n      $$\n      f(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\n      E[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}\n      $$\n\n   4. loi gamma\n      $$\n      f(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\n      E[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}\n      $$\n\n   5. loi normale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\n      E[X] = m, Var(X) = \\sigma^2\n      $$\n\n   6. Loi lognormale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\n      E[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)\n      $$\n\n   7. Loi du $ \\chi^2 $\n      $$\n      X = U_1^2+...+U_n^2 \\\\\n      U_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\n      E[X] = n, Var(X) = 2n\n      $$\n\n   8. Loi de Student\n      $$\n      X = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\n      U\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\n      Z\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}\n      $$\n\n2. \n   $$\n   \\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\n   t \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}\n   $$\n   XPX = =\n\n   PX $f \\in L^1$\n   $$\n   \\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}\n   $$\n\n   - \n\n     - $$\n       \\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1\n       $$\n\n       $$\n       \\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)\n       $$\n\n       $$\n       \\varphi_X  \\\\\n       \\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0\n       $$\n\n   - \n\n     - \n\n     - PXlebesgue\n\n     - $$\n       \\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0\n       $$\n\n     - XYP\n\n     - $$\n       \\varphi_X=\\varphi_Y\n       $$\n\n     - \n\n     - $$\n       \\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt\n       $$\n\n   - \n\n     - \n       $$\n       X_1,...,X_N \\text{ } \\\\\n       \\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\n       where\\ X = (X_1,...,X_N)\n       $$\n\n     - \n       $$\n       X_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n       \\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n       \\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n       \\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }\n       $$\n\n\n","source":"_posts/proba-ch3.md","raw":"---\ntitle: proba-ch3 \ndate: 2016-12-01 14:54:10\ncategories: math\ntags: [probability, math]\n---\n\n1. \n\n    f=0\n\n   1. loi uniforme\n      $$\n      f(x)=\\frac{1}{b-a} si\\ x \\in [a,b]\n      $$\n\n   2. loi exponentielle\n      $$\n      f(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\n      E[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2\n      $$\n\n   3. Loi de weibull\n      $$\n      f(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\n      E[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}\n      $$\n\n   4. loi gamma\n      $$\n      f(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\n      E[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}\n      $$\n\n   5. loi normale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\n      E[X] = m, Var(X) = \\sigma^2\n      $$\n\n   6. Loi lognormale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\n      E[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)\n      $$\n\n   7. Loi du $ \\chi^2 $\n      $$\n      X = U_1^2+...+U_n^2 \\\\\n      U_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\n      E[X] = n, Var(X) = 2n\n      $$\n\n   8. Loi de Student\n      $$\n      X = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\n      U\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\n      Z\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}\n      $$\n\n2. \n   $$\n   \\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\n   t \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}\n   $$\n   XPX = =\n\n   PX $f \\in L^1$\n   $$\n   \\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}\n   $$\n\n   - \n\n     - $$\n       \\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1\n       $$\n\n       $$\n       \\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)\n       $$\n\n       $$\n       \\varphi_X  \\\\\n       \\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0\n       $$\n\n   - \n\n     - \n\n     - PXlebesgue\n\n     - $$\n       \\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0\n       $$\n\n     - XYP\n\n     - $$\n       \\varphi_X=\\varphi_Y\n       $$\n\n     - \n\n     - $$\n       \\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt\n       $$\n\n   - \n\n     - \n       $$\n       X_1,...,X_N \\text{ } \\\\\n       \\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\n       where\\ X = (X_1,...,X_N)\n       $$\n\n     - \n       $$\n       X_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n       \\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n       \\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n       \\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }\n       $$\n\n\n","slug":"proba-ch3","published":1,"updated":"2016-12-01T15:28:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvrz003jpzm9r96acd4r","content":"<ol>\n<li><p></p>\n<p> f=0</p>\n<ol>\n<li><p>loi uniforme</p>\n<script type=\"math/tex; mode=display\">\nf(x)=\\frac{1}{b-a} si\\ x \\in [a,b]</script></li>\n<li><p>loi exponentielle</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\nE[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2</script></li>\n<li><p>Loi de weibull</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\nE[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}</script></li>\n<li><p>loi gamma</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\nE[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}</script></li>\n<li><p>loi normale</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\nE[X] = m, Var(X) = \\sigma^2</script></li>\n<li><p>Loi lognormale</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\nE[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)</script></li>\n<li><p>Loi du $ \\chi^2 $</p>\n<script type=\"math/tex; mode=display\">\nX = U_1^2+...+U_n^2 \\\\\nU_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\nE[X] = n, Var(X) = 2n</script></li>\n<li><p>Loi de Student</p>\n<script type=\"math/tex; mode=display\">\nX = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\nU\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\nZ\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}</script></li>\n</ol>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\nt \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}</script><p>XPX = =</p>\n<p>PX $f \\in L^1$</p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}</script><ul>\n<li><p></p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\n\\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1</script><script type=\"math/tex; mode=display\">\n\\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)</script><script type=\"math/tex; mode=display\">\n\\varphi_X  \\\\\n\\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0</script></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n</li>\n<li><p>PXlebesgue</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0</script></li>\n<li><p>XYP</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\varphi_X=\\varphi_Y</script></li>\n<li><p></p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt</script></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX_1,...,X_N \\text{ } \\\\\n\\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\nwhere\\ X = (X_1,...,X_N)</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n\\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n\\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n\\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }</script></li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<ol>\n<li><p></p>\n<p> f=0</p>\n<ol>\n<li><p>loi uniforme</p>\n<script type=\"math/tex; mode=display\">\nf(x)=\\frac{1}{b-a} si\\ x \\in [a,b]</script></li>\n<li><p>loi exponentielle</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\nE[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2</script></li>\n<li><p>Loi de weibull</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\nE[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}</script></li>\n<li><p>loi gamma</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\nE[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}</script></li>\n<li><p>loi normale</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\nE[X] = m, Var(X) = \\sigma^2</script></li>\n<li><p>Loi lognormale</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\nE[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)</script></li>\n<li><p>Loi du $ \\chi^2 $</p>\n<script type=\"math/tex; mode=display\">\nX = U_1^2+...+U_n^2 \\\\\nU_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\nE[X] = n, Var(X) = 2n</script></li>\n<li><p>Loi de Student</p>\n<script type=\"math/tex; mode=display\">\nX = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\nU\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\nZ\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}</script></li>\n</ol>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\nt \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}</script><p>XPX = =</p>\n<p>PX $f \\in L^1$</p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}</script><ul>\n<li><p></p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\n\\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1</script><script type=\"math/tex; mode=display\">\n\\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)</script><script type=\"math/tex; mode=display\">\n\\varphi_X  \\\\\n\\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0</script></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n</li>\n<li><p>PXlebesgue</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0</script></li>\n<li><p>XYP</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\varphi_X=\\varphi_Y</script></li>\n<li><p></p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt</script></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX_1,...,X_N \\text{ } \\\\\n\\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\nwhere\\ X = (X_1,...,X_N)</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n\\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n\\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n\\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }</script></li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n"},{"title":"proba-ch4 ","date":"2016-12-01T15:28:52.000Z","_content":"\n\n\nUn vecteur alatoire est dit gaussien si toute combinaison linaire de ses composantes suit une loi gaussienne.\n\n\n$$\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}\n$$\n\n- \n  $$\n  \\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n  => \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}\n  $$\n  $\\mu$, le vecteur moyenne, \n\n  D, la matrice de covariances de X, \n\n- X=(X1,,XN) XjD\n\n- Densite de la loi d'un vecteur gaussien\n  $$\n  D \\ne 0 \\\\\n  \\mathcal{N}(\\mu,D) \\text{Lebesgue}\\mathbb{R}^N\\text{} \\\\\n  x \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}\n  $$\n\n","source":"_posts/proba-ch4.md","raw":"---\ntitle: proba-ch4 \ndate: 2016-12-01 16:28:52\ncategories: math\ntags: [probability, math, vector]\n---\n\n\n\nUn vecteur alatoire est dit gaussien si toute combinaison linaire de ses composantes suit une loi gaussienne.\n\n\n$$\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}\n$$\n\n- \n  $$\n  \\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n  => \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}\n  $$\n  $\\mu$, le vecteur moyenne, \n\n  D, la matrice de covariances de X, \n\n- X=(X1,,XN) XjD\n\n- Densite de la loi d'un vecteur gaussien\n  $$\n  D \\ne 0 \\\\\n  \\mathcal{N}(\\mu,D) \\text{Lebesgue}\\mathbb{R}^N\\text{} \\\\\n  x \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}\n  $$\n\n","slug":"proba-ch4","published":1,"updated":"2016-12-19T13:11:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvs0003mpzm9ta3ygc4h","content":"<p></p>\n<p>Un vecteur alatoire est dit gaussien si toute combinaison linaire de ses composantes suit une loi gaussienne.</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}</script><ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n=> \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}</script><p>$\\mu$, le vecteur moyenne, </p>\n<p>D, la matrice de covariances de X, </p>\n</li>\n<li><p>X=(X1,,XN) XjD</p>\n</li>\n<li><p>Densite de la loi dun vecteur gaussien</p>\n<script type=\"math/tex; mode=display\">\nD \\ne 0 \\\\\n\\mathcal{N}(\\mu,D) \\text{Lebesgue}\\mathbb{R}^N\\text{} \\\\\nx \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}</script></li>\n</ul>\n","excerpt":"","more":"<p></p>\n<p>Un vecteur alatoire est dit gaussien si toute combinaison linaire de ses composantes suit une loi gaussienne.</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}</script><ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n=> \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}</script><p>$\\mu$, le vecteur moyenne, </p>\n<p>D, la matrice de covariances de X, </p>\n</li>\n<li><p>X=(X1,,XN) XjD</p>\n</li>\n<li><p>Densite de la loi dun vecteur gaussien</p>\n<script type=\"math/tex; mode=display\">\nD \\ne 0 \\\\\n\\mathcal{N}(\\mu,D) \\text{Lebesgue}\\mathbb{R}^N\\text{} \\\\\nx \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}</script></li>\n</ul>\n"},{"title":"proba-ch5 ","date":"2016-12-01T22:14:28.000Z","_content":"\n# \n\n1. \n\n   > ****  wiki\n\n   $$\n   (X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n   \\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n   \\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}\n   $$\n   - (loi de zero-un)\n\n     A$\\mathcal{T}_{\\infty}$P(A)01\n\n2. \n\n   - convergence presque sure\n\n     \n     $$\n     \\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\n     $$\n     (p.s.)\n     $$\n     P\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1\n     $$\n\n   - Convergence dans Lp\n\n     XnXLpp- -|||\n\n     \n     $$\n     \\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0\n     $$\n\n   - convergence en probabilite\n\n     \n     $$\n     \\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\n     ou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0\n     $$\n     \n\n     1. XnX(p.s.)fXnfX(p.s.)\n     2. XnX(P)fXnfX(P)\n\n     \n\n     Xn\n     $$\n     X_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0\n     $$\n     \n\n     Xn\n     $$\n     X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\n     X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\\n     $$\n     \n\n     XnXnX\n     $$\n     (X_{n_k})_{k \\in \\mathbb{N}}\n     $$\n     \n     $$\n     X_n \\to X, p.s.\n     $$\n     \n\n     XnXnX$Y \\in L^p, |X_n| \\le Y$\n     $$\n     X \\in L^p X_n \\xrightarrow{L^p}X\n     $$\n\n\n\n\n\n3. \n\n   >  wiki\n\n   1. \n   2. \n\n4. \n\n   >   wiki\n\n   - \n     $$\n     X_n \\in L^2 \\text{} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.\n     $$\n\n   - \n     $$\n     X_n  \\text{} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ } E[X_i] \\text{i}\n     $$\n\n5. Convergence en loi\n\n   \n   $$\n   \\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}\n   $$\n   PXnPXXn convergence en loi vers X\n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   \n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]\n   $$\n   \n   $$\n   X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.\n\n   - convergence en loi\n   - convergence en loi\n   - convergence en loi\n\n   =_=\n\n6. \n   $$\n   Var(X_n) < \\infty \\\\\n   S_n = \\sum{Xi} \\\\\n   \\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)\n   $$\n   \n\n","source":"_posts/proba-ch5.md","raw":"---\ntitle: proba-ch5 \ncategories: math\ntags:\n  - math\n  - probability\ndate: 2016-12-01 23:14:28\n---\n\n# \n\n1. \n\n   > ****  wiki\n\n   $$\n   (X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n   \\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n   \\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}\n   $$\n   - (loi de zero-un)\n\n     A$\\mathcal{T}_{\\infty}$P(A)01\n\n2. \n\n   - convergence presque sure\n\n     \n     $$\n     \\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\n     $$\n     (p.s.)\n     $$\n     P\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1\n     $$\n\n   - Convergence dans Lp\n\n     XnXLpp- -|||\n\n     \n     $$\n     \\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0\n     $$\n\n   - convergence en probabilite\n\n     \n     $$\n     \\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\n     ou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0\n     $$\n     \n\n     1. XnX(p.s.)fXnfX(p.s.)\n     2. XnX(P)fXnfX(P)\n\n     \n\n     Xn\n     $$\n     X_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0\n     $$\n     \n\n     Xn\n     $$\n     X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\n     X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\\n     $$\n     \n\n     XnXnX\n     $$\n     (X_{n_k})_{k \\in \\mathbb{N}}\n     $$\n     \n     $$\n     X_n \\to X, p.s.\n     $$\n     \n\n     XnXnX$Y \\in L^p, |X_n| \\le Y$\n     $$\n     X \\in L^p X_n \\xrightarrow{L^p}X\n     $$\n\n\n\n\n\n3. \n\n   >  wiki\n\n   1. \n   2. \n\n4. \n\n   >   wiki\n\n   - \n     $$\n     X_n \\in L^2 \\text{} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.\n     $$\n\n   - \n     $$\n     X_n  \\text{} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ } E[X_i] \\text{i}\n     $$\n\n5. Convergence en loi\n\n   \n   $$\n   \\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}\n   $$\n   PXnPXXn convergence en loi vers X\n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   \n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]\n   $$\n   \n   $$\n   X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.\n\n   - convergence en loi\n   - convergence en loi\n   - convergence en loi\n\n   =_=\n\n6. \n   $$\n   Var(X_n) < \\infty \\\\\n   S_n = \\sum{Xi} \\\\\n   \\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)\n   $$\n   \n\n","slug":"proba-ch5","published":1,"updated":"2016-12-11T11:05:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvs5003rpzm93eazg1rd","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<blockquote>\n<p><strong></strong>  wiki</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\n(X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n\\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n\\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}</script><ul>\n<li><p>(loi de zero-un)</p>\n<p>A$\\mathcal{T}_{\\infty}$P(A)01</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p>convergence presque sure</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)</script><p>(p.s.)</p>\n<script type=\"math/tex; mode=display\">\nP\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1</script></li>\n<li><p>Convergence dans Lp</p>\n<p>XnXLpp- -|||</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0</script></li>\n<li><p>convergence en probabilite</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\nou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0</script><p></p>\n<ol>\n<li>XnX(p.s.)fXnfX(p.s.)</li>\n<li>XnX(P)fXnfX(P)</li>\n</ol>\n<p></p>\n<p>Xn</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0</script><p></p>\n<p>Xn</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\nX_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\</script><p></p>\n<p>XnXnX</p>\n<script type=\"math/tex; mode=display\">\n(X_{n_k})_{k \\in \\mathbb{N}}</script><p></p>\n<script type=\"math/tex; mode=display\">\nX_n \\to X, p.s.</script><p></p>\n<p>XnXnX$Y \\in L^p, |X_n| \\le Y$</p>\n<script type=\"math/tex; mode=display\">\nX \\in L^p X_n \\xrightarrow{L^p}X</script></li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p></p>\n<blockquote>\n<p> wiki</p>\n</blockquote>\n<ol>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p></p>\n<blockquote>\n<p>  wiki</p>\n</blockquote>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX_n \\in L^2 \\text{} \\\\\nlim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX_n  \\text{} \\\\\nlim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ } E[X_i] \\text{i}</script></li>\n</ul>\n</li>\n<li><p>Convergence en loi</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}</script><p>PXnPXXn convergence en loi vers X</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{\\mathcal{D}} X</script><p></p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]</script><p></p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X</script><p>si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.</p>\n<ul>\n<li>convergence en loi</li>\n<li>convergence en loi</li>\n<li>convergence en loi</li>\n</ul>\n<p>=_=</p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nVar(X_n) < \\infty \\\\\nS_n = \\sum{Xi} \\\\\n\\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)</script><p></p>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<blockquote>\n<p><strong></strong>  wiki</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\n(X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n\\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n\\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}</script><ul>\n<li><p>(loi de zero-un)</p>\n<p>A$\\mathcal{T}_{\\infty}$P(A)01</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p>convergence presque sure</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)</script><p>(p.s.)</p>\n<script type=\"math/tex; mode=display\">\nP\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1</script></li>\n<li><p>Convergence dans Lp</p>\n<p>XnXLpp- -|||</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0</script></li>\n<li><p>convergence en probabilite</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\nou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0</script><p></p>\n<ol>\n<li>XnX(p.s.)fXnfX(p.s.)</li>\n<li>XnX(P)fXnfX(P)</li>\n</ol>\n<p></p>\n<p>Xn</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0</script><p></p>\n<p>Xn</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\nX_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\</script><p></p>\n<p>XnXnX</p>\n<script type=\"math/tex; mode=display\">\n(X_{n_k})_{k \\in \\mathbb{N}}</script><p></p>\n<script type=\"math/tex; mode=display\">\nX_n \\to X, p.s.</script><p></p>\n<p>XnXnX$Y \\in L^p, |X_n| \\le Y$</p>\n<script type=\"math/tex; mode=display\">\nX \\in L^p X_n \\xrightarrow{L^p}X</script></li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p></p>\n<blockquote>\n<p> wiki</p>\n</blockquote>\n<ol>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p></p>\n<blockquote>\n<p>  wiki</p>\n</blockquote>\n<ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX_n \\in L^2 \\text{} \\\\\nlim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX_n  \\text{} \\\\\nlim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ } E[X_i] \\text{i}</script></li>\n</ul>\n</li>\n<li><p>Convergence en loi</p>\n<p></p>\n<script type=\"math/tex; mode=display\">\n\\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}</script><p>PXnPXXn convergence en loi vers X</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{\\mathcal{D}} X</script><p></p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]</script><p></p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X</script><p>si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.</p>\n<ul>\n<li>convergence en loi</li>\n<li>convergence en loi</li>\n<li>convergence en loi</li>\n</ul>\n<p>=_=</p>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nVar(X_n) < \\infty \\\\\nS_n = \\sum{Xi} \\\\\n\\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)</script><p></p>\n</li>\n</ol>\n"},{"title":"proba-ch6 ","date":"2016-12-02T20:32:30.000Z","_content":"\n$$\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}\n$$\n\n$$\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}\n$$\n\n$$\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0\n$$\n\n$$\nE[X|Y] = \\psi(Y)\n$$\n\n- \n  $$\n  \\mathcal{G} sous-tribu\\\\\n  E[X|\\mathcal{G}] Y, \\\\\n  Y \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP\n  $$\n\n-  L2\n  $$\n  X \\in L^2, \\mathcal{G} sous-tribu \\\\\n  E[X|\\mathcal{G}] Y, \\\\\n  \\forall Z \\in L^2, E[XZ] = E[YZ]\n  $$\n\n  - \n    $$\n    E[E[X|\\mathcal{G}]] = E[X]\n    $$\n\n  - \n    $$\n    X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X\\mathcal{G}\n    $$\n\n  - \n    $$\n    X\\mathcal{G}, X,Y,XY \\in L^1 \\\\\n    \\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]\n    $$\n\n- \n  $$\n  E[X|Y] = E[X|\\sigma(Y)]\n  $$\n\n  -  XYh\n    $$\n    E[X|Y] = h(Y)\n    $$\n","source":"_posts/proba-ch6.md","raw":"---\ntitle: proba-ch6 \ncategories: math\ntags:\n  - math\n  - probability\ndate: 2016-12-02 21:32:30\n---\n\n$$\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}\n$$\n\n$$\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}\n$$\n\n$$\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0\n$$\n\n$$\nE[X|Y] = \\psi(Y)\n$$\n\n- \n  $$\n  \\mathcal{G} sous-tribu\\\\\n  E[X|\\mathcal{G}] Y, \\\\\n  Y \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP\n  $$\n\n-  L2\n  $$\n  X \\in L^2, \\mathcal{G} sous-tribu \\\\\n  E[X|\\mathcal{G}] Y, \\\\\n  \\forall Z \\in L^2, E[XZ] = E[YZ]\n  $$\n\n  - \n    $$\n    E[E[X|\\mathcal{G}]] = E[X]\n    $$\n\n  - \n    $$\n    X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X\\mathcal{G}\n    $$\n\n  - \n    $$\n    X\\mathcal{G}, X,Y,XY \\in L^1 \\\\\n    \\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]\n    $$\n\n- \n  $$\n  E[X|Y] = E[X|\\sigma(Y)]\n  $$\n\n  -  XYh\n    $$\n    E[X|Y] = h(Y)\n    $$\n","slug":"proba-ch6","published":1,"updated":"2016-12-02T21:09:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvs6003upzm9jt15kvi9","content":"<script type=\"math/tex; mode=display\">\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}</script><script type=\"math/tex; mode=display\">\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}</script><script type=\"math/tex; mode=display\">\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0</script><script type=\"math/tex; mode=display\">\nE[X|Y] = \\psi(Y)</script><ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{G} sous-tribu\\\\\nE[X|\\mathcal{G}] Y, \\\\\nY \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP</script></li>\n<li><p> L2</p>\n<script type=\"math/tex; mode=display\">\nX \\in L^2, \\mathcal{G} sous-tribu \\\\\nE[X|\\mathcal{G}] Y, \\\\\n\\forall Z \\in L^2, E[XZ] = E[YZ]</script><ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[E[X|\\mathcal{G}]] = E[X]</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X\\mathcal{G}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX\\mathcal{G}, X,Y,XY \\in L^1 \\\\\n\\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]</script></li>\n</ul>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[X|Y] = E[X|\\sigma(Y)]</script><ul>\n<li> XYh<script type=\"math/tex; mode=display\">\nE[X|Y] = h(Y)</script></li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<script type=\"math/tex; mode=display\">\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}</script><script type=\"math/tex; mode=display\">\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}</script><script type=\"math/tex; mode=display\">\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0</script><script type=\"math/tex; mode=display\">\nE[X|Y] = \\psi(Y)</script><ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{G} sous-tribu\\\\\nE[X|\\mathcal{G}] Y, \\\\\nY \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP</script></li>\n<li><p> L2</p>\n<script type=\"math/tex; mode=display\">\nX \\in L^2, \\mathcal{G} sous-tribu \\\\\nE[X|\\mathcal{G}] Y, \\\\\n\\forall Z \\in L^2, E[XZ] = E[YZ]</script><ul>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[E[X|\\mathcal{G}]] = E[X]</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X\\mathcal{G}</script></li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nX\\mathcal{G}, X,Y,XY \\in L^1 \\\\\n\\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]</script></li>\n</ul>\n</li>\n<li><p></p>\n<script type=\"math/tex; mode=display\">\nE[X|Y] = E[X|\\sigma(Y)]</script><ul>\n<li> XYh<script type=\"math/tex; mode=display\">\nE[X|Y] = h(Y)</script></li>\n</ul>\n</li>\n</ul>\n"},{"title":"Chrome - Hello world","date":"2016-11-30T11:01:24.000Z","_content":"\nprojetchrome\n\n# Hello world!\n\nhello world\n\n1. chrome\n\n2. manifest.jsonchrome\n\n   hello worlddefault_popup\n\n   ```json\n   {\n     \"manifest_version\": 2,\n     \"name\": \"TrelloGement\",\n     \"description\": \"Organiser ses recherches d'appartement sur Paris grce  Trello!\",\n     \"version\": \"0.2.1\",\n     \"browser_action\": {\n       \"default_icon\": \"icon.png\",\n       \"default_popup\": \"popup.html\"\n     },\n     \"background\": {\n       \"scripts\": [\"background.js\", \"jquery-3.1.1.min.js\", \"client.js\"]\n     },\n     \"permissions\": [\"activeTab\", \"storage\", \"tabs\", \"https://api.trello.com/*\", \"https://trello.com/*\"]\n   }\n   ```\n\n3. popup.html\n\n   ```html\n   <!DOCTYPE html>\n   <html lang=\"en\">\n   <head>\n   \t<meta charset=\"UTF-8\">\n   \t<title>Trellogement</title>\n   </head>\n   <body>\n     <h1> Hello, world! </h1>\n   </body>\n   </html>\n   ```\n\n4. Hello worldchromepopupHello, world!\n\n","source":"_posts/projet-enjeu-plugin-chrome-101.md","raw":"---\ntitle: Chrome - Hello world\ndate: 2016-11-30 12:01:24\ncategories: programming\ntags: [web, chrome]\n---\n\nprojetchrome\n\n# Hello world!\n\nhello world\n\n1. chrome\n\n2. manifest.jsonchrome\n\n   hello worlddefault_popup\n\n   ```json\n   {\n     \"manifest_version\": 2,\n     \"name\": \"TrelloGement\",\n     \"description\": \"Organiser ses recherches d'appartement sur Paris grce  Trello!\",\n     \"version\": \"0.2.1\",\n     \"browser_action\": {\n       \"default_icon\": \"icon.png\",\n       \"default_popup\": \"popup.html\"\n     },\n     \"background\": {\n       \"scripts\": [\"background.js\", \"jquery-3.1.1.min.js\", \"client.js\"]\n     },\n     \"permissions\": [\"activeTab\", \"storage\", \"tabs\", \"https://api.trello.com/*\", \"https://trello.com/*\"]\n   }\n   ```\n\n3. popup.html\n\n   ```html\n   <!DOCTYPE html>\n   <html lang=\"en\">\n   <head>\n   \t<meta charset=\"UTF-8\">\n   \t<title>Trellogement</title>\n   </head>\n   <body>\n     <h1> Hello, world! </h1>\n   </body>\n   </html>\n   ```\n\n4. Hello worldchromepopupHello, world!\n\n","slug":"projet-enjeu-plugin-chrome-101","published":1,"updated":"2016-11-30T11:19:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"cjebtxvwq009dpzm9tdq64c5f","content":"<p>projetchrome</p>\n<h1 id=\"Hello-world\"><a href=\"#Hello-world\" class=\"headerlink\" title=\"Hello world!\"></a>Hello world!</h1><p>hello world</p>\n<ol>\n<li><p>chrome</p>\n</li>\n<li><p>manifest.jsonchrome</p>\n<p>hello worlddefault_popup</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  <span class=\"attr\">\"manifest_version\"</span>: <span class=\"number\">2</span>,</div><div class=\"line\">  <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"TrelloGement\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"Organiser ses recherches d'appartement sur Paris grce  Trello!\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"version\"</span>: <span class=\"string\">\"0.2.1\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"browser_action\"</span>: &#123;</div><div class=\"line\">    <span class=\"attr\">\"default_icon\"</span>: <span class=\"string\">\"icon.png\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"default_popup\"</span>: <span class=\"string\">\"popup.html\"</span></div><div class=\"line\">  &#125;,</div><div class=\"line\">  <span class=\"attr\">\"background\"</span>: &#123;</div><div class=\"line\">    <span class=\"attr\">\"scripts\"</span>: [<span class=\"string\">\"background.js\"</span>, <span class=\"string\">\"jquery-3.1.1.min.js\"</span>, <span class=\"string\">\"client.js\"</span>]</div><div class=\"line\">  &#125;,</div><div class=\"line\">  <span class=\"attr\">\"permissions\"</span>: [<span class=\"string\">\"activeTab\"</span>, <span class=\"string\">\"storage\"</span>, <span class=\"string\">\"tabs\"</span>, <span class=\"string\">\"https://api.trello.com/*\"</span>, <span class=\"string\">\"https://trello.com/*\"</span>]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>popup.html</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&lt;!DOCTYPE html&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">\"en\"</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></div><div class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"UTF-8\"</span>&gt;</span></div><div class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>Trellogement<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">h1</span>&gt;</span> Hello, world! <span class=\"tag\">&lt;/<span class=\"name\">h1</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></div></pre></td></tr></table></figure>\n</li>\n<li><p>Hello worldchromepopupHello, world!</p>\n</li>\n</ol>\n","excerpt":"","more":"<p>projetchrome</p>\n<h1 id=\"Hello-world\"><a href=\"#Hello-world\" class=\"headerlink\" title=\"Hello world!\"></a>Hello world!</h1><p>hello world</p>\n<ol>\n<li><p>chrome</p>\n</li>\n<li><p>manifest.jsonchrome</p>\n<p>hello worlddefault_popup</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  <span class=\"attr\">\"manifest_version\"</span>: <span class=\"number\">2</span>,</div><div class=\"line\">  <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"TrelloGement\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"Organiser ses recherches d'appartement sur Paris grce  Trello!\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"version\"</span>: <span class=\"string\">\"0.2.1\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"browser_action\"</span>: &#123;</div><div class=\"line\">    <span class=\"attr\">\"default_icon\"</span>: <span class=\"string\">\"icon.png\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"default_popup\"</span>: <span class=\"string\">\"popup.html\"</span></div><div class=\"line\">  &#125;,</div><div class=\"line\">  <span class=\"attr\">\"background\"</span>: &#123;</div><div class=\"line\">    <span class=\"attr\">\"scripts\"</span>: [<span class=\"string\">\"background.js\"</span>, <span class=\"string\">\"jquery-3.1.1.min.js\"</span>, <span class=\"string\">\"client.js\"</span>]</div><div class=\"line\">  &#125;,</div><div class=\"line\">  <span class=\"attr\">\"permissions\"</span>: [<span class=\"string\">\"activeTab\"</span>, <span class=\"string\">\"storage\"</span>, <span class=\"string\">\"tabs\"</span>, <span class=\"string\">\"https://api.trello.com/*\"</span>, <span class=\"string\">\"https://trello.com/*\"</span>]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>popup.html</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&lt;!DOCTYPE html&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">\"en\"</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></div><div class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"UTF-8\"</span>&gt;</span></div><div class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>Trellogement<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">h1</span>&gt;</span> Hello, world! <span class=\"tag\">&lt;/<span class=\"name\">h1</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></div></pre></td></tr></table></figure>\n</li>\n<li><p>Hello worldchromepopupHello, world!</p>\n</li>\n</ol>\n"}],"PostAsset":[{"_id":"source/_posts/Generative-Adversarial-Network/gan.png","slug":"gan.png","post":"cjebtxvpi0008pzm9dwby3sc0","modified":1,"renderable":0},{"_id":"source/_posts/[2018.1.14]Models-for-relation-extraction/overview.png","post":"cjebtxvr9001spzm9jr61qiyr","slug":"overview.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.1.14]Models-for-relation-extraction/wrong_label_reduction.png","post":"cjebtxvr9001spzm9jr61qiyr","slug":"wrong_label_reduction.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/character.png","post":"cjebtxvrc001zpzm9j6m6iv54","slug":"character.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/trigger_labeling.png","post":"cjebtxvrc001zpzm9j6m6iv54","slug":"trigger_labeling.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/algo.png","post":"cjebtxvrd0022pzm9qy2f3wli","slug":"algo.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/illustration.png","slug":"illustration.png","post":"cjebtxvrd0022pzm9qy2f3wli","modified":1,"renderable":0},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce/augmented_event.png","post":"cjebtxvra001wpzm94r7d8x0r","slug":"augmented_event.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce/basic_event.png","post":"cjebtxvra001wpzm94r7d8x0r","slug":"basic_event.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce/overview.png","post":"cjebtxvra001wpzm94r7d8x0r","slug":"overview.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/MWRW.png","post":"cjebtxvre0026pzm9e01tr9vh","slug":"MWRW.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/arch.png","post":"cjebtxvre0026pzm9e01tr9vh","slug":"arch.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/illustration.png","post":"cjebtxvre0026pzm9e01tr9vh","slug":"illustration.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/ComputationalGraph.png","post":"cjebtxvrf0029pzm91lfdtp9v","slug":"ComputationalGraph.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/GNMT_residual.png","post":"cjebtxvrf0029pzm91lfdtp9v","slug":"GNMT_residual.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/NestedLSTM.png","post":"cjebtxvrf0029pzm91lfdtp9v","slug":"NestedLSTM.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/StackedLSTM.png","post":"cjebtxvrf0029pzm91lfdtp9v","slug":"StackedLSTM.png","modified":1,"renderable":1},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs/singleLSTM.png","post":"cjebtxvrf0029pzm91lfdtp9v","slug":"singleLSTM.png","modified":1,"renderable":1}],"PostCategory":[{"post_id":"cjebtxvp60002pzm97n61od1o","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvpo000cpzm92nnnrkca"},{"post_id":"cjebtxvp90003pzm9py4ale94","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvpt000ipzm9y895z2b0"},{"post_id":"cjebtxvpo000dpzm9mzhs3zhw","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvpv000npzm922z8ul8u"},{"post_id":"cjebtxvpe0006pzm9psg9y3w8","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvpz000ppzm9vwnebaxq"},{"post_id":"cjebtxvpf0007pzm9wz4vz332","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvqm000wpzm9r3r29wr7"},{"post_id":"cjebtxvpf0007pzm9wz4vz332","category_id":"cjebtxvpt000kpzm9w9cjpwac","_id":"cjebtxvqs0010pzm95h783259"},{"post_id":"cjebtxvpi0008pzm9dwby3sc0","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvqw0013pzm98ui2olk3"},{"post_id":"cjebtxvql000vpzm9lze8mf54","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvqy0017pzm9h4y8aw90"},{"post_id":"cjebtxvqr000zpzm91ojgviqw","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvr0001apzm9hm34huet"},{"post_id":"cjebtxvpm000bpzm9rfxtzdm9","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvr2001fpzm9r8vo21ks"},{"post_id":"cjebtxvqv0012pzm9wd26j7z4","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvr3001ipzm9ihwnu9yu"},{"post_id":"cjebtxvqx0015pzm99vx0i946","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvr5001mpzm9g4zr1y43"},{"post_id":"cjebtxvqx0015pzm99vx0i946","category_id":"cjebtxvpt000kpzm9w9cjpwac","_id":"cjebtxvr8001qpzm99di05u9e"},{"post_id":"cjebtxvr1001dpzm9whneu765","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvra001upzm9huz2q7xe"},{"post_id":"cjebtxvpt000jpzm9ha42dod1","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvrb001xpzm90wdjvd8y"},{"post_id":"cjebtxvr3001hpzm9ijp0gil4","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvrc0020pzm9rajec26o"},{"post_id":"cjebtxvr3001hpzm9ijp0gil4","category_id":"cjebtxvpt000kpzm9w9cjpwac","_id":"cjebtxvrd0023pzm9bprirueo"},{"post_id":"cjebtxvpv000opzm9namnozlq","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvre0027pzm91ofyx43f"},{"post_id":"cjebtxvq0000qpzm9qs5ujq1r","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvrg002bpzm9nm24e19w"},{"post_id":"cjebtxvq7000tpzm9un7kkhbo","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvri002epzm9qs3qysyf"},{"post_id":"cjebtxvq7000tpzm9un7kkhbo","category_id":"cjebtxvrb001ypzm9zi3ru51g","_id":"cjebtxvrk002gpzm9if0cbhmh"},{"post_id":"cjebtxvpq000gpzm9b898e6rw","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvrm002kpzm92vi63rd2"},{"post_id":"cjebtxvpq000gpzm9b898e6rw","category_id":"cjebtxvrb001ypzm9zi3ru51g","_id":"cjebtxvrn002mpzm9l6lu4rvt"},{"post_id":"cjebtxvrh002dpzm9npdzxhoq","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvro002qpzm94p3w620h"},{"post_id":"cjebtxvqz0019pzm9oju9evg5","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvrp002spzm91dk4x96c"},{"post_id":"cjebtxvqz0019pzm9oju9evg5","category_id":"cjebtxvrb001ypzm9zi3ru51g","_id":"cjebtxvrr002wpzm99bl7gobb"},{"post_id":"cjebtxvrj002fpzm9cnzuzfrn","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvrs002zpzm9uwq0qway"},{"post_id":"cjebtxvrl002jpzm9ay5clz3r","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvrt0034pzm9ygeu8jo3"},{"post_id":"cjebtxvrm002lpzm9lve9z3sy","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvru0037pzm910upvdxx"},{"post_id":"cjebtxvr4001lpzm9cpb3h9gb","category_id":"cjebtxvrk002ipzm9onbjtm6h","_id":"cjebtxvrx003cpzm9z4lng73b"},{"post_id":"cjebtxvro002opzm9lqoc7amw","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvry003epzm9xcmlbohq"},{"post_id":"cjebtxvrp002rpzm9hg9vqse1","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvrz003hpzm9hrjof3x4"},{"post_id":"cjebtxvr6001opzm9nmea0n24","category_id":"cjebtxvrk002ipzm9onbjtm6h","_id":"cjebtxvs0003lpzm99us15e7k"},{"post_id":"cjebtxvr9001spzm9jr61qiyr","category_id":"cjebtxvrk002ipzm9onbjtm6h","_id":"cjebtxvs4003ppzm9q25qejj5"},{"post_id":"cjebtxvrr002ypzm9mcvij53s","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvs6003tpzm9wujt6yhw"},{"post_id":"cjebtxvrr002ypzm9mcvij53s","category_id":"cjebtxvrb001ypzm9zi3ru51g","_id":"cjebtxvs9003wpzm93ycnwi0t"},{"post_id":"cjebtxvrs0031pzm9yz184apm","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvs9003ypzm9xqg1tg4q"},{"post_id":"cjebtxvrs0031pzm9yz184apm","category_id":"cjebtxvrb001ypzm9zi3ru51g","_id":"cjebtxvsa0040pzm9bs4lgszj"},{"post_id":"cjebtxvra001wpzm94r7d8x0r","category_id":"cjebtxvrk002ipzm9onbjtm6h","_id":"cjebtxvsa0042pzm99v75iigb"},{"post_id":"cjebtxvrx003dpzm9axm4jfox","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvsa0044pzm924yd4eoy"},{"post_id":"cjebtxvrc001zpzm9j6m6iv54","category_id":"cjebtxvrk002ipzm9onbjtm6h","_id":"cjebtxvsb0045pzm99ytsi3ax"},{"post_id":"cjebtxvry003fpzm9jgrppbjf","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvsb0049pzm937ra0y9x"},{"post_id":"cjebtxvrz003jpzm9r96acd4r","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvsc004bpzm90ylnqyy2"},{"post_id":"cjebtxvrd0022pzm9qy2f3wli","category_id":"cjebtxvrk002ipzm9onbjtm6h","_id":"cjebtxvsd004epzm9cl1tem3o"},{"post_id":"cjebtxvs0003mpzm9ta3ygc4h","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvsd004gpzm9ngbskbrj"},{"post_id":"cjebtxvs5003rpzm93eazg1rd","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvsd004jpzm9ej7eeo89"},{"post_id":"cjebtxvre0026pzm9e01tr9vh","category_id":"cjebtxvrk002ipzm9onbjtm6h","_id":"cjebtxvse004lpzm9p2fz0rxy"},{"post_id":"cjebtxvs6003upzm9jt15kvi9","category_id":"cjebtxvpb0004pzm9vzyfrzfh","_id":"cjebtxvse004npzm99wq8euq9"},{"post_id":"cjebtxvrf0029pzm91lfdtp9v","category_id":"cjebtxvrk002ipzm9onbjtm6h","_id":"cjebtxvse004opzm9c9zo1knd"},{"post_id":"cjebtxvrq002upzm9fvw9l715","category_id":"cjebtxvs9003zpzm9sm2wvicu","_id":"cjebtxvse004qpzm9qwf90096"},{"post_id":"cjebtxvru0036pzm9769rghce","category_id":"cjebtxvs9003zpzm9sm2wvicu","_id":"cjebtxvse004rpzm9etvn9qlw"},{"post_id":"cjebtxvrv0039pzm9g9rbtp6g","category_id":"cjebtxvsb0048pzm99vutybjv","_id":"cjebtxvse004tpzm94p6j4j0u"},{"post_id":"cjebtxvwq009dpzm9tdq64c5f","category_id":"cjebtxvq2000rpzm9537rgxgy","_id":"cjebtxvwu009gpzm949pfts7z"}],"PostTag":[{"post_id":"cjebtxvp60002pzm97n61od1o","tag_id":"cjebtxvpd0005pzm937zdb9da","_id":"cjebtxvps000hpzm954rmsydl"},{"post_id":"cjebtxvp60002pzm97n61od1o","tag_id":"cjebtxvpl000apzm9s6a0n1lc","_id":"cjebtxvpu000lpzm902jcb2y7"},{"post_id":"cjebtxvp90003pzm9py4ale94","tag_id":"cjebtxvpp000fpzm9nre8c22w","_id":"cjebtxvql000upzm9o5e39mod"},{"post_id":"cjebtxvp90003pzm9py4ale94","tag_id":"cjebtxvpu000mpzm9x8iz6zub","_id":"cjebtxvqr000ypzm9179gxap6"},{"post_id":"cjebtxvpe0006pzm9psg9y3w8","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvqy0018pzm93jh4tttm"},{"post_id":"cjebtxvpe0006pzm9psg9y3w8","tag_id":"cjebtxvpp000fpzm9nre8c22w","_id":"cjebtxvr1001cpzm9gnshflpl"},{"post_id":"cjebtxvqx0015pzm99vx0i946","tag_id":"cjebtxvpl000apzm9s6a0n1lc","_id":"cjebtxvr3001gpzm9jc25pufw"},{"post_id":"cjebtxvqx0015pzm99vx0i946","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvr4001kpzm9wx44mrpp"},{"post_id":"cjebtxvpf0007pzm9wz4vz332","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvr7001ppzm94j0jq2sc"},{"post_id":"cjebtxvpf0007pzm9wz4vz332","tag_id":"cjebtxvr2001epzm905hqkdg1","_id":"cjebtxvr9001tpzm9dqt37mby"},{"post_id":"cjebtxvpi0008pzm9dwby3sc0","tag_id":"cjebtxvr5001npzm9s0tceftd","_id":"cjebtxvre0024pzm9grmgqmla"},{"post_id":"cjebtxvpi0008pzm9dwby3sc0","tag_id":"cjebtxvra001vpzm9lh82h27c","_id":"cjebtxvrf0028pzm9xfnyjj3a"},{"post_id":"cjebtxvpm000bpzm9rfxtzdm9","tag_id":"cjebtxvrd0021pzm97cy9xq3e","_id":"cjebtxvrr002xpzm90v0jvd1e"},{"post_id":"cjebtxvpm000bpzm9rfxtzdm9","tag_id":"cjebtxvrg002apzm98qvof0mm","_id":"cjebtxvrs0030pzm9cii6g0te"},{"post_id":"cjebtxvpm000bpzm9rfxtzdm9","tag_id":"cjebtxvrk002hpzm9535rm6te","_id":"cjebtxvru0035pzm9ipjnm3be"},{"post_id":"cjebtxvpm000bpzm9rfxtzdm9","tag_id":"cjebtxvrn002npzm9gbhk90y0","_id":"cjebtxvrv0038pzm934h2x83l"},{"post_id":"cjebtxvpo000dpzm9mzhs3zhw","tag_id":"cjebtxvrp002tpzm988abd59h","_id":"cjebtxvs0003kpzm98bzmjod2"},{"post_id":"cjebtxvpo000dpzm9mzhs3zhw","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvs4003opzm9edmg4px9"},{"post_id":"cjebtxvpo000dpzm9mzhs3zhw","tag_id":"cjebtxvrw003bpzm9fsg52g46","_id":"cjebtxvs5003spzm91g561wsv"},{"post_id":"cjebtxvpq000gpzm9b898e6rw","tag_id":"cjebtxvrz003ipzm9q2hhgtmh","_id":"cjebtxvsb0047pzm9x1wadpjd"},{"post_id":"cjebtxvpq000gpzm9b898e6rw","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvsc004apzm9l8c93sn1"},{"post_id":"cjebtxvpq000gpzm9b898e6rw","tag_id":"cjebtxvs9003xpzm9x25m7ynp","_id":"cjebtxvsd004dpzm9jldjqsjq"},{"post_id":"cjebtxvpq000gpzm9b898e6rw","tag_id":"cjebtxvsa0041pzm9tog0ppil","_id":"cjebtxvsd004fpzm9yln5ct35"},{"post_id":"cjebtxvpt000jpzm9ha42dod1","tag_id":"cjebtxvs9003xpzm9x25m7ynp","_id":"cjebtxvsd004ipzm98zigl6ws"},{"post_id":"cjebtxvpt000jpzm9ha42dod1","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvse004kpzm9wfr1mkqv"},{"post_id":"cjebtxvpv000opzm9namnozlq","tag_id":"cjebtxvsd004hpzm9vwqazc5d","_id":"cjebtxvsf004vpzm94n78bvun"},{"post_id":"cjebtxvpv000opzm9namnozlq","tag_id":"cjebtxvse004mpzm9w37ou21x","_id":"cjebtxvsf004wpzm9do32vyne"},{"post_id":"cjebtxvpv000opzm9namnozlq","tag_id":"cjebtxvse004ppzm9w5b7ckhr","_id":"cjebtxvsf004ypzm9mfrwwxjf"},{"post_id":"cjebtxvpv000opzm9namnozlq","tag_id":"cjebtxvrg002apzm98qvof0mm","_id":"cjebtxvsf004zpzm91rlik0x5"},{"post_id":"cjebtxvq0000qpzm9qs5ujq1r","tag_id":"cjebtxvse004upzm95ld6bi66","_id":"cjebtxvsf0052pzm9it1msvbg"},{"post_id":"cjebtxvq0000qpzm9qs5ujq1r","tag_id":"cjebtxvrz003ipzm9q2hhgtmh","_id":"cjebtxvsf0053pzm9scw8o2bm"},{"post_id":"cjebtxvq0000qpzm9qs5ujq1r","tag_id":"cjebtxvra001vpzm9lh82h27c","_id":"cjebtxvsg0055pzm9y88dd6do"},{"post_id":"cjebtxvq7000tpzm9un7kkhbo","tag_id":"cjebtxvsf0051pzm90pbvh1xr","_id":"cjebtxvsg0056pzm9bou07ngz"},{"post_id":"cjebtxvql000vpzm9lze8mf54","tag_id":"cjebtxvs9003xpzm9x25m7ynp","_id":"cjebtxvsh0059pzm9q1lsqvhp"},{"post_id":"cjebtxvql000vpzm9lze8mf54","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvsh005apzm9x48cewt4"},{"post_id":"cjebtxvqr000zpzm91ojgviqw","tag_id":"cjebtxvsg0058pzm9mm3gwgoo","_id":"cjebtxvsh005epzm9eh0wsc1x"},{"post_id":"cjebtxvqr000zpzm91ojgviqw","tag_id":"cjebtxvrz003ipzm9q2hhgtmh","_id":"cjebtxvsi005fpzm9wdg0alh5"},{"post_id":"cjebtxvqr000zpzm91ojgviqw","tag_id":"cjebtxvsf0051pzm90pbvh1xr","_id":"cjebtxvsi005hpzm97d2vt44p"},{"post_id":"cjebtxvqv0012pzm9wd26j7z4","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvsi005ipzm9a29w3sdn"},{"post_id":"cjebtxvqv0012pzm9wd26j7z4","tag_id":"cjebtxvsh005dpzm9ugcutrr3","_id":"cjebtxvsi005kpzm9lh4iquo0"},{"post_id":"cjebtxvqz0019pzm9oju9evg5","tag_id":"cjebtxvsi005gpzm92xbutu4a","_id":"cjebtxvsi005lpzm9bq7ts5zf"},{"post_id":"cjebtxvr1001dpzm9whneu765","tag_id":"cjebtxvs9003xpzm9x25m7ynp","_id":"cjebtxvsj005opzm9e9u8oq1r"},{"post_id":"cjebtxvr1001dpzm9whneu765","tag_id":"cjebtxvsi005mpzm9k7dxeha6","_id":"cjebtxvsj005ppzm9d6qmva2y"},{"post_id":"cjebtxvr3001hpzm9ijp0gil4","tag_id":"cjebtxvsi005npzm9y4b7j43q","_id":"cjebtxvsj005spzm90kb9nv9z"},{"post_id":"cjebtxvr3001hpzm9ijp0gil4","tag_id":"cjebtxvrw003bpzm9fsg52g46","_id":"cjebtxvsj005tpzm97uu6mw6b"},{"post_id":"cjebtxvr3001hpzm9ijp0gil4","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvsj005vpzm94qhb3oer"},{"post_id":"cjebtxvr3001hpzm9ijp0gil4","tag_id":"cjebtxvpp000fpzm9nre8c22w","_id":"cjebtxvsk005wpzm9wza0i57p"},{"post_id":"cjebtxvr4001lpzm9cpb3h9gb","tag_id":"cjebtxvsj005rpzm9r0cnj98v","_id":"cjebtxvsk005zpzm9zzen4xjd"},{"post_id":"cjebtxvr4001lpzm9cpb3h9gb","tag_id":"cjebtxvsj005upzm9m3oabe9v","_id":"cjebtxvsk0060pzm9bdzwib5x"},{"post_id":"cjebtxvr4001lpzm9cpb3h9gb","tag_id":"cjebtxvsk005xpzm957om4r9w","_id":"cjebtxvsk0062pzm9m7mr58wj"},{"post_id":"cjebtxvr6001opzm9nmea0n24","tag_id":"cjebtxvsk005ypzm95m4829ng","_id":"cjebtxvsm0067pzm9z5exvryq"},{"post_id":"cjebtxvr6001opzm9nmea0n24","tag_id":"cjebtxvsk0061pzm98bdfd0sk","_id":"cjebtxvsm0068pzm9ktirjimu"},{"post_id":"cjebtxvr6001opzm9nmea0n24","tag_id":"cjebtxvsk005xpzm957om4r9w","_id":"cjebtxvsm006apzm9iar9rtnt"},{"post_id":"cjebtxvr6001opzm9nmea0n24","tag_id":"cjebtxvsk0064pzm9ctpfs6v1","_id":"cjebtxvsm006bpzm9a2dzom80"},{"post_id":"cjebtxvr6001opzm9nmea0n24","tag_id":"cjebtxvsl0065pzm9dmwq9qlg","_id":"cjebtxvsn006dpzm92fzm7cxl"},{"post_id":"cjebtxvr9001spzm9jr61qiyr","tag_id":"cjebtxvsk005xpzm957om4r9w","_id":"cjebtxvsn006epzm9nevwei5k"},{"post_id":"cjebtxvr9001spzm9jr61qiyr","tag_id":"cjebtxvsm0069pzm91816o94y","_id":"cjebtxvsn006gpzm9szesdosj"},{"post_id":"cjebtxvra001wpzm94r7d8x0r","tag_id":"cjebtxvsm006cpzm9lzjfxy8p","_id":"cjebtxvso006ipzm961lj54rr"},{"post_id":"cjebtxvra001wpzm94r7d8x0r","tag_id":"cjebtxvsn006fpzm9bpt77yh1","_id":"cjebtxvso006jpzm9n2vbixa7"},{"post_id":"cjebtxvrc001zpzm9j6m6iv54","tag_id":"cjebtxvso006hpzm9e7ytp6cg","_id":"cjebtxvsp006npzm9qwqna0fa"},{"post_id":"cjebtxvrc001zpzm9j6m6iv54","tag_id":"cjebtxvso006kpzm9mgakovzn","_id":"cjebtxvsp006opzm9uxyjmdvw"},{"post_id":"cjebtxvrc001zpzm9j6m6iv54","tag_id":"cjebtxvsp006lpzm9c4085oju","_id":"cjebtxvsp006qpzm93nndcfsu"},{"post_id":"cjebtxvrd0022pzm9qy2f3wli","tag_id":"cjebtxvsk005xpzm957om4r9w","_id":"cjebtxvsq006tpzm9x3f13m9b"},{"post_id":"cjebtxvrd0022pzm9qy2f3wli","tag_id":"cjebtxvsp006ppzm966dpkur7","_id":"cjebtxvsq006upzm9ulabod6j"},{"post_id":"cjebtxvrd0022pzm9qy2f3wli","tag_id":"cjebtxvsp006rpzm9voj8hk5i","_id":"cjebtxvsq006wpzm9cshgk5bb"},{"post_id":"cjebtxvre0026pzm9e01tr9vh","tag_id":"cjebtxvsq006spzm9uy8fmrcd","_id":"cjebtxvsr006zpzm9no6qaga6"},{"post_id":"cjebtxvre0026pzm9e01tr9vh","tag_id":"cjebtxvsa0041pzm9tog0ppil","_id":"cjebtxvsr0070pzm91etuuk61"},{"post_id":"cjebtxvre0026pzm9e01tr9vh","tag_id":"cjebtxvsg0058pzm9mm3gwgoo","_id":"cjebtxvsr0072pzm91sukvhh4"},{"post_id":"cjebtxvrf0029pzm91lfdtp9v","tag_id":"cjebtxvsk0064pzm9ctpfs6v1","_id":"cjebtxvss0074pzm923os7676"},{"post_id":"cjebtxvrf0029pzm91lfdtp9v","tag_id":"cjebtxvsl0065pzm9dmwq9qlg","_id":"cjebtxvss0075pzm9gmrolllh"},{"post_id":"cjebtxvrh002dpzm9npdzxhoq","tag_id":"cjebtxvs9003xpzm9x25m7ynp","_id":"cjebtxvst0079pzm916wxluc1"},{"post_id":"cjebtxvrh002dpzm9npdzxhoq","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvst007apzm9wh8lht67"},{"post_id":"cjebtxvrh002dpzm9npdzxhoq","tag_id":"cjebtxvss0077pzm96rwt1l4l","_id":"cjebtxvst007cpzm9rekgm67h"},{"post_id":"cjebtxvrj002fpzm9cnzuzfrn","tag_id":"cjebtxvs9003xpzm9x25m7ynp","_id":"cjebtxvsu007fpzm927v1mx0q"},{"post_id":"cjebtxvrj002fpzm9cnzuzfrn","tag_id":"cjebtxvst007bpzm9t490lwci","_id":"cjebtxvsu007gpzm9ux7o6p8x"},{"post_id":"cjebtxvrj002fpzm9cnzuzfrn","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvsu007ipzm9lc6zyg9f"},{"post_id":"cjebtxvrl002jpzm9ay5clz3r","tag_id":"cjebtxvsf0051pzm90pbvh1xr","_id":"cjebtxvsw007mpzm9ckbnfqdm"},{"post_id":"cjebtxvrl002jpzm9ay5clz3r","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvsw007npzm9t7xl43ww"},{"post_id":"cjebtxvrl002jpzm9ay5clz3r","tag_id":"cjebtxvsv007jpzm9s0ldrqdg","_id":"cjebtxvsw007ppzm9cfgaizp3"},{"post_id":"cjebtxvrl002jpzm9ay5clz3r","tag_id":"cjebtxvsv007kpzm9yap2b06w","_id":"cjebtxvsw007qpzm99w97hnth"},{"post_id":"cjebtxvrm002lpzm9lve9z3sy","tag_id":"cjebtxvsf0051pzm90pbvh1xr","_id":"cjebtxvsw007spzm981op3pkc"},{"post_id":"cjebtxvrm002lpzm9lve9z3sy","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvsx007tpzm97hk2fku4"},{"post_id":"cjebtxvro002opzm9lqoc7amw","tag_id":"cjebtxvsf0051pzm90pbvh1xr","_id":"cjebtxvsz007xpzm9uvgkd42n"},{"post_id":"cjebtxvro002opzm9lqoc7amw","tag_id":"cjebtxvsx007upzm9ukz43th2","_id":"cjebtxvsz007ypzm93yyvq0xz"},{"post_id":"cjebtxvro002opzm9lqoc7amw","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvsz0080pzm94xosuk1p"},{"post_id":"cjebtxvrp002rpzm9hg9vqse1","tag_id":"cjebtxvsy007wpzm9i9tcz0no","_id":"cjebtxvt00083pzm9qc2vw0hp"},{"post_id":"cjebtxvrp002rpzm9hg9vqse1","tag_id":"cjebtxvs9003xpzm9x25m7ynp","_id":"cjebtxvt00084pzm9uds2tbeu"},{"post_id":"cjebtxvrp002rpzm9hg9vqse1","tag_id":"cjebtxvs5003qpzm9j6q0hbjm","_id":"cjebtxvt00086pzm929ooq34n"},{"post_id":"cjebtxvrq002upzm9fvw9l715","tag_id":"cjebtxvsz0082pzm9eti6uyid","_id":"cjebtxvt1008apzm9h8u55rct"},{"post_id":"cjebtxvrq002upzm9fvw9l715","tag_id":"cjebtxvt00085pzm98ufnmb3e","_id":"cjebtxvt1008bpzm9ftq98gaq"},{"post_id":"cjebtxvrq002upzm9fvw9l715","tag_id":"cjebtxvt00087pzm9pjlfy06x","_id":"cjebtxvt1008dpzm9jg9iz2uf"},{"post_id":"cjebtxvrq002upzm9fvw9l715","tag_id":"cjebtxvt10088pzm9dyx8grr9","_id":"cjebtxvt2008epzm975mmuaek"},{"post_id":"cjebtxvrr002ypzm9mcvij53s","tag_id":"cjebtxvsi005gpzm92xbutu4a","_id":"cjebtxvt2008gpzm9411tjm9w"},{"post_id":"cjebtxvrr002ypzm9mcvij53s","tag_id":"cjebtxvt1008cpzm9gvu096jz","_id":"cjebtxvt2008hpzm90v61nkk9"},{"post_id":"cjebtxvrs0031pzm9yz184apm","tag_id":"cjebtxvrz003ipzm9q2hhgtmh","_id":"cjebtxvt2008jpzm9ll7c956r"},{"post_id":"cjebtxvru0036pzm9769rghce","tag_id":"cjebtxvt2008ipzm9dnfqqcb0","_id":"cjebtxvt3008mpzm9mvxgq65x"},{"post_id":"cjebtxvru0036pzm9769rghce","tag_id":"cjebtxvt2008kpzm9aosrfebl","_id":"cjebtxvt3008npzm99pez6cet"},{"post_id":"cjebtxvrv0039pzm9g9rbtp6g","tag_id":"cjebtxvt2008lpzm9g3wfet3i","_id":"cjebtxvt3008qpzm9323mg0ct"},{"post_id":"cjebtxvrv0039pzm9g9rbtp6g","tag_id":"cjebtxvt3008opzm92kkn35ez","_id":"cjebtxvt3008rpzm9apay5x0h"},{"post_id":"cjebtxvrx003dpzm9axm4jfox","tag_id":"cjebtxvsh005dpzm9ugcutrr3","_id":"cjebtxvt4008tpzm99cwlksl7"},{"post_id":"cjebtxvrx003dpzm9axm4jfox","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvt4008upzm9aof7vynx"},{"post_id":"cjebtxvry003fpzm9jgrppbjf","tag_id":"cjebtxvsh005dpzm9ugcutrr3","_id":"cjebtxvt4008xpzm92jiiah8f"},{"post_id":"cjebtxvry003fpzm9jgrppbjf","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvt4008ypzm9dwnk8yz8"},{"post_id":"cjebtxvry003fpzm9jgrppbjf","tag_id":"cjebtxvt4008vpzm9221e3bm0","_id":"cjebtxvt50090pzm9280n1p23"},{"post_id":"cjebtxvrz003jpzm9r96acd4r","tag_id":"cjebtxvsh005dpzm9ugcutrr3","_id":"cjebtxvt50091pzm952e5jywx"},{"post_id":"cjebtxvrz003jpzm9r96acd4r","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvt50093pzm92kgij6xw"},{"post_id":"cjebtxvs0003mpzm9ta3ygc4h","tag_id":"cjebtxvsh005dpzm9ugcutrr3","_id":"cjebtxvt60095pzm9wevsdvsu"},{"post_id":"cjebtxvs0003mpzm9ta3ygc4h","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvt60096pzm9cbtyq48e"},{"post_id":"cjebtxvs0003mpzm9ta3ygc4h","tag_id":"cjebtxvt50092pzm9zy6b4vsv","_id":"cjebtxvt60098pzm9sdvbyydd"},{"post_id":"cjebtxvs5003rpzm93eazg1rd","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvt70099pzm9dq24hvm3"},{"post_id":"cjebtxvs5003rpzm93eazg1rd","tag_id":"cjebtxvsh005dpzm9ugcutrr3","_id":"cjebtxvt7009apzm924cfqb8z"},{"post_id":"cjebtxvs6003upzm9jt15kvi9","tag_id":"cjebtxvq6000spzm9vzgrah94","_id":"cjebtxvt7009bpzm9u66mzzpc"},{"post_id":"cjebtxvs6003upzm9jt15kvi9","tag_id":"cjebtxvsh005dpzm9ugcutrr3","_id":"cjebtxvt7009cpzm95ssds8t7"},{"post_id":"cjebtxvwq009dpzm9tdq64c5f","tag_id":"cjebtxvwt009fpzm93smim4ci","_id":"cjebtxvwv009ipzm9g3q1sdq6"},{"post_id":"cjebtxvwq009dpzm9tdq64c5f","tag_id":"cjebtxvwu009hpzm9tt35ltbp","_id":"cjebtxvwv009jpzm9xlnp6aj3"}],"Tag":[{"name":"Bayes","_id":"cjebtxvpd0005pzm937zdb9da"},{"name":"statistic","_id":"cjebtxvpl000apzm9s6a0n1lc"},{"name":"EDP","_id":"cjebtxvpp000fpzm9nre8c22w"},{"name":"matrix","_id":"cjebtxvpu000mpzm9x8iz6zub"},{"name":"math","_id":"cjebtxvq6000spzm9vzgrah94"},{"name":"FEM","_id":"cjebtxvr2001epzm905hqkdg1"},{"name":"GAN","_id":"cjebtxvr5001npzm9s0tceftd"},{"name":"deep-learning","_id":"cjebtxvra001vpzm9lh82h27c"},{"name":"scrapy","_id":"cjebtxvrd0021pzm97cy9xq3e"},{"name":"python","_id":"cjebtxvrg002apzm98qvof0mm"},{"name":"spider","_id":"cjebtxvrk002hpzm9535rm6te"},{"name":"crawl","_id":"cjebtxvrn002npzm9gbhk90y0"},{"name":"Hilbert","_id":"cjebtxvrp002tpzm988abd59h"},{"name":"analyse","_id":"cjebtxvrw003bpzm9fsg52g46"},{"name":"machine-learning","_id":"cjebtxvrz003ipzm9q2hhgtmh"},{"name":"programming","_id":"cjebtxvs5003qpzm9j6q0hbjm"},{"name":"algo","_id":"cjebtxvs9003xpzm9x25m7ynp"},{"name":"CNN","_id":"cjebtxvsa0041pzm9tog0ppil"},{"name":"mongo","_id":"cjebtxvsd004hpzm9vwqazc5d"},{"name":"mongodb","_id":"cjebtxvse004mpzm9w37ou21x"},{"name":"docker","_id":"cjebtxvse004ppzm9w5b7ckhr"},{"name":"nlp","_id":"cjebtxvse004upzm95ld6bi66"},{"name":"datamining","_id":"cjebtxvsf0051pzm90pbvh1xr"},{"name":"knowledge-graph","_id":"cjebtxvsg0058pzm9mm3gwgoo"},{"name":"probability","_id":"cjebtxvsh005dpzm9ugcutrr3"},{"name":"OS","_id":"cjebtxvsi005gpzm92xbutu4a"},{"name":"data-structure","_id":"cjebtxvsi005mpzm9k7dxeha6"},{"name":"Sobolev","_id":"cjebtxvsi005npzm9y4b7j43q"},{"name":"relation-classification","_id":"cjebtxvsj005rpzm9r0cnj98v"},{"name":"attention","_id":"cjebtxvsj005upzm9m3oabe9v"},{"name":"relation-extraction","_id":"cjebtxvsk005xpzm957om4r9w"},{"name":"entity-resolution","_id":"cjebtxvsk005ypzm95m4829ng"},{"name":"sequence-labeling","_id":"cjebtxvsk0061pzm98bdfd0sk"},{"name":"LSTM","_id":"cjebtxvsk0064pzm9ctpfs6v1"},{"name":"RNN","_id":"cjebtxvsl0065pzm9dmwq9qlg"},{"name":"distant-supervision","_id":"cjebtxvsm0069pzm91816o94y"},{"name":"event-detection","_id":"cjebtxvsm006cpzm9lzjfxy8p"},{"name":"co-reference","_id":"cjebtxvsn006fpzm9bpt77yh1"},{"name":"convolution","_id":"cjebtxvso006hpzm9e7ytp6cg"},{"name":"BiLSTM","_id":"cjebtxvso006kpzm9mgakovzn"},{"name":"event-extraction","_id":"cjebtxvsp006lpzm9c4085oju"},{"name":"limited-supervision","_id":"cjebtxvsp006ppzm966dpkur7"},{"name":"weak-supervision","_id":"cjebtxvsp006rpzm9voj8hk5i"},{"name":"KGC","_id":"cjebtxvsq006spzm9uy8fmrcd"},{"name":"complexity","_id":"cjebtxvss0077pzm96rwt1l4l"},{"name":"compression","_id":"cjebtxvst007bpzm9t490lwci"},{"name":"classification","_id":"cjebtxvsv007jpzm9s0ldrqdg"},{"name":"prediction","_id":"cjebtxvsv007kpzm9yap2b06w"},{"name":"qualitative-induction","_id":"cjebtxvsx007upzm9ukz43th2"},{"name":"graph","_id":"cjebtxvsy007wpzm9i9tcz0no"},{"name":"hexo","_id":"cjebtxvsz0082pzm9eti6uyid"},{"name":"latex","_id":"cjebtxvt00085pzm98ufnmb3e"},{"name":"mathjax","_id":"cjebtxvt00087pzm9pjlfy06x"},{"name":"marked","_id":"cjebtxvt10088pzm9dyx8grr9"},{"name":"kernel","_id":"cjebtxvt1008cpzm9gvu096jz"},{"name":"management","_id":"cjebtxvt2008ipzm9dnfqqcb0"},{"name":"firm","_id":"cjebtxvt2008kpzm9aosrfebl"},{"name":"francais","_id":"cjebtxvt2008lpzm9g3wfet3i"},{"name":"language","_id":"cjebtxvt3008opzm92kkn35ez"},{"name":"aleatoire","_id":"cjebtxvt4008vpzm9221e3bm0"},{"name":"vector","_id":"cjebtxvt50092pzm9zy6b4vsv"},{"name":"web","_id":"cjebtxvwt009fpzm93smim4ci"},{"name":"chrome","_id":"cjebtxvwu009hpzm9tt35ltbp"}]}}