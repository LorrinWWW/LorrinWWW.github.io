{"meta":{"version":1,"warehouse":"2.2.0"},"models":{"Asset":[{"_id":"themes/next/source/css/main.styl","path":"css/main.styl","modified":1,"renderable":1},{"_id":"themes/next/source/images/algolia_logo.svg","path":"images/algolia_logo.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/avatar.gif","path":"images/avatar.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","path":"images/cc-by-nc-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-sa.svg","path":"images/cc-by-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nd.svg","path":"images/cc-by-nd.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc.svg","path":"images/cc-by-nc.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","path":"images/cc-by-nc-sa.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-by.svg","path":"images/cc-by.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/cc-zero.svg","path":"images/cc-zero.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-l.svg","path":"images/quote-l.svg","modified":1,"renderable":1},{"_id":"themes/next/source/images/loading.gif","path":"images/loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/searchicon.png","path":"images/searchicon.png","modified":1,"renderable":1},{"_id":"themes/next/source/images/placeholder.gif","path":"images/placeholder.gif","modified":1,"renderable":1},{"_id":"themes/next/source/images/quote-r.svg","path":"images/quote-r.svg","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/hook-duoshuo.js","path":"js/src/hook-duoshuo.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/algolia-search.js","path":"js/src/algolia-search.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/affix.js","path":"js/src/affix.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/bootstrap.js","path":"js/src/bootstrap.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/post-details.js","path":"js/src/post-details.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/utils.js","path":"js/src/utils.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/motion.js","path":"js/src/motion.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/scrollspy.js","path":"js/src/scrollspy.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","path":"lib/algolia-instant-search/instantsearch.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/LICENSE","path":"lib/fastclick/LICENSE","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/bower.json","path":"lib/fastclick/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/README.md","path":"lib/fastclick/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/bower.json","path":"lib/font-awesome/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","path":"lib/font-awesome/HELP-US-OUT.txt","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","path":"lib/jquery_lazyload/CONTRIBUTING.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","path":"lib/jquery_lazyload/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","path":"lib/jquery_lazyload/README.md","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","path":"lib/jquery_lazyload/jquery.scrollstop.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","path":"lib/jquery_lazyload/jquery.lazyload.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/bower.json","path":"lib/velocity/bower.json","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","path":"lib/velocity/velocity.ui.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","path":"lib/velocity/velocity.ui.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.min.js","path":"lib/velocity/velocity.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/jquery/index.js","path":"lib/jquery/index.js","modified":1,"renderable":1},{"_id":"themes/next/source/js/src/schemes/pisces.js","path":"js/src/schemes/pisces.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","path":"lib/fancybox/source/blank.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","path":"lib/fancybox/source/fancybox_loading.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","path":"lib/fancybox/source/fancybox_sprite@2x.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","path":"lib/fancybox/source/fancybox_overlay.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","path":"lib/fancybox/source/fancybox_sprite.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","path":"lib/fancybox/source/fancybox_loading@2x.gif","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","path":"lib/fancybox/source/jquery.fancybox.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","path":"lib/fancybox/source/jquery.fancybox.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","path":"lib/fastclick/lib/fastclick.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","path":"lib/fancybox/source/jquery.fancybox.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","path":"lib/fastclick/lib/fastclick.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","path":"lib/font-awesome/css/font-awesome.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","path":"lib/font-awesome/css/font-awesome.css.map","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","path":"lib/font-awesome/css/font-awesome.min.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","path":"lib/ua-parser-js/dist/ua-parser.pack.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","path":"lib/ua-parser-js/dist/ua-parser.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","path":"lib/font-awesome/fonts/fontawesome-webfont.eot","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","path":"lib/font-awesome/fonts/fontawesome-webfont.woff2","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","path":"lib/font-awesome/fonts/fontawesome-webfont.woff","modified":1,"renderable":1},{"_id":"themes/next/source/lib/velocity/velocity.js","path":"lib/velocity/velocity.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","path":"lib/font-awesome/fonts/FontAwesome.otf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","path":"lib/fancybox/source/helpers/fancybox_buttons.png","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","path":"lib/fancybox/source/helpers/jquery.fancybox-media.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","path":"lib/fancybox/source/helpers/jquery.fancybox-buttons.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","modified":1,"renderable":1},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","path":"lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","path":"lib/font-awesome/fonts/fontawesome-webfont.ttf","modified":1,"renderable":1},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","path":"lib/algolia-instant-search/instantsearch.min.js","modified":1,"renderable":1},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","path":"lib/font-awesome/fonts/fontawesome-webfont.svg","modified":1,"renderable":1}],"Cache":[{"_id":"source/.DS_Store","hash":"5893d4aabd5c61860da0929e43a0e770ea2146f8","modified":1487104253000},{"_id":"source/google50e2fbd5160eafe4.html","hash":"83768ebbfc295d00d798936de171951e469685f9","modified":1481235745000},{"_id":"themes/next/.editorconfig","hash":"792fd2bd8174ece1a75d5fd24ab16594886f3a7f","modified":1480248297000},{"_id":"themes/next/.bowerrc","hash":"3228a58ed0ece9f85e1e3136352094080b8dece1","modified":1480248297000},{"_id":"themes/next/.DS_Store","hash":"9457f542cf2c3f2a50b9ecd64858fc6f50b0d0c4","modified":1481024229000},{"_id":"themes/next/.javascript_ignore","hash":"f9ea3c5395f8feb225a24e2c32baa79afda30c16","modified":1480248297000},{"_id":"themes/next/.gitignore","hash":"5f09fca02e030b7676c1d312cd88ce8fbccf381c","modified":1480248297000},{"_id":"themes/next/.jshintrc","hash":"9928f81bd822f6a8d67fdbc909b517178533bca9","modified":1480248297000},{"_id":"themes/next/.hound.yml","hash":"b76daa84c9ca3ad292c78412603370a367cc2bc3","modified":1480248297000},{"_id":"themes/next/README.md","hash":"500b5606eb6a09c979d16128f8b00f4bf9bc95ac","modified":1480248297000},{"_id":"themes/next/README.en.md","hash":"565ba52b3825b85a9f05b41183caca7f18b741d4","modified":1480248297000},{"_id":"themes/next/bower.json","hash":"5abc236d9cc2512f5457ed57c1fba76669eb7399","modified":1480248297000},{"_id":"themes/next/gulpfile.coffee","hash":"61ef0606a8134894d7ac796bc8d0fa4ba6a94483","modified":1480248297000},{"_id":"themes/next/_config.yml","hash":"8a1711a5a17126aae0a8192557a136e56b3d3611","modified":1480543695000},{"_id":"themes/next/package.json","hash":"877cb98025e59015532c4c9a04a33e2af4ad56f9","modified":1480248297000},{"_id":"source/_posts/.DS_Store","hash":"7a866c583cb4c5ccc5e58646a8c0fda9f290beb6","modified":1481816162000},{"_id":"source/_posts/EDP-basic-matrix-review.md","hash":"c1fbeae751298cce65cc1985c9690442e015336b","modified":1486464009000},{"_id":"source/_posts/Hilbert-space.md","hash":"3c6db443cefd12c241cbb609a6b75e7765101f9a","modified":1486817852000},{"_id":"source/_posts/Bayes-estimation.md","hash":"3e5aad795853e179d954d3205db4e7b2289908a9","modified":1483807698000},{"_id":"source/_posts/ML-CNN.md","hash":"ef69323536f07aab053cd6d2895c486ad8f21ac9","modified":1481816209000},{"_id":"source/_posts/Note-of-probability.md","hash":"ad5d49330cc0839512071921029120eda20f715c","modified":1480947409000},{"_id":"source/_posts/Method-of-programming-facing-to-exams.md","hash":"1a8fd1060250aede23ca2874e6128a18d349f844","modified":1480502724000},{"_id":"source/_posts/Note-of-datamining.md","hash":"33cfd2f704bd9ae07d4ead3c17696e0a1a52400e","modified":1481058293000},{"_id":"source/_posts/Note-of-learning-Algo.md","hash":"b7b7e260aaeb65905941d8b4bd4571e1574b7c55","modified":1480503398000},{"_id":"source/_posts/Note-of-statistic.md","hash":"4b9ce4b578af1309675aaa85a8d39c9634a632db","modified":1485626526000},{"_id":"source/_posts/compression.md","hash":"6c09d635d6e901b27df17fe64aa759930e9e4ada","modified":1480502772000},{"_id":"source/_posts/QuadTree.md","hash":"f49ef2bd1def94710756b31b74f3208bc2397d20","modified":1481664012000},{"_id":"source/_posts/Sobolev-space.md","hash":"ccf8b23ac2f15a49576f204f3b309f6c94493017","modified":1486831727000},{"_id":"source/_posts/complexity.md","hash":"884bea5a67590cca6019d9a12442352f0e5aa284","modified":1480502588000},{"_id":"source/_posts/graph.md","hash":"fb81eb7a78b150f0133ada157a40e8437d3a135c","modified":1486814910000},{"_id":"source/_posts/datamining-qualitative-induction.md","hash":"732e1ebd08758c64a7325b269d7f788671221e1b","modified":1482476111000},{"_id":"source/_posts/datamining-class-pred.md","hash":"bed4bfa4b40d639d5a22a25c135d2ac7fb65eda2","modified":1482767562000},{"_id":"source/_posts/datamining-pretreatment.md","hash":"c274b6cd8f6388eae82e6786eae0da41b0a20a1c","modified":1481228966000},{"_id":"source/_posts/learning-OS-and-building-LorriOS.md","hash":"3175d7713fd05ad446bca7841057946988b74216","modified":1484049518000},{"_id":"source/_posts/machine-learning.md","hash":"5304e7f0e49d9060a8bf3556e1c5a940e249d37c","modified":1481576860000},{"_id":"source/_posts/hexo-with-latex.md","hash":"8bb31822f906a82bc52db60a54d08e6e85c9a94e","modified":1480542334000},{"_id":"source/_posts/management-of-the-firm.md","hash":"720d9655a8216e9732a4af5e20cc76e88e7cde5b","modified":1481664406000},{"_id":"source/_posts/proba-ch2.md","hash":"ce0ed109def5c1802f4cbe2f545698830ac41053","modified":1480599840000},{"_id":"source/_posts/participe-present-et-gerondif.md","hash":"754b1e438f2f1c593b0a33993af2b8788db80232","modified":1481664512000},{"_id":"source/_posts/proba-ch3.md","hash":"c83c5d8f3c8b9631fb804fa14bca32b7c8f3df98","modified":1480606117000},{"_id":"source/_posts/proba-ch1.md","hash":"dba3dc8fb9720b16d533037452729bd83b6599c5","modified":1480591178000},{"_id":"source/_posts/proba-ch6.md","hash":"25e4cdddd7bcf976a6491622111db0c7a195e2c3","modified":1480712994000},{"_id":"source/_posts/projet-enjeu-plugin-chrome-101.md","hash":"2b82eded6334d7d1afd6a427c6db2bf71431b4de","modified":1480504742000},{"_id":"source/_posts/proba-ch4.md","hash":"7cd6e2d4d3b7fb4e5f8547082cea9611aa13e542","modified":1482153097000},{"_id":"source/_posts/proba-ch5.md","hash":"ccd8f72481bdf1b8ad53605254a3d3d43c3f3787","modified":1481454317000},{"_id":"source/categories/index.md","hash":"e499584b3f5a05f5274b82dd34859016d064d7f9","modified":1487104253000},{"_id":"source/tags/index.md","hash":"e9f9acd08b85f950a4f28cfcb1e6e237265f6a45","modified":1487104253000},{"_id":"themes/next/.git/HEAD","hash":"acbaef275e46a7f14c1ef456fff2c8bbe8c84724","modified":1480248297000},{"_id":"themes/next/.git/description","hash":"9635f1b7e12c045212819dd934d809ef07efa2f4","modified":1480248279000},{"_id":"themes/next/.git/config","hash":"bf7d1df65cf34d0f25a7184a58c37a09f72e4be7","modified":1480248297000},{"_id":"themes/next/.git/index","hash":"138cae75aa9e592129f7fea1a4281e8fe72c1863","modified":1480248297000},{"_id":"themes/next/.git/packed-refs","hash":"09a09da39b7d77dcf2904850874cf00817abdb45","modified":1480248297000},{"_id":"themes/next/.github/ISSUE_TEMPLATE.md","hash":"c2024ded82143807c28a299c5fe6b927ef3525ff","modified":1480248297000},{"_id":"themes/next/.github/CONTRIBUTING.md","hash":"5ab257af816986cd0e53f9527a92d5934ac70ae9","modified":1480248297000},{"_id":"themes/next/languages/de.yml","hash":"1fdea1f84b7f691f5b4dd4d2b43eeb27b10fa0c8","modified":1480248297000},{"_id":"themes/next/languages/default.yml","hash":"767470a80dc257e23e14c3a78e8c52a46c9d6209","modified":1480248297000},{"_id":"themes/next/languages/en.yml","hash":"40057d6608e825d06e0864bac4dcd27ed88ada87","modified":1480248297000},{"_id":"themes/next/languages/fr-FR.yml","hash":"9fca01ef917d33ae2ae6bc04561ec6799dff5351","modified":1480248297000},{"_id":"themes/next/languages/id.yml","hash":"34396bef27c4ab9e9a3c5d3e3aa94b0e3b3a7b0d","modified":1480248297000},{"_id":"themes/next/languages/ja.yml","hash":"49f12149edcc1892b26a6207328cda64da20116d","modified":1480248297000},{"_id":"themes/next/languages/ko.yml","hash":"b6bc5d6b0c000deb44099b42d3aebb8c49dbfca9","modified":1480248297000},{"_id":"themes/next/languages/pt-BR.yml","hash":"7742ba4c0d682cbe1d38305332ebc928abd754b5","modified":1480248297000},{"_id":"themes/next/languages/zh-Hans.yml","hash":"f6c9fafa0f5f0050cd07ca2cf5e38fbae3e28145","modified":1480248297000},{"_id":"themes/next/languages/pt.yml","hash":"6b660b117314cad93f08757601df3adb04c68beb","modified":1480248297000},{"_id":"themes/next/languages/ru.yml","hash":"257d11e626cbe4b9b78785a764190b9278f95c28","modified":1480248297000},{"_id":"themes/next/languages/zh-hk.yml","hash":"34c84c6d04447a25bd5eac576922a13947c000e2","modified":1480248297000},{"_id":"themes/next/languages/zh-tw.yml","hash":"c97a5c41149de9b17f33439b0ecf0eff6fdae50e","modified":1480248297000},{"_id":"themes/next/layout/_layout.swig","hash":"7a1e4443c3ba1e08c20e64ddbf0b8255d034dab0","modified":1480248297000},{"_id":"themes/next/layout/archive.swig","hash":"b5b59d70fc1563f482fa07afd435752774ad5981","modified":1480248297000},{"_id":"themes/next/layout/page.swig","hash":"3727fab9dadb967e9c2204edca787dc72264674a","modified":1480248297000},{"_id":"themes/next/layout/category.swig","hash":"6422d196ceaff4220d54b8af770e7e957f3364ad","modified":1480248297000},{"_id":"themes/next/layout/index.swig","hash":"427d0b95b854e311ae363088ab39a393bf8fdc8b","modified":1480248297000},{"_id":"themes/next/layout/tag.swig","hash":"07cf49c49c39a14dfbe9ce8e7d7eea3d4d0a4911","modified":1480248297000},{"_id":"themes/next/scripts/merge-configs.js","hash":"0c56be2e85c694247cfa327ea6d627b99ca265e8","modified":1480248297000},{"_id":"themes/next/layout/schedule.swig","hash":"1f1cdc268f4ef773fd3ae693bbdf7d0b2f45c3a3","modified":1480248297000},{"_id":"themes/next/layout/post.swig","hash":"e2e512142961ddfe77eba29eaa88f4a2ee43ae18","modified":1480248297000},{"_id":"themes/next/source/.DS_Store","hash":"3037d5331d92d3f549f33102664cadfff9459707","modified":1481024235000},{"_id":"themes/next/test/intern.js","hash":"11fa8a4f5c3b4119a179ae0a2584c8187f907a73","modified":1480248297000},{"_id":"themes/next/test/.jshintrc","hash":"19f93d13d1689fe033c82eb2d5f3ce30b6543cc0","modified":1480248297000},{"_id":"themes/next/test/helpers.js","hash":"a1f5de25154c3724ffc24a91ddc576cdbd60864f","modified":1480248297000},{"_id":"themes/next/source/fonts/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/.git/hooks/applypatch-msg.sample","hash":"4de88eb95a5e93fd27e78b5fb3b5231a8d8917dd","modified":1480248279000},{"_id":"themes/next/.git/hooks/commit-msg.sample","hash":"ee1ed5aad98a435f2020b6de35c173b75d9affac","modified":1480248279000},{"_id":"themes/next/.git/hooks/post-update.sample","hash":"b614c2f63da7dca9f1db2e7ade61ef30448fc96c","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-commit.sample","hash":"36aed8976dcc08b5076844f0ec645b18bc37758f","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-applypatch.sample","hash":"f208287c1a92525de9f5462e905a9d31de1e2d75","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-push.sample","hash":"5c8518bfd1d1d3d2c1a7194994c0a16d8a313a41","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-receive.sample","hash":"705a17d259e7896f0082fe2e9f2c0c3b127be5ac","modified":1480248279000},{"_id":"themes/next/.git/hooks/pre-rebase.sample","hash":"5885a56ab4fca8075a05a562d005e922cde9853b","modified":1480248279000},{"_id":"themes/next/.git/hooks/prepare-commit-msg.sample","hash":"2b6275eda365cad50d167fe3a387c9bc9fedd54f","modified":1480248279000},{"_id":"themes/next/.git/hooks/update.sample","hash":"e729cd61b27c128951d139de8e7c63d1a3758dde","modified":1480248279000},{"_id":"themes/next/.git/info/exclude","hash":"c879df015d97615050afa7b9641e3352a1e701ac","modified":1480248279000},{"_id":"themes/next/.git/logs/HEAD","hash":"54213eda4d20b2a283cee08a3595ada36e83cb1c","modified":1480248297000},{"_id":"themes/next/layout/_custom/header.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1480248297000},{"_id":"themes/next/layout/_custom/sidebar.swig","hash":"adc83b19e793491b1c6ea0fd8b46cd9f32e592fc","modified":1480248297000},{"_id":"themes/next/layout/_macro/reward.swig","hash":"37e5b7c42ec17b9b6b786c5512bcc481a21c974e","modified":1480248297000},{"_id":"themes/next/layout/_macro/sidebar.swig","hash":"b8aaa008aafe4c6e325f7513719e1c251430883e","modified":1480248297000},{"_id":"themes/next/layout/_macro/post-collapse.swig","hash":"43c3433155ccd9abcbe7dce2e6bfa1f3a66af18b","modified":1480248297000},{"_id":"themes/next/layout/_macro/post.swig","hash":"f12f108c1f8e91cc55d49805d42c1fd96cdf51a6","modified":1480248297000},{"_id":"themes/next/layout/_macro/wechat-subscriber.swig","hash":"14e785adeb0e671ba0ff9a553e6f0d8def6c670c","modified":1480248297000},{"_id":"themes/next/layout/_scripts/commons.swig","hash":"766b2bdda29523ed6cd8d7aa197f996022f8fd94","modified":1480248297000},{"_id":"themes/next/layout/_scripts/baidu-push.swig","hash":"c057b17f79e8261680fbae8dc4e81317a127c799","modified":1480248297000},{"_id":"themes/next/layout/_scripts/boostrap.swig","hash":"03aaebe9d50f6acb007ec38cc04acd1cfceb404d","modified":1480248297000},{"_id":"themes/next/layout/_scripts/vendors.swig","hash":"0b91cadecead8e0b5211cc42b085998d94af503a","modified":1480248297000},{"_id":"themes/next/layout/_partials/duoshuo-hot-articles.swig","hash":"5d4638c46aef65bf32a01681495b62416ccc98db","modified":1480248297000},{"_id":"themes/next/layout/_partials/comments.swig","hash":"7a3ef28678467c45ee9416b41b943252e8036285","modified":1480248297000},{"_id":"themes/next/layout/_partials/footer.swig","hash":"1a43dde8c7bc53891be26b915a172b1f01e6bc26","modified":1480248297000},{"_id":"themes/next/layout/_partials/pagination.swig","hash":"9e8e21d194ef44d271b1cca0bc1448c14d7edf4f","modified":1480248297000},{"_id":"themes/next/layout/_partials/head.swig","hash":"ca56f92e2fa82b03853869f5073ee1a5626a4796","modified":1480248297000},{"_id":"themes/next/layout/_partials/header.swig","hash":"f3627f51810bc906e4020a3fef61bc3629b63581","modified":1480248297000},{"_id":"themes/next/layout/_partials/search.swig","hash":"1431719d1dbba3f5ee385eebc46376d1a960b2d5","modified":1480248297000},{"_id":"themes/next/layout/_partials/page-header.swig","hash":"39d613e5a9f8389d4ea52d6082502af8e833b9f2","modified":1480248297000},{"_id":"themes/next/scripts/tags/center-quote.js","hash":"535fc542781021c4326dec24d8495cbb1387634a","modified":1480248297000},{"_id":"themes/next/scripts/tags/full-image.js","hash":"8eeb3fb89540299bdbb799edfdfdac3743b50596","modified":1480248297000},{"_id":"themes/next/scripts/tags/group-pictures.js","hash":"49252824cd53184dc9b97b2f2d87ff28e1b3ef27","modified":1480248297000},{"_id":"themes/next/scripts/tags/note.js","hash":"6752925eedbdb939d8ec4d11bdfb75199f18dd70","modified":1480248297000},{"_id":"themes/next/source/css/.DS_Store","hash":"bbd874d841ee8ed19a25b4fd8382ed8fc6f2c115","modified":1481024373000},{"_id":"themes/next/source/css/main.styl","hash":"20702c48d6053c92c5bcdbc68e8d0ef1369848a0","modified":1480248297000},{"_id":"themes/next/source/images/algolia_logo.svg","hash":"90035272fa31a3f65b3c0e2cb8a633876ef457dc","modified":1480248297000},{"_id":"themes/next/source/images/avatar.gif","hash":"264082bb3a1af70d5499c7d22b0902cb454b6d12","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-nc-nd.svg","hash":"c6524ece3f8039a5f612feaf865d21ec8a794564","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-sa.svg","hash":"aa4742d733c8af8d38d4c183b8adbdcab045872e","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-nd.svg","hash":"c563508ce9ced1e66948024ba1153400ac0e0621","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-nc.svg","hash":"8d39b39d88f8501c0d27f8df9aae47136ebc59b7","modified":1480248297000},{"_id":"themes/next/source/images/cc-by-nc-sa.svg","hash":"3031be41e8753c70508aa88e84ed8f4f653f157e","modified":1480248297000},{"_id":"themes/next/source/images/cc-by.svg","hash":"28a0a4fe355a974a5e42f68031652b76798d4f7e","modified":1480248297000},{"_id":"themes/next/source/images/cc-zero.svg","hash":"87669bf8ac268a91d027a0a4802c92a1473e9030","modified":1480248297000},{"_id":"themes/next/source/images/quote-l.svg","hash":"94e870b4c8c48da61d09522196d4dd40e277a98f","modified":1480248297000},{"_id":"themes/next/source/images/loading.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1480248297000},{"_id":"themes/next/source/images/searchicon.png","hash":"67727a6a969be0b2659b908518fa6706eed307b8","modified":1480248297000},{"_id":"themes/next/source/images/placeholder.gif","hash":"5fbd472222feb8a22cf5b8aa5dc5b8e13af88e2b","modified":1480248297000},{"_id":"themes/next/source/images/quote-r.svg","hash":"e60ae504f9d99b712c793c3740c6b100d057d4ec","modified":1480248297000},{"_id":"themes/next/layout/_scripts/schemes/mist.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/layout/_scripts/schemes/muse.swig","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/Mist.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_variables/Muse.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/source/css/_variables/custom.styl","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1480248297000},{"_id":"themes/next/layout/_components/algolia-search/assets.swig","hash":"28ff4ed6714c59124569ffcbd10f1173d53ca923","modified":1480248297000},{"_id":"themes/next/.git/refs/heads/master","hash":"776e91b78b954875a8d38297e05b80eab20df4b9","modified":1480248297000},{"_id":"themes/next/layout/_components/algolia-search/dom.swig","hash":"636f1181dd5887a70b4a08ca8f655d4e46635792","modified":1480248297000},{"_id":"themes/next/layout/_scripts/pages/post-details.swig","hash":"069d1357c717572256e5cdee09574ebce529cbae","modified":1480248297000},{"_id":"themes/next/layout/_scripts/schemes/pisces.swig","hash":"a44acf9b0d0f44ef3dfc767376a95c984cc127de","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/comments.swig","hash":"82a2ac14d4200480a36bf10abcc3cc554ad744d6","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics.swig","hash":"394d9fff7951287cc90f52acc2d4cbfd1bae079d","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/lean-analytics.swig","hash":"92dc60821307fc9769bea9b2d60adaeb798342af","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/localsearch.swig","hash":"b460e27db3dcd4ab40b17d8926a5c4e624f293a9","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/mathjax.swig","hash":"6d25596d6a7c57700d37b607f8d9a62d89708683","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/schedule.swig","hash":"22369026c87fc23893c35a7f250b42f3bb1b60f1","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/tinysou.swig","hash":"cb3a5d36dbe1630bab84e03a52733a46df7c219b","modified":1480248297000},{"_id":"themes/next/layout/_partials/head/custom-head.swig","hash":"9e1b9666efa77f4cf8d8261bcfa445a9ac608e53","modified":1480248297000},{"_id":"themes/next/layout/_partials/head/external-fonts.swig","hash":"7ce76358411184482bb0934e70037949dd0da8ca","modified":1480248297000},{"_id":"themes/next/layout/_partials/search/swiftype.swig","hash":"959b7e04a96a5596056e4009b73b6489c117597e","modified":1480248297000},{"_id":"themes/next/layout/_partials/search/localsearch.swig","hash":"ff5523d5dacaa77a55a24e50e6e6530c3b98bfad","modified":1480248297000},{"_id":"themes/next/layout/_partials/search/tinysou.swig","hash":"eefe2388ff3d424694045eda21346989b123977c","modified":1480248297000},{"_id":"themes/next/layout/_partials/share/duoshuo_share.swig","hash":"89c5a5240ecb223acfe1d12377df5562a943fd5d","modified":1480248297000},{"_id":"themes/next/layout/_partials/share/baidushare.swig","hash":"1f1107468aaf03f7d0dcd7eb2b653e2813a675b4","modified":1480248297000},{"_id":"themes/next/layout/_partials/share/add-this.swig","hash":"23e23dc0f76ef3c631f24c65277adf7ea517b383","modified":1480248297000},{"_id":"themes/next/layout/_partials/share/jiathis.swig","hash":"63315fcf210799f894208c9f512737096df84962","modified":1480248297000},{"_id":"themes/next/source/css/_custom/custom.styl","hash":"328d9a9696cc2ccf59c67d3c26000d569f46344c","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/Pisces.styl","hash":"715d5b40dc52f319fe4bff0325beb874774d9bd9","modified":1480248297000},{"_id":"themes/next/source/css/_variables/Pisces.styl","hash":"c5b28519b446c2af1e8754a6ae4d766823e6b348","modified":1480248297000},{"_id":"themes/next/source/css/_variables/Mist.styl","hash":"c8d35a6b9e3bff6d8fdb66de853065af9d37562d","modified":1480248297000},{"_id":"themes/next/source/css/_mixins/base.styl","hash":"78a83c38f69a8747bb74e420e6c9eeef1ea76525","modified":1480248297000},{"_id":"themes/next/source/css/_variables/base.styl","hash":"3f0d6aa424f434e82ea507f740eeff110f996269","modified":1480248297000},{"_id":"themes/next/source/js/src/hook-duoshuo.js","hash":"a6119070c0119f33e08b29da7d2cce2635eb40a0","modified":1480248297000},{"_id":"themes/next/source/js/src/algolia-search.js","hash":"96b29f69b8b916b22f62c9959a117b5a968200a5","modified":1480248297000},{"_id":"themes/next/source/js/src/affix.js","hash":"978e0422b5bf1b560236d8d10ebc1adcf66392e3","modified":1480248297000},{"_id":"themes/next/source/js/src/bootstrap.js","hash":"39bf93769d9080fa01a9a875183b43198f79bc19","modified":1480248297000},{"_id":"themes/next/source/js/src/post-details.js","hash":"2038f54e289b6da5def09689e69f623187147be5","modified":1480248297000},{"_id":"themes/next/source/js/src/utils.js","hash":"384e17ff857f073060f5bf8c6e4f4b7353236331","modified":1480248297000},{"_id":"themes/next/source/js/src/motion.js","hash":"269414e84df544a4ccb88519f6abae4943db3c67","modified":1480248297000},{"_id":"themes/next/source/js/src/scrollspy.js","hash":"fe4da1b9fe73518226446f5f27d2831e4426fc35","modified":1480248297000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.css","hash":"90ef19edc982645b118b095615838d9c5eaba0de","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/.bower.json","hash":"93ebd5b35e632f714dcf1753e1f6db77ec74449b","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/.bower.json","hash":"cc40a9b11e52348e554c84e4a5c058056f6b7aeb","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/.gitattributes","hash":"2db21acfbd457452462f71cc4048a943ee61b8e0","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/LICENSE","hash":"dcd5b6b43095d9e90353a28b09cb269de8d4838e","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/bower.json","hash":"13379463c7463b4b96d13556b46faa4cc38d81e6","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/README.md","hash":"1decd8e1adad2cd6db0ab50cf56de6035156f4ea","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/.gitignore","hash":"69d152fa46b517141ec3b1114dd6134724494d83","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/.bower.json","hash":"c1072942459fa0880e8a33a1bd929176b62b4171","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/.npmignore","hash":"dcf470ab3a358103bb896a539cc03caeda10fa8b","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/bower.json","hash":"279a8a718ab6c930a67c41237f0aac166c1b9440","modified":1480248297000},{"_id":"themes/next/source/lib/jquery/.bower.json","hash":"91745c2cc6c946c7275f952b2b0760b880cea69e","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/HELP-US-OUT.txt","hash":"4f7bf961f1bed448f6ba99aeb9219fabf930ba96","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/CONTRIBUTING.md","hash":"4891864c24c28efecd81a6a8d3f261145190f901","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/.bower.json","hash":"b7638afc93e9cd350d0783565ee9a7da6805ad8e","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/bower.json","hash":"65bc85d12197e71c40a55c0cd7f6823995a05222","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/README.md","hash":"895d50fa29759af7835256522e9dd7dac597765c","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.scrollstop.js","hash":"0e9a81785a011c98be5ea821a8ed7d411818cfd1","modified":1480248297000},{"_id":"themes/next/source/lib/jquery_lazyload/jquery.lazyload.js","hash":"481fd478650e12b67c201a0ea41e92743f8b45a3","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/bower.json","hash":"2ec99573e84c7117368beccb9e94b6bf35d2db03","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/.bower.json","hash":"05f960846f1c7a93dab1d3f9a1121e86812e8c88","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/velocity.ui.min.js","hash":"ed5e534cd680a25d8d14429af824f38a2c7d9908","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/velocity.ui.js","hash":"6a1d101eab3de87527bb54fcc8c7b36b79d8f0df","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/velocity.min.js","hash":"2f1afadc12e4cf59ef3b405308d21baa97e739c6","modified":1480248297000},{"_id":"themes/next/source/lib/jquery/index.js","hash":"41b4bfbaa96be6d1440db6e78004ade1c134e276","modified":1480248297000},{"_id":"themes/next/.git/refs/remotes/origin/HEAD","hash":"d9427cda09aba1cdde5c69c2b13c905bddb0bc51","modified":1480248297000},{"_id":"themes/next/.git/logs/refs/heads/master","hash":"54213eda4d20b2a283cee08a3595ada36e83cb1c","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/application-insights.swig","hash":"60426bf73f8a89ba61fb1be2df3ad5398e32c4ef","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/busuanzi-counter.swig","hash":"4fcbf57c4918528ab51d3d042cff92cf5aefb599","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/cnzz-analytics.swig","hash":"8160b27bee0aa372c7dc7c8476c05bae57f58d0f","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/baidu-analytics.swig","hash":"7c43d66da93cde65b473a7d6db2a86f9a42647d6","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/facebook-sdk.swig","hash":"394d008e5e94575280407ad8a1607a028026cbc3","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/comments/duoshuo.swig","hash":"a356b2185d40914447fde817eb3d358ab6b3e4c3","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/google-analytics.swig","hash":"30a23fa7e816496fdec0e932aa42e2d13098a9c2","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/analytics/tencent-analytics.swig","hash":"3658414379e0e8a34c45c40feadc3edc8dc55f88","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/comments/disqus.swig","hash":"fb1d04ede838b52ca7541973f86c3810f1ad396e","modified":1480248297000},{"_id":"themes/next/layout/_scripts/third-party/comments/hypercomments.swig","hash":"3e8dc5c6c912628a37e3b5f886bec7b2e5ed14ea","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/back-to-top.styl","hash":"b49efc66bd055a2d0be7deabfcb02ee72a9a28c8","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/buttons.styl","hash":"0dfb4b3ba3180d7285e66f270e1d3fa0f132c3d2","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/comments.styl","hash":"471f1627891aca5c0e1973e09fbcb01e1510d193","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/components.styl","hash":"10994990d6e0b4d965a728a22cf7f6ee29cae9f6","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pagination.styl","hash":"711c8830886619d4f4a0598b0cde5499dce50c62","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tag-cloud.styl","hash":"dd8a3b22fc2f222ac6e6c05bd8a773fb039169c0","modified":1480248297000},{"_id":"themes/next/source/css/_common/outline/outline.styl","hash":"2186be20e317505cd31886f1291429cc21f76703","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/base.styl","hash":"5304f99581da3a31de3ecec959b7adf9002fde83","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/helpers.styl","hash":"54c90cf7bdbf5c596179d8dae6e671bad1292662","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/normalize.styl","hash":"ece571f38180febaf02ace8187ead8318a300ea7","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/scaffolding.styl","hash":"013619c472c7e4b08311c464fcbe9fcf5edde603","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_header.styl","hash":"5ae7906dc7c1d9468c7f4b4a6feddddc555797a1","modified":1480248297000},{"_id":"themes/next/source/css/_common/scaffolding/tables.styl","hash":"64f5d56c08d74a338813df1265580ca0cbf0190b","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_base.styl","hash":"c2d079788d6fc2e9a191ccdae94e50d55bf849dc","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_logo.styl","hash":"38e5df90c8689a71c978fd83ba74af3d4e4e5386","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_posts-expanded.styl","hash":"4303776991ef28f5742ca51c7dffe6f12f0acf34","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/_menu.styl","hash":"b0dcca862cd0cc6e732e33d975b476d744911742","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/index.styl","hash":"9a5581a770af8964064fef7afd3e16963e45547f","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/_layout.styl","hash":"0efa036a15c18f5abb058b7c0fad1dd9ac5eed4c","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/_menu.styl","hash":"82bbaa6322764779a1ac2e2c8390ce901c7972e2","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/_search.styl","hash":"1452cbe674cc1d008e1e9640eb4283841058fc64","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/_logo.styl","hash":"8829bc556ca38bfec4add4f15a2f028092ac6d46","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/index.styl","hash":"a0e2030a606c934fb2c5c7373aaae04a1caac4c5","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_brand.styl","hash":"be22ad34f546a07f6d56b424338cdd898683eea4","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_layout.styl","hash":"7b206cd8921bc042f8e37a74aea1abc8a5ec8ab4","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_full-image.styl","hash":"938d39eedc6e3d33918c1145a5bf1e79991d3fcf","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_posts.styl","hash":"2f878213cb24c5ddc18877f6d15ec5c5f57745ac","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_menu.styl","hash":"d09280e5b79f3b573edb30f30c7a5f03ac640986","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/_sidebar.styl","hash":"d4b7bd610ca03dbb2f5b66631c0e84a79fb4660b","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Pisces/index.styl","hash":"1b10ba2d3ad0c063c418dc94a0b7e0db4b342c53","modified":1480248297000},{"_id":"themes/next/source/js/src/schemes/pisces.js","hash":"7506e7490c69a200831393c38d25e91c156bd471","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/blank.gif","hash":"2daeaa8b5f19f0bc209d976c02bd6acb51b00b0a","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading.gif","hash":"1a755fb2599f3a313cc6cfdb14df043f8c14a99c","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite@2x.png","hash":"30c58913f327e28f466a00f4c1ac8001b560aed8","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_overlay.png","hash":"b3a4ee645ba494f52840ef8412015ba0f465dbe0","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_sprite.png","hash":"17df19f97628e77be09c352bf27425faea248251","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/fancybox_loading@2x.gif","hash":"273b123496a42ba45c3416adb027cd99745058b0","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.css","hash":"5f163444617b6cf267342f06ac166a237bb62df9","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.js","hash":"1cf3d47b5ccb7cb6e9019c64f2a88d03a64853e4","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.min.js","hash":"2cae0f5a6c5d6f3cb993015e6863f9483fc4de18","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/jquery.fancybox.pack.js","hash":"53360764b429c212f424399384417ccc233bb3be","modified":1480248297000},{"_id":"themes/next/source/lib/fastclick/lib/fastclick.js","hash":"06cef196733a710e77ad7e386ced6963f092dc55","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css","hash":"4eda182cbcc046dbf449aef97c02c230cf80a494","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.css.map","hash":"0189d278706509412bac4745f96c83984e1d59f4","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/css/font-awesome.min.css","hash":"fb5b49426dee7f1508500e698d1b3c6b04c8fcce","modified":1480248297000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.pack.js","hash":"214dad442a92d36af77ed0ca1d9092b16687f02f","modified":1480248297000},{"_id":"themes/next/source/lib/ua-parser-js/dist/ua-parser.min.js","hash":"38628e75e4412cc6f11074e03e1c6d257aae495b","modified":1480248297000},{"_id":"themes/next/.git/objects/pack/pack-5c4d26201d7d4cf7b7a109eab4d66f2aa3d88bca.idx","hash":"3a1a29007edd8fef8ba11b3a97678e2904c934ff","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.eot","hash":"965ce8f688fedbeed504efd498bc9c1622d12362","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff2","hash":"97e438cc545714309882fbceadbf344fcaddcec5","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.woff","hash":"6d7e6a5fc802b13694d8820fc0138037c0977d2e","modified":1480248297000},{"_id":"themes/next/source/lib/velocity/velocity.js","hash":"9f08181baea0cc0e906703b7e5df9111b9ef3373","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/FontAwesome.otf","hash":"1b22f17fdc38070de50e6d1ab3a32da71aa2d819","modified":1480248297000},{"_id":"themes/next/.git/logs/refs/remotes/origin/HEAD","hash":"54213eda4d20b2a283cee08a3595ada36e83cb1c","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/footer/footer.styl","hash":"8994ffcce84deac0471532f270f97c44fea54dc0","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/header.styl","hash":"ae1ca14e51de67b07dba8f61ec79ee0e2e344574","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/headerband.styl","hash":"d27448f199fc2f9980b601bc22b87f08b5d64dd1","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/menu.styl","hash":"c890ce7fe933abad7baf39764a01894924854e92","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/highlight/highlight.styl","hash":"4b7f81e1006e7acee3d1c840ccba155239f830cc","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/site-meta.styl","hash":"6c00f6e0978f4d8f9a846a15579963728aaa6a17","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/header/site-nav.styl","hash":"49c2b2c14a1e7fcc810c6be4b632975d0204c281","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/highlight/diff.styl","hash":"96f32ea6c3265a3889e6abe57587f6e2a2a40dfb","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/highlight/theme.styl","hash":"b76387934fb6bb75212b23c1a194486892cc495e","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/categories.styl","hash":"4eff5b252d7b614e500fc7d52c97ce325e57d3ab","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/archive.styl","hash":"7778920dd105fa4de3a7ab206eeba30b1a7bac45","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/pages.styl","hash":"2039590632bba3943c39319d80ef630af7928185","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/post-detail.styl","hash":"9bf4362a4d0ae151ada84b219d39fbe5bb8c790e","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/pages/schedule.styl","hash":"a82afbb72d83ee394aedc7b37ac0008a9823b4f4","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-collapse.styl","hash":"8fae54591877a73dff0b29b2be2e8935e3c63575","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-gallery.styl","hash":"387ce23bba52b22a586b2dfb4ec618fe1ffd3926","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-more-link.styl","hash":"15063d79b5befc21820baf05d6f20cc1c1787477","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-eof.styl","hash":"2cdc094ecf907a02fce25ad4a607cd5c40da0f2b","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-expand.styl","hash":"b25132fe6a7ad67059a2c3afc60feabb479bdd75","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-meta.styl","hash":"5357db10656b260f8b332c67bb06e486bc64a4ad","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-nav.styl","hash":"c6dab7661a6b8c678b21b7eb273cef7100f970f6","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-reward.styl","hash":"e792c8dc41561c96d128e9b421187f1c3dc978a0","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-tags.styl","hash":"a352ae5b1f8857393bf770d2e638bf15f0c9585d","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-title.styl","hash":"963105a531403d7aad6d9e5e23e3bfabb8ec065a","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author-links.styl","hash":"2e7ec9aaa3293941106b1bdd09055246aa3c3dc6","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-author.styl","hash":"920343e41c124221a17f050bbb989494d44f7a24","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-blogroll.styl","hash":"c44f6a553ec7ea5508f2054a13be33a62a15d3a9","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post-type.styl","hash":"10251257aceecb117233c9554dcf8ecfef8e2104","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/post/post.styl","hash":"4eb18b12fa0ea6c35925d9a64f64e2a7dae8c7fd","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-feed-link.styl","hash":"9486ddd2cb255227db102d09a7df4cae0fabad72","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toc.styl","hash":"7690b9596ec3a49befbe529a5a2649abec0faf76","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-nav.styl","hash":"45fa7193435a8eae9960267438750b4c9fa9587f","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/site-state.styl","hash":"3623e7fa4324ec1307370f33d8f287a9e20a5578","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/blockquote-center.styl","hash":"c2abe4d87148e23e15d49ee225bc650de60baf46","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar-toggle.styl","hash":"2d3abbc85b979a648e0e579e45f16a6eba49d1e7","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/sidebar/sidebar.styl","hash":"234facd038f144bd0fe09a31ed1357c5d74c517f","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/tags.styl","hash":"3eb73cee103b810fa56901577ecb9c9bb1793cff","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/note.styl","hash":"74d0ba86f698165d13402670382a822c8736a556","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/full-image.styl","hash":"618f73450cf541f88a4fddc3d22898aee49d105d","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/tags/group-pictures.styl","hash":"4851b981020c5cbc354a1af9b831a2dcb3cf9d39","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/duoshuo.styl","hash":"2340dd9b3202c61d73cc708b790fac5adddbfc7f","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/baidushare.styl","hash":"93b08815c4d17e2b96fef8530ec1f1064dede6ef","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/busuanzi-counter.styl","hash":"b03f891883446f3a5548b7cc90d29c77e62f1053","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/algolia-search.styl","hash":"eba491ae624b4c843c8be4c94a044085dad4ba0f","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/jiathis.styl","hash":"327b5f63d55ec26f7663185c1a778440588d9803","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/third-party.styl","hash":"5433b6bc9d8f0c4685e760b326445ac51245b0a8","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/outline/outline.styl","hash":"5dc4859c66305f871e56cba78f64bfe3bf1b5f01","modified":1480248297000},{"_id":"themes/next/source/css/_common/components/third-party/localsearch.styl","hash":"637c6b32c58ecf40041be6e911471cd82671919b","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Muse/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1480248297000},{"_id":"themes/next/source/css/_schemes/Mist/sidebar/sidebar-blogroll.styl","hash":"8b8e8cbce98a9296c8fd77f512ae85d945f65d40","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.js","hash":"91e41741c2e93f732c82aaacec4cfc6e3f3ec876","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/fancybox_buttons.png","hash":"e385b139516c6813dcd64b8fc431c364ceafe5f3","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-media.js","hash":"3bdf69ed2469e4fb57f5a95f17300eef891ff90d","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-buttons.css","hash":"1a9d8e5c22b371fcc69d4dbbb823d9c39f04c0c8","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.css","hash":"4ac329c16a5277592fc12a37cca3d72ca4ec292f","modified":1480248297000},{"_id":"themes/next/source/lib/fancybox/source/helpers/jquery.fancybox-thumbs.js","hash":"53e194f4a72e649c04fb586dd57762b8c022800b","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.ttf","hash":"61d8d967807ef12598d81582fa95b9f600c3ee01","modified":1480248297000},{"_id":"themes/next/source/lib/algolia-instant-search/instantsearch.min.js","hash":"9ccc6f8144f54e86df9a3fd33a18368d81cf3a4f","modified":1480248297000},{"_id":"themes/next/source/lib/font-awesome/fonts/fontawesome-webfont.svg","hash":"c0522272bbaef2acb3d341912754d6ea2d0ecfc0","modified":1480248297000},{"_id":"themes/next/.git/objects/pack/pack-5c4d26201d7d4cf7b7a109eab4d66f2aa3d88bca.pack","hash":"ed727435eb82de0486b2a011827e53b71342c928","modified":1480248297000}],"Category":[{"name":"math","_id":"ciz5zkjgr0005zemmf1qlwykm"},{"name":"programming","_id":"ciz5zkjhe000mzemmgc43sdy7"},{"name":"unfinished","parent":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjhv001czemmv01pbazy"},{"name":"unfinished","parent":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkji0001jzemm9rghc6kf"},{"name":"other","_id":"ciz5zkjii002gzemmsf0z2y2z"},{"name":"francais","_id":"ciz5zkjil002szemmtayw8tgz"}],"Data":[],"Page":[{"_content":"google-site-verification: google50e2fbd5160eafe4.html","source":"google50e2fbd5160eafe4.html","raw":"google-site-verification: google50e2fbd5160eafe4.html","date":"2017-02-14T20:18:29.000Z","updated":"2016-12-08T22:22:25.000Z","path":"google50e2fbd5160eafe4.html","title":"","comments":1,"layout":"page","_id":"ciz5zkjbq0000zemm34qcrg3h","content":"google-site-verification: google50e2fbd5160eafe4.html","excerpt":"","more":"google-site-verification: google50e2fbd5160eafe4.html"},{"title":"categories","date":"2016-11-27T12:13:12.000Z","type":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2016-11-27 13:13:12\ntype: \"categories\" \n---\n","updated":"2017-02-14T20:30:53.000Z","path":"categories/index.html","comments":1,"layout":"page","_id":"ciz5zkjgl0002zemmj1rkizxj","content":"","excerpt":"","more":""},{"title":"tags","date":"2016-11-27T12:15:12.000Z","type":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2016-11-27 13:15:12\ntype: \"tags\"\n---\n","updated":"2017-02-14T20:30:53.000Z","path":"tags/index.html","comments":1,"layout":"page","_id":"ciz5zkjgp0004zemmrk0xsteb","content":"","excerpt":"","more":""}],"Post":[{"title":"EDP基础：矩阵的复习","date":"2017-02-07T09:22:27.000Z","_content":"\n## 注意点：\n\n1. A est une matrice hermitienne <=> A=A* et donc A est normale\n2. A est une matrice  unitaire (酉矩阵) <=> A^-1 = A* et donc A est normale\n3. A est une matrice orthogonale <=> A=A^T\n\n\n\n## Schur定理（矩陣三角化）\n\n$$\nA = [a_{ij}]_{n\\times n} , 特征值\\lambda_i , 对应特征向量x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n则,A是可对角化矩阵 \\\\\nA = SDS^{-1}\n$$\n\n如果**A**是*n*阶的复方阵，则存在*n*阶酉矩阵U，*n*阶上三角矩阵T，使得：\n$$\nA = UTU^{-1}\n$$\n\n## 酉矩阵\n\n$$\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}\n$$\n\nU是酉矩阵。\n\n\n\n## Cholesky分解\n\n条件：\n\n1. une matrice hermitienne：矩阵中的元素共轭对称（复数域的定义，类比于实数对称矩阵）。Hermitiank意味着对于任意向量x和y，(x*)Ay共轭相等\n2. Positive-definite：正定矩阵A意味着，对于任何向量x，(x^T)Ax总是大于零(复数域是(x*)Ax>0)\n\n则存在L为下三角矩阵，使得 A = LL*。\n\n\n\n## QR分解\n\n目标：A = QR，*Q*是正交矩阵（意味着*Q*T*Q* = *I*）而*R*是上三角矩阵。\n\n","source":"_posts/EDP-basic-matrix-review.md","raw":"---\ntitle: 'EDP基础：矩阵的复习'\ndate: 2017-02-07 10:22:27\ncategories: [math]\ntags: [EDP, matrix]\n---\n\n## 注意点：\n\n1. A est une matrice hermitienne <=> A=A* et donc A est normale\n2. A est une matrice  unitaire (酉矩阵) <=> A^-1 = A* et donc A est normale\n3. A est une matrice orthogonale <=> A=A^T\n\n\n\n## Schur定理（矩陣三角化）\n\n$$\nA = [a_{ij}]_{n\\times n} , 特征值\\lambda_i , 对应特征向量x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n则,A是可对角化矩阵 \\\\\nA = SDS^{-1}\n$$\n\n如果**A**是*n*阶的复方阵，则存在*n*阶酉矩阵U，*n*阶上三角矩阵T，使得：\n$$\nA = UTU^{-1}\n$$\n\n## 酉矩阵\n\n$$\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}\n$$\n\nU是酉矩阵。\n\n\n\n## Cholesky分解\n\n条件：\n\n1. une matrice hermitienne：矩阵中的元素共轭对称（复数域的定义，类比于实数对称矩阵）。Hermitiank意味着对于任意向量x和y，(x*)Ay共轭相等\n2. Positive-definite：正定矩阵A意味着，对于任何向量x，(x^T)Ax总是大于零(复数域是(x*)Ax>0)\n\n则存在L为下三角矩阵，使得 A = LL*。\n\n\n\n## QR分解\n\n目标：A = QR，*Q*是正交矩阵（意味着*Q*T*Q* = *I*）而*R*是上三角矩阵。\n\n","slug":"EDP-basic-matrix-review","published":1,"updated":"2017-02-07T10:40:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjgh0001zemmd8qr7rk1","content":"<h2 id=\"注意点：\"><a href=\"#注意点：\" class=\"headerlink\" title=\"注意点：\"></a>注意点：</h2><ol>\n<li>A est une matrice hermitienne &lt;=&gt; A=A* et donc A est normale</li>\n<li>A est une matrice  unitaire (酉矩阵) &lt;=&gt; A^-1 = A* et donc A est normale</li>\n<li>A est une matrice orthogonale &lt;=&gt; A=A^T</li>\n</ol>\n<h2 id=\"Schur定理（矩陣三角化）\"><a href=\"#Schur定理（矩陣三角化）\" class=\"headerlink\" title=\"Schur定理（矩陣三角化）\"></a>Schur定理（矩陣三角化）</h2><script type=\"math/tex; mode=display\">\nA = [a_{ij}]_{n\\times n} , 特征值\\lambda_i , 对应特征向量x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n则,A是可对角化矩阵 \\\\\nA = SDS^{-1}</script><p>如果<strong>A</strong>是<em>n</em>阶的复方阵，则存在<em>n</em>阶酉矩阵U，<em>n</em>阶上三角矩阵T，使得：</p>\n<script type=\"math/tex; mode=display\">\nA = UTU^{-1}</script><h2 id=\"酉矩阵\"><a href=\"#酉矩阵\" class=\"headerlink\" title=\"酉矩阵\"></a>酉矩阵</h2><script type=\"math/tex; mode=display\">\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}</script><p>U是酉矩阵。</p>\n<h2 id=\"Cholesky分解\"><a href=\"#Cholesky分解\" class=\"headerlink\" title=\"Cholesky分解\"></a>Cholesky分解</h2><p>条件：</p>\n<ol>\n<li>une matrice hermitienne：矩阵中的元素共轭对称（复数域的定义，类比于实数对称矩阵）。Hermitiank意味着对于任意向量x和y，(x*)Ay共轭相等</li>\n<li>Positive-definite：正定矩阵A意味着，对于任何向量x，(x^T)Ax总是大于零(复数域是(x*)Ax&gt;0)</li>\n</ol>\n<p>则存在L为下三角矩阵，使得 A = LL*。</p>\n<h2 id=\"QR分解\"><a href=\"#QR分解\" class=\"headerlink\" title=\"QR分解\"></a>QR分解</h2><p>目标：A = QR，<em>Q</em>是正交矩阵（意味着<em>Q</em>T<em>Q</em> = <em>I</em>）而<em>R</em>是上三角矩阵。</p>\n","excerpt":"","more":"<h2 id=\"注意点：\"><a href=\"#注意点：\" class=\"headerlink\" title=\"注意点：\"></a>注意点：</h2><ol>\n<li>A est une matrice hermitienne &lt;=&gt; A=A* et donc A est normale</li>\n<li>A est une matrice  unitaire (酉矩阵) &lt;=&gt; A^-1 = A* et donc A est normale</li>\n<li>A est une matrice orthogonale &lt;=&gt; A=A^T</li>\n</ol>\n<h2 id=\"Schur定理（矩陣三角化）\"><a href=\"#Schur定理（矩陣三角化）\" class=\"headerlink\" title=\"Schur定理（矩陣三角化）\"></a>Schur定理（矩陣三角化）</h2><script type=\"math/tex; mode=display\">\nA = [a_{ij}]_{n\\times n} , 特征值\\lambda_i , 对应特征向量x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n则,A是可对角化矩阵 \\\\\nA = SDS^{-1}</script><p>如果<strong>A</strong>是<em>n</em>阶的复方阵，则存在<em>n</em>阶酉矩阵U，<em>n</em>阶上三角矩阵T，使得：</p>\n<script type=\"math/tex; mode=display\">\nA = UTU^{-1}</script><h2 id=\"酉矩阵\"><a href=\"#酉矩阵\" class=\"headerlink\" title=\"酉矩阵\"></a>酉矩阵</h2><script type=\"math/tex; mode=display\">\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}</script><p>U是酉矩阵。</p>\n<h2 id=\"Cholesky分解\"><a href=\"#Cholesky分解\" class=\"headerlink\" title=\"Cholesky分解\"></a>Cholesky分解</h2><p>条件：</p>\n<ol>\n<li>une matrice hermitienne：矩阵中的元素共轭对称（复数域的定义，类比于实数对称矩阵）。Hermitiank意味着对于任意向量x和y，(x*)Ay共轭相等</li>\n<li>Positive-definite：正定矩阵A意味着，对于任何向量x，(x^T)Ax总是大于零(复数域是(x*)Ax&gt;0)</li>\n</ol>\n<p>则存在L为下三角矩阵，使得 A = LL*。</p>\n<h2 id=\"QR分解\"><a href=\"#QR分解\" class=\"headerlink\" title=\"QR分解\"></a>QR分解</h2><p>目标：A = QR，<em>Q</em>是正交矩阵（意味着<em>Q</em>T<em>Q</em> = <em>I</em>）而<em>R</em>是上三角矩阵。</p>\n"},{"title":"Hilbert space","date":"2017-02-11T12:10:06.000Z","_content":"\n# 希尔伯特空间 Hilbert space\n\n## 感性认识\n\n摘自wiki:\n\n>在数学里，**希尔伯特空间**即**完备的内积空间**，也就是说一个带有内积的完备向量空间。\n\n要弄清楚希尔伯特空间，我们需要从几个基本的地方出发。\n\n### 几个形容词\n\n- 线性\n\n  有线性结构的。\n\n- 赋范\n\n  空间中用于度量“长度”，引入范数。\n\n- 完备(complet)\n\n  其上所有的柯西序列会收敛到此空间里的一点，序列的极限依然在此空间内。通俗的说，我们认为这个空间是不缺点、有皮的。\n\n- 内积\n\n  补充“角度”概念，引入内积。\n\n### 几类空间\n\n- 线性空间\n\n- 度量空间\n\n  最基本的空间。前者有线性结构，后者有度量空间，二者没有交集。\n\n- 赋范线性空间\n\n  引入范数\n\n- 内积空间\n\n  内积空间是赋范线性空间。\n\n- 希尔伯特空间\n\n  希尔伯特空间是完备的内积空间\n\n((线性空间 + 范数  = 赋范空间 + 线性结构) + 内积 = 内积空间) + 完备性 = 希尔伯特空间\n\n## 可以由以下空间获得\n\n- 欧几里得空间\n\n  定义内积。\n\n- 序列空间\n\n- 勒贝格空间\n\n  特指L^2空间，定义其内积:\n\n  ​\n  $$\n  (f|g) = \\int{\\overline{f}g}\n  $$\n  还需证明其完备性.\n\n- 索伯列夫空间\n\n  一般表示为H^s或W^(s,2)。在偏微分方程中常用。\n\n## 希尔伯特空间的基\n\n- 所有基的范数为1\n- 彼此正交\n- 其线性扩张稠密：即其中的所有元素的有限的线性组合是H的一个稠密子集。\n\n## 相关\n\n- 内积(produit scalaire)\n\n  满足以下四个条件：\n\n$$\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0\n$$\n","source":"_posts/Hilbert-space.md","raw":"---\ntitle: Hilbert space\ndate: 2017-02-11 13:10:06\ncategories: [math]\ntags: [Hilbert, math, analyse]\n---\n\n# 希尔伯特空间 Hilbert space\n\n## 感性认识\n\n摘自wiki:\n\n>在数学里，**希尔伯特空间**即**完备的内积空间**，也就是说一个带有内积的完备向量空间。\n\n要弄清楚希尔伯特空间，我们需要从几个基本的地方出发。\n\n### 几个形容词\n\n- 线性\n\n  有线性结构的。\n\n- 赋范\n\n  空间中用于度量“长度”，引入范数。\n\n- 完备(complet)\n\n  其上所有的柯西序列会收敛到此空间里的一点，序列的极限依然在此空间内。通俗的说，我们认为这个空间是不缺点、有皮的。\n\n- 内积\n\n  补充“角度”概念，引入内积。\n\n### 几类空间\n\n- 线性空间\n\n- 度量空间\n\n  最基本的空间。前者有线性结构，后者有度量空间，二者没有交集。\n\n- 赋范线性空间\n\n  引入范数\n\n- 内积空间\n\n  内积空间是赋范线性空间。\n\n- 希尔伯特空间\n\n  希尔伯特空间是完备的内积空间\n\n((线性空间 + 范数  = 赋范空间 + 线性结构) + 内积 = 内积空间) + 完备性 = 希尔伯特空间\n\n## 可以由以下空间获得\n\n- 欧几里得空间\n\n  定义内积。\n\n- 序列空间\n\n- 勒贝格空间\n\n  特指L^2空间，定义其内积:\n\n  ​\n  $$\n  (f|g) = \\int{\\overline{f}g}\n  $$\n  还需证明其完备性.\n\n- 索伯列夫空间\n\n  一般表示为H^s或W^(s,2)。在偏微分方程中常用。\n\n## 希尔伯特空间的基\n\n- 所有基的范数为1\n- 彼此正交\n- 其线性扩张稠密：即其中的所有元素的有限的线性组合是H的一个稠密子集。\n\n## 相关\n\n- 内积(produit scalaire)\n\n  满足以下四个条件：\n\n$$\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0\n$$\n","slug":"Hilbert-space","published":1,"updated":"2017-02-11T12:57:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjgn0003zemmxkk0vwkv","content":"<h1 id=\"希尔伯特空间-Hilbert-space\"><a href=\"#希尔伯特空间-Hilbert-space\" class=\"headerlink\" title=\"希尔伯特空间 Hilbert space\"></a>希尔伯特空间 Hilbert space</h1><h2 id=\"感性认识\"><a href=\"#感性认识\" class=\"headerlink\" title=\"感性认识\"></a>感性认识</h2><p>摘自wiki:</p>\n<blockquote>\n<p>在数学里，<strong>希尔伯特空间</strong>即<strong>完备的内积空间</strong>，也就是说一个带有内积的完备向量空间。</p>\n</blockquote>\n<p>要弄清楚希尔伯特空间，我们需要从几个基本的地方出发。</p>\n<h3 id=\"几个形容词\"><a href=\"#几个形容词\" class=\"headerlink\" title=\"几个形容词\"></a>几个形容词</h3><ul>\n<li><p>线性</p>\n<p>有线性结构的。</p>\n</li>\n<li><p>赋范</p>\n<p>空间中用于度量“长度”，引入范数。</p>\n</li>\n<li><p>完备(complet)</p>\n<p>其上所有的柯西序列会收敛到此空间里的一点，序列的极限依然在此空间内。通俗的说，我们认为这个空间是不缺点、有皮的。</p>\n</li>\n<li><p>内积</p>\n<p>补充“角度”概念，引入内积。</p>\n</li>\n</ul>\n<h3 id=\"几类空间\"><a href=\"#几类空间\" class=\"headerlink\" title=\"几类空间\"></a>几类空间</h3><ul>\n<li><p>线性空间</p>\n</li>\n<li><p>度量空间</p>\n<p>最基本的空间。前者有线性结构，后者有度量空间，二者没有交集。</p>\n</li>\n<li><p>赋范线性空间</p>\n<p>引入范数</p>\n</li>\n<li><p>内积空间</p>\n<p>内积空间是赋范线性空间。</p>\n</li>\n<li><p>希尔伯特空间</p>\n<p>希尔伯特空间是完备的内积空间</p>\n</li>\n</ul>\n<p>((线性空间 + 范数  = 赋范空间 + 线性结构) + 内积 = 内积空间) + 完备性 = 希尔伯特空间</p>\n<h2 id=\"可以由以下空间获得\"><a href=\"#可以由以下空间获得\" class=\"headerlink\" title=\"可以由以下空间获得\"></a>可以由以下空间获得</h2><ul>\n<li><p>欧几里得空间</p>\n<p>定义内积。</p>\n</li>\n<li><p>序列空间</p>\n</li>\n<li><p>勒贝格空间</p>\n<p>特指L^2空间，定义其内积:</p>\n<p>​</p>\n<script type=\"math/tex; mode=display\">\n(f|g) = \\int{\\overline{f}g}</script><p>还需证明其完备性.</p>\n</li>\n<li><p>索伯列夫空间</p>\n<p>一般表示为H^s或W^(s,2)。在偏微分方程中常用。</p>\n</li>\n</ul>\n<h2 id=\"希尔伯特空间的基\"><a href=\"#希尔伯特空间的基\" class=\"headerlink\" title=\"希尔伯特空间的基\"></a>希尔伯特空间的基</h2><ul>\n<li>所有基的范数为1</li>\n<li>彼此正交</li>\n<li>其线性扩张稠密：即其中的所有元素的有限的线性组合是H的一个稠密子集。</li>\n</ul>\n<h2 id=\"相关\"><a href=\"#相关\" class=\"headerlink\" title=\"相关\"></a>相关</h2><ul>\n<li><p>内积(produit scalaire)</p>\n<p>满足以下四个条件：</p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0</script>","excerpt":"","more":"<h1 id=\"希尔伯特空间-Hilbert-space\"><a href=\"#希尔伯特空间-Hilbert-space\" class=\"headerlink\" title=\"希尔伯特空间 Hilbert space\"></a>希尔伯特空间 Hilbert space</h1><h2 id=\"感性认识\"><a href=\"#感性认识\" class=\"headerlink\" title=\"感性认识\"></a>感性认识</h2><p>摘自wiki:</p>\n<blockquote>\n<p>在数学里，<strong>希尔伯特空间</strong>即<strong>完备的内积空间</strong>，也就是说一个带有内积的完备向量空间。</p>\n</blockquote>\n<p>要弄清楚希尔伯特空间，我们需要从几个基本的地方出发。</p>\n<h3 id=\"几个形容词\"><a href=\"#几个形容词\" class=\"headerlink\" title=\"几个形容词\"></a>几个形容词</h3><ul>\n<li><p>线性</p>\n<p>有线性结构的。</p>\n</li>\n<li><p>赋范</p>\n<p>空间中用于度量“长度”，引入范数。</p>\n</li>\n<li><p>完备(complet)</p>\n<p>其上所有的柯西序列会收敛到此空间里的一点，序列的极限依然在此空间内。通俗的说，我们认为这个空间是不缺点、有皮的。</p>\n</li>\n<li><p>内积</p>\n<p>补充“角度”概念，引入内积。</p>\n</li>\n</ul>\n<h3 id=\"几类空间\"><a href=\"#几类空间\" class=\"headerlink\" title=\"几类空间\"></a>几类空间</h3><ul>\n<li><p>线性空间</p>\n</li>\n<li><p>度量空间</p>\n<p>最基本的空间。前者有线性结构，后者有度量空间，二者没有交集。</p>\n</li>\n<li><p>赋范线性空间</p>\n<p>引入范数</p>\n</li>\n<li><p>内积空间</p>\n<p>内积空间是赋范线性空间。</p>\n</li>\n<li><p>希尔伯特空间</p>\n<p>希尔伯特空间是完备的内积空间</p>\n</li>\n</ul>\n<p>((线性空间 + 范数  = 赋范空间 + 线性结构) + 内积 = 内积空间) + 完备性 = 希尔伯特空间</p>\n<h2 id=\"可以由以下空间获得\"><a href=\"#可以由以下空间获得\" class=\"headerlink\" title=\"可以由以下空间获得\"></a>可以由以下空间获得</h2><ul>\n<li><p>欧几里得空间</p>\n<p>定义内积。</p>\n</li>\n<li><p>序列空间</p>\n</li>\n<li><p>勒贝格空间</p>\n<p>特指L^2空间，定义其内积:</p>\n<p>​</p>\n<script type=\"math/tex; mode=display\">\n(f|g) = \\int{\\overline{f}g}</script><p>还需证明其完备性.</p>\n</li>\n<li><p>索伯列夫空间</p>\n<p>一般表示为H^s或W^(s,2)。在偏微分方程中常用。</p>\n</li>\n</ul>\n<h2 id=\"希尔伯特空间的基\"><a href=\"#希尔伯特空间的基\" class=\"headerlink\" title=\"希尔伯特空间的基\"></a>希尔伯特空间的基</h2><ul>\n<li>所有基的范数为1</li>\n<li>彼此正交</li>\n<li>其线性扩张稠密：即其中的所有元素的有限的线性组合是H的一个稠密子集。</li>\n</ul>\n<h2 id=\"相关\"><a href=\"#相关\" class=\"headerlink\" title=\"相关\"></a>相关</h2><ul>\n<li><p>内积(produit scalaire)</p>\n<p>满足以下四个条件：</p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0</script>"},{"title":"贝叶斯估计 Bayes estimation","date":"2017-01-07T15:46:31.000Z","_content":"\n在机器学习中，贝叶斯这个名字被不止一次的提到。正好又看到了贝叶斯参数估计，简单记录方法，可能没有严谨的数学推导，见谅。\n\n首先我们必须提及的就是历史上的两大学派——经典统计学派和贝叶斯统计学派。\n\n这里我们假设要估计的参数为$\\theta$，简单来说，经典统计学派认为$\\theta$是一个未知但固定的常数，而贝叶斯学派认为$\\theta$是一个变量。\n\n## 贝叶斯公式\n\n我们为什么需要贝叶斯估计呢？\n\n我们不妨看一个例子，经典统计学派我们使用极大似然估计法。\n\n假如学生在做一道题，当一个学生会做这道题时，他的正确率是98%。当他不会做这道题时，答题的正确率为5%。现在，有一个学生的对这道题测验结果为错误，问这个人会做这道题吗？ \n既然会做并做对的概率为98%，不会做但做对的概率为5%，如果用最大似然估计的方法，我们认为这个人已经感染了病毒。 \n\n但是如果如果这道题十分容易呢？比如，题目是1+1=？，事实上，就算是幼儿园的小孩也会做。那么这个估计结果其实是有时偏颇的。\n\n此时我们用贝叶斯方法进行估计，如果我们得知有一个先验概率，比如整体学生中只有1%的人会感染此种病毒，那么由贝叶斯公式： \n$$\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}\n$$\n\n$$\np(不会做|做错)=\\frac{p(做错|不会做)p(不会做)}{p(做错)}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324\n$$\n\n这么看来，还是会做的概率比较高，只不过这个学生比较粗心罢了。\n\n## 利用贝叶斯进行参数估计\n\n贝叶斯估计中，需要对参数有一个先验估计，并记录其分布为：\n$$\n\\theta: \\pi(\\theta)\n$$\n已知样本为\n$$\n\\widetilde{X} = \\{ X_1,...,X_n \\}\n$$\n参数的联合分布为\n$$\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)\n$$\n所以\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}\n$$\n特别的，若T是一个充分统计量\n$$\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)\n$$\n从而\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )\n$$\n这样，参数的分布就已经得到了，接下来一般通过三种方法进行估计：\n\n- 后验分布的众数进行估计\n- 后验分布的中位数进行估计\n- 后验分布的期望进行估计\n\n总结一下，贝叶斯估计就是，认为被估计参数是一个随机变量，通过已有的数据得到一个先验分布，结合这个先验分布再通过现有的条件，最后得到一个较为合理的后验分布。\n\n注：\n\n- 如果x的方差趋于无穷，意味着样本没有任何意义，估计结果等于先验估计。\n- 如果样本数量趋于无穷，则估计结果与先验估计无关。这说明先验估计实际上是为了弥补样本的不足。","source":"_posts/Bayes-estimation.md","raw":"---\ntitle: 贝叶斯估计 Bayes estimation\ndate: 2017-01-07 16:46:31\ncategories: [math]\ntags: [Bayes, statistic]\n---\n\n在机器学习中，贝叶斯这个名字被不止一次的提到。正好又看到了贝叶斯参数估计，简单记录方法，可能没有严谨的数学推导，见谅。\n\n首先我们必须提及的就是历史上的两大学派——经典统计学派和贝叶斯统计学派。\n\n这里我们假设要估计的参数为$\\theta$，简单来说，经典统计学派认为$\\theta$是一个未知但固定的常数，而贝叶斯学派认为$\\theta$是一个变量。\n\n## 贝叶斯公式\n\n我们为什么需要贝叶斯估计呢？\n\n我们不妨看一个例子，经典统计学派我们使用极大似然估计法。\n\n假如学生在做一道题，当一个学生会做这道题时，他的正确率是98%。当他不会做这道题时，答题的正确率为5%。现在，有一个学生的对这道题测验结果为错误，问这个人会做这道题吗？ \n既然会做并做对的概率为98%，不会做但做对的概率为5%，如果用最大似然估计的方法，我们认为这个人已经感染了病毒。 \n\n但是如果如果这道题十分容易呢？比如，题目是1+1=？，事实上，就算是幼儿园的小孩也会做。那么这个估计结果其实是有时偏颇的。\n\n此时我们用贝叶斯方法进行估计，如果我们得知有一个先验概率，比如整体学生中只有1%的人会感染此种病毒，那么由贝叶斯公式： \n$$\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}\n$$\n\n$$\np(不会做|做错)=\\frac{p(做错|不会做)p(不会做)}{p(做错)}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324\n$$\n\n这么看来，还是会做的概率比较高，只不过这个学生比较粗心罢了。\n\n## 利用贝叶斯进行参数估计\n\n贝叶斯估计中，需要对参数有一个先验估计，并记录其分布为：\n$$\n\\theta: \\pi(\\theta)\n$$\n已知样本为\n$$\n\\widetilde{X} = \\{ X_1,...,X_n \\}\n$$\n参数的联合分布为\n$$\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)\n$$\n所以\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}\n$$\n特别的，若T是一个充分统计量\n$$\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)\n$$\n从而\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )\n$$\n这样，参数的分布就已经得到了，接下来一般通过三种方法进行估计：\n\n- 后验分布的众数进行估计\n- 后验分布的中位数进行估计\n- 后验分布的期望进行估计\n\n总结一下，贝叶斯估计就是，认为被估计参数是一个随机变量，通过已有的数据得到一个先验分布，结合这个先验分布再通过现有的条件，最后得到一个较为合理的后验分布。\n\n注：\n\n- 如果x的方差趋于无穷，意味着样本没有任何意义，估计结果等于先验估计。\n- 如果样本数量趋于无穷，则估计结果与先验估计无关。这说明先验估计实际上是为了弥补样本的不足。","slug":"Bayes-estimation","published":1,"updated":"2017-01-07T16:48:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjgu0007zemmcjopsnjo","content":"<p>在机器学习中，贝叶斯这个名字被不止一次的提到。正好又看到了贝叶斯参数估计，简单记录方法，可能没有严谨的数学推导，见谅。</p>\n<p>首先我们必须提及的就是历史上的两大学派——经典统计学派和贝叶斯统计学派。</p>\n<p>这里我们假设要估计的参数为$\\theta$，简单来说，经典统计学派认为$\\theta$是一个未知但固定的常数，而贝叶斯学派认为$\\theta$是一个变量。</p>\n<h2 id=\"贝叶斯公式\"><a href=\"#贝叶斯公式\" class=\"headerlink\" title=\"贝叶斯公式\"></a>贝叶斯公式</h2><p>我们为什么需要贝叶斯估计呢？</p>\n<p>我们不妨看一个例子，经典统计学派我们使用极大似然估计法。</p>\n<p>假如学生在做一道题，当一个学生会做这道题时，他的正确率是98%。当他不会做这道题时，答题的正确率为5%。现在，有一个学生的对这道题测验结果为错误，问这个人会做这道题吗？<br>既然会做并做对的概率为98%，不会做但做对的概率为5%，如果用最大似然估计的方法，我们认为这个人已经感染了病毒。 </p>\n<p>但是如果如果这道题十分容易呢？比如，题目是1+1=？，事实上，就算是幼儿园的小孩也会做。那么这个估计结果其实是有时偏颇的。</p>\n<p>此时我们用贝叶斯方法进行估计，如果我们得知有一个先验概率，比如整体学生中只有1%的人会感染此种病毒，那么由贝叶斯公式： </p>\n<script type=\"math/tex; mode=display\">\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}</script><script type=\"math/tex; mode=display\">\np(不会做|做错)=\\frac{p(做错|不会做)p(不会做)}{p(做错)}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324</script><p>这么看来，还是会做的概率比较高，只不过这个学生比较粗心罢了。</p>\n<h2 id=\"利用贝叶斯进行参数估计\"><a href=\"#利用贝叶斯进行参数估计\" class=\"headerlink\" title=\"利用贝叶斯进行参数估计\"></a>利用贝叶斯进行参数估计</h2><p>贝叶斯估计中，需要对参数有一个先验估计，并记录其分布为：</p>\n<script type=\"math/tex; mode=display\">\n\\theta: \\pi(\\theta)</script><p>已知样本为</p>\n<script type=\"math/tex; mode=display\">\n\\widetilde{X} = \\{ X_1,...,X_n \\}</script><p>参数的联合分布为</p>\n<script type=\"math/tex; mode=display\">\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)</script><p>所以</p>\n<script type=\"math/tex; mode=display\">\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}</script><p>特别的，若T是一个充分统计量</p>\n<script type=\"math/tex; mode=display\">\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)</script><p>从而</p>\n<script type=\"math/tex; mode=display\">\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )</script><p>这样，参数的分布就已经得到了，接下来一般通过三种方法进行估计：</p>\n<ul>\n<li>后验分布的众数进行估计</li>\n<li>后验分布的中位数进行估计</li>\n<li>后验分布的期望进行估计</li>\n</ul>\n<p>总结一下，贝叶斯估计就是，认为被估计参数是一个随机变量，通过已有的数据得到一个先验分布，结合这个先验分布再通过现有的条件，最后得到一个较为合理的后验分布。</p>\n<p>注：</p>\n<ul>\n<li>如果x的方差趋于无穷，意味着样本没有任何意义，估计结果等于先验估计。</li>\n<li>如果样本数量趋于无穷，则估计结果与先验估计无关。这说明先验估计实际上是为了弥补样本的不足。</li>\n</ul>\n","excerpt":"","more":"<p>在机器学习中，贝叶斯这个名字被不止一次的提到。正好又看到了贝叶斯参数估计，简单记录方法，可能没有严谨的数学推导，见谅。</p>\n<p>首先我们必须提及的就是历史上的两大学派——经典统计学派和贝叶斯统计学派。</p>\n<p>这里我们假设要估计的参数为$\\theta$，简单来说，经典统计学派认为$\\theta$是一个未知但固定的常数，而贝叶斯学派认为$\\theta$是一个变量。</p>\n<h2 id=\"贝叶斯公式\"><a href=\"#贝叶斯公式\" class=\"headerlink\" title=\"贝叶斯公式\"></a>贝叶斯公式</h2><p>我们为什么需要贝叶斯估计呢？</p>\n<p>我们不妨看一个例子，经典统计学派我们使用极大似然估计法。</p>\n<p>假如学生在做一道题，当一个学生会做这道题时，他的正确率是98%。当他不会做这道题时，答题的正确率为5%。现在，有一个学生的对这道题测验结果为错误，问这个人会做这道题吗？<br>既然会做并做对的概率为98%，不会做但做对的概率为5%，如果用最大似然估计的方法，我们认为这个人已经感染了病毒。 </p>\n<p>但是如果如果这道题十分容易呢？比如，题目是1+1=？，事实上，就算是幼儿园的小孩也会做。那么这个估计结果其实是有时偏颇的。</p>\n<p>此时我们用贝叶斯方法进行估计，如果我们得知有一个先验概率，比如整体学生中只有1%的人会感染此种病毒，那么由贝叶斯公式： </p>\n<script type=\"math/tex; mode=display\">\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}</script><script type=\"math/tex; mode=display\">\np(不会做|做错)=\\frac{p(做错|不会做)p(不会做)}{p(做错)}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324</script><p>这么看来，还是会做的概率比较高，只不过这个学生比较粗心罢了。</p>\n<h2 id=\"利用贝叶斯进行参数估计\"><a href=\"#利用贝叶斯进行参数估计\" class=\"headerlink\" title=\"利用贝叶斯进行参数估计\"></a>利用贝叶斯进行参数估计</h2><p>贝叶斯估计中，需要对参数有一个先验估计，并记录其分布为：</p>\n<script type=\"math/tex; mode=display\">\n\\theta: \\pi(\\theta)</script><p>已知样本为</p>\n<script type=\"math/tex; mode=display\">\n\\widetilde{X} = \\{ X_1,...,X_n \\}</script><p>参数的联合分布为</p>\n<script type=\"math/tex; mode=display\">\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)</script><p>所以</p>\n<script type=\"math/tex; mode=display\">\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}</script><p>特别的，若T是一个充分统计量</p>\n<script type=\"math/tex; mode=display\">\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)</script><p>从而</p>\n<script type=\"math/tex; mode=display\">\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )</script><p>这样，参数的分布就已经得到了，接下来一般通过三种方法进行估计：</p>\n<ul>\n<li>后验分布的众数进行估计</li>\n<li>后验分布的中位数进行估计</li>\n<li>后验分布的期望进行估计</li>\n</ul>\n<p>总结一下，贝叶斯估计就是，认为被估计参数是一个随机变量，通过已有的数据得到一个先验分布，结合这个先验分布再通过现有的条件，最后得到一个较为合理的后验分布。</p>\n<p>注：</p>\n<ul>\n<li>如果x的方差趋于无穷，意味着样本没有任何意义，估计结果等于先验估计。</li>\n<li>如果样本数量趋于无穷，则估计结果与先验估计无关。这说明先验估计实际上是为了弥补样本的不足。</li>\n</ul>\n"},{"title":"ML CNN","date":"2016-12-14T09:34:43.000Z","_content":"\n笔记向\n\n目前来说，深度学习中比较火的两大类是卷积神经网络(CNN)和递归神经网络(RNN)。\n\n# 全连接层\n\n全连接层一般由两个部分— 线性部分和非线性部分组成。\n\n## 线性部分\n\n输入：\n$$\nx = [x_0,x_1,...,x_n]^T\n$$\n输出：\n$$\nz = [z_0,z_1,...,z_m]^T\n$$\n参数为一个矩阵\n$$\nW_{m \\times n}\n$$\n偏执项：\n$$\nb = [b_0,b_1,...,b_m]^T\n$$\n于是：\n$$\nW * x + b = z\n$$\n\n## 非线性部分\n\n根据我们线性代数的知识，如果一系列变换都是线形变换，那么我们可以使用一次线形变换来代替之前的所有变换。也就是说，若没有非线性部分，那么**多元**神经元在这里也就没有意义了(因为只需要一层神经元就可以代替其他所有的)。\n\n当然，非线性部分也不是为了存在而存在的，用途我们会在后面有更深的理解。\n\n非线性部分的模型也不是唯一的，但是我们常常使用以下几种。\n\n1. sigmoid\n\n   记得就在前几天，在数理统计的书上也看到了这个函数— sigmoid。\n\n   先写出它的形式：\n   $$\n   f(x) = \\frac{1}{1+e^{-x}}\n   $$\n   这个函数把一个取值在R上的变量，变成了一个取值在(0, 1)上的变量。\n\n2. 双曲正切\n   $$\n   f(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n   $$\n   它的取值范围是(-1,1)。可以看出，它是有正有负的，而sigmoid是全为正的。\n\n","source":"_posts/ML-CNN.md","raw":"---\ntitle: ML CNN\ndate: 2016-12-14 10:34:43\ncategories: [programming, unfinished]\ntags: [machine-learning, programming, algo, CNN]\n---\n\n笔记向\n\n目前来说，深度学习中比较火的两大类是卷积神经网络(CNN)和递归神经网络(RNN)。\n\n# 全连接层\n\n全连接层一般由两个部分— 线性部分和非线性部分组成。\n\n## 线性部分\n\n输入：\n$$\nx = [x_0,x_1,...,x_n]^T\n$$\n输出：\n$$\nz = [z_0,z_1,...,z_m]^T\n$$\n参数为一个矩阵\n$$\nW_{m \\times n}\n$$\n偏执项：\n$$\nb = [b_0,b_1,...,b_m]^T\n$$\n于是：\n$$\nW * x + b = z\n$$\n\n## 非线性部分\n\n根据我们线性代数的知识，如果一系列变换都是线形变换，那么我们可以使用一次线形变换来代替之前的所有变换。也就是说，若没有非线性部分，那么**多元**神经元在这里也就没有意义了(因为只需要一层神经元就可以代替其他所有的)。\n\n当然，非线性部分也不是为了存在而存在的，用途我们会在后面有更深的理解。\n\n非线性部分的模型也不是唯一的，但是我们常常使用以下几种。\n\n1. sigmoid\n\n   记得就在前几天，在数理统计的书上也看到了这个函数— sigmoid。\n\n   先写出它的形式：\n   $$\n   f(x) = \\frac{1}{1+e^{-x}}\n   $$\n   这个函数把一个取值在R上的变量，变成了一个取值在(0, 1)上的变量。\n\n2. 双曲正切\n   $$\n   f(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n   $$\n   它的取值范围是(-1,1)。可以看出，它是有正有负的，而sigmoid是全为正的。\n\n","slug":"ML-CNN","published":1,"updated":"2016-12-15T15:36:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjgw0008zemmccgenkxw","content":"<p>笔记向</p>\n<p>目前来说，深度学习中比较火的两大类是卷积神经网络(CNN)和递归神经网络(RNN)。</p>\n<h1 id=\"全连接层\"><a href=\"#全连接层\" class=\"headerlink\" title=\"全连接层\"></a>全连接层</h1><p>全连接层一般由两个部分— 线性部分和非线性部分组成。</p>\n<h2 id=\"线性部分\"><a href=\"#线性部分\" class=\"headerlink\" title=\"线性部分\"></a>线性部分</h2><p>输入：</p>\n<script type=\"math/tex; mode=display\">\nx = [x_0,x_1,...,x_n]^T</script><p>输出：</p>\n<script type=\"math/tex; mode=display\">\nz = [z_0,z_1,...,z_m]^T</script><p>参数为一个矩阵</p>\n<script type=\"math/tex; mode=display\">\nW_{m \\times n}</script><p>偏执项：</p>\n<script type=\"math/tex; mode=display\">\nb = [b_0,b_1,...,b_m]^T</script><p>于是：</p>\n<script type=\"math/tex; mode=display\">\nW * x + b = z</script><h2 id=\"非线性部分\"><a href=\"#非线性部分\" class=\"headerlink\" title=\"非线性部分\"></a>非线性部分</h2><p>根据我们线性代数的知识，如果一系列变换都是线形变换，那么我们可以使用一次线形变换来代替之前的所有变换。也就是说，若没有非线性部分，那么<strong>多元</strong>神经元在这里也就没有意义了(因为只需要一层神经元就可以代替其他所有的)。</p>\n<p>当然，非线性部分也不是为了存在而存在的，用途我们会在后面有更深的理解。</p>\n<p>非线性部分的模型也不是唯一的，但是我们常常使用以下几种。</p>\n<ol>\n<li><p>sigmoid</p>\n<p>记得就在前几天，在数理统计的书上也看到了这个函数— sigmoid。</p>\n<p>先写出它的形式：</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{1+e^{-x}}</script><p>这个函数把一个取值在R上的变量，变成了一个取值在(0, 1)上的变量。</p>\n</li>\n<li><p>双曲正切</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}</script><p>它的取值范围是(-1,1)。可以看出，它是有正有负的，而sigmoid是全为正的。</p>\n</li>\n</ol>\n","excerpt":"","more":"<p>笔记向</p>\n<p>目前来说，深度学习中比较火的两大类是卷积神经网络(CNN)和递归神经网络(RNN)。</p>\n<h1 id=\"全连接层\"><a href=\"#全连接层\" class=\"headerlink\" title=\"全连接层\"></a>全连接层</h1><p>全连接层一般由两个部分— 线性部分和非线性部分组成。</p>\n<h2 id=\"线性部分\"><a href=\"#线性部分\" class=\"headerlink\" title=\"线性部分\"></a>线性部分</h2><p>输入：</p>\n<script type=\"math/tex; mode=display\">\nx = [x_0,x_1,...,x_n]^T</script><p>输出：</p>\n<script type=\"math/tex; mode=display\">\nz = [z_0,z_1,...,z_m]^T</script><p>参数为一个矩阵</p>\n<script type=\"math/tex; mode=display\">\nW_{m \\times n}</script><p>偏执项：</p>\n<script type=\"math/tex; mode=display\">\nb = [b_0,b_1,...,b_m]^T</script><p>于是：</p>\n<script type=\"math/tex; mode=display\">\nW * x + b = z</script><h2 id=\"非线性部分\"><a href=\"#非线性部分\" class=\"headerlink\" title=\"非线性部分\"></a>非线性部分</h2><p>根据我们线性代数的知识，如果一系列变换都是线形变换，那么我们可以使用一次线形变换来代替之前的所有变换。也就是说，若没有非线性部分，那么<strong>多元</strong>神经元在这里也就没有意义了(因为只需要一层神经元就可以代替其他所有的)。</p>\n<p>当然，非线性部分也不是为了存在而存在的，用途我们会在后面有更深的理解。</p>\n<p>非线性部分的模型也不是唯一的，但是我们常常使用以下几种。</p>\n<ol>\n<li><p>sigmoid</p>\n<p>记得就在前几天，在数理统计的书上也看到了这个函数— sigmoid。</p>\n<p>先写出它的形式：</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{1+e^{-x}}</script><p>这个函数把一个取值在R上的变量，变成了一个取值在(0, 1)上的变量。</p>\n</li>\n<li><p>双曲正切</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}</script><p>它的取值范围是(-1,1)。可以看出，它是有正有负的，而sigmoid是全为正的。</p>\n</li>\n</ol>\n"},{"title":"概率论笔记 Note of probability","date":"2016-11-30T18:35:53.000Z","_content":"\n该笔记只是记录在法国学的一些东西，因为学的是法语的翻译可能有些摸不着头脑，并且记的凌乱，望见谅。\n\n另外，这里的概率论是基于测度论的概率论，这里假设已经学过测度学了。\n\n# Part 1 公理、概率空间\n\n{% post_link proba-ch1 Savoir plus  %}\n\n# Part 2 概率与随机变量\n\n{% post_link proba-ch2 Savoir plus  %}\n\n# Part 3 实域概率和特征方程\n\n{% post_link proba-ch3 Savoir plus  %}\n\n# Part 4 高斯向量\n\n{% post_link proba-ch4 Savoir plus  %}\n\n# Part 5 数列和随机变量系列\n\n{% post_link proba-ch5 Savoir plus  %}\n\n# Part 6 条件数学期望\n\n{% post_link proba-ch6 Savoir plus  %}\n","source":"_posts/Note-of-probability.md","raw":"---\ntitle: 概率论笔记 Note of probability\ndate: 2016-11-30 19:35:53\ncategories: [math]\ntags: [math, probability]\n---\n\n该笔记只是记录在法国学的一些东西，因为学的是法语的翻译可能有些摸不着头脑，并且记的凌乱，望见谅。\n\n另外，这里的概率论是基于测度论的概率论，这里假设已经学过测度学了。\n\n# Part 1 公理、概率空间\n\n{% post_link proba-ch1 Savoir plus  %}\n\n# Part 2 概率与随机变量\n\n{% post_link proba-ch2 Savoir plus  %}\n\n# Part 3 实域概率和特征方程\n\n{% post_link proba-ch3 Savoir plus  %}\n\n# Part 4 高斯向量\n\n{% post_link proba-ch4 Savoir plus  %}\n\n# Part 5 数列和随机变量系列\n\n{% post_link proba-ch5 Savoir plus  %}\n\n# Part 6 条件数学期望\n\n{% post_link proba-ch6 Savoir plus  %}\n","slug":"Note-of-probability","published":1,"updated":"2016-12-05T14:16:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjh00009zemmshinm0tf","content":"<p>该笔记只是记录在法国学的一些东西，因为学的是法语的翻译可能有些摸不着头脑，并且记的凌乱，望见谅。</p>\n<p>另外，这里的概率论是基于测度论的概率论，这里假设已经学过测度学了。</p>\n<h1 id=\"Part-1-公理、概率空间\"><a href=\"#Part-1-公理、概率空间\" class=\"headerlink\" title=\"Part 1 公理、概率空间\"></a>Part 1 公理、概率空间</h1><a href=\"/2016/12/01/proba-ch1/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-2-概率与随机变量\"><a href=\"#Part-2-概率与随机变量\" class=\"headerlink\" title=\"Part 2 概率与随机变量\"></a>Part 2 概率与随机变量</h1><a href=\"/2016/12/01/proba-ch2/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-3-实域概率和特征方程\"><a href=\"#Part-3-实域概率和特征方程\" class=\"headerlink\" title=\"Part 3 实域概率和特征方程\"></a>Part 3 实域概率和特征方程</h1><a href=\"/2016/12/01/proba-ch3/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-4-高斯向量\"><a href=\"#Part-4-高斯向量\" class=\"headerlink\" title=\"Part 4 高斯向量\"></a>Part 4 高斯向量</h1><a href=\"/2016/12/01/proba-ch4/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-5-数列和随机变量系列\"><a href=\"#Part-5-数列和随机变量系列\" class=\"headerlink\" title=\"Part 5 数列和随机变量系列\"></a>Part 5 数列和随机变量系列</h1><a href=\"/2016/12/01/proba-ch5/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-6-条件数学期望\"><a href=\"#Part-6-条件数学期望\" class=\"headerlink\" title=\"Part 6 条件数学期望\"></a>Part 6 条件数学期望</h1><a href=\"/2016/12/02/proba-ch6/\" title=\"Savoir plus\">Savoir plus</a>\n","excerpt":"","more":"<p>该笔记只是记录在法国学的一些东西，因为学的是法语的翻译可能有些摸不着头脑，并且记的凌乱，望见谅。</p>\n<p>另外，这里的概率论是基于测度论的概率论，这里假设已经学过测度学了。</p>\n<h1 id=\"Part-1-公理、概率空间\"><a href=\"#Part-1-公理、概率空间\" class=\"headerlink\" title=\"Part 1 公理、概率空间\"></a>Part 1 公理、概率空间</h1><a href=\"/2016/12/01/proba-ch1/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-2-概率与随机变量\"><a href=\"#Part-2-概率与随机变量\" class=\"headerlink\" title=\"Part 2 概率与随机变量\"></a>Part 2 概率与随机变量</h1><a href=\"/2016/12/01/proba-ch2/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-3-实域概率和特征方程\"><a href=\"#Part-3-实域概率和特征方程\" class=\"headerlink\" title=\"Part 3 实域概率和特征方程\"></a>Part 3 实域概率和特征方程</h1><a href=\"/2016/12/01/proba-ch3/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-4-高斯向量\"><a href=\"#Part-4-高斯向量\" class=\"headerlink\" title=\"Part 4 高斯向量\"></a>Part 4 高斯向量</h1><a href=\"/2016/12/01/proba-ch4/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-5-数列和随机变量系列\"><a href=\"#Part-5-数列和随机变量系列\" class=\"headerlink\" title=\"Part 5 数列和随机变量系列\"></a>Part 5 数列和随机变量系列</h1><a href=\"/2016/12/01/proba-ch5/\" title=\"Savoir plus\">Savoir plus</a>\n<h1 id=\"Part-6-条件数学期望\"><a href=\"#Part-6-条件数学期望\" class=\"headerlink\" title=\"Part 6 条件数学期望\"></a>Part 6 条件数学期望</h1><a href=\"/2016/12/02/proba-ch6/\" title=\"Savoir plus\">Savoir plus</a>\n"},{"title":"面向考试常用编程思想 Method of programming facing to exams","date":"2016-11-27T12:49:31.000Z","_content":"\n1. 穷举法\n\n   略\n\n2. 贪心法\n\n   略\n\n3. 分治法\n\n   ```Python\n   def merge(A, B):\n       # merge two small solved problems into one.\n       return merged\n\n   def divideConquer(S, divide, combine):\n       if len(S) == 1: return S\n       # divide a grand problems\n       L, R = divide(S)\n       A = divideConquer(L, divide, combine)\n       B = divideConquer(R, divide, combine)\n       return merge(A, B)\n   ```\n\n   上面的情形只供参考，参数等视具体情况而定。\n\n4. 动态规划\n\n   比较经典的就是背包问题。[代码来源](http://blog.csdn.net/littlethunder/article/details/26575417)\n\n   ```Python\n   def bag(n,c,w,v):  \n       res=[[-1 for j in range(c+1)] for i in range(n+1)]  \n       for j in range(c+1):  \n           res[0][j]=0  \n       for i in range(1,n+1):  \n           for j in range(1,c+1):  \n               res[i][j]=res[i-1][j]  \n               if j>=w[i-1] and res[i][j]<res[i-1][j-w[i-1]]+v[i-1]:  \n                   res[i][j]=res[i-1][j-w[i-1]]+v[i-1]  \n       return res  \n     \n   def show(n,c,w,res):  \n       print('最大价值为:',res[n][c])  \n       x=[False for i in range(n)]  \n       j=c  \n       for i in range(1,n+1):  \n           if res[i][j]>res[i-1][j]:  \n               x[i-1]=True  \n               j-=w[i-1]  \n       print('选择的物品为:')  \n       for i in range(n):  \n           if x[i]:  \n               print('第',i,'个,',end='')  \n       print('')  \n     \n   if __name__=='__main__':  \n       n=5  \n       c=10  \n       w=[2,2,6,5,4]  \n       v=[6,3,5,4,6]  \n       res=bag(n,c,w,v)  \n       show(n,c,w,res)\n   ```\n\n   ​","source":"_posts/Method-of-programming-facing-to-exams.md","raw":"---\ntitle: 面向考试常用编程思想 Method of programming facing to exams\ndate: 2016-11-27 13:49:31\ncategories: programming\ntags: [algo, programming]\n---\n\n1. 穷举法\n\n   略\n\n2. 贪心法\n\n   略\n\n3. 分治法\n\n   ```Python\n   def merge(A, B):\n       # merge two small solved problems into one.\n       return merged\n\n   def divideConquer(S, divide, combine):\n       if len(S) == 1: return S\n       # divide a grand problems\n       L, R = divide(S)\n       A = divideConquer(L, divide, combine)\n       B = divideConquer(R, divide, combine)\n       return merge(A, B)\n   ```\n\n   上面的情形只供参考，参数等视具体情况而定。\n\n4. 动态规划\n\n   比较经典的就是背包问题。[代码来源](http://blog.csdn.net/littlethunder/article/details/26575417)\n\n   ```Python\n   def bag(n,c,w,v):  \n       res=[[-1 for j in range(c+1)] for i in range(n+1)]  \n       for j in range(c+1):  \n           res[0][j]=0  \n       for i in range(1,n+1):  \n           for j in range(1,c+1):  \n               res[i][j]=res[i-1][j]  \n               if j>=w[i-1] and res[i][j]<res[i-1][j-w[i-1]]+v[i-1]:  \n                   res[i][j]=res[i-1][j-w[i-1]]+v[i-1]  \n       return res  \n     \n   def show(n,c,w,res):  \n       print('最大价值为:',res[n][c])  \n       x=[False for i in range(n)]  \n       j=c  \n       for i in range(1,n+1):  \n           if res[i][j]>res[i-1][j]:  \n               x[i-1]=True  \n               j-=w[i-1]  \n       print('选择的物品为:')  \n       for i in range(n):  \n           if x[i]:  \n               print('第',i,'个,',end='')  \n       print('')  \n     \n   if __name__=='__main__':  \n       n=5  \n       c=10  \n       w=[2,2,6,5,4]  \n       v=[6,3,5,4,6]  \n       res=bag(n,c,w,v)  \n       show(n,c,w,res)\n   ```\n\n   ​","slug":"Method-of-programming-facing-to-exams","published":1,"updated":"2016-11-30T10:45:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjh5000czemmcrpt8fzg","content":"<ol>\n<li><p>穷举法</p>\n<p>略</p>\n</li>\n<li><p>贪心法</p>\n<p>略</p>\n</li>\n<li><p>分治法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">merge</span><span class=\"params\">(A, B)</span>:</span></div><div class=\"line\">    <span class=\"comment\"># merge two small solved problems into one.</span></div><div class=\"line\">    <span class=\"keyword\">return</span> merged</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">divideConquer</span><span class=\"params\">(S, divide, combine)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">if</span> len(S) == <span class=\"number\">1</span>: <span class=\"keyword\">return</span> S</div><div class=\"line\">    <span class=\"comment\"># divide a grand problems</span></div><div class=\"line\">    L, R = divide(S)</div><div class=\"line\">    A = divideConquer(L, divide, combine)</div><div class=\"line\">    B = divideConquer(R, divide, combine)</div><div class=\"line\">    <span class=\"keyword\">return</span> merge(A, B)</div></pre></td></tr></table></figure>\n<p>上面的情形只供参考，参数等视具体情况而定。</p>\n</li>\n<li><p>动态规划</p>\n<p>比较经典的就是背包问题。<a href=\"http://blog.csdn.net/littlethunder/article/details/26575417\" target=\"_blank\" rel=\"external\">代码来源</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bag</span><span class=\"params\">(n,c,w,v)</span>:</span>  </div><div class=\"line\">    res=[[<span class=\"number\">-1</span> <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(c+<span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n+<span class=\"number\">1</span>)]  </div><div class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(c+<span class=\"number\">1</span>):  </div><div class=\"line\">        res[<span class=\"number\">0</span>][j]=<span class=\"number\">0</span>  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </div><div class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,c+<span class=\"number\">1</span>):  </div><div class=\"line\">            res[i][j]=res[i<span class=\"number\">-1</span>][j]  </div><div class=\"line\">            <span class=\"keyword\">if</span> j&gt;=w[i<span class=\"number\">-1</span>] <span class=\"keyword\">and</span> res[i][j]&lt;res[i<span class=\"number\">-1</span>][j-w[i<span class=\"number\">-1</span>]]+v[i<span class=\"number\">-1</span>]:  </div><div class=\"line\">                res[i][j]=res[i<span class=\"number\">-1</span>][j-w[i<span class=\"number\">-1</span>]]+v[i<span class=\"number\">-1</span>]  </div><div class=\"line\">    <span class=\"keyword\">return</span> res  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">show</span><span class=\"params\">(n,c,w,res)</span>:</span>  </div><div class=\"line\">    print(<span class=\"string\">'最大价值为:'</span>,res[n][c])  </div><div class=\"line\">    x=[<span class=\"keyword\">False</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n)]  </div><div class=\"line\">    j=c  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </div><div class=\"line\">        <span class=\"keyword\">if</span> res[i][j]&gt;res[i<span class=\"number\">-1</span>][j]:  </div><div class=\"line\">            x[i<span class=\"number\">-1</span>]=<span class=\"keyword\">True</span>  </div><div class=\"line\">            j-=w[i<span class=\"number\">-1</span>]  </div><div class=\"line\">    print(<span class=\"string\">'选择的物品为:'</span>)  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):  </div><div class=\"line\">        <span class=\"keyword\">if</span> x[i]:  </div><div class=\"line\">            print(<span class=\"string\">'第'</span>,i,<span class=\"string\">'个,'</span>,end=<span class=\"string\">''</span>)  </div><div class=\"line\">    print(<span class=\"string\">''</span>)  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"keyword\">if</span> __name__==<span class=\"string\">'__main__'</span>:  </div><div class=\"line\">    n=<span class=\"number\">5</span>  </div><div class=\"line\">    c=<span class=\"number\">10</span>  </div><div class=\"line\">    w=[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">6</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>]  </div><div class=\"line\">    v=[<span class=\"number\">6</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">6</span>]  </div><div class=\"line\">    res=bag(n,c,w,v)  </div><div class=\"line\">    show(n,c,w,res)</div></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n</ol>\n","excerpt":"","more":"<ol>\n<li><p>穷举法</p>\n<p>略</p>\n</li>\n<li><p>贪心法</p>\n<p>略</p>\n</li>\n<li><p>分治法</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">merge</span><span class=\"params\">(A, B)</span>:</span></div><div class=\"line\">    <span class=\"comment\"># merge two small solved problems into one.</span></div><div class=\"line\">    <span class=\"keyword\">return</span> merged</div><div class=\"line\"></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">divideConquer</span><span class=\"params\">(S, divide, combine)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">if</span> len(S) == <span class=\"number\">1</span>: <span class=\"keyword\">return</span> S</div><div class=\"line\">    <span class=\"comment\"># divide a grand problems</span></div><div class=\"line\">    L, R = divide(S)</div><div class=\"line\">    A = divideConquer(L, divide, combine)</div><div class=\"line\">    B = divideConquer(R, divide, combine)</div><div class=\"line\">    <span class=\"keyword\">return</span> merge(A, B)</div></pre></td></tr></table></figure>\n<p>上面的情形只供参考，参数等视具体情况而定。</p>\n</li>\n<li><p>动态规划</p>\n<p>比较经典的就是背包问题。<a href=\"http://blog.csdn.net/littlethunder/article/details/26575417\">代码来源</a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div><div class=\"line\">23</div><div class=\"line\">24</div><div class=\"line\">25</div><div class=\"line\">26</div><div class=\"line\">27</div><div class=\"line\">28</div><div class=\"line\">29</div><div class=\"line\">30</div><div class=\"line\">31</div><div class=\"line\">32</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bag</span><span class=\"params\">(n,c,w,v)</span>:</span>  </div><div class=\"line\">    res=[[<span class=\"number\">-1</span> <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(c+<span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n+<span class=\"number\">1</span>)]  </div><div class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(c+<span class=\"number\">1</span>):  </div><div class=\"line\">        res[<span class=\"number\">0</span>][j]=<span class=\"number\">0</span>  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </div><div class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,c+<span class=\"number\">1</span>):  </div><div class=\"line\">            res[i][j]=res[i<span class=\"number\">-1</span>][j]  </div><div class=\"line\">            <span class=\"keyword\">if</span> j&gt;=w[i<span class=\"number\">-1</span>] <span class=\"keyword\">and</span> res[i][j]&lt;res[i<span class=\"number\">-1</span>][j-w[i<span class=\"number\">-1</span>]]+v[i<span class=\"number\">-1</span>]:  </div><div class=\"line\">                res[i][j]=res[i<span class=\"number\">-1</span>][j-w[i<span class=\"number\">-1</span>]]+v[i<span class=\"number\">-1</span>]  </div><div class=\"line\">    <span class=\"keyword\">return</span> res  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">show</span><span class=\"params\">(n,c,w,res)</span>:</span>  </div><div class=\"line\">    print(<span class=\"string\">'最大价值为:'</span>,res[n][c])  </div><div class=\"line\">    x=[<span class=\"keyword\">False</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n)]  </div><div class=\"line\">    j=c  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </div><div class=\"line\">        <span class=\"keyword\">if</span> res[i][j]&gt;res[i<span class=\"number\">-1</span>][j]:  </div><div class=\"line\">            x[i<span class=\"number\">-1</span>]=<span class=\"keyword\">True</span>  </div><div class=\"line\">            j-=w[i<span class=\"number\">-1</span>]  </div><div class=\"line\">    print(<span class=\"string\">'选择的物品为:'</span>)  </div><div class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):  </div><div class=\"line\">        <span class=\"keyword\">if</span> x[i]:  </div><div class=\"line\">            print(<span class=\"string\">'第'</span>,i,<span class=\"string\">'个,'</span>,end=<span class=\"string\">''</span>)  </div><div class=\"line\">    print(<span class=\"string\">''</span>)  </div><div class=\"line\">  </div><div class=\"line\"><span class=\"keyword\">if</span> __name__==<span class=\"string\">'__main__'</span>:  </div><div class=\"line\">    n=<span class=\"number\">5</span>  </div><div class=\"line\">    c=<span class=\"number\">10</span>  </div><div class=\"line\">    w=[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">6</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>]  </div><div class=\"line\">    v=[<span class=\"number\">6</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">6</span>]  </div><div class=\"line\">    res=bag(n,c,w,v)  </div><div class=\"line\">    show(n,c,w,res)</div></pre></td></tr></table></figure>\n<p>​</p>\n</li>\n</ol>\n"},{"title":"数据挖掘笔记 Note of datamining","date":"2016-12-06T14:35:24.000Z","_content":"\n# 构成\n\n一般说的数据挖掘指的是知识挖掘，构成如下：\n\n1. 数据清洗 - data clearing\n2. 数据集成 - data integration\n3. 数据转换 - data transformation\n4. 数据挖掘 - data mining\n5. 模式评估 - pattern evaluation\n6. 知识表示 - knowledge presentation\n\n# 分析\n\n1. 关联分析\n\n   age(X, \"20-29\") ^ income(X, \"20K-30K\") => buys(X, \"MP3\")\n\n   [support = 2%, confidence = 60%]\n\n2. 分类预测\n\n   分类挖掘的主要表示手段有：\n\n   - 分类规则\n   - 决策树\n   - 数学公式\n   - 神经网络\n\n3. 聚类分析\n\n   与分类预测的主要区别是，后者是分类已知，属于监督学习方法；前者无事先确定类别归属，属于无监督学习方法。\n\n   聚类分析中，首先需要根据“各聚集内部数据对象间的相似度最大化；而各聚集对象间相似度最小化”的基本聚类分析原则，以及度量数据对象之间相似度的计算公式，将聚类分析的数据对象划分为若干组。\n\n4. 异类分析\n\n   不符合大多数数据对象所构成的规律(模型)的数据对象就被称为异类。\n\n   我们往往将异类作为噪声或者意外而将其排除，但是某些情况下这些异类反而更有价值，对异类数据的分析处理通常就称为异类挖掘。\n\n   例如，通过对银行账户的异类分析，发现信用卡诈骗等。\n\n5. 演化分析\n\n   数据演化分析就是对随时间变化的数据对象的变化规律和趋势进行建模描述。\n\n   例如股票市场。\n\n# 数据挖掘结果评估\n\n一个数据挖掘系统在完成一次分析后会获得大量的模式或规则，其中只有很小的一部分是有实际使用价值的。\n\n通常，有以下几个标准\n\n1. 易于用户理解;\n2. 对新数据或测试数据能够确定有效程度;\n3. 具有潜在价值;\n4. 新奇的\n\n# 数据挖掘系统分类\n\n数据挖掘系统可以按照三种标准进行划分，它们是数据库类型、所挖掘的知识和所使用的技术。","source":"_posts/Note-of-datamining.md","raw":"---\ntitle: 数据挖掘笔记 Note of datamining\ndate: 2016-12-6 15:35:24\ncategories: [programming, unfinished]\ntags: [datamining]\n---\n\n# 构成\n\n一般说的数据挖掘指的是知识挖掘，构成如下：\n\n1. 数据清洗 - data clearing\n2. 数据集成 - data integration\n3. 数据转换 - data transformation\n4. 数据挖掘 - data mining\n5. 模式评估 - pattern evaluation\n6. 知识表示 - knowledge presentation\n\n# 分析\n\n1. 关联分析\n\n   age(X, \"20-29\") ^ income(X, \"20K-30K\") => buys(X, \"MP3\")\n\n   [support = 2%, confidence = 60%]\n\n2. 分类预测\n\n   分类挖掘的主要表示手段有：\n\n   - 分类规则\n   - 决策树\n   - 数学公式\n   - 神经网络\n\n3. 聚类分析\n\n   与分类预测的主要区别是，后者是分类已知，属于监督学习方法；前者无事先确定类别归属，属于无监督学习方法。\n\n   聚类分析中，首先需要根据“各聚集内部数据对象间的相似度最大化；而各聚集对象间相似度最小化”的基本聚类分析原则，以及度量数据对象之间相似度的计算公式，将聚类分析的数据对象划分为若干组。\n\n4. 异类分析\n\n   不符合大多数数据对象所构成的规律(模型)的数据对象就被称为异类。\n\n   我们往往将异类作为噪声或者意外而将其排除，但是某些情况下这些异类反而更有价值，对异类数据的分析处理通常就称为异类挖掘。\n\n   例如，通过对银行账户的异类分析，发现信用卡诈骗等。\n\n5. 演化分析\n\n   数据演化分析就是对随时间变化的数据对象的变化规律和趋势进行建模描述。\n\n   例如股票市场。\n\n# 数据挖掘结果评估\n\n一个数据挖掘系统在完成一次分析后会获得大量的模式或规则，其中只有很小的一部分是有实际使用价值的。\n\n通常，有以下几个标准\n\n1. 易于用户理解;\n2. 对新数据或测试数据能够确定有效程度;\n3. 具有潜在价值;\n4. 新奇的\n\n# 数据挖掘系统分类\n\n数据挖掘系统可以按照三种标准进行划分，它们是数据库类型、所挖掘的知识和所使用的技术。","slug":"Note-of-datamining","published":1,"updated":"2016-12-06T21:04:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjh9000ezemmyu65lo34","content":"<h1 id=\"构成\"><a href=\"#构成\" class=\"headerlink\" title=\"构成\"></a>构成</h1><p>一般说的数据挖掘指的是知识挖掘，构成如下：</p>\n<ol>\n<li>数据清洗 - data clearing</li>\n<li>数据集成 - data integration</li>\n<li>数据转换 - data transformation</li>\n<li>数据挖掘 - data mining</li>\n<li>模式评估 - pattern evaluation</li>\n<li>知识表示 - knowledge presentation</li>\n</ol>\n<h1 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h1><ol>\n<li><p>关联分析</p>\n<p>age(X, “20-29”) ^ income(X, “20K-30K”) =&gt; buys(X, “MP3”)</p>\n<p>[support = 2%, confidence = 60%]</p>\n</li>\n<li><p>分类预测</p>\n<p>分类挖掘的主要表示手段有：</p>\n<ul>\n<li>分类规则</li>\n<li>决策树</li>\n<li>数学公式</li>\n<li>神经网络</li>\n</ul>\n</li>\n<li><p>聚类分析</p>\n<p>与分类预测的主要区别是，后者是分类已知，属于监督学习方法；前者无事先确定类别归属，属于无监督学习方法。</p>\n<p>聚类分析中，首先需要根据“各聚集内部数据对象间的相似度最大化；而各聚集对象间相似度最小化”的基本聚类分析原则，以及度量数据对象之间相似度的计算公式，将聚类分析的数据对象划分为若干组。</p>\n</li>\n<li><p>异类分析</p>\n<p>不符合大多数数据对象所构成的规律(模型)的数据对象就被称为异类。</p>\n<p>我们往往将异类作为噪声或者意外而将其排除，但是某些情况下这些异类反而更有价值，对异类数据的分析处理通常就称为异类挖掘。</p>\n<p>例如，通过对银行账户的异类分析，发现信用卡诈骗等。</p>\n</li>\n<li><p>演化分析</p>\n<p>数据演化分析就是对随时间变化的数据对象的变化规律和趋势进行建模描述。</p>\n<p>例如股票市场。</p>\n</li>\n</ol>\n<h1 id=\"数据挖掘结果评估\"><a href=\"#数据挖掘结果评估\" class=\"headerlink\" title=\"数据挖掘结果评估\"></a>数据挖掘结果评估</h1><p>一个数据挖掘系统在完成一次分析后会获得大量的模式或规则，其中只有很小的一部分是有实际使用价值的。</p>\n<p>通常，有以下几个标准</p>\n<ol>\n<li>易于用户理解;</li>\n<li>对新数据或测试数据能够确定有效程度;</li>\n<li>具有潜在价值;</li>\n<li>新奇的</li>\n</ol>\n<h1 id=\"数据挖掘系统分类\"><a href=\"#数据挖掘系统分类\" class=\"headerlink\" title=\"数据挖掘系统分类\"></a>数据挖掘系统分类</h1><p>数据挖掘系统可以按照三种标准进行划分，它们是数据库类型、所挖掘的知识和所使用的技术。</p>\n","excerpt":"","more":"<h1 id=\"构成\"><a href=\"#构成\" class=\"headerlink\" title=\"构成\"></a>构成</h1><p>一般说的数据挖掘指的是知识挖掘，构成如下：</p>\n<ol>\n<li>数据清洗 - data clearing</li>\n<li>数据集成 - data integration</li>\n<li>数据转换 - data transformation</li>\n<li>数据挖掘 - data mining</li>\n<li>模式评估 - pattern evaluation</li>\n<li>知识表示 - knowledge presentation</li>\n</ol>\n<h1 id=\"分析\"><a href=\"#分析\" class=\"headerlink\" title=\"分析\"></a>分析</h1><ol>\n<li><p>关联分析</p>\n<p>age(X, “20-29”) ^ income(X, “20K-30K”) =&gt; buys(X, “MP3”)</p>\n<p>[support = 2%, confidence = 60%]</p>\n</li>\n<li><p>分类预测</p>\n<p>分类挖掘的主要表示手段有：</p>\n<ul>\n<li>分类规则</li>\n<li>决策树</li>\n<li>数学公式</li>\n<li>神经网络</li>\n</ul>\n</li>\n<li><p>聚类分析</p>\n<p>与分类预测的主要区别是，后者是分类已知，属于监督学习方法；前者无事先确定类别归属，属于无监督学习方法。</p>\n<p>聚类分析中，首先需要根据“各聚集内部数据对象间的相似度最大化；而各聚集对象间相似度最小化”的基本聚类分析原则，以及度量数据对象之间相似度的计算公式，将聚类分析的数据对象划分为若干组。</p>\n</li>\n<li><p>异类分析</p>\n<p>不符合大多数数据对象所构成的规律(模型)的数据对象就被称为异类。</p>\n<p>我们往往将异类作为噪声或者意外而将其排除，但是某些情况下这些异类反而更有价值，对异类数据的分析处理通常就称为异类挖掘。</p>\n<p>例如，通过对银行账户的异类分析，发现信用卡诈骗等。</p>\n</li>\n<li><p>演化分析</p>\n<p>数据演化分析就是对随时间变化的数据对象的变化规律和趋势进行建模描述。</p>\n<p>例如股票市场。</p>\n</li>\n</ol>\n<h1 id=\"数据挖掘结果评估\"><a href=\"#数据挖掘结果评估\" class=\"headerlink\" title=\"数据挖掘结果评估\"></a>数据挖掘结果评估</h1><p>一个数据挖掘系统在完成一次分析后会获得大量的模式或规则，其中只有很小的一部分是有实际使用价值的。</p>\n<p>通常，有以下几个标准</p>\n<ol>\n<li>易于用户理解;</li>\n<li>对新数据或测试数据能够确定有效程度;</li>\n<li>具有潜在价值;</li>\n<li>新奇的</li>\n</ol>\n<h1 id=\"数据挖掘系统分类\"><a href=\"#数据挖掘系统分类\" class=\"headerlink\" title=\"数据挖掘系统分类\"></a>数据挖掘系统分类</h1><p>数据挖掘系统可以按照三种标准进行划分，它们是数据库类型、所挖掘的知识和所使用的技术。</p>\n"},{"title":"算法笔记 Note of learning Algo","date":"2016-11-27T11:38:32.000Z","_content":"\n# Data Structure\n\n{% post_link complexity How to calcul the complexity?  %} \n\n{% post_link compression How to make a compression?  %}\n\n1. The data : int, double, etc.\n2. The basic data structure\n   - Container\n   - Table \n   - Stack \n   - Queue \n   - List\n3. Tree\n   - Arbres binaires - 二叉树\n     - ABR - 二叉树的查询\n   - Arbres n-aires\n4. Dictionary \n   - Hash table - Table de hachage - 哈希表\n5. **Heap - Tas - 堆 **\n   - 二叉堆\n   - 堆排序\n6. Find-Union\n\n# Method of programming\n\n{% post_link Method-of-programming-facing-to-exams Savoir plus %}\n\n1. Echaustive / force brute - 穷举法\n2. Try-error - Essai-erreur 试错法\n3. Glouton - 贪心法\n4. Recursif - recursive - 递归\n5. Divede merge - Diviser pour regner - 分治\n6. Dynamic - Dynamique - 动态规划\n\n# Graph\n\n{% post_link graph Savoir plus %}\n\n1. Traversal - parcours - 遍历\n   - BFS\n   - DFS\n2. Critical path method - plus court chemin\n   - Dijkstra\n   - Floyd\n   - Bellman-Ford\n3. Tree - arbre\n   - Prim\n   - Kruskal\n\n*backtracking\n\n*Branch and bound\n\n# Others\n\n1. 排序\n   - 选择，冒泡\n   - 分治（fusion）\n   - 快速\n   - tas ","source":"_posts/Note-of-learning-Algo.md","raw":"---\ntitle: 算法笔记 Note of learning Algo\ndate: 2016-11-27 12:38:32\ncategories: programming\ntags: [algo, programming]\n---\n\n# Data Structure\n\n{% post_link complexity How to calcul the complexity?  %} \n\n{% post_link compression How to make a compression?  %}\n\n1. The data : int, double, etc.\n2. The basic data structure\n   - Container\n   - Table \n   - Stack \n   - Queue \n   - List\n3. Tree\n   - Arbres binaires - 二叉树\n     - ABR - 二叉树的查询\n   - Arbres n-aires\n4. Dictionary \n   - Hash table - Table de hachage - 哈希表\n5. **Heap - Tas - 堆 **\n   - 二叉堆\n   - 堆排序\n6. Find-Union\n\n# Method of programming\n\n{% post_link Method-of-programming-facing-to-exams Savoir plus %}\n\n1. Echaustive / force brute - 穷举法\n2. Try-error - Essai-erreur 试错法\n3. Glouton - 贪心法\n4. Recursif - recursive - 递归\n5. Divede merge - Diviser pour regner - 分治\n6. Dynamic - Dynamique - 动态规划\n\n# Graph\n\n{% post_link graph Savoir plus %}\n\n1. Traversal - parcours - 遍历\n   - BFS\n   - DFS\n2. Critical path method - plus court chemin\n   - Dijkstra\n   - Floyd\n   - Bellman-Ford\n3. Tree - arbre\n   - Prim\n   - Kruskal\n\n*backtracking\n\n*Branch and bound\n\n# Others\n\n1. 排序\n   - 选择，冒泡\n   - 分治（fusion）\n   - 快速\n   - tas ","slug":"Note-of-learning-Algo","published":1,"updated":"2016-11-30T10:56:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhb000izemmdkpyr3gy","content":"<h1 id=\"Data-Structure\"><a href=\"#Data-Structure\" class=\"headerlink\" title=\"Data Structure\"></a>Data Structure</h1><a href=\"/2016/11/27/complexity/\" title=\"How to calcul the complexity?\">How to calcul the complexity?</a> \n<a href=\"/2016/11/27/compression/\" title=\"How to make a compression?\">How to make a compression?</a>\n<ol>\n<li>The data : int, double, etc.</li>\n<li>The basic data structure<ul>\n<li>Container</li>\n<li>Table </li>\n<li>Stack </li>\n<li>Queue </li>\n<li>List</li>\n</ul>\n</li>\n<li>Tree<ul>\n<li>Arbres binaires - 二叉树<ul>\n<li>ABR - 二叉树的查询</li>\n</ul>\n</li>\n<li>Arbres n-aires</li>\n</ul>\n</li>\n<li>Dictionary <ul>\n<li>Hash table - Table de hachage - 哈希表</li>\n</ul>\n</li>\n<li><strong>Heap - Tas - 堆 </strong><ul>\n<li>二叉堆</li>\n<li>堆排序</li>\n</ul>\n</li>\n<li>Find-Union</li>\n</ol>\n<h1 id=\"Method-of-programming\"><a href=\"#Method-of-programming\" class=\"headerlink\" title=\"Method of programming\"></a>Method of programming</h1><a href=\"/2016/11/27/Method-of-programming-facing-to-exams/\" title=\"Savoir plus\">Savoir plus</a>\n<ol>\n<li>Echaustive / force brute - 穷举法</li>\n<li>Try-error - Essai-erreur 试错法</li>\n<li>Glouton - 贪心法</li>\n<li>Recursif - recursive - 递归</li>\n<li>Divede merge - Diviser pour regner - 分治</li>\n<li>Dynamic - Dynamique - 动态规划</li>\n</ol>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><a href=\"/2016/11/27/graph/\" title=\"Savoir plus\">Savoir plus</a>\n<ol>\n<li>Traversal - parcours - 遍历<ul>\n<li>BFS</li>\n<li>DFS</li>\n</ul>\n</li>\n<li>Critical path method - plus court chemin<ul>\n<li>Dijkstra</li>\n<li>Floyd</li>\n<li>Bellman-Ford</li>\n</ul>\n</li>\n<li>Tree - arbre<ul>\n<li>Prim</li>\n<li>Kruskal</li>\n</ul>\n</li>\n</ol>\n<p>*backtracking</p>\n<p>*Branch and bound</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><ol>\n<li>排序<ul>\n<li>选择，冒泡</li>\n<li>分治（fusion）</li>\n<li>快速</li>\n<li>tas </li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"Data-Structure\"><a href=\"#Data-Structure\" class=\"headerlink\" title=\"Data Structure\"></a>Data Structure</h1><a href=\"/2016/11/27/complexity/\" title=\"How to calcul the complexity?\">How to calcul the complexity?</a> \n<a href=\"/2016/11/27/compression/\" title=\"How to make a compression?\">How to make a compression?</a>\n<ol>\n<li>The data : int, double, etc.</li>\n<li>The basic data structure<ul>\n<li>Container</li>\n<li>Table </li>\n<li>Stack </li>\n<li>Queue </li>\n<li>List</li>\n</ul>\n</li>\n<li>Tree<ul>\n<li>Arbres binaires - 二叉树<ul>\n<li>ABR - 二叉树的查询</li>\n</ul>\n</li>\n<li>Arbres n-aires</li>\n</ul>\n</li>\n<li>Dictionary <ul>\n<li>Hash table - Table de hachage - 哈希表</li>\n</ul>\n</li>\n<li><strong>Heap - Tas - 堆 </strong><ul>\n<li>二叉堆</li>\n<li>堆排序</li>\n</ul>\n</li>\n<li>Find-Union</li>\n</ol>\n<h1 id=\"Method-of-programming\"><a href=\"#Method-of-programming\" class=\"headerlink\" title=\"Method of programming\"></a>Method of programming</h1><a href=\"/2016/11/27/Method-of-programming-facing-to-exams/\" title=\"Savoir plus\">Savoir plus</a>\n<ol>\n<li>Echaustive / force brute - 穷举法</li>\n<li>Try-error - Essai-erreur 试错法</li>\n<li>Glouton - 贪心法</li>\n<li>Recursif - recursive - 递归</li>\n<li>Divede merge - Diviser pour regner - 分治</li>\n<li>Dynamic - Dynamique - 动态规划</li>\n</ol>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><a href=\"/2016/11/27/graph/\" title=\"Savoir plus\">Savoir plus</a>\n<ol>\n<li>Traversal - parcours - 遍历<ul>\n<li>BFS</li>\n<li>DFS</li>\n</ul>\n</li>\n<li>Critical path method - plus court chemin<ul>\n<li>Dijkstra</li>\n<li>Floyd</li>\n<li>Bellman-Ford</li>\n</ul>\n</li>\n<li>Tree - arbre<ul>\n<li>Prim</li>\n<li>Kruskal</li>\n</ul>\n</li>\n</ol>\n<p>*backtracking</p>\n<p>*Branch and bound</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><ol>\n<li>排序<ul>\n<li>选择，冒泡</li>\n<li>分治（fusion）</li>\n<li>快速</li>\n<li>tas </li>\n</ul>\n</li>\n</ol>\n"},{"title":"Note of statistic","date":"2017-01-28T17:13:13.000Z","_content":"\n# 各种定理\n\n### 大数定理，中心极限定理\n\n略\n\n### Slutsky\n\nif\n$$\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c\n$$\nthen\n$$\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c\n$$\n\n# 假设检验\n\n## un test de $\\chi^2$\n\n列表：\n\n| Liste | a    | b    | c    |\n| ----- | ---- | ---- | ---- |\n| pi    | xx   | xx   | xx   |\n| npi   | xx   | xx   | xx   |\n| ni    | xx   | xx   | xx   |\n\n计算：\n$$\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}\n$$\n其服从卡方分布，自由度为n-1，从而进行检验。","source":"_posts/Note-of-statistic.md","raw":"---\ntitle: Note of statistic\ndate: 2017-01-28 18:13:13\ncategories: [math, unfinished]\ntags: [statistic, math]\n---\n\n# 各种定理\n\n### 大数定理，中心极限定理\n\n略\n\n### Slutsky\n\nif\n$$\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c\n$$\nthen\n$$\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c\n$$\n\n# 假设检验\n\n## un test de $\\chi^2$\n\n列表：\n\n| Liste | a    | b    | c    |\n| ----- | ---- | ---- | ---- |\n| pi    | xx   | xx   | xx   |\n| npi   | xx   | xx   | xx   |\n| ni    | xx   | xx   | xx   |\n\n计算：\n$$\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}\n$$\n其服从卡方分布，自由度为n-1，从而进行检验。","slug":"Note-of-statistic","published":1,"updated":"2017-01-28T18:02:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhc000lzemm5cz049vw","content":"<h1 id=\"各种定理\"><a href=\"#各种定理\" class=\"headerlink\" title=\"各种定理\"></a>各种定理</h1><h3 id=\"大数定理，中心极限定理\"><a href=\"#大数定理，中心极限定理\" class=\"headerlink\" title=\"大数定理，中心极限定理\"></a>大数定理，中心极限定理</h3><p>略</p>\n<h3 id=\"Slutsky\"><a href=\"#Slutsky\" class=\"headerlink\" title=\"Slutsky\"></a>Slutsky</h3><p>if</p>\n<script type=\"math/tex; mode=display\">\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c</script><p>then</p>\n<script type=\"math/tex; mode=display\">\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c</script><h1 id=\"假设检验\"><a href=\"#假设检验\" class=\"headerlink\" title=\"假设检验\"></a>假设检验</h1><h2 id=\"un-test-de-chi-2\"><a href=\"#un-test-de-chi-2\" class=\"headerlink\" title=\"un test de $\\chi^2$\"></a>un test de $\\chi^2$</h2><p>列表：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Liste</th>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>npi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>ni</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>计算：</p>\n<script type=\"math/tex; mode=display\">\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}</script><p>其服从卡方分布，自由度为n-1，从而进行检验。</p>\n","excerpt":"","more":"<h1 id=\"各种定理\"><a href=\"#各种定理\" class=\"headerlink\" title=\"各种定理\"></a>各种定理</h1><h3 id=\"大数定理，中心极限定理\"><a href=\"#大数定理，中心极限定理\" class=\"headerlink\" title=\"大数定理，中心极限定理\"></a>大数定理，中心极限定理</h3><p>略</p>\n<h3 id=\"Slutsky\"><a href=\"#Slutsky\" class=\"headerlink\" title=\"Slutsky\"></a>Slutsky</h3><p>if</p>\n<script type=\"math/tex; mode=display\">\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c</script><p>then</p>\n<script type=\"math/tex; mode=display\">\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c</script><h1 id=\"假设检验\"><a href=\"#假设检验\" class=\"headerlink\" title=\"假设检验\"></a>假设检验</h1><h2 id=\"un-test-de-chi-2\"><a href=\"#un-test-de-chi-2\" class=\"headerlink\" title=\"un test de $\\chi^2$\"></a>un test de $\\chi^2$</h2><p>列表：</p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Liste</th>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>pi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>npi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>ni</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>计算：</p>\n<script type=\"math/tex; mode=display\">\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}</script><p>其服从卡方分布，自由度为n-1，从而进行检验。</p>\n"},{"title":"编码解码 compression","date":"2016-11-27T13:22:11.000Z","_content":"\n1. Run length encoding\n\n   ex:\n\n   0101 — 0,101 — \"3 pixels are color '0'\"\n\n   1101 — 1,101 — \"6 pixels are color '1'\"\n\n   You can also define other signification like:\n\n   1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.\n\n2. Huffman\n\n   Defined in wiki\n\n   Normally we supppose higher number with \"1\".\n\n   ex:\n\n   ​                        (1)\n\n   ​                   0/       \\1\n\n   ​            a(0.45)     (0.55)\n\n   ​                             0/     \\1\n\n   ​                     b(0.25)    c(0.30)\n\n3. Lempel-Ziv\n\n   Encode:\n\n   - Origin: ababcbab...\n   - Init: a:0, b:1, c:2\n   - Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6...\n   - Result: 01324...\n\n   Decode: pass\n\n   ​","source":"_posts/compression.md","raw":"---\ntitle: 编码解码 compression\ndate: 2016-11-27 14:22:11\ncategories: programming\ntags: [algo, compression, programming]\n---\n\n1. Run length encoding\n\n   ex:\n\n   0101 — 0,101 — \"3 pixels are color '0'\"\n\n   1101 — 1,101 — \"6 pixels are color '1'\"\n\n   You can also define other signification like:\n\n   1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.\n\n2. Huffman\n\n   Defined in wiki\n\n   Normally we supppose higher number with \"1\".\n\n   ex:\n\n   ​                        (1)\n\n   ​                   0/       \\1\n\n   ​            a(0.45)     (0.55)\n\n   ​                             0/     \\1\n\n   ​                     b(0.25)    c(0.30)\n\n3. Lempel-Ziv\n\n   Encode:\n\n   - Origin: ababcbab...\n   - Init: a:0, b:1, c:2\n   - Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6...\n   - Result: 01324...\n\n   Decode: pass\n\n   ​","slug":"compression","published":1,"updated":"2016-11-30T10:46:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhg000pzemmm182vl3p","content":"<ol>\n<li><p>Run length encoding</p>\n<p>ex:</p>\n<p>0101 — 0,101 — “3 pixels are color ‘0’”</p>\n<p>1101 — 1,101 — “6 pixels are color ‘1’”</p>\n<p>You can also define other signification like:</p>\n<p>1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.</p>\n</li>\n<li><p>Huffman</p>\n<p>Defined in wiki</p>\n<p>Normally we supppose higher number with “1”.</p>\n<p>ex:</p>\n<p>​                        (1)</p>\n<p>​                   0/       \\1</p>\n<p>​            a(0.45)     (0.55)</p>\n<p>​                             0/     \\1</p>\n<p>​                     b(0.25)    c(0.30)</p>\n</li>\n<li><p>Lempel-Ziv</p>\n<p>Encode:</p>\n<ul>\n<li>Origin: ababcbab…</li>\n<li>Init: a:0, b:1, c:2</li>\n<li>Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6…</li>\n<li>Result: 01324…</li>\n</ul>\n<p>Decode: pass</p>\n<p>​</p>\n</li>\n</ol>\n","excerpt":"","more":"<ol>\n<li><p>Run length encoding</p>\n<p>ex:</p>\n<p>0101 — 0,101 — “3 pixels are color ‘0’”</p>\n<p>1101 — 1,101 — “6 pixels are color ‘1’”</p>\n<p>You can also define other signification like:</p>\n<p>1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.</p>\n</li>\n<li><p>Huffman</p>\n<p>Defined in wiki</p>\n<p>Normally we supppose higher number with “1”.</p>\n<p>ex:</p>\n<p>​                        (1)</p>\n<p>​                   0/       \\1</p>\n<p>​            a(0.45)     (0.55)</p>\n<p>​                             0/     \\1</p>\n<p>​                     b(0.25)    c(0.30)</p>\n</li>\n<li><p>Lempel-Ziv</p>\n<p>Encode:</p>\n<ul>\n<li>Origin: ababcbab…</li>\n<li>Init: a:0, b:1, c:2</li>\n<li>Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6…</li>\n<li>Result: 01324…</li>\n</ul>\n<p>Decode: pass</p>\n<p>​</p>\n</li>\n</ol>\n"},{"title":"四叉树 QuadTree","date":"2016-12-13T17:45:37.000Z","_content":"\n在ECP的实验课用到了四叉树，故来记录一下。\n\n四叉树是一种数据结构，每一个节点有四个孩子。一般需要用到四叉树的情况往往是二位平面，通过把区域分成四个区块来定义。\n\n在确定并显示一条曲线的具体位置时，需要使用一种算法。一种比较直观的想法就是，将平面细分成小块，通过计算验证曲线是否在这个小块内部。但是这种算法也有一个十分致命的缺点— 复杂度极高，计算量极大。而事实上，平面上大多数的区域是空白的，我们不需要对其每一个小块进行检测。仿照二分法的思路我们可以按如下方法进行。\n\n```Python\n# 确保使用的是等宽字体，用嵌入代码=_=\n\"\"\"\n3-------2       \n|       |\n|       |\n|       |\n0-------1\n检查曲线是否在内，若是，此节点为枝，分为四个小区域，作为四个儿子；若否，此节点为叶，没有儿子。\n=>\n3---7---2\n|   |   |\n8---4---6\n|   |   |\n0---5---1\n以此分别对四个儿子执行以上操作，直到达到所需精度。\n=>\n...\n\"\"\"\n```\n\n按照这个数据结构，若曲线不在内部，则将节点设为叶，无需继续细分。寻找一个点的话复杂度是O(logn)。\n\n\n\n在实验课的内容里，用python进行数据处理，用paraview进行数据可视化。代码其实挺简单（算法就不难= =），实验课还没结束暂时不附代码了，附一个效果图。\n\n![QTree](http://oi4yiqiop.bkt.clouddn.com/QTree.png?imageMogr2/thumbnail/!50p)\n\n","source":"_posts/QuadTree.md","raw":"---\ntitle: 四叉树 QuadTree\ndate: 2016-12-13 18:45:37\ncategories: [programming]\ntags: [algo, data-structure]\n---\n\n在ECP的实验课用到了四叉树，故来记录一下。\n\n四叉树是一种数据结构，每一个节点有四个孩子。一般需要用到四叉树的情况往往是二位平面，通过把区域分成四个区块来定义。\n\n在确定并显示一条曲线的具体位置时，需要使用一种算法。一种比较直观的想法就是，将平面细分成小块，通过计算验证曲线是否在这个小块内部。但是这种算法也有一个十分致命的缺点— 复杂度极高，计算量极大。而事实上，平面上大多数的区域是空白的，我们不需要对其每一个小块进行检测。仿照二分法的思路我们可以按如下方法进行。\n\n```Python\n# 确保使用的是等宽字体，用嵌入代码=_=\n\"\"\"\n3-------2       \n|       |\n|       |\n|       |\n0-------1\n检查曲线是否在内，若是，此节点为枝，分为四个小区域，作为四个儿子；若否，此节点为叶，没有儿子。\n=>\n3---7---2\n|   |   |\n8---4---6\n|   |   |\n0---5---1\n以此分别对四个儿子执行以上操作，直到达到所需精度。\n=>\n...\n\"\"\"\n```\n\n按照这个数据结构，若曲线不在内部，则将节点设为叶，无需继续细分。寻找一个点的话复杂度是O(logn)。\n\n\n\n在实验课的内容里，用python进行数据处理，用paraview进行数据可视化。代码其实挺简单（算法就不难= =），实验课还没结束暂时不附代码了，附一个效果图。\n\n![QTree](http://oi4yiqiop.bkt.clouddn.com/QTree.png?imageMogr2/thumbnail/!50p)\n\n","slug":"QuadTree","published":1,"updated":"2016-12-13T21:20:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhi000rzemm52qnyglq","content":"<p>在ECP的实验课用到了四叉树，故来记录一下。</p>\n<p>四叉树是一种数据结构，每一个节点有四个孩子。一般需要用到四叉树的情况往往是二位平面，通过把区域分成四个区块来定义。</p>\n<p>在确定并显示一条曲线的具体位置时，需要使用一种算法。一种比较直观的想法就是，将平面细分成小块，通过计算验证曲线是否在这个小块内部。但是这种算法也有一个十分致命的缺点— 复杂度极高，计算量极大。而事实上，平面上大多数的区域是空白的，我们不需要对其每一个小块进行检测。仿照二分法的思路我们可以按如下方法进行。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 确保使用的是等宽字体，用嵌入代码=_=</span></div><div class=\"line\"><span class=\"string\">\"\"\"</span></div><div class=\"line\">3-------2       </div><div class=\"line\">|       |</div><div class=\"line\">|       |</div><div class=\"line\">|       |</div><div class=\"line\">0-------1</div><div class=\"line\">检查曲线是否在内，若是，此节点为枝，分为四个小区域，作为四个儿子；若否，此节点为叶，没有儿子。</div><div class=\"line\">=&gt;</div><div class=\"line\">3---7---2</div><div class=\"line\">|   |   |</div><div class=\"line\">8---4---6</div><div class=\"line\">|   |   |</div><div class=\"line\">0---5---1</div><div class=\"line\">以此分别对四个儿子执行以上操作，直到达到所需精度。</div><div class=\"line\">=&gt;</div><div class=\"line\">...</div><div class=\"line\">\"\"\"</div></pre></td></tr></table></figure>\n<p>按照这个数据结构，若曲线不在内部，则将节点设为叶，无需继续细分。寻找一个点的话复杂度是O(logn)。</p>\n<p>在实验课的内容里，用python进行数据处理，用paraview进行数据可视化。代码其实挺简单（算法就不难= =），实验课还没结束暂时不附代码了，附一个效果图。</p>\n<p><img src=\"http://oi4yiqiop.bkt.clouddn.com/QTree.png?imageMogr2/thumbnail/!50p\" alt=\"QTree\"></p>\n","excerpt":"","more":"<p>在ECP的实验课用到了四叉树，故来记录一下。</p>\n<p>四叉树是一种数据结构，每一个节点有四个孩子。一般需要用到四叉树的情况往往是二位平面，通过把区域分成四个区块来定义。</p>\n<p>在确定并显示一条曲线的具体位置时，需要使用一种算法。一种比较直观的想法就是，将平面细分成小块，通过计算验证曲线是否在这个小块内部。但是这种算法也有一个十分致命的缺点— 复杂度极高，计算量极大。而事实上，平面上大多数的区域是空白的，我们不需要对其每一个小块进行检测。仿照二分法的思路我们可以按如下方法进行。</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 确保使用的是等宽字体，用嵌入代码=_=</span></div><div class=\"line\"><span class=\"string\">\"\"\"</div><div class=\"line\">3-------2       </div><div class=\"line\">|       |</div><div class=\"line\">|       |</div><div class=\"line\">|       |</div><div class=\"line\">0-------1</div><div class=\"line\">检查曲线是否在内，若是，此节点为枝，分为四个小区域，作为四个儿子；若否，此节点为叶，没有儿子。</div><div class=\"line\">=&gt;</div><div class=\"line\">3---7---2</div><div class=\"line\">|   |   |</div><div class=\"line\">8---4---6</div><div class=\"line\">|   |   |</div><div class=\"line\">0---5---1</div><div class=\"line\">以此分别对四个儿子执行以上操作，直到达到所需精度。</div><div class=\"line\">=&gt;</div><div class=\"line\">...</div><div class=\"line\">\"\"\"</span></div></pre></td></tr></table></figure>\n<p>按照这个数据结构，若曲线不在内部，则将节点设为叶，无需继续细分。寻找一个点的话复杂度是O(logn)。</p>\n<p>在实验课的内容里，用python进行数据处理，用paraview进行数据可视化。代码其实挺简单（算法就不难= =），实验课还没结束暂时不附代码了，附一个效果图。</p>\n<p><img src=\"http://oi4yiqiop.bkt.clouddn.com/QTree.png?imageMogr2/thumbnail/!50p\" alt=\"QTree\"></p>\n"},{"title":"Sobolev space","date":"2017-02-11T13:37:53.000Z","_content":"\n# 索伯列夫空间 Sobolev space\n\n## 感性认识\n\n摘自wiki：\n\n>数学上，一个索博列夫空间是一个由函数组成的赋范向量空间，对于某个给定的p ≥ 1，它对一个函数f和它的直到某个k阶导数加上有限Lp范数的这个条件。\n\n我们通常在C1(函数1阶可导并且1阶导数连续)上研究微分方程的解，但是在偏微分方程上并不是特别方便，人们便开始研究索伯列夫空间。\n\n## 范数\n\n$$\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p\n$$\n\n赋予了范数的$W^{k,p}$是一个完备空间。\n\n## $H^k$\n\n一些记号：\n$$\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}\n$$\n\n范数和半范数：\n$$\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}\n$$\n","source":"_posts/Sobolev-space.md","raw":"---\ntitle: Sobolev space\ndate: 2017-02-11 14:37:53\ncategories: [math, unfinished]\ntags: [Sobolev, analyse, math, EDP]\n---\n\n# 索伯列夫空间 Sobolev space\n\n## 感性认识\n\n摘自wiki：\n\n>数学上，一个索博列夫空间是一个由函数组成的赋范向量空间，对于某个给定的p ≥ 1，它对一个函数f和它的直到某个k阶导数加上有限Lp范数的这个条件。\n\n我们通常在C1(函数1阶可导并且1阶导数连续)上研究微分方程的解，但是在偏微分方程上并不是特别方便，人们便开始研究索伯列夫空间。\n\n## 范数\n\n$$\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p\n$$\n\n赋予了范数的$W^{k,p}$是一个完备空间。\n\n## $H^k$\n\n一些记号：\n$$\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}\n$$\n\n范数和半范数：\n$$\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}\n$$\n","slug":"Sobolev-space","published":1,"updated":"2017-02-11T16:48:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhk000uzemm3qalyoib","content":"<h1 id=\"索伯列夫空间-Sobolev-space\"><a href=\"#索伯列夫空间-Sobolev-space\" class=\"headerlink\" title=\"索伯列夫空间 Sobolev space\"></a>索伯列夫空间 Sobolev space</h1><h2 id=\"感性认识\"><a href=\"#感性认识\" class=\"headerlink\" title=\"感性认识\"></a>感性认识</h2><p>摘自wiki：</p>\n<blockquote>\n<p>数学上，一个索博列夫空间是一个由函数组成的赋范向量空间，对于某个给定的p ≥ 1，它对一个函数f和它的直到某个k阶导数加上有限Lp范数的这个条件。</p>\n</blockquote>\n<p>我们通常在C1(函数1阶可导并且1阶导数连续)上研究微分方程的解，但是在偏微分方程上并不是特别方便，人们便开始研究索伯列夫空间。</p>\n<h2 id=\"范数\"><a href=\"#范数\" class=\"headerlink\" title=\"范数\"></a>范数</h2><script type=\"math/tex; mode=display\">\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p</script><p>赋予了范数的$W^{k,p}$是一个完备空间。</p>\n<h2 id=\"H-k\"><a href=\"#H-k\" class=\"headerlink\" title=\"$H^k$\"></a>$H^k$</h2><p>一些记号：</p>\n<script type=\"math/tex; mode=display\">\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}</script><p>范数和半范数：</p>\n<script type=\"math/tex; mode=display\">\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}</script>","excerpt":"","more":"<h1 id=\"索伯列夫空间-Sobolev-space\"><a href=\"#索伯列夫空间-Sobolev-space\" class=\"headerlink\" title=\"索伯列夫空间 Sobolev space\"></a>索伯列夫空间 Sobolev space</h1><h2 id=\"感性认识\"><a href=\"#感性认识\" class=\"headerlink\" title=\"感性认识\"></a>感性认识</h2><p>摘自wiki：</p>\n<blockquote>\n<p>数学上，一个索博列夫空间是一个由函数组成的赋范向量空间，对于某个给定的p ≥ 1，它对一个函数f和它的直到某个k阶导数加上有限Lp范数的这个条件。</p>\n</blockquote>\n<p>我们通常在C1(函数1阶可导并且1阶导数连续)上研究微分方程的解，但是在偏微分方程上并不是特别方便，人们便开始研究索伯列夫空间。</p>\n<h2 id=\"范数\"><a href=\"#范数\" class=\"headerlink\" title=\"范数\"></a>范数</h2><script type=\"math/tex; mode=display\">\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p</script><p>赋予了范数的$W^{k,p}$是一个完备空间。</p>\n<h2 id=\"H-k\"><a href=\"#H-k\" class=\"headerlink\" title=\"$H^k$\"></a>$H^k$</h2><p>一些记号：</p>\n<script type=\"math/tex; mode=display\">\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}</script><p>范数和半范数：</p>\n<script type=\"math/tex; mode=display\">\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}</script>"},{"title":"复杂度 complexity","date":"2016-11-27T09:52:05.000Z","_content":"\n# 计算复杂度 - Calcul the complexity\n\n这里我们只考虑时间复杂度。\n\nThere, we only discuss the time complexity.\n\n## 通常 - Normal\n\n1. Single operation - O(1)\n\n2. Loop\n\n   ```Python\n   def fun(n):\n   \tfor i in range(n):\n      \t\tpass\n   ```\n\n   ```python\n   def fun(n):\n   \twhile i < n :\n       \ti += 1\n   ```\n\n   — O(n)\n\n   ```python\n   def fun(n):\n       while i < n :\n           i *= 2\n   ```\n\n   — O(logn)\n\n   Etc.\n\n   ## 递归 - Recursion\n   1.  代入法\n\n       预估其复杂度，代入原方程，若相符，则可能为解。\n\n       ex:\n\n       T(n) = 2*T(n/2) + O(n)\n\n       假设 T(n) = kn^2\n\n       代入原式，成立。\n\n       接下来用数学归纳法验证。\n\n   2.  迭代法\n\n          迭代地展开递归方程的右端，使其成为一个非递归的和式，随后进行复杂度计算\n\n          ex:\n\n          T(n) = T(n-1) + O(1)\n\n          T(1) = O(1)\n\n          所以，T(n) = T(n-1) + O(1) = T(n-1) + 2 * O(1) = … = n*O(1) = O(n)\n\n   3.  套用公式\n\n          对于形如\n\n          T(n) = aT(n/b) +f(n)\n\n          的方程已有固定判断法，套用公式即可。\n\n   4.  差分方程法\n\n          利用查分方程解，这个比较复杂，这里先占个位，以后在补。","source":"_posts/complexity.md","raw":"---\ntitle: 复杂度 complexity\ndate: 2016-11-27 10:52:05\ncategories: programming\ntags: [algo, programming, complexity]\n---\n\n# 计算复杂度 - Calcul the complexity\n\n这里我们只考虑时间复杂度。\n\nThere, we only discuss the time complexity.\n\n## 通常 - Normal\n\n1. Single operation - O(1)\n\n2. Loop\n\n   ```Python\n   def fun(n):\n   \tfor i in range(n):\n      \t\tpass\n   ```\n\n   ```python\n   def fun(n):\n   \twhile i < n :\n       \ti += 1\n   ```\n\n   — O(n)\n\n   ```python\n   def fun(n):\n       while i < n :\n           i *= 2\n   ```\n\n   — O(logn)\n\n   Etc.\n\n   ## 递归 - Recursion\n   1.  代入法\n\n       预估其复杂度，代入原方程，若相符，则可能为解。\n\n       ex:\n\n       T(n) = 2*T(n/2) + O(n)\n\n       假设 T(n) = kn^2\n\n       代入原式，成立。\n\n       接下来用数学归纳法验证。\n\n   2.  迭代法\n\n          迭代地展开递归方程的右端，使其成为一个非递归的和式，随后进行复杂度计算\n\n          ex:\n\n          T(n) = T(n-1) + O(1)\n\n          T(1) = O(1)\n\n          所以，T(n) = T(n-1) + O(1) = T(n-1) + 2 * O(1) = … = n*O(1) = O(n)\n\n   3.  套用公式\n\n          对于形如\n\n          T(n) = aT(n/b) +f(n)\n\n          的方程已有固定判断法，套用公式即可。\n\n   4.  差分方程法\n\n          利用查分方程解，这个比较复杂，这里先占个位，以后在补。","slug":"complexity","published":1,"updated":"2016-11-30T10:43:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhl000wzemmnb73wevo","content":"<h1 id=\"计算复杂度-Calcul-the-complexity\"><a href=\"#计算复杂度-Calcul-the-complexity\" class=\"headerlink\" title=\"计算复杂度 - Calcul the complexity\"></a>计算复杂度 - Calcul the complexity</h1><p>这里我们只考虑时间复杂度。</p>\n<p>There, we only discuss the time complexity.</p>\n<h2 id=\"通常-Normal\"><a href=\"#通常-Normal\" class=\"headerlink\" title=\"通常 - Normal\"></a>通常 - Normal</h2><ol>\n<li><p>Single operation - O(1)</p>\n</li>\n<li><p>Loop</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):</div><div class=\"line\">   \t\t<span class=\"keyword\">pass</span></div></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">\t<span class=\"keyword\">while</span> i &lt; n :</div><div class=\"line\">    \ti += <span class=\"number\">1</span></div></pre></td></tr></table></figure>\n<p>— O(n)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">while</span> i &lt; n :</div><div class=\"line\">        i *= <span class=\"number\">2</span></div></pre></td></tr></table></figure>\n<p>— O(logn)</p>\n<p>Etc.</p>\n<h2 id=\"递归-Recursion\"><a href=\"#递归-Recursion\" class=\"headerlink\" title=\"递归 - Recursion\"></a>递归 - Recursion</h2><ol>\n<li><p>代入法</p>\n<p>预估其复杂度，代入原方程，若相符，则可能为解。</p>\n<p>ex:</p>\n<p>T(n) = 2*T(n/2) + O(n)</p>\n<p>假设 T(n) = kn^2</p>\n<p>代入原式，成立。</p>\n<p>接下来用数学归纳法验证。</p>\n</li>\n<li><p>迭代法</p>\n<p>   迭代地展开递归方程的右端，使其成为一个非递归的和式，随后进行复杂度计算</p>\n<p>   ex:</p>\n<p>   T(n) = T(n-1) + O(1)</p>\n<p>   T(1) = O(1)</p>\n<p>   所以，T(n) = T(n-1) + O(1) = T(n-1) + 2 <em> O(1) = … = n</em>O(1) = O(n)</p>\n</li>\n<li><p>套用公式</p>\n<p>   对于形如</p>\n<p>   T(n) = aT(n/b) +f(n)</p>\n<p>   的方程已有固定判断法，套用公式即可。</p>\n</li>\n<li><p>差分方程法</p>\n<p>   利用查分方程解，这个比较复杂，这里先占个位，以后在补。</p>\n</li>\n</ol>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"计算复杂度-Calcul-the-complexity\"><a href=\"#计算复杂度-Calcul-the-complexity\" class=\"headerlink\" title=\"计算复杂度 - Calcul the complexity\"></a>计算复杂度 - Calcul the complexity</h1><p>这里我们只考虑时间复杂度。</p>\n<p>There, we only discuss the time complexity.</p>\n<h2 id=\"通常-Normal\"><a href=\"#通常-Normal\" class=\"headerlink\" title=\"通常 - Normal\"></a>通常 - Normal</h2><ol>\n<li><p>Single operation - O(1)</p>\n</li>\n<li><p>Loop</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> range(n):</div><div class=\"line\">   \t\t<span class=\"keyword\">pass</span></div></pre></td></tr></table></figure>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">\t<span class=\"keyword\">while</span> i &lt; n :</div><div class=\"line\">    \ti += <span class=\"number\">1</span></div></pre></td></tr></table></figure>\n<p>— O(n)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span><span class=\"params\">(n)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">while</span> i &lt; n :</div><div class=\"line\">        i *= <span class=\"number\">2</span></div></pre></td></tr></table></figure>\n<p>— O(logn)</p>\n<p>Etc.</p>\n<h2 id=\"递归-Recursion\"><a href=\"#递归-Recursion\" class=\"headerlink\" title=\"递归 - Recursion\"></a>递归 - Recursion</h2><ol>\n<li><p>代入法</p>\n<p>预估其复杂度，代入原方程，若相符，则可能为解。</p>\n<p>ex:</p>\n<p>T(n) = 2*T(n/2) + O(n)</p>\n<p>假设 T(n) = kn^2</p>\n<p>代入原式，成立。</p>\n<p>接下来用数学归纳法验证。</p>\n</li>\n<li><p>迭代法</p>\n<p>   迭代地展开递归方程的右端，使其成为一个非递归的和式，随后进行复杂度计算</p>\n<p>   ex:</p>\n<p>   T(n) = T(n-1) + O(1)</p>\n<p>   T(1) = O(1)</p>\n<p>   所以，T(n) = T(n-1) + O(1) = T(n-1) + 2 <em> O(1) = … = n</em>O(1) = O(n)</p>\n</li>\n<li><p>套用公式</p>\n<p>   对于形如</p>\n<p>   T(n) = aT(n/b) +f(n)</p>\n<p>   的方程已有固定判断法，套用公式即可。</p>\n</li>\n<li><p>差分方程法</p>\n<p>   利用查分方程解，这个比较复杂，这里先占个位，以后在补。</p>\n</li>\n</ol>\n</li>\n</ol>\n"},{"title":"图论 graph","date":"2016-11-27T13:42:24.000Z","_content":"\n# The symbols\n\nIn graph thery, a graph G = (V, E) is a collection of points.\n\nV, called vertices and lines connecting some subset of them\n\nE, called edges, is contained by V ✖ V\n\nUnion-Find\n\n# Others\n\n以后涉及相关问题再回过头来补充，暂时引用wiki凑数：\n\n[图论](https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA)\n\n重要算法：\n\n>- [戴克斯特拉算法](https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95)(D.A)\n>- [克鲁斯卡尔算法](https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95)(K.A)\n>- [普里姆算法](https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95)(P.A)\n>- [拓扑排序](https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F)算法(TSA)\n>- [关键路径](https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84)算法(CPA)\n>- [广度优先搜索](https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)算法([BFS](https://zh.wikipedia.org/wiki/BFS)'s A)\n>- [深度优先搜索](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)算法([DFS](https://zh.wikipedia.org/wiki/DFS)'s A)\n\n","source":"_posts/graph.md","raw":"---\ntitle: 图论 graph\ndate: 2016-11-27 14:42:24\ncategories: [programming]\ntags: [graph, algo, programming]\n---\n\n# The symbols\n\nIn graph thery, a graph G = (V, E) is a collection of points.\n\nV, called vertices and lines connecting some subset of them\n\nE, called edges, is contained by V ✖ V\n\nUnion-Find\n\n# Others\n\n以后涉及相关问题再回过头来补充，暂时引用wiki凑数：\n\n[图论](https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA)\n\n重要算法：\n\n>- [戴克斯特拉算法](https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95)(D.A)\n>- [克鲁斯卡尔算法](https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95)(K.A)\n>- [普里姆算法](https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95)(P.A)\n>- [拓扑排序](https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F)算法(TSA)\n>- [关键路径](https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84)算法(CPA)\n>- [广度优先搜索](https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)算法([BFS](https://zh.wikipedia.org/wiki/BFS)'s A)\n>- [深度优先搜索](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)算法([DFS](https://zh.wikipedia.org/wiki/DFS)'s A)\n\n","slug":"graph","published":1,"updated":"2017-02-11T12:08:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhn000zzemmvb3ut0jg","content":"<h1 id=\"The-symbols\"><a href=\"#The-symbols\" class=\"headerlink\" title=\"The symbols\"></a>The symbols</h1><p>In graph thery, a graph G = (V, E) is a collection of points.</p>\n<p>V, called vertices and lines connecting some subset of them</p>\n<p>E, called edges, is contained by V ✖ V</p>\n<p>Union-Find</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><p>以后涉及相关问题再回过头来补充，暂时引用wiki凑数：</p>\n<p><a href=\"https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA\" target=\"_blank\" rel=\"external\">图论</a></p>\n<p>重要算法：</p>\n<blockquote>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"external\">戴克斯特拉算法</a>(D.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"external\">克鲁斯卡尔算法</a>(K.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95\" target=\"_blank\" rel=\"external\">普里姆算法</a>(P.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F\" target=\"_blank\" rel=\"external\">拓扑排序</a>算法(TSA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84\" target=\"_blank\" rel=\"external\">关键路径</a>算法(CPA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\" target=\"_blank\" rel=\"external\">广度优先搜索</a>算法(<a href=\"https://zh.wikipedia.org/wiki/BFS\" target=\"_blank\" rel=\"external\">BFS</a>‘s A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\" target=\"_blank\" rel=\"external\">深度优先搜索</a>算法(<a href=\"https://zh.wikipedia.org/wiki/DFS\" target=\"_blank\" rel=\"external\">DFS</a>‘s A)</li>\n</ul>\n</blockquote>\n","excerpt":"","more":"<h1 id=\"The-symbols\"><a href=\"#The-symbols\" class=\"headerlink\" title=\"The symbols\"></a>The symbols</h1><p>In graph thery, a graph G = (V, E) is a collection of points.</p>\n<p>V, called vertices and lines connecting some subset of them</p>\n<p>E, called edges, is contained by V ✖ V</p>\n<p>Union-Find</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><p>以后涉及相关问题再回过头来补充，暂时引用wiki凑数：</p>\n<p><a href=\"https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA\">图论</a></p>\n<p>重要算法：</p>\n<blockquote>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95\">戴克斯特拉算法</a>(D.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95\">克鲁斯卡尔算法</a>(K.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95\">普里姆算法</a>(P.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F\">拓扑排序</a>算法(TSA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84\">关键路径</a>算法(CPA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\">广度优先搜索</a>算法(<a href=\"https://zh.wikipedia.org/wiki/BFS\">BFS</a>‘s A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\">深度优先搜索</a>算法(<a href=\"https://zh.wikipedia.org/wiki/DFS\">DFS</a>‘s A)</li>\n</ul>\n</blockquote>\n"},{"title":"数据挖掘-定性归纳","date":"2016-12-08T20:31:50.000Z","_content":"\n# 数据泛化和概念对比\n\n1.    数据立方方法\n\n      利用数据立方方法进行数据泛化，被分析的数据存放在一个多维数据库(数据立方)中。\n\n      数据立方的维是通过一系列能够形成层次的属性或网格，例如:日期可以包含属性天、周、月、季和年，这些属性构成了维的网格。一个数据立方中存放着预先对部分或所有维(属性)的合计计算结果。 \n\n      roll up: 数据泛化\n\n      drill down: 数据细化\n\n2.    基于属性的归纳方法\n\n      它是一种在线数据分析技术方法。\n\n      基于属性归纳的基本思想就是，首先利用关系数据库查询来收集与任务相关的数据，并通过对任务相关数据集中各属性不同值个数的检查，完成数据泛化操作。数据泛化操作是通过属性消减或属性泛化(又称为概念层次提升)操作来完成的。通过合并(泛化后)相同行并累计它们相应的个数。这就自然减少了泛化后的数据集大小。所获(泛化后)结果以图表和规则等多种不同形式提供给用户。\n\n      涉及的操作有两种：\n\n      1. 属性消减\n\n         例如，有四个属性：街道、城市、省份，国家，那么街道的更高层次是由后面三个属性来表示的，此时取消街道属性相当于泛化操作。\n\n      2. 属性泛化\n\n         它是基于以下规则进行:若一个属性(在初始数据集中) 有许多不同数值，且该属性存在一组泛化操作，则可以选择一个泛化操作对该属性进行处理。 \n\n      这里我们注意到泛化的过程不足，则依然不方便分析；若泛化太过，则会使其失去本身所含有的意义。通常我们通过以下两种方法控制泛化程度。\n\n      1. 属性泛化阀值控制\n\n         将属性泛化至设定的阀值。\n\n      2. 泛化关系阀值控制\n\n      用户都应能调整阀值。\n\n3.    属性关联分析\n\n      从概念上讲，属性关联分析的过程如下\n\n      1. 数据收集\n\n      2. 利用保守AOI方法进行属性相关分析\n\n         一般来说，这里主要是消除数据集中取不同值个数过多的属性或对可泛化属性进行泛化。一般而言，保险起见，这里的阀值一般比较大。\n\n      3. 利用所确定评估标准评估每个初选后的属性。\n\n         如信息增益方法。\n\n      4. 消除无关或弱相关的属性\n\n      5. 利用AOI方法生成概念描述\n\n         采用更严格的属性泛化控制阈值来进行 基于属性的归纳操作。\n\n4.    概念对比\n\n      1. 概念对比方法和实现\n         1. 数据收集\n\n         2. 属性相关分析\n\n            应用分析概念对比方法，以便保留相关程度最高的若干属性(维)供稍后分析处理。\n\n         3. 同步泛化\n         4. 卷上卷下\n         5. 挖掘结果表示\n\n      2. t_weight - 同一行所占比例\n\n      3. d_weight - 同一列所占比例\n\n5.    挖掘数据库\n\n      1. 计算中心趋势\n\n         1. 算数平均\n         2. 加权算术平均\n         3. 中间值\n\n      2. 计算数据分布\n\n         最常用的数据分布度量参数就是五值摘要(四分值)、值间范围和标准偏差。\n\n         四分值的三个分度为Q1,Q2,Q3。\n\n         中间数为M。\n\n         最小数据Minimum，最大数据Maximum。\n\n         - 分值间范围：IQR = Q3 - Q1\n         - 五值摘要：Minimum, Q3, M, Q1, Maximum\n\n         数据变化程度用方差来表示，自由度为n-1.","source":"_posts/datamining-qualitative-induction.md","raw":"---\ntitle: 数据挖掘-定性归纳\ndate: 2016-12-08 21:31:50\ncategories: [programming]\ntags: [datamining, qualitative-induction, programming]\n---\n\n# 数据泛化和概念对比\n\n1.    数据立方方法\n\n      利用数据立方方法进行数据泛化，被分析的数据存放在一个多维数据库(数据立方)中。\n\n      数据立方的维是通过一系列能够形成层次的属性或网格，例如:日期可以包含属性天、周、月、季和年，这些属性构成了维的网格。一个数据立方中存放着预先对部分或所有维(属性)的合计计算结果。 \n\n      roll up: 数据泛化\n\n      drill down: 数据细化\n\n2.    基于属性的归纳方法\n\n      它是一种在线数据分析技术方法。\n\n      基于属性归纳的基本思想就是，首先利用关系数据库查询来收集与任务相关的数据，并通过对任务相关数据集中各属性不同值个数的检查，完成数据泛化操作。数据泛化操作是通过属性消减或属性泛化(又称为概念层次提升)操作来完成的。通过合并(泛化后)相同行并累计它们相应的个数。这就自然减少了泛化后的数据集大小。所获(泛化后)结果以图表和规则等多种不同形式提供给用户。\n\n      涉及的操作有两种：\n\n      1. 属性消减\n\n         例如，有四个属性：街道、城市、省份，国家，那么街道的更高层次是由后面三个属性来表示的，此时取消街道属性相当于泛化操作。\n\n      2. 属性泛化\n\n         它是基于以下规则进行:若一个属性(在初始数据集中) 有许多不同数值，且该属性存在一组泛化操作，则可以选择一个泛化操作对该属性进行处理。 \n\n      这里我们注意到泛化的过程不足，则依然不方便分析；若泛化太过，则会使其失去本身所含有的意义。通常我们通过以下两种方法控制泛化程度。\n\n      1. 属性泛化阀值控制\n\n         将属性泛化至设定的阀值。\n\n      2. 泛化关系阀值控制\n\n      用户都应能调整阀值。\n\n3.    属性关联分析\n\n      从概念上讲，属性关联分析的过程如下\n\n      1. 数据收集\n\n      2. 利用保守AOI方法进行属性相关分析\n\n         一般来说，这里主要是消除数据集中取不同值个数过多的属性或对可泛化属性进行泛化。一般而言，保险起见，这里的阀值一般比较大。\n\n      3. 利用所确定评估标准评估每个初选后的属性。\n\n         如信息增益方法。\n\n      4. 消除无关或弱相关的属性\n\n      5. 利用AOI方法生成概念描述\n\n         采用更严格的属性泛化控制阈值来进行 基于属性的归纳操作。\n\n4.    概念对比\n\n      1. 概念对比方法和实现\n         1. 数据收集\n\n         2. 属性相关分析\n\n            应用分析概念对比方法，以便保留相关程度最高的若干属性(维)供稍后分析处理。\n\n         3. 同步泛化\n         4. 卷上卷下\n         5. 挖掘结果表示\n\n      2. t_weight - 同一行所占比例\n\n      3. d_weight - 同一列所占比例\n\n5.    挖掘数据库\n\n      1. 计算中心趋势\n\n         1. 算数平均\n         2. 加权算术平均\n         3. 中间值\n\n      2. 计算数据分布\n\n         最常用的数据分布度量参数就是五值摘要(四分值)、值间范围和标准偏差。\n\n         四分值的三个分度为Q1,Q2,Q3。\n\n         中间数为M。\n\n         最小数据Minimum，最大数据Maximum。\n\n         - 分值间范围：IQR = Q3 - Q1\n         - 五值摘要：Minimum, Q3, M, Q1, Maximum\n\n         数据变化程度用方差来表示，自由度为n-1.","slug":"datamining-qualitative-induction","published":1,"updated":"2016-12-23T06:55:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhq0012zemmu4jbe80d","content":"<h1 id=\"数据泛化和概念对比\"><a href=\"#数据泛化和概念对比\" class=\"headerlink\" title=\"数据泛化和概念对比\"></a>数据泛化和概念对比</h1><ol>\n<li><p>数据立方方法</p>\n<p>利用数据立方方法进行数据泛化，被分析的数据存放在一个多维数据库(数据立方)中。</p>\n<p>数据立方的维是通过一系列能够形成层次的属性或网格，例如:日期可以包含属性天、周、月、季和年，这些属性构成了维的网格。一个数据立方中存放着预先对部分或所有维(属性)的合计计算结果。 </p>\n<p>roll up: 数据泛化</p>\n<p>drill down: 数据细化</p>\n</li>\n<li><p>基于属性的归纳方法</p>\n<p>它是一种在线数据分析技术方法。</p>\n<p>基于属性归纳的基本思想就是，首先利用关系数据库查询来收集与任务相关的数据，并通过对任务相关数据集中各属性不同值个数的检查，完成数据泛化操作。数据泛化操作是通过属性消减或属性泛化(又称为概念层次提升)操作来完成的。通过合并(泛化后)相同行并累计它们相应的个数。这就自然减少了泛化后的数据集大小。所获(泛化后)结果以图表和规则等多种不同形式提供给用户。</p>\n<p>涉及的操作有两种：</p>\n<ol>\n<li><p>属性消减</p>\n<p>例如，有四个属性：街道、城市、省份，国家，那么街道的更高层次是由后面三个属性来表示的，此时取消街道属性相当于泛化操作。</p>\n</li>\n<li><p>属性泛化</p>\n<p>它是基于以下规则进行:若一个属性(在初始数据集中) 有许多不同数值，且该属性存在一组泛化操作，则可以选择一个泛化操作对该属性进行处理。 </p>\n</li>\n</ol>\n<p>这里我们注意到泛化的过程不足，则依然不方便分析；若泛化太过，则会使其失去本身所含有的意义。通常我们通过以下两种方法控制泛化程度。</p>\n<ol>\n<li><p>属性泛化阀值控制</p>\n<p>将属性泛化至设定的阀值。</p>\n</li>\n<li><p>泛化关系阀值控制</p>\n</li>\n</ol>\n<p>用户都应能调整阀值。</p>\n</li>\n<li><p>属性关联分析</p>\n<p>从概念上讲，属性关联分析的过程如下</p>\n<ol>\n<li><p>数据收集</p>\n</li>\n<li><p>利用保守AOI方法进行属性相关分析</p>\n<p>一般来说，这里主要是消除数据集中取不同值个数过多的属性或对可泛化属性进行泛化。一般而言，保险起见，这里的阀值一般比较大。</p>\n</li>\n<li><p>利用所确定评估标准评估每个初选后的属性。</p>\n<p>如信息增益方法。</p>\n</li>\n<li><p>消除无关或弱相关的属性</p>\n</li>\n<li><p>利用AOI方法生成概念描述</p>\n<p>采用更严格的属性泛化控制阈值来进行 基于属性的归纳操作。</p>\n</li>\n</ol>\n</li>\n<li><p>概念对比</p>\n<ol>\n<li><p>概念对比方法和实现</p>\n<ol>\n<li><p>数据收集</p>\n</li>\n<li><p>属性相关分析</p>\n<p>应用分析概念对比方法，以便保留相关程度最高的若干属性(维)供稍后分析处理。</p>\n</li>\n<li><p>同步泛化</p>\n</li>\n<li>卷上卷下</li>\n<li>挖掘结果表示</li>\n</ol>\n</li>\n<li><p>t_weight - 同一行所占比例</p>\n</li>\n<li><p>d_weight - 同一列所占比例</p>\n</li>\n</ol>\n</li>\n<li><p>挖掘数据库</p>\n<ol>\n<li><p>计算中心趋势</p>\n<ol>\n<li>算数平均</li>\n<li>加权算术平均</li>\n<li>中间值</li>\n</ol>\n</li>\n<li><p>计算数据分布</p>\n<p>最常用的数据分布度量参数就是五值摘要(四分值)、值间范围和标准偏差。</p>\n<p>四分值的三个分度为Q1,Q2,Q3。</p>\n<p>中间数为M。</p>\n<p>最小数据Minimum，最大数据Maximum。</p>\n<ul>\n<li>分值间范围：IQR = Q3 - Q1</li>\n<li>五值摘要：Minimum, Q3, M, Q1, Maximum</li>\n</ul>\n<p>数据变化程度用方差来表示，自由度为n-1.</p>\n</li>\n</ol>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"数据泛化和概念对比\"><a href=\"#数据泛化和概念对比\" class=\"headerlink\" title=\"数据泛化和概念对比\"></a>数据泛化和概念对比</h1><ol>\n<li><p>数据立方方法</p>\n<p>利用数据立方方法进行数据泛化，被分析的数据存放在一个多维数据库(数据立方)中。</p>\n<p>数据立方的维是通过一系列能够形成层次的属性或网格，例如:日期可以包含属性天、周、月、季和年，这些属性构成了维的网格。一个数据立方中存放着预先对部分或所有维(属性)的合计计算结果。 </p>\n<p>roll up: 数据泛化</p>\n<p>drill down: 数据细化</p>\n</li>\n<li><p>基于属性的归纳方法</p>\n<p>它是一种在线数据分析技术方法。</p>\n<p>基于属性归纳的基本思想就是，首先利用关系数据库查询来收集与任务相关的数据，并通过对任务相关数据集中各属性不同值个数的检查，完成数据泛化操作。数据泛化操作是通过属性消减或属性泛化(又称为概念层次提升)操作来完成的。通过合并(泛化后)相同行并累计它们相应的个数。这就自然减少了泛化后的数据集大小。所获(泛化后)结果以图表和规则等多种不同形式提供给用户。</p>\n<p>涉及的操作有两种：</p>\n<ol>\n<li><p>属性消减</p>\n<p>例如，有四个属性：街道、城市、省份，国家，那么街道的更高层次是由后面三个属性来表示的，此时取消街道属性相当于泛化操作。</p>\n</li>\n<li><p>属性泛化</p>\n<p>它是基于以下规则进行:若一个属性(在初始数据集中) 有许多不同数值，且该属性存在一组泛化操作，则可以选择一个泛化操作对该属性进行处理。 </p>\n</li>\n</ol>\n<p>这里我们注意到泛化的过程不足，则依然不方便分析；若泛化太过，则会使其失去本身所含有的意义。通常我们通过以下两种方法控制泛化程度。</p>\n<ol>\n<li><p>属性泛化阀值控制</p>\n<p>将属性泛化至设定的阀值。</p>\n</li>\n<li><p>泛化关系阀值控制</p>\n</li>\n</ol>\n<p>用户都应能调整阀值。</p>\n</li>\n<li><p>属性关联分析</p>\n<p>从概念上讲，属性关联分析的过程如下</p>\n<ol>\n<li><p>数据收集</p>\n</li>\n<li><p>利用保守AOI方法进行属性相关分析</p>\n<p>一般来说，这里主要是消除数据集中取不同值个数过多的属性或对可泛化属性进行泛化。一般而言，保险起见，这里的阀值一般比较大。</p>\n</li>\n<li><p>利用所确定评估标准评估每个初选后的属性。</p>\n<p>如信息增益方法。</p>\n</li>\n<li><p>消除无关或弱相关的属性</p>\n</li>\n<li><p>利用AOI方法生成概念描述</p>\n<p>采用更严格的属性泛化控制阈值来进行 基于属性的归纳操作。</p>\n</li>\n</ol>\n</li>\n<li><p>概念对比</p>\n<ol>\n<li><p>概念对比方法和实现</p>\n<ol>\n<li><p>数据收集</p>\n</li>\n<li><p>属性相关分析</p>\n<p>应用分析概念对比方法，以便保留相关程度最高的若干属性(维)供稍后分析处理。</p>\n</li>\n<li><p>同步泛化</p>\n</li>\n<li>卷上卷下</li>\n<li>挖掘结果表示</li>\n</ol>\n</li>\n<li><p>t_weight - 同一行所占比例</p>\n</li>\n<li><p>d_weight - 同一列所占比例</p>\n</li>\n</ol>\n</li>\n<li><p>挖掘数据库</p>\n<ol>\n<li><p>计算中心趋势</p>\n<ol>\n<li>算数平均</li>\n<li>加权算术平均</li>\n<li>中间值</li>\n</ol>\n</li>\n<li><p>计算数据分布</p>\n<p>最常用的数据分布度量参数就是五值摘要(四分值)、值间范围和标准偏差。</p>\n<p>四分值的三个分度为Q1,Q2,Q3。</p>\n<p>中间数为M。</p>\n<p>最小数据Minimum，最大数据Maximum。</p>\n<ul>\n<li>分值间范围：IQR = Q3 - Q1</li>\n<li>五值摘要：Minimum, Q3, M, Q1, Maximum</li>\n</ul>\n<p>数据变化程度用方差来表示，自由度为n-1.</p>\n</li>\n</ol>\n</li>\n</ol>\n"},{"title":"数据挖掘-分类与预测","date":"2016-12-26T13:56:57.000Z","_content":"\n# 基本知识\n\n主要分为两个步骤：\n\n1. 建立一个描述已知数据集类别或概念的模型。\n\n   分类规则形式、决策树形式，或数学公式形式。\n\n2. 利用所获得的模型进行分类操作。\n\n   首先要对模型分类准确率进行估计。\n\n   若其准确率可以接受，则可以使用该模型进行分类。   \t\n\n可以根据以下几条标准对各种分类方法进行比较:\n\n1. 预测准确率，它描述(学习所获)模型能够正确预测未知对象类别或(类别)数值的能力。\n2. 速度，它描述在构造和使用模型时的计算效率。 \n3. 鲁棒性，它描述在数据带有噪声和有数据遗失情况下，(学习所获)模型仍能进行正确预测的能力。 \n4. 可扩展性，它描述对处理大量数据并构造相应学习模型所需要的能力。\n5. 易理解性，它描述学习所获模型表示的可理解程度。 在本章的后面各节，将要陆续介绍上述有关问题的实现方法。\n\n# 基于决策树的分类\n\n1. 决策树的生成算法\n\n   - 基本决策树算法\n\n     本质是一个贪心算法，自上而下分而治之。\n\n2. 属性选择方法\n\n   信息量\n   $$\n   I(s_1,…,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}\n   $$\n   利用属性A划分当前样本集合所需要的信息可以计算：\n   $$\n   E(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,…,s_m) }\n   $$\n   E(A)的值越小，说明其子集划分结果越纯，即越好。而对于一个子集Sj，它的信息为\n   $$\n   I(s_{1j},…,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}\n   $$\n   这样利用属性A对当前分支结点进行相应样本集合划分所获得的信息增益是:\n   $$\n   Gain(A) =I(s_1,…,s_m)- E(A)\n   $$\n   也就是说Gain(A)被认为是利用属性A进行划分后，所获的的信息熵的减少量。\n\n   决策树归纳算法计算每个属性的Gain，选择信息增益最大的属性，作为测试属性并由此产生相应的分支节点。\n\n3. 树枝的修剪\n\n   1. 事前修剪\n\n      基本原理是设置一个阀值，当某一节点的的样本数少于阀值，则停止细分。难点在于设置一个合理的阀值。\n\n   2. 事后修剪\n\n      从一个充分生长的树中修建。\n\n      可以使用基于代价成本的方法，也可以使用最短描述长度(MDL)。\n\n      前者计算其分类错误率，若修剪枝导致分类错误率变高，则保留，否则剪枝；后者选择最简单的，无需独立的数据测试\n\n4. 规则获取\n\n   在已经获得了一个决策树的基础上，可以使用\"if...else...\"语句描述该决策树。\n\n5. 基本决策树方法改进及其扩展性\n\n#  贝叶斯分类方法\n\n贝叶斯分类器是一个统计分类器，基于贝叶斯定理。\n\n简单贝叶斯分类器的分类性能可以与决策树和神经网络相比。\n\n简单贝叶斯分类器假设一个指定类别中各属性的取值是互相独立的，它可以帮助减少计算量。\n\n1. 贝叶斯定理\n\n   设X为一个类别未知的数据样本，H为某个假设，则：\n   $$\n   P(H|X) = \\frac{P(X|H)P(H)}{P(X)}\n   $$\n\n2. 简单贝叶斯分类方法\n\n   步骤说明如下：\n\n   1. 每一个数据都是有一个n维特征向量X={x1,…,xn}构成，分别描述其n个属性(A1,…,An)。\n\n   2. 若有m个不同的类别(C1,…,Cm)，分类器将未知X归属到类别Ci，当仅当\n      $$\n      P(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)\n      $$\n      所以我们要找到最大的\n      $$\n      P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}\n      $$\n\n   3. 要找到它，只需要P(X|Ci)P(Ci)取最大即可。由于各类别的事前概率是未知的，我们假设P(Ci)是互相相等的，这样，第二步中的式子取最大就转化为了寻找最大的P(X|Ci)\n\n   4. 由于所含的属性比较多，直接计算P(X|Ci)的计算量还是很大的。由于简单贝叶斯分类器假设各属性独立，则：\n      $$\n      P(X|C_i) = \\prod{P(x_k|C_i)}\n      $$\n      可以根据训练数据样本估算P(xk|Ci)的值。具体如下：\n\n      - 若Ak是符号量\n        $$\n        P(x_k|Ci)=\\frac{s_{ik}}{s_i}\n        $$\n        这里sik为训练样本中类别为Ci且属性Ak取vk的样本数。si为训练样本中类别为Ci的样本数。\n\n      - 若Ak是连续量\n        $$\n        P(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}\n        $$\n        其中$g(x_k,\\mu_{C_i},\\sigma_{C_i})$ï为属性为Ak的高斯规范密度函数。\n\n   5. 为了预测X的分类，我们通过上述方法估计各个类别的正确率，将X归属到可能性最高的类别。\n\n3. 贝叶斯信念网络\n\n   简单贝叶斯假设属性相互独立，从而简化计算，而实际上属性相互依赖的情况比较常见，所以又出现了贝叶斯信念网络，用于描述这种相互关联的概率分布。\n\n   贝叶斯信念网络提供了一个图形模型来描述其中的因果关系。信念网络包括两个部分。\n\n   - 第一部分是有向无环图\n\n     每一个节点代表随机变量。\n\n     每一条弧代表一个概率依赖。\n\n     给定父节点，每个变量有条件的独立于图中非子节点。\n\n   - 第二部分是包含所有变量的条件概率表(CPT)\n\n     对于一个变量Z，CPT定义了P(Z|parent(Z))，由此可以得到一个表。\n\n     例如，LunCancer的父节点是FamilyHistory和Smoker，\n\n|             | FH, S | FH, ~S | ~FH, S | ~FH, ~S |\n| ----------- | ----- | ------ | ------ | ------- |\n| LungCancer  | 0.8   | 0.5    | 0.7    | 0.1     |\n| ~LungCancer | 0.2   | 0.5    | 0.3    | 0.9     |\n\n\n数据对象的联合概率通过如下公式计算。\n$$\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}\n$$\n\n4. 贝叶斯信念网络的学习\n\n   学习算法步骤如下：\n\n   1. 计算下降梯度\n      $$\n      \\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}\n      $$\n      ​\n      左边是计算训练集合S中每个样本Xd的概率。设这一概率为p。\n\n      由Yi和Ui表示隐含变量，p可通过样本中可观察到的变量以及标准贝叶斯网络推理计算得到。\n\n   2. 沿梯度方向前进一小步，权重更新计算如下\n      $$\n      w_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}\n      $$\n      l为学习速率代表学习步长。通常学习速率为较小的常数。\n\n   3. 重新规格化权重\n\n      保证wijk的取值在0～1，其和等于1.\n\n# 神经网络分类方法\n\n1. 多层反馈神经网络\n\n   输入同时赋给第一层(输入层)单元，这些单元输出赋予权重，输出给第二层(隐藏层)。\n\n   隐藏层的带权输出又作为输入再馈给另一隐层。\n\n   最后的隐层结点带权输出馈给输出层单元，最终给出相应样本的预测输出。\n\n   该网络是前馈的，即每一个反馈只能发送到前面的输出层或隐含层。\n\n   它也是全连接的，即每一个层中单元均与前面一层的各单元相连接。\n\n   只要中间隐层足够多的话，多层前馈网络中的线性阈值函数，可以充分逼近任何函数。\n\n2. 神经网络结构\n\n   确定结构，即：\n\n   - 输入层的单元数\n   - 隐含层的个数(和层数)\n   - 每个隐含层的单元数目\n   - 输出层单元数目\n\n   对输入值规格化，一般取值在0～1.\n\n   离散数据可以为每一个取值增加一个节点进行编码。例如A={a0,a1,a2}则我们设立三个输入单元I0, I1, I2，每个单元默认为0，若A=a0，则I1置为1.\n\n   此外没有什么特定的规律或规则来指导隐含层的最佳单元数量，它的确定是一个不断试错的过程。\n\n3. 后传方法\n\n   后传方法不断地处理一个训练样本集。将处理结果与训练样本已知类别比较所获误差，修改权重，使网络输出与实际类别之间的均方差最小。权重的修改是后传的，即从前向后的。\n\n   其收敛性不能保证。\n\n   流程(伪代码)：\n\n   ```python\n   # 定义sum函数，以变量x对f(x)求和\n   def sum(f(x), x):\n       pass\n\n   # 初始化\n   init();\n\n   while !conditions:           # 条件不满足时\n       for X in samples:\n           for each layer:      # 每个隐含层和输出层\n               O[j] = 1 / (1 + exp( - I[j]))\n               I[j] = sum(w[i][j]O[i], i) + theta[j]\n           for each unit of output layer as j:    # 每个输出层单元j，计算向后传播误差\n               Err[j] = O[j] * (1 - O[j]) * (T[j] - O[j])\n           for each unit of hidden layer as j:    # 每个隐含层单元j，从最后一层到第一层隐含层\n               Err[j] = O[j] * (1 - O[j]) * sum(Err[k] * w[i][j][k], k)\n           for each w[i][j] in the network:       # network中的权重wij\n               delta_w[i][j] = (l) * Err[j] * O[i]     # (l)是学习速率，取值在0～1\n               w[i][j] += delta_w[i][j]\n           for each theta[j] in the network:      # network中的偏差thetaij\n               delta_theta[j] = (l) * Err[j]\n               v[i] = theta[j] + delta_theta[j]\n           \n   ```\n\n   看伪代码基本就能明白它的过程了。虽然伪代码可能写的比较迷。。。\n\n# 基于关联的分类方法\n\n略，后面会详细说。\n\n# 其他分类\n\n其他分类我也没有细看，纪录一下名字，以后有时间再看。\n\n1. k-最邻近方法\n\n   这个很简单，就是比较两个点的欧式距离。比较基本的分类方法，略。\n\n2. 基于示例推理\n\n3. 遗传算法\n\n4. 粗糙集方法\n\n5. 模糊集合方法\n\n# 预测方法\n\n1. 线形与多变量回归\n\n   线性代数、概率统计、数值计算方法里都学过。核心是利用最小二乘法。\n\n2. 非线性回归\n\n   例如多项式回归\n   $$\n   Y = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3\n   $$\n   为了将其转化为线性形式，令：\n   $$\n   X_1 = X;X_2 = X^2 ; X_3 = X^3\n   $$\n   接下来就用最小二乘法即可。\n\n3. 其他回归模型\n\n   对数回归、泊松回归等\n\n# 分类器准确性\n\n分层k次交叉验证方法普遍应用于对分类器预测准确性的评估方面。而bagging方法和boosting方法则通过学习和组合多个(单)分类器来帮助提高整个(数据训练样本所获)分类器的预测准确性。","source":"_posts/datamining-class-pred.md","raw":"---\ntitle: 数据挖掘-分类与预测\ndate: 2016-12-26 14:56:57\ncategories: [programming]\ntags: [datamining, programming, classification, prediction]\n---\n\n# 基本知识\n\n主要分为两个步骤：\n\n1. 建立一个描述已知数据集类别或概念的模型。\n\n   分类规则形式、决策树形式，或数学公式形式。\n\n2. 利用所获得的模型进行分类操作。\n\n   首先要对模型分类准确率进行估计。\n\n   若其准确率可以接受，则可以使用该模型进行分类。   \t\n\n可以根据以下几条标准对各种分类方法进行比较:\n\n1. 预测准确率，它描述(学习所获)模型能够正确预测未知对象类别或(类别)数值的能力。\n2. 速度，它描述在构造和使用模型时的计算效率。 \n3. 鲁棒性，它描述在数据带有噪声和有数据遗失情况下，(学习所获)模型仍能进行正确预测的能力。 \n4. 可扩展性，它描述对处理大量数据并构造相应学习模型所需要的能力。\n5. 易理解性，它描述学习所获模型表示的可理解程度。 在本章的后面各节，将要陆续介绍上述有关问题的实现方法。\n\n# 基于决策树的分类\n\n1. 决策树的生成算法\n\n   - 基本决策树算法\n\n     本质是一个贪心算法，自上而下分而治之。\n\n2. 属性选择方法\n\n   信息量\n   $$\n   I(s_1,…,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}\n   $$\n   利用属性A划分当前样本集合所需要的信息可以计算：\n   $$\n   E(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,…,s_m) }\n   $$\n   E(A)的值越小，说明其子集划分结果越纯，即越好。而对于一个子集Sj，它的信息为\n   $$\n   I(s_{1j},…,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}\n   $$\n   这样利用属性A对当前分支结点进行相应样本集合划分所获得的信息增益是:\n   $$\n   Gain(A) =I(s_1,…,s_m)- E(A)\n   $$\n   也就是说Gain(A)被认为是利用属性A进行划分后，所获的的信息熵的减少量。\n\n   决策树归纳算法计算每个属性的Gain，选择信息增益最大的属性，作为测试属性并由此产生相应的分支节点。\n\n3. 树枝的修剪\n\n   1. 事前修剪\n\n      基本原理是设置一个阀值，当某一节点的的样本数少于阀值，则停止细分。难点在于设置一个合理的阀值。\n\n   2. 事后修剪\n\n      从一个充分生长的树中修建。\n\n      可以使用基于代价成本的方法，也可以使用最短描述长度(MDL)。\n\n      前者计算其分类错误率，若修剪枝导致分类错误率变高，则保留，否则剪枝；后者选择最简单的，无需独立的数据测试\n\n4. 规则获取\n\n   在已经获得了一个决策树的基础上，可以使用\"if...else...\"语句描述该决策树。\n\n5. 基本决策树方法改进及其扩展性\n\n#  贝叶斯分类方法\n\n贝叶斯分类器是一个统计分类器，基于贝叶斯定理。\n\n简单贝叶斯分类器的分类性能可以与决策树和神经网络相比。\n\n简单贝叶斯分类器假设一个指定类别中各属性的取值是互相独立的，它可以帮助减少计算量。\n\n1. 贝叶斯定理\n\n   设X为一个类别未知的数据样本，H为某个假设，则：\n   $$\n   P(H|X) = \\frac{P(X|H)P(H)}{P(X)}\n   $$\n\n2. 简单贝叶斯分类方法\n\n   步骤说明如下：\n\n   1. 每一个数据都是有一个n维特征向量X={x1,…,xn}构成，分别描述其n个属性(A1,…,An)。\n\n   2. 若有m个不同的类别(C1,…,Cm)，分类器将未知X归属到类别Ci，当仅当\n      $$\n      P(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)\n      $$\n      所以我们要找到最大的\n      $$\n      P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}\n      $$\n\n   3. 要找到它，只需要P(X|Ci)P(Ci)取最大即可。由于各类别的事前概率是未知的，我们假设P(Ci)是互相相等的，这样，第二步中的式子取最大就转化为了寻找最大的P(X|Ci)\n\n   4. 由于所含的属性比较多，直接计算P(X|Ci)的计算量还是很大的。由于简单贝叶斯分类器假设各属性独立，则：\n      $$\n      P(X|C_i) = \\prod{P(x_k|C_i)}\n      $$\n      可以根据训练数据样本估算P(xk|Ci)的值。具体如下：\n\n      - 若Ak是符号量\n        $$\n        P(x_k|Ci)=\\frac{s_{ik}}{s_i}\n        $$\n        这里sik为训练样本中类别为Ci且属性Ak取vk的样本数。si为训练样本中类别为Ci的样本数。\n\n      - 若Ak是连续量\n        $$\n        P(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}\n        $$\n        其中$g(x_k,\\mu_{C_i},\\sigma_{C_i})$ï为属性为Ak的高斯规范密度函数。\n\n   5. 为了预测X的分类，我们通过上述方法估计各个类别的正确率，将X归属到可能性最高的类别。\n\n3. 贝叶斯信念网络\n\n   简单贝叶斯假设属性相互独立，从而简化计算，而实际上属性相互依赖的情况比较常见，所以又出现了贝叶斯信念网络，用于描述这种相互关联的概率分布。\n\n   贝叶斯信念网络提供了一个图形模型来描述其中的因果关系。信念网络包括两个部分。\n\n   - 第一部分是有向无环图\n\n     每一个节点代表随机变量。\n\n     每一条弧代表一个概率依赖。\n\n     给定父节点，每个变量有条件的独立于图中非子节点。\n\n   - 第二部分是包含所有变量的条件概率表(CPT)\n\n     对于一个变量Z，CPT定义了P(Z|parent(Z))，由此可以得到一个表。\n\n     例如，LunCancer的父节点是FamilyHistory和Smoker，\n\n|             | FH, S | FH, ~S | ~FH, S | ~FH, ~S |\n| ----------- | ----- | ------ | ------ | ------- |\n| LungCancer  | 0.8   | 0.5    | 0.7    | 0.1     |\n| ~LungCancer | 0.2   | 0.5    | 0.3    | 0.9     |\n\n\n数据对象的联合概率通过如下公式计算。\n$$\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}\n$$\n\n4. 贝叶斯信念网络的学习\n\n   学习算法步骤如下：\n\n   1. 计算下降梯度\n      $$\n      \\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}\n      $$\n      ​\n      左边是计算训练集合S中每个样本Xd的概率。设这一概率为p。\n\n      由Yi和Ui表示隐含变量，p可通过样本中可观察到的变量以及标准贝叶斯网络推理计算得到。\n\n   2. 沿梯度方向前进一小步，权重更新计算如下\n      $$\n      w_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}\n      $$\n      l为学习速率代表学习步长。通常学习速率为较小的常数。\n\n   3. 重新规格化权重\n\n      保证wijk的取值在0～1，其和等于1.\n\n# 神经网络分类方法\n\n1. 多层反馈神经网络\n\n   输入同时赋给第一层(输入层)单元，这些单元输出赋予权重，输出给第二层(隐藏层)。\n\n   隐藏层的带权输出又作为输入再馈给另一隐层。\n\n   最后的隐层结点带权输出馈给输出层单元，最终给出相应样本的预测输出。\n\n   该网络是前馈的，即每一个反馈只能发送到前面的输出层或隐含层。\n\n   它也是全连接的，即每一个层中单元均与前面一层的各单元相连接。\n\n   只要中间隐层足够多的话，多层前馈网络中的线性阈值函数，可以充分逼近任何函数。\n\n2. 神经网络结构\n\n   确定结构，即：\n\n   - 输入层的单元数\n   - 隐含层的个数(和层数)\n   - 每个隐含层的单元数目\n   - 输出层单元数目\n\n   对输入值规格化，一般取值在0～1.\n\n   离散数据可以为每一个取值增加一个节点进行编码。例如A={a0,a1,a2}则我们设立三个输入单元I0, I1, I2，每个单元默认为0，若A=a0，则I1置为1.\n\n   此外没有什么特定的规律或规则来指导隐含层的最佳单元数量，它的确定是一个不断试错的过程。\n\n3. 后传方法\n\n   后传方法不断地处理一个训练样本集。将处理结果与训练样本已知类别比较所获误差，修改权重，使网络输出与实际类别之间的均方差最小。权重的修改是后传的，即从前向后的。\n\n   其收敛性不能保证。\n\n   流程(伪代码)：\n\n   ```python\n   # 定义sum函数，以变量x对f(x)求和\n   def sum(f(x), x):\n       pass\n\n   # 初始化\n   init();\n\n   while !conditions:           # 条件不满足时\n       for X in samples:\n           for each layer:      # 每个隐含层和输出层\n               O[j] = 1 / (1 + exp( - I[j]))\n               I[j] = sum(w[i][j]O[i], i) + theta[j]\n           for each unit of output layer as j:    # 每个输出层单元j，计算向后传播误差\n               Err[j] = O[j] * (1 - O[j]) * (T[j] - O[j])\n           for each unit of hidden layer as j:    # 每个隐含层单元j，从最后一层到第一层隐含层\n               Err[j] = O[j] * (1 - O[j]) * sum(Err[k] * w[i][j][k], k)\n           for each w[i][j] in the network:       # network中的权重wij\n               delta_w[i][j] = (l) * Err[j] * O[i]     # (l)是学习速率，取值在0～1\n               w[i][j] += delta_w[i][j]\n           for each theta[j] in the network:      # network中的偏差thetaij\n               delta_theta[j] = (l) * Err[j]\n               v[i] = theta[j] + delta_theta[j]\n           \n   ```\n\n   看伪代码基本就能明白它的过程了。虽然伪代码可能写的比较迷。。。\n\n# 基于关联的分类方法\n\n略，后面会详细说。\n\n# 其他分类\n\n其他分类我也没有细看，纪录一下名字，以后有时间再看。\n\n1. k-最邻近方法\n\n   这个很简单，就是比较两个点的欧式距离。比较基本的分类方法，略。\n\n2. 基于示例推理\n\n3. 遗传算法\n\n4. 粗糙集方法\n\n5. 模糊集合方法\n\n# 预测方法\n\n1. 线形与多变量回归\n\n   线性代数、概率统计、数值计算方法里都学过。核心是利用最小二乘法。\n\n2. 非线性回归\n\n   例如多项式回归\n   $$\n   Y = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3\n   $$\n   为了将其转化为线性形式，令：\n   $$\n   X_1 = X;X_2 = X^2 ; X_3 = X^3\n   $$\n   接下来就用最小二乘法即可。\n\n3. 其他回归模型\n\n   对数回归、泊松回归等\n\n# 分类器准确性\n\n分层k次交叉验证方法普遍应用于对分类器预测准确性的评估方面。而bagging方法和boosting方法则通过学习和组合多个(单)分类器来帮助提高整个(数据训练样本所获)分类器的预测准确性。","slug":"datamining-class-pred","published":1,"updated":"2016-12-26T15:52:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhr0016zemmdnt8olms","content":"<h1 id=\"基本知识\"><a href=\"#基本知识\" class=\"headerlink\" title=\"基本知识\"></a>基本知识</h1><p>主要分为两个步骤：</p>\n<ol>\n<li><p>建立一个描述已知数据集类别或概念的模型。</p>\n<p>分类规则形式、决策树形式，或数学公式形式。</p>\n</li>\n<li><p>利用所获得的模型进行分类操作。</p>\n<p>首先要对模型分类准确率进行估计。</p>\n<p>若其准确率可以接受，则可以使用该模型进行分类。       </p>\n</li>\n</ol>\n<p>可以根据以下几条标准对各种分类方法进行比较:</p>\n<ol>\n<li>预测准确率，它描述(学习所获)模型能够正确预测未知对象类别或(类别)数值的能力。</li>\n<li>速度，它描述在构造和使用模型时的计算效率。 </li>\n<li>鲁棒性，它描述在数据带有噪声和有数据遗失情况下，(学习所获)模型仍能进行正确预测的能力。 </li>\n<li>可扩展性，它描述对处理大量数据并构造相应学习模型所需要的能力。</li>\n<li>易理解性，它描述学习所获模型表示的可理解程度。 在本章的后面各节，将要陆续介绍上述有关问题的实现方法。</li>\n</ol>\n<h1 id=\"基于决策树的分类\"><a href=\"#基于决策树的分类\" class=\"headerlink\" title=\"基于决策树的分类\"></a>基于决策树的分类</h1><ol>\n<li><p>决策树的生成算法</p>\n<ul>\n<li><p>基本决策树算法</p>\n<p>本质是一个贪心算法，自上而下分而治之。</p>\n</li>\n</ul>\n</li>\n<li><p>属性选择方法</p>\n<p>信息量</p>\n<script type=\"math/tex; mode=display\">\nI(s_1,…,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}</script><p>利用属性A划分当前样本集合所需要的信息可以计算：</p>\n<script type=\"math/tex; mode=display\">\nE(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,…,s_m) }</script><p>E(A)的值越小，说明其子集划分结果越纯，即越好。而对于一个子集Sj，它的信息为</p>\n<script type=\"math/tex; mode=display\">\nI(s_{1j},…,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}</script><p>这样利用属性A对当前分支结点进行相应样本集合划分所获得的信息增益是:</p>\n<script type=\"math/tex; mode=display\">\nGain(A) =I(s_1,…,s_m)- E(A)</script><p>也就是说Gain(A)被认为是利用属性A进行划分后，所获的的信息熵的减少量。</p>\n<p>决策树归纳算法计算每个属性的Gain，选择信息增益最大的属性，作为测试属性并由此产生相应的分支节点。</p>\n</li>\n<li><p>树枝的修剪</p>\n<ol>\n<li><p>事前修剪</p>\n<p>基本原理是设置一个阀值，当某一节点的的样本数少于阀值，则停止细分。难点在于设置一个合理的阀值。</p>\n</li>\n<li><p>事后修剪</p>\n<p>从一个充分生长的树中修建。</p>\n<p>可以使用基于代价成本的方法，也可以使用最短描述长度(MDL)。</p>\n<p>前者计算其分类错误率，若修剪枝导致分类错误率变高，则保留，否则剪枝；后者选择最简单的，无需独立的数据测试</p>\n</li>\n</ol>\n</li>\n<li><p>规则获取</p>\n<p>在已经获得了一个决策树的基础上，可以使用”if…else…”语句描述该决策树。</p>\n</li>\n<li><p>基本决策树方法改进及其扩展性</p>\n</li>\n</ol>\n<h1 id=\"贝叶斯分类方法\"><a href=\"#贝叶斯分类方法\" class=\"headerlink\" title=\"贝叶斯分类方法\"></a>贝叶斯分类方法</h1><p>贝叶斯分类器是一个统计分类器，基于贝叶斯定理。</p>\n<p>简单贝叶斯分类器的分类性能可以与决策树和神经网络相比。</p>\n<p>简单贝叶斯分类器假设一个指定类别中各属性的取值是互相独立的，它可以帮助减少计算量。</p>\n<ol>\n<li><p>贝叶斯定理</p>\n<p>设X为一个类别未知的数据样本，H为某个假设，则：</p>\n<script type=\"math/tex; mode=display\">\nP(H|X) = \\frac{P(X|H)P(H)}{P(X)}</script></li>\n<li><p>简单贝叶斯分类方法</p>\n<p>步骤说明如下：</p>\n<ol>\n<li><p>每一个数据都是有一个n维特征向量X={x1,…,xn}构成，分别描述其n个属性(A1,…,An)。</p>\n</li>\n<li><p>若有m个不同的类别(C1,…,Cm)，分类器将未知X归属到类别Ci，当仅当</p>\n<script type=\"math/tex; mode=display\">\nP(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)</script><p>所以我们要找到最大的</p>\n<script type=\"math/tex; mode=display\">\nP(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}</script></li>\n<li><p>要找到它，只需要P(X|Ci)P(Ci)取最大即可。由于各类别的事前概率是未知的，我们假设P(Ci)是互相相等的，这样，第二步中的式子取最大就转化为了寻找最大的P(X|Ci)</p>\n</li>\n<li><p>由于所含的属性比较多，直接计算P(X|Ci)的计算量还是很大的。由于简单贝叶斯分类器假设各属性独立，则：</p>\n<script type=\"math/tex; mode=display\">\nP(X|C_i) = \\prod{P(x_k|C_i)}</script><p>可以根据训练数据样本估算P(xk|Ci)的值。具体如下：</p>\n<ul>\n<li><p>若Ak是符号量</p>\n<script type=\"math/tex; mode=display\">\nP(x_k|Ci)=\\frac{s_{ik}}{s_i}</script><p>这里sik为训练样本中类别为Ci且属性Ak取vk的样本数。si为训练样本中类别为Ci的样本数。</p>\n</li>\n<li><p>若Ak是连续量</p>\n<script type=\"math/tex; mode=display\">\nP(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}</script><p>其中$g(x<em>k,\\mu</em>{C<em>i},\\sigma</em>{C_i})$ï为属性为Ak的高斯规范密度函数。</p>\n</li>\n</ul>\n</li>\n<li><p>为了预测X的分类，我们通过上述方法估计各个类别的正确率，将X归属到可能性最高的类别。</p>\n</li>\n</ol>\n</li>\n<li><p>贝叶斯信念网络</p>\n<p>简单贝叶斯假设属性相互独立，从而简化计算，而实际上属性相互依赖的情况比较常见，所以又出现了贝叶斯信念网络，用于描述这种相互关联的概率分布。</p>\n<p>贝叶斯信念网络提供了一个图形模型来描述其中的因果关系。信念网络包括两个部分。</p>\n<ul>\n<li><p>第一部分是有向无环图</p>\n<p>每一个节点代表随机变量。</p>\n<p>每一条弧代表一个概率依赖。</p>\n<p>给定父节点，每个变量有条件的独立于图中非子节点。</p>\n</li>\n<li><p>第二部分是包含所有变量的条件概率表(CPT)</p>\n<p>对于一个变量Z，CPT定义了P(Z|parent(Z))，由此可以得到一个表。</p>\n<p>例如，LunCancer的父节点是FamilyHistory和Smoker，</p>\n</li>\n</ul>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>FH, S</th>\n<th>FH, ~S</th>\n<th>~FH, S</th>\n<th>~FH, ~S</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>LungCancer</td>\n<td>0.8</td>\n<td>0.5</td>\n<td>0.7</td>\n<td>0.1</td>\n</tr>\n<tr>\n<td>~LungCancer</td>\n<td>0.2</td>\n<td>0.5</td>\n<td>0.3</td>\n<td>0.9</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>数据对象的联合概率通过如下公式计算。</p>\n<script type=\"math/tex; mode=display\">\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}</script><ol>\n<li><p>贝叶斯信念网络的学习</p>\n<p>学习算法步骤如下：</p>\n<ol>\n<li><p>计算下降梯度</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}</script><p>​<br>左边是计算训练集合S中每个样本Xd的概率。设这一概率为p。</p>\n<p>由Yi和Ui表示隐含变量，p可通过样本中可观察到的变量以及标准贝叶斯网络推理计算得到。</p>\n</li>\n<li><p>沿梯度方向前进一小步，权重更新计算如下</p>\n<script type=\"math/tex; mode=display\">\nw_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}</script><p>l为学习速率代表学习步长。通常学习速率为较小的常数。</p>\n</li>\n<li><p>重新规格化权重</p>\n<p>保证wijk的取值在0～1，其和等于1.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"神经网络分类方法\"><a href=\"#神经网络分类方法\" class=\"headerlink\" title=\"神经网络分类方法\"></a>神经网络分类方法</h1><ol>\n<li><p>多层反馈神经网络</p>\n<p>输入同时赋给第一层(输入层)单元，这些单元输出赋予权重，输出给第二层(隐藏层)。</p>\n<p>隐藏层的带权输出又作为输入再馈给另一隐层。</p>\n<p>最后的隐层结点带权输出馈给输出层单元，最终给出相应样本的预测输出。</p>\n<p>该网络是前馈的，即每一个反馈只能发送到前面的输出层或隐含层。</p>\n<p>它也是全连接的，即每一个层中单元均与前面一层的各单元相连接。</p>\n<p>只要中间隐层足够多的话，多层前馈网络中的线性阈值函数，可以充分逼近任何函数。</p>\n</li>\n<li><p>神经网络结构</p>\n<p>确定结构，即：</p>\n<ul>\n<li>输入层的单元数</li>\n<li>隐含层的个数(和层数)</li>\n<li>每个隐含层的单元数目</li>\n<li>输出层单元数目</li>\n</ul>\n<p>对输入值规格化，一般取值在0～1.</p>\n<p>离散数据可以为每一个取值增加一个节点进行编码。例如A={a0,a1,a2}则我们设立三个输入单元I0, I1, I2，每个单元默认为0，若A=a0，则I1置为1.</p>\n<p>此外没有什么特定的规律或规则来指导隐含层的最佳单元数量，它的确定是一个不断试错的过程。</p>\n</li>\n<li><p>后传方法</p>\n<p>后传方法不断地处理一个训练样本集。将处理结果与训练样本已知类别比较所获误差，修改权重，使网络输出与实际类别之间的均方差最小。权重的修改是后传的，即从前向后的。</p>\n<p>其收敛性不能保证。</p>\n<p>流程(伪代码)：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 定义sum函数，以变量x对f(x)求和</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sum</span><span class=\"params\">(f<span class=\"params\">(x)</span>, x)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 初始化</span></div><div class=\"line\">init();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span> !conditions:           <span class=\"comment\"># 条件不满足时</span></div><div class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> samples:</div><div class=\"line\">        <span class=\"keyword\">for</span> each layer:      <span class=\"comment\"># 每个隐含层和输出层</span></div><div class=\"line\">            O[j] = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + exp( - I[j]))</div><div class=\"line\">            I[j] = sum(w[i][j]O[i], i) + theta[j]</div><div class=\"line\">        <span class=\"keyword\">for</span> each unit of output layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># 每个输出层单元j，计算向后传播误差</span></div><div class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * (T[j] - O[j])</div><div class=\"line\">        <span class=\"keyword\">for</span> each unit of hidden layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># 每个隐含层单元j，从最后一层到第一层隐含层</span></div><div class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * sum(Err[k] * w[i][j][k], k)</div><div class=\"line\">        <span class=\"keyword\">for</span> each w[i][j] <span class=\"keyword\">in</span> the network:       <span class=\"comment\"># network中的权重wij</span></div><div class=\"line\">            delta_w[i][j] = (l) * Err[j] * O[i]     <span class=\"comment\"># (l)是学习速率，取值在0～1</span></div><div class=\"line\">            w[i][j] += delta_w[i][j]</div><div class=\"line\">        <span class=\"keyword\">for</span> each theta[j] <span class=\"keyword\">in</span> the network:      <span class=\"comment\"># network中的偏差thetaij</span></div><div class=\"line\">            delta_theta[j] = (l) * Err[j]</div><div class=\"line\">            v[i] = theta[j] + delta_theta[j]</div></pre></td></tr></table></figure>\n<p>看伪代码基本就能明白它的过程了。虽然伪代码可能写的比较迷。。。</p>\n</li>\n</ol>\n<h1 id=\"基于关联的分类方法\"><a href=\"#基于关联的分类方法\" class=\"headerlink\" title=\"基于关联的分类方法\"></a>基于关联的分类方法</h1><p>略，后面会详细说。</p>\n<h1 id=\"其他分类\"><a href=\"#其他分类\" class=\"headerlink\" title=\"其他分类\"></a>其他分类</h1><p>其他分类我也没有细看，纪录一下名字，以后有时间再看。</p>\n<ol>\n<li><p>k-最邻近方法</p>\n<p>这个很简单，就是比较两个点的欧式距离。比较基本的分类方法，略。</p>\n</li>\n<li><p>基于示例推理</p>\n</li>\n<li><p>遗传算法</p>\n</li>\n<li><p>粗糙集方法</p>\n</li>\n<li><p>模糊集合方法</p>\n</li>\n</ol>\n<h1 id=\"预测方法\"><a href=\"#预测方法\" class=\"headerlink\" title=\"预测方法\"></a>预测方法</h1><ol>\n<li><p>线形与多变量回归</p>\n<p>线性代数、概率统计、数值计算方法里都学过。核心是利用最小二乘法。</p>\n</li>\n<li><p>非线性回归</p>\n<p>例如多项式回归</p>\n<script type=\"math/tex; mode=display\">\nY = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3</script><p>为了将其转化为线性形式，令：</p>\n<script type=\"math/tex; mode=display\">\nX_1 = X;X_2 = X^2 ; X_3 = X^3</script><p>接下来就用最小二乘法即可。</p>\n</li>\n<li><p>其他回归模型</p>\n<p>对数回归、泊松回归等</p>\n</li>\n</ol>\n<h1 id=\"分类器准确性\"><a href=\"#分类器准确性\" class=\"headerlink\" title=\"分类器准确性\"></a>分类器准确性</h1><p>分层k次交叉验证方法普遍应用于对分类器预测准确性的评估方面。而bagging方法和boosting方法则通过学习和组合多个(单)分类器来帮助提高整个(数据训练样本所获)分类器的预测准确性。</p>\n","excerpt":"","more":"<h1 id=\"基本知识\"><a href=\"#基本知识\" class=\"headerlink\" title=\"基本知识\"></a>基本知识</h1><p>主要分为两个步骤：</p>\n<ol>\n<li><p>建立一个描述已知数据集类别或概念的模型。</p>\n<p>分类规则形式、决策树形式，或数学公式形式。</p>\n</li>\n<li><p>利用所获得的模型进行分类操作。</p>\n<p>首先要对模型分类准确率进行估计。</p>\n<p>若其准确率可以接受，则可以使用该模型进行分类。       </p>\n</li>\n</ol>\n<p>可以根据以下几条标准对各种分类方法进行比较:</p>\n<ol>\n<li>预测准确率，它描述(学习所获)模型能够正确预测未知对象类别或(类别)数值的能力。</li>\n<li>速度，它描述在构造和使用模型时的计算效率。 </li>\n<li>鲁棒性，它描述在数据带有噪声和有数据遗失情况下，(学习所获)模型仍能进行正确预测的能力。 </li>\n<li>可扩展性，它描述对处理大量数据并构造相应学习模型所需要的能力。</li>\n<li>易理解性，它描述学习所获模型表示的可理解程度。 在本章的后面各节，将要陆续介绍上述有关问题的实现方法。</li>\n</ol>\n<h1 id=\"基于决策树的分类\"><a href=\"#基于决策树的分类\" class=\"headerlink\" title=\"基于决策树的分类\"></a>基于决策树的分类</h1><ol>\n<li><p>决策树的生成算法</p>\n<ul>\n<li><p>基本决策树算法</p>\n<p>本质是一个贪心算法，自上而下分而治之。</p>\n</li>\n</ul>\n</li>\n<li><p>属性选择方法</p>\n<p>信息量</p>\n<script type=\"math/tex; mode=display\">\nI(s_1,…,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}</script><p>利用属性A划分当前样本集合所需要的信息可以计算：</p>\n<script type=\"math/tex; mode=display\">\nE(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,…,s_m) }</script><p>E(A)的值越小，说明其子集划分结果越纯，即越好。而对于一个子集Sj，它的信息为</p>\n<script type=\"math/tex; mode=display\">\nI(s_{1j},…,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}</script><p>这样利用属性A对当前分支结点进行相应样本集合划分所获得的信息增益是:</p>\n<script type=\"math/tex; mode=display\">\nGain(A) =I(s_1,…,s_m)- E(A)</script><p>也就是说Gain(A)被认为是利用属性A进行划分后，所获的的信息熵的减少量。</p>\n<p>决策树归纳算法计算每个属性的Gain，选择信息增益最大的属性，作为测试属性并由此产生相应的分支节点。</p>\n</li>\n<li><p>树枝的修剪</p>\n<ol>\n<li><p>事前修剪</p>\n<p>基本原理是设置一个阀值，当某一节点的的样本数少于阀值，则停止细分。难点在于设置一个合理的阀值。</p>\n</li>\n<li><p>事后修剪</p>\n<p>从一个充分生长的树中修建。</p>\n<p>可以使用基于代价成本的方法，也可以使用最短描述长度(MDL)。</p>\n<p>前者计算其分类错误率，若修剪枝导致分类错误率变高，则保留，否则剪枝；后者选择最简单的，无需独立的数据测试</p>\n</li>\n</ol>\n</li>\n<li><p>规则获取</p>\n<p>在已经获得了一个决策树的基础上，可以使用”if…else…”语句描述该决策树。</p>\n</li>\n<li><p>基本决策树方法改进及其扩展性</p>\n</li>\n</ol>\n<h1 id=\"贝叶斯分类方法\"><a href=\"#贝叶斯分类方法\" class=\"headerlink\" title=\"贝叶斯分类方法\"></a>贝叶斯分类方法</h1><p>贝叶斯分类器是一个统计分类器，基于贝叶斯定理。</p>\n<p>简单贝叶斯分类器的分类性能可以与决策树和神经网络相比。</p>\n<p>简单贝叶斯分类器假设一个指定类别中各属性的取值是互相独立的，它可以帮助减少计算量。</p>\n<ol>\n<li><p>贝叶斯定理</p>\n<p>设X为一个类别未知的数据样本，H为某个假设，则：</p>\n<script type=\"math/tex; mode=display\">\nP(H|X) = \\frac{P(X|H)P(H)}{P(X)}</script></li>\n<li><p>简单贝叶斯分类方法</p>\n<p>步骤说明如下：</p>\n<ol>\n<li><p>每一个数据都是有一个n维特征向量X={x1,…,xn}构成，分别描述其n个属性(A1,…,An)。</p>\n</li>\n<li><p>若有m个不同的类别(C1,…,Cm)，分类器将未知X归属到类别Ci，当仅当</p>\n<script type=\"math/tex; mode=display\">\nP(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)</script><p>所以我们要找到最大的</p>\n<script type=\"math/tex; mode=display\">\nP(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}</script></li>\n<li><p>要找到它，只需要P(X|Ci)P(Ci)取最大即可。由于各类别的事前概率是未知的，我们假设P(Ci)是互相相等的，这样，第二步中的式子取最大就转化为了寻找最大的P(X|Ci)</p>\n</li>\n<li><p>由于所含的属性比较多，直接计算P(X|Ci)的计算量还是很大的。由于简单贝叶斯分类器假设各属性独立，则：</p>\n<script type=\"math/tex; mode=display\">\nP(X|C_i) = \\prod{P(x_k|C_i)}</script><p>可以根据训练数据样本估算P(xk|Ci)的值。具体如下：</p>\n<ul>\n<li><p>若Ak是符号量</p>\n<script type=\"math/tex; mode=display\">\nP(x_k|Ci)=\\frac{s_{ik}}{s_i}</script><p>这里sik为训练样本中类别为Ci且属性Ak取vk的样本数。si为训练样本中类别为Ci的样本数。</p>\n</li>\n<li><p>若Ak是连续量</p>\n<script type=\"math/tex; mode=display\">\nP(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}</script><p>其中$g(x<em>k,\\mu</em>{C<em>i},\\sigma</em>{C_i})$ï为属性为Ak的高斯规范密度函数。</p>\n</li>\n</ul>\n</li>\n<li><p>为了预测X的分类，我们通过上述方法估计各个类别的正确率，将X归属到可能性最高的类别。</p>\n</li>\n</ol>\n</li>\n<li><p>贝叶斯信念网络</p>\n<p>简单贝叶斯假设属性相互独立，从而简化计算，而实际上属性相互依赖的情况比较常见，所以又出现了贝叶斯信念网络，用于描述这种相互关联的概率分布。</p>\n<p>贝叶斯信念网络提供了一个图形模型来描述其中的因果关系。信念网络包括两个部分。</p>\n<ul>\n<li><p>第一部分是有向无环图</p>\n<p>每一个节点代表随机变量。</p>\n<p>每一条弧代表一个概率依赖。</p>\n<p>给定父节点，每个变量有条件的独立于图中非子节点。</p>\n</li>\n<li><p>第二部分是包含所有变量的条件概率表(CPT)</p>\n<p>对于一个变量Z，CPT定义了P(Z|parent(Z))，由此可以得到一个表。</p>\n<p>例如，LunCancer的父节点是FamilyHistory和Smoker，</p>\n</li>\n</ul>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th></th>\n<th>FH, S</th>\n<th>FH, ~S</th>\n<th>~FH, S</th>\n<th>~FH, ~S</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>LungCancer</td>\n<td>0.8</td>\n<td>0.5</td>\n<td>0.7</td>\n<td>0.1</td>\n</tr>\n<tr>\n<td>~LungCancer</td>\n<td>0.2</td>\n<td>0.5</td>\n<td>0.3</td>\n<td>0.9</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>数据对象的联合概率通过如下公式计算。</p>\n<script type=\"math/tex; mode=display\">\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}</script><ol>\n<li><p>贝叶斯信念网络的学习</p>\n<p>学习算法步骤如下：</p>\n<ol>\n<li><p>计算下降梯度</p>\n<script type=\"math/tex; mode=display\">\n\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}</script><p>​<br>左边是计算训练集合S中每个样本Xd的概率。设这一概率为p。</p>\n<p>由Yi和Ui表示隐含变量，p可通过样本中可观察到的变量以及标准贝叶斯网络推理计算得到。</p>\n</li>\n<li><p>沿梯度方向前进一小步，权重更新计算如下</p>\n<script type=\"math/tex; mode=display\">\nw_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}</script><p>l为学习速率代表学习步长。通常学习速率为较小的常数。</p>\n</li>\n<li><p>重新规格化权重</p>\n<p>保证wijk的取值在0～1，其和等于1.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"神经网络分类方法\"><a href=\"#神经网络分类方法\" class=\"headerlink\" title=\"神经网络分类方法\"></a>神经网络分类方法</h1><ol>\n<li><p>多层反馈神经网络</p>\n<p>输入同时赋给第一层(输入层)单元，这些单元输出赋予权重，输出给第二层(隐藏层)。</p>\n<p>隐藏层的带权输出又作为输入再馈给另一隐层。</p>\n<p>最后的隐层结点带权输出馈给输出层单元，最终给出相应样本的预测输出。</p>\n<p>该网络是前馈的，即每一个反馈只能发送到前面的输出层或隐含层。</p>\n<p>它也是全连接的，即每一个层中单元均与前面一层的各单元相连接。</p>\n<p>只要中间隐层足够多的话，多层前馈网络中的线性阈值函数，可以充分逼近任何函数。</p>\n</li>\n<li><p>神经网络结构</p>\n<p>确定结构，即：</p>\n<ul>\n<li>输入层的单元数</li>\n<li>隐含层的个数(和层数)</li>\n<li>每个隐含层的单元数目</li>\n<li>输出层单元数目</li>\n</ul>\n<p>对输入值规格化，一般取值在0～1.</p>\n<p>离散数据可以为每一个取值增加一个节点进行编码。例如A={a0,a1,a2}则我们设立三个输入单元I0, I1, I2，每个单元默认为0，若A=a0，则I1置为1.</p>\n<p>此外没有什么特定的规律或规则来指导隐含层的最佳单元数量，它的确定是一个不断试错的过程。</p>\n</li>\n<li><p>后传方法</p>\n<p>后传方法不断地处理一个训练样本集。将处理结果与训练样本已知类别比较所获误差，修改权重，使网络输出与实际类别之间的均方差最小。权重的修改是后传的，即从前向后的。</p>\n<p>其收敛性不能保证。</p>\n<p>流程(伪代码)：</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div><div class=\"line\">15</div><div class=\"line\">16</div><div class=\"line\">17</div><div class=\"line\">18</div><div class=\"line\">19</div><div class=\"line\">20</div><div class=\"line\">21</div><div class=\"line\">22</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"comment\"># 定义sum函数，以变量x对f(x)求和</span></div><div class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sum</span><span class=\"params\">(f<span class=\"params\">(x)</span>, x)</span>:</span></div><div class=\"line\">    <span class=\"keyword\">pass</span></div><div class=\"line\"></div><div class=\"line\"><span class=\"comment\"># 初始化</span></div><div class=\"line\">init();</div><div class=\"line\"></div><div class=\"line\"><span class=\"keyword\">while</span> !conditions:           <span class=\"comment\"># 条件不满足时</span></div><div class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> samples:</div><div class=\"line\">        <span class=\"keyword\">for</span> each layer:      <span class=\"comment\"># 每个隐含层和输出层</span></div><div class=\"line\">            O[j] = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + exp( - I[j]))</div><div class=\"line\">            I[j] = sum(w[i][j]O[i], i) + theta[j]</div><div class=\"line\">        <span class=\"keyword\">for</span> each unit of output layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># 每个输出层单元j，计算向后传播误差</span></div><div class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * (T[j] - O[j])</div><div class=\"line\">        <span class=\"keyword\">for</span> each unit of hidden layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># 每个隐含层单元j，从最后一层到第一层隐含层</span></div><div class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * sum(Err[k] * w[i][j][k], k)</div><div class=\"line\">        <span class=\"keyword\">for</span> each w[i][j] <span class=\"keyword\">in</span> the network:       <span class=\"comment\"># network中的权重wij</span></div><div class=\"line\">            delta_w[i][j] = (l) * Err[j] * O[i]     <span class=\"comment\"># (l)是学习速率，取值在0～1</span></div><div class=\"line\">            w[i][j] += delta_w[i][j]</div><div class=\"line\">        <span class=\"keyword\">for</span> each theta[j] <span class=\"keyword\">in</span> the network:      <span class=\"comment\"># network中的偏差thetaij</span></div><div class=\"line\">            delta_theta[j] = (l) * Err[j]</div><div class=\"line\">            v[i] = theta[j] + delta_theta[j]</div></pre></td></tr></table></figure>\n<p>看伪代码基本就能明白它的过程了。虽然伪代码可能写的比较迷。。。</p>\n</li>\n</ol>\n<h1 id=\"基于关联的分类方法\"><a href=\"#基于关联的分类方法\" class=\"headerlink\" title=\"基于关联的分类方法\"></a>基于关联的分类方法</h1><p>略，后面会详细说。</p>\n<h1 id=\"其他分类\"><a href=\"#其他分类\" class=\"headerlink\" title=\"其他分类\"></a>其他分类</h1><p>其他分类我也没有细看，纪录一下名字，以后有时间再看。</p>\n<ol>\n<li><p>k-最邻近方法</p>\n<p>这个很简单，就是比较两个点的欧式距离。比较基本的分类方法，略。</p>\n</li>\n<li><p>基于示例推理</p>\n</li>\n<li><p>遗传算法</p>\n</li>\n<li><p>粗糙集方法</p>\n</li>\n<li><p>模糊集合方法</p>\n</li>\n</ol>\n<h1 id=\"预测方法\"><a href=\"#预测方法\" class=\"headerlink\" title=\"预测方法\"></a>预测方法</h1><ol>\n<li><p>线形与多变量回归</p>\n<p>线性代数、概率统计、数值计算方法里都学过。核心是利用最小二乘法。</p>\n</li>\n<li><p>非线性回归</p>\n<p>例如多项式回归</p>\n<script type=\"math/tex; mode=display\">\nY = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3</script><p>为了将其转化为线性形式，令：</p>\n<script type=\"math/tex; mode=display\">\nX_1 = X;X_2 = X^2 ; X_3 = X^3</script><p>接下来就用最小二乘法即可。</p>\n</li>\n<li><p>其他回归模型</p>\n<p>对数回归、泊松回归等</p>\n</li>\n</ol>\n<h1 id=\"分类器准确性\"><a href=\"#分类器准确性\" class=\"headerlink\" title=\"分类器准确性\"></a>分类器准确性</h1><p>分层k次交叉验证方法普遍应用于对分类器预测准确性的评估方面。而bagging方法和boosting方法则通过学习和组合多个(单)分类器来帮助提高整个(数据训练样本所获)分类器的预测准确性。</p>\n"},{"title":"数据挖掘-预处理","date":"2016-12-06T21:05:57.000Z","_content":"\n由于数据的快速膨胀，我们获得的数据往往带有大量的噪声，所以我们需要对其进行一定的预处理。\n\n主要包括数据清洗、数据集成、 数据转换和数据消减。\n\n- 数据清洗\n\n  填补遗漏的数据值、平滑有噪声数据、识别或除去异常值，以及解决不一致问题。\n\n- 数据集成\n\n  将来自多个数据源的数据合并到一起。\n\n- 数据转换\n\n  主要是对数据进行规格化操作。\n\n- 数据消减\n\n  缩小所挖掘数据的规模，但却不会影响(或基本不影响)最终的挖掘结果。\n\n  - 数据聚合\n  - 消减维数\n  - 数据压缩\n  - 数据块消减\n\n# 数据清洗\n\n1. 处理空数据\n   - 忽略该数据\n   - 手工填补\n   - 利用缺省填补\n   - 利用均值填补\n   - 利用同类别均值\n   - 利用最可能的值\n     - 回归分析\n     - 贝叶斯计算公式\n\n   ​最后一种是最常用的。\n\n2. 噪声处理\n\n   - Bin方法 — 排序，分组，平滑处理（分组取均值、按边界等）\n   - 聚类方法\n   - 人机结合检查方法\n   - 回归方法 — 借助回归曲线\n\n\n# 数据的集成与转换\n\n1. 数据的集成处理\n\n   几个问题：\n\n   - 模式集成，例如：\"custom_id\", \"cum_num\" 是不是同一个模式？\n\n   - 冗余问题，若一个属性能从其他属性推算出来，那么它是冗余的。\n\n     我们可以通过相关系数的推算来确定：\n     $$\n     r_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}\n     $$\n\n   - 数据值冲突检测与消除，比如单位不同，语意偏差。\n\n2. 数据的转化处理\n\n   1. 平滑处理，bin、聚类、回归\n\n   2. 合计处理，对数据进行总结合计操作。\n\n   3. 数据泛化处理，例如：年龄映射到老年、中老年、青年等。\n\n   4. 规格化，例如：将成绩(可能总分是10分、20分或100分)折算成4分制绩点。\n\n      - 最大最小规格化方法 — 一种线性规格化，绩点的处理属于这种\n\n      - 零均值规格化方法\n        $$\n        v' = \\frac{v - \\bar{v}}{\\sigma}\n        $$\n\n      - 十基数变换规格化方法\n        $$\n        v' = \\frac{v}{10^j}\n        $$\n\n   5. 属性构造，根据已有的属性构造新的属性，例如根据高宽生成面积。\n\n# 数据消减\n\n数据消减技术正是用于帮助从原有庞大数据集中获得一个精简的数据集合，并使这一精简数据集保持原有数据集的完整性，这样在精简数据集上进行数据挖掘显然效率 更高，并且挖掘出来的结果与使用原有数据集所获得结果基本相同。\n\n1. 数据立方合计\n\n   以三个轴，生成一个数据立方。\n\n   每一层次的数据立方都是对其低一层数据的进一步抽象，因此它是一种有效的数据消减。\n\n2. 维数消减\n\n3. 数据压缩\n\n   - 小波分析\n   - 主要素分析\n\n4. 数据块消减\n\n   - 回归与线性对数模型\n   - 直方图\n   - 聚类\n   - 采样\n\n5. 离散化与概念层次生成\n\n   - bin方法\n   - 直方图\n   - 聚类\n   - 基于熵的离散化\n   - 自然划分分段法\n\n# 自动生成概念层次树\n\n对于数值属性，可以利用划分规则、直方图分析和聚类分析方法对数据进行分段并构造相应的概念层次树；而对于类别属性，则可以利用概念层次树所涉及属性的不同值个数，构造相应的概念层次树。 ","source":"_posts/datamining-pretreatment.md","raw":"---\ntitle: 数据挖掘-预处理\ndate: 2016-12-06 22:05:57\ncategories: programming\ntags: [datamining, programming]\n---\n\n由于数据的快速膨胀，我们获得的数据往往带有大量的噪声，所以我们需要对其进行一定的预处理。\n\n主要包括数据清洗、数据集成、 数据转换和数据消减。\n\n- 数据清洗\n\n  填补遗漏的数据值、平滑有噪声数据、识别或除去异常值，以及解决不一致问题。\n\n- 数据集成\n\n  将来自多个数据源的数据合并到一起。\n\n- 数据转换\n\n  主要是对数据进行规格化操作。\n\n- 数据消减\n\n  缩小所挖掘数据的规模，但却不会影响(或基本不影响)最终的挖掘结果。\n\n  - 数据聚合\n  - 消减维数\n  - 数据压缩\n  - 数据块消减\n\n# 数据清洗\n\n1. 处理空数据\n   - 忽略该数据\n   - 手工填补\n   - 利用缺省填补\n   - 利用均值填补\n   - 利用同类别均值\n   - 利用最可能的值\n     - 回归分析\n     - 贝叶斯计算公式\n\n   ​最后一种是最常用的。\n\n2. 噪声处理\n\n   - Bin方法 — 排序，分组，平滑处理（分组取均值、按边界等）\n   - 聚类方法\n   - 人机结合检查方法\n   - 回归方法 — 借助回归曲线\n\n\n# 数据的集成与转换\n\n1. 数据的集成处理\n\n   几个问题：\n\n   - 模式集成，例如：\"custom_id\", \"cum_num\" 是不是同一个模式？\n\n   - 冗余问题，若一个属性能从其他属性推算出来，那么它是冗余的。\n\n     我们可以通过相关系数的推算来确定：\n     $$\n     r_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}\n     $$\n\n   - 数据值冲突检测与消除，比如单位不同，语意偏差。\n\n2. 数据的转化处理\n\n   1. 平滑处理，bin、聚类、回归\n\n   2. 合计处理，对数据进行总结合计操作。\n\n   3. 数据泛化处理，例如：年龄映射到老年、中老年、青年等。\n\n   4. 规格化，例如：将成绩(可能总分是10分、20分或100分)折算成4分制绩点。\n\n      - 最大最小规格化方法 — 一种线性规格化，绩点的处理属于这种\n\n      - 零均值规格化方法\n        $$\n        v' = \\frac{v - \\bar{v}}{\\sigma}\n        $$\n\n      - 十基数变换规格化方法\n        $$\n        v' = \\frac{v}{10^j}\n        $$\n\n   5. 属性构造，根据已有的属性构造新的属性，例如根据高宽生成面积。\n\n# 数据消减\n\n数据消减技术正是用于帮助从原有庞大数据集中获得一个精简的数据集合，并使这一精简数据集保持原有数据集的完整性，这样在精简数据集上进行数据挖掘显然效率 更高，并且挖掘出来的结果与使用原有数据集所获得结果基本相同。\n\n1. 数据立方合计\n\n   以三个轴，生成一个数据立方。\n\n   每一层次的数据立方都是对其低一层数据的进一步抽象，因此它是一种有效的数据消减。\n\n2. 维数消减\n\n3. 数据压缩\n\n   - 小波分析\n   - 主要素分析\n\n4. 数据块消减\n\n   - 回归与线性对数模型\n   - 直方图\n   - 聚类\n   - 采样\n\n5. 离散化与概念层次生成\n\n   - bin方法\n   - 直方图\n   - 聚类\n   - 基于熵的离散化\n   - 自然划分分段法\n\n# 自动生成概念层次树\n\n对于数值属性，可以利用划分规则、直方图分析和聚类分析方法对数据进行分段并构造相应的概念层次树；而对于类别属性，则可以利用概念层次树所涉及属性的不同值个数，构造相应的概念层次树。 ","slug":"datamining-pretreatment","published":1,"updated":"2016-12-08T20:29:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhu001azemmo2xawczp","content":"<p>由于数据的快速膨胀，我们获得的数据往往带有大量的噪声，所以我们需要对其进行一定的预处理。</p>\n<p>主要包括数据清洗、数据集成、 数据转换和数据消减。</p>\n<ul>\n<li><p>数据清洗</p>\n<p>填补遗漏的数据值、平滑有噪声数据、识别或除去异常值，以及解决不一致问题。</p>\n</li>\n<li><p>数据集成</p>\n<p>将来自多个数据源的数据合并到一起。</p>\n</li>\n<li><p>数据转换</p>\n<p>主要是对数据进行规格化操作。</p>\n</li>\n<li><p>数据消减</p>\n<p>缩小所挖掘数据的规模，但却不会影响(或基本不影响)最终的挖掘结果。</p>\n<ul>\n<li>数据聚合</li>\n<li>消减维数</li>\n<li>数据压缩</li>\n<li>数据块消减</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"数据清洗\"><a href=\"#数据清洗\" class=\"headerlink\" title=\"数据清洗\"></a>数据清洗</h1><ol>\n<li><p>处理空数据</p>\n<ul>\n<li>忽略该数据</li>\n<li>手工填补</li>\n<li>利用缺省填补</li>\n<li>利用均值填补</li>\n<li>利用同类别均值</li>\n<li>利用最可能的值<ul>\n<li>回归分析</li>\n<li>贝叶斯计算公式</li>\n</ul>\n</li>\n</ul>\n<p>​最后一种是最常用的。</p>\n</li>\n<li><p>噪声处理</p>\n<ul>\n<li>Bin方法 — 排序，分组，平滑处理（分组取均值、按边界等）</li>\n<li>聚类方法</li>\n<li>人机结合检查方法</li>\n<li>回归方法 — 借助回归曲线</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"数据的集成与转换\"><a href=\"#数据的集成与转换\" class=\"headerlink\" title=\"数据的集成与转换\"></a>数据的集成与转换</h1><ol>\n<li><p>数据的集成处理</p>\n<p>几个问题：</p>\n<ul>\n<li><p>模式集成，例如：”custom_id”, “cum_num” 是不是同一个模式？</p>\n</li>\n<li><p>冗余问题，若一个属性能从其他属性推算出来，那么它是冗余的。</p>\n<p>我们可以通过相关系数的推算来确定：</p>\n<script type=\"math/tex; mode=display\">\nr_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}</script></li>\n<li><p>数据值冲突检测与消除，比如单位不同，语意偏差。</p>\n</li>\n</ul>\n</li>\n<li><p>数据的转化处理</p>\n<ol>\n<li><p>平滑处理，bin、聚类、回归</p>\n</li>\n<li><p>合计处理，对数据进行总结合计操作。</p>\n</li>\n<li><p>数据泛化处理，例如：年龄映射到老年、中老年、青年等。</p>\n</li>\n<li><p>规格化，例如：将成绩(可能总分是10分、20分或100分)折算成4分制绩点。</p>\n<ul>\n<li><p>最大最小规格化方法 — 一种线性规格化，绩点的处理属于这种</p>\n</li>\n<li><p>零均值规格化方法</p>\n<script type=\"math/tex; mode=display\">\nv' = \\frac{v - \\bar{v}}{\\sigma}</script></li>\n<li><p>十基数变换规格化方法</p>\n<script type=\"math/tex; mode=display\">\nv' = \\frac{v}{10^j}</script></li>\n</ul>\n</li>\n<li><p>属性构造，根据已有的属性构造新的属性，例如根据高宽生成面积。</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"数据消减\"><a href=\"#数据消减\" class=\"headerlink\" title=\"数据消减\"></a>数据消减</h1><p>数据消减技术正是用于帮助从原有庞大数据集中获得一个精简的数据集合，并使这一精简数据集保持原有数据集的完整性，这样在精简数据集上进行数据挖掘显然效率 更高，并且挖掘出来的结果与使用原有数据集所获得结果基本相同。</p>\n<ol>\n<li><p>数据立方合计</p>\n<p>以三个轴，生成一个数据立方。</p>\n<p>每一层次的数据立方都是对其低一层数据的进一步抽象，因此它是一种有效的数据消减。</p>\n</li>\n<li><p>维数消减</p>\n</li>\n<li><p>数据压缩</p>\n<ul>\n<li>小波分析</li>\n<li>主要素分析</li>\n</ul>\n</li>\n<li><p>数据块消减</p>\n<ul>\n<li>回归与线性对数模型</li>\n<li>直方图</li>\n<li>聚类</li>\n<li>采样</li>\n</ul>\n</li>\n<li><p>离散化与概念层次生成</p>\n<ul>\n<li>bin方法</li>\n<li>直方图</li>\n<li>聚类</li>\n<li>基于熵的离散化</li>\n<li>自然划分分段法</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"自动生成概念层次树\"><a href=\"#自动生成概念层次树\" class=\"headerlink\" title=\"自动生成概念层次树\"></a>自动生成概念层次树</h1><p>对于数值属性，可以利用划分规则、直方图分析和聚类分析方法对数据进行分段并构造相应的概念层次树；而对于类别属性，则可以利用概念层次树所涉及属性的不同值个数，构造相应的概念层次树。 </p>\n","excerpt":"","more":"<p>由于数据的快速膨胀，我们获得的数据往往带有大量的噪声，所以我们需要对其进行一定的预处理。</p>\n<p>主要包括数据清洗、数据集成、 数据转换和数据消减。</p>\n<ul>\n<li><p>数据清洗</p>\n<p>填补遗漏的数据值、平滑有噪声数据、识别或除去异常值，以及解决不一致问题。</p>\n</li>\n<li><p>数据集成</p>\n<p>将来自多个数据源的数据合并到一起。</p>\n</li>\n<li><p>数据转换</p>\n<p>主要是对数据进行规格化操作。</p>\n</li>\n<li><p>数据消减</p>\n<p>缩小所挖掘数据的规模，但却不会影响(或基本不影响)最终的挖掘结果。</p>\n<ul>\n<li>数据聚合</li>\n<li>消减维数</li>\n<li>数据压缩</li>\n<li>数据块消减</li>\n</ul>\n</li>\n</ul>\n<h1 id=\"数据清洗\"><a href=\"#数据清洗\" class=\"headerlink\" title=\"数据清洗\"></a>数据清洗</h1><ol>\n<li><p>处理空数据</p>\n<ul>\n<li>忽略该数据</li>\n<li>手工填补</li>\n<li>利用缺省填补</li>\n<li>利用均值填补</li>\n<li>利用同类别均值</li>\n<li>利用最可能的值<ul>\n<li>回归分析</li>\n<li>贝叶斯计算公式</li>\n</ul>\n</li>\n</ul>\n<p>​最后一种是最常用的。</p>\n</li>\n<li><p>噪声处理</p>\n<ul>\n<li>Bin方法 — 排序，分组，平滑处理（分组取均值、按边界等）</li>\n<li>聚类方法</li>\n<li>人机结合检查方法</li>\n<li>回归方法 — 借助回归曲线</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"数据的集成与转换\"><a href=\"#数据的集成与转换\" class=\"headerlink\" title=\"数据的集成与转换\"></a>数据的集成与转换</h1><ol>\n<li><p>数据的集成处理</p>\n<p>几个问题：</p>\n<ul>\n<li><p>模式集成，例如：”custom_id”, “cum_num” 是不是同一个模式？</p>\n</li>\n<li><p>冗余问题，若一个属性能从其他属性推算出来，那么它是冗余的。</p>\n<p>我们可以通过相关系数的推算来确定：</p>\n<script type=\"math/tex; mode=display\">\nr_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}</script></li>\n<li><p>数据值冲突检测与消除，比如单位不同，语意偏差。</p>\n</li>\n</ul>\n</li>\n<li><p>数据的转化处理</p>\n<ol>\n<li><p>平滑处理，bin、聚类、回归</p>\n</li>\n<li><p>合计处理，对数据进行总结合计操作。</p>\n</li>\n<li><p>数据泛化处理，例如：年龄映射到老年、中老年、青年等。</p>\n</li>\n<li><p>规格化，例如：将成绩(可能总分是10分、20分或100分)折算成4分制绩点。</p>\n<ul>\n<li><p>最大最小规格化方法 — 一种线性规格化，绩点的处理属于这种</p>\n</li>\n<li><p>零均值规格化方法</p>\n<script type=\"math/tex; mode=display\">\nv' = \\frac{v - \\bar{v}}{\\sigma}</script></li>\n<li><p>十基数变换规格化方法</p>\n<script type=\"math/tex; mode=display\">\nv' = \\frac{v}{10^j}</script></li>\n</ul>\n</li>\n<li><p>属性构造，根据已有的属性构造新的属性，例如根据高宽生成面积。</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"数据消减\"><a href=\"#数据消减\" class=\"headerlink\" title=\"数据消减\"></a>数据消减</h1><p>数据消减技术正是用于帮助从原有庞大数据集中获得一个精简的数据集合，并使这一精简数据集保持原有数据集的完整性，这样在精简数据集上进行数据挖掘显然效率 更高，并且挖掘出来的结果与使用原有数据集所获得结果基本相同。</p>\n<ol>\n<li><p>数据立方合计</p>\n<p>以三个轴，生成一个数据立方。</p>\n<p>每一层次的数据立方都是对其低一层数据的进一步抽象，因此它是一种有效的数据消减。</p>\n</li>\n<li><p>维数消减</p>\n</li>\n<li><p>数据压缩</p>\n<ul>\n<li>小波分析</li>\n<li>主要素分析</li>\n</ul>\n</li>\n<li><p>数据块消减</p>\n<ul>\n<li>回归与线性对数模型</li>\n<li>直方图</li>\n<li>聚类</li>\n<li>采样</li>\n</ul>\n</li>\n<li><p>离散化与概念层次生成</p>\n<ul>\n<li>bin方法</li>\n<li>直方图</li>\n<li>聚类</li>\n<li>基于熵的离散化</li>\n<li>自然划分分段法</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"自动生成概念层次树\"><a href=\"#自动生成概念层次树\" class=\"headerlink\" title=\"自动生成概念层次树\"></a>自动生成概念层次树</h1><p>对于数值属性，可以利用划分规则、直方图分析和聚类分析方法对数据进行分段并构造相应的概念层次树；而对于类别属性，则可以利用概念层次树所涉及属性的不同值个数，构造相应的概念层次树。 </p>\n"},{"title":"machine learning","date":"2016-12-12T21:04:47.000Z","_content":"\n# 笔记\n\n这里先占个位，等有空来填。\n\n# 参考\n\n[轻松看懂机器学习十大常用算法](http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&utm_medium=relatedPosts)","source":"_posts/machine-learning.md","raw":"---\ntitle: machine learning\ndate: 2016-12-12 22:04:47\ncategories: [programming, unfinished]\ntags: [machine-learning]\n---\n\n# 笔记\n\n这里先占个位，等有空来填。\n\n# 参考\n\n[轻松看懂机器学习十大常用算法](http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&utm_medium=relatedPosts)","slug":"machine-learning","published":1,"updated":"2016-12-12T21:07:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhx001dzemm74loy1rx","content":"<h1 id=\"笔记\"><a href=\"#笔记\" class=\"headerlink\" title=\"笔记\"></a>笔记</h1><p>这里先占个位，等有空来填。</p>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><p><a href=\"http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&amp;utm_medium=relatedPosts\" target=\"_blank\" rel=\"external\">轻松看懂机器学习十大常用算法</a></p>\n","excerpt":"","more":"<h1 id=\"笔记\"><a href=\"#笔记\" class=\"headerlink\" title=\"笔记\"></a>笔记</h1><p>这里先占个位，等有空来填。</p>\n<h1 id=\"参考\"><a href=\"#参考\" class=\"headerlink\" title=\"参考\"></a>参考</h1><p><a href=\"http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&amp;utm_medium=relatedPosts\">轻松看懂机器学习十大常用算法</a></p>\n"},{"title":"learning OS and building LorriOS","date":"2016-12-28T14:00:08.000Z","_content":"\n暂时用以记录操作系统的学习，以及开发自己的一个toy OS，作为一个项目日志?(如果能成功的话。。)。写这个东西的目的还是给我自己看的（估计其他人也会看的一头雾水吧，笑），毕竟人不太可能一次就找到正确的道路，所以日志写起来可能非常乱糟糟。所以说这只是一个记录，没有什么真正的参考价值。等这个toy os完成的差不多了，我应该会再来总结和记录一下。\n\n另外，下面的DayN并不是真正的天数，毕竟平时也要上课，不可能连续进行。所以大概是按每一次尝试，来进行划分的。\n\n----\n\n刚开始浏览了一下操作系统的基本知识，按考研复习的来吧，然后看的忽然有点跃跃欲试就想能不能写一个简单的OS。\n\n# Day1:\n\n一开始从《30天自制操作系统》开始看，以前有一点汇编基础所以看起来感觉还是可以接受的。\n\n看到第三天就下不去了，倒不是因为内容看不懂，而是环境的问题吧。作者是基于win，用了很多小程序，我用的是os x，很多时候要找一些替代方法。参考网上linux的解决方案，毕竟os x还是不太一样，到下面这一步就是不行，把haribote.bin写到myos.img。\n\n```shell\n# makefile\nmkdir -p /tmp/floppy\nmount -o loop myos.img /tmp/floppy -o fat=12 # 这一条在mac不适用\nsleep 1\ncp haribote.bin /tmp/floppy\nsleep 1\numount /tmp/floppy\n```\n\nOs x 上貌似不能直接mount，当然我也尝试了一些其他的办法，最终失败，感觉不太想再花时间在细枝末节上，打算回法国后在ubuntu下开发，或者和书上保持一样，在win下开发。\n\n# Day2:\n\n第二天开始阅读《ORANGE'S：一个操作系统的实现》，并打算先阅读，等了解大致情况再动手，不然也只是抄代码，并且在一知半解的情况下容易卡在一些细枝末节的地方。\n\n同时也可以参考UnixV6，这个是MIT用于教学写的一个类unix的OS，有配套的课程。\n\n两天下来感觉mac用于web开发十分方便，但是内核开发感觉网上的文档、案例偏少，当然主要也是我比较弱，不能够举一反三。一般来说，要不是面向初学者如《30天》而采用win，要不就是使用linux（果然linux才是王道= =）\n\n下面是在mac上编译uv6的配置（没有测试，纯搬运）\n\n>### Configuration\n>\n>1.  Install [Xcode](http://itunes.apple.com/us/app/xcode/id497799835).  After installing Xcode install the Command Line Tools from the Downloads section of Xcode's preferences.  I've installed Xcode Version 4.5 (4G182).\n>2.  Install [Homebrew](http://mxcl.github.com/homebrew/)\n>3.  Install pre-requisites for building xv6\n>    ```bash\n>        $ brew install glib gmp mpfr pkgconfig ppl\n>        $ brew install libmpc --use-llvm\n>        $ brew install qemu --use-gcc\n>    ```\n>4.  Install GNU binutils\n>    ```bash\n>        $ cd /tmp\n>        $ curl -O http://ftp.gnu.org/gnu/binutils/binutils-2.22.tar.gz\n>        $ tar -xvzf binutils-2.22.tar.gz\n>        $ ./configure --target=i386-jos-elf --disable-nls --prefix=/opt/gnu\n>        $ make\n>    ```\n>5.  Install GCC 4.5 via Homebrew\n>    ```bash\n>        $ cd /tmp\n>        $ curl -O http://ftp.gnu.org/gnu/gcc/gcc-4.7.2/gcc-4.7.2.tar.gz\n>        $ cd gcc-4.7.2\n>        $ ./configure --target=i386-jos-elf --disable-nls --without-headers --with-newlib --disable-threads --disable-shared --disable-libmudflap --disable-libssp --with-system-zlib --disable-lto --with-gmp=/usr/local --enable-languages=c --prefix=/opt/gnu\n>        $ LDFLAGS=-L/usr/lib make\n>        $ make install\n>    ```\n>\n>### Install and build xv6 with GCC\n>\n>```bash\n>$ git clone git://pdos.csail.mit.edu/xv6/xv6.git\n>cd xv6\n>make qemu-nox\n>```\n\n# Day3:\n\n目前跟着ORANGE，暂时比较顺利，开发环境仍然是mac。基于freedos下成功进入了保护模式。\n\n下面就保护模式做一点笔记。\n\n关于保护模式网上的资料很多，在为什么需要保护模式这个问题上，这里有一个非常直接的要求——我们的系统要运行在32位上，实模式仅支持16位寻址。当然保护模式远远不止如此，但是对于初学者（比如现在的我，囧），它应该是最大的用途之一。\n\n- GDT\n\n   首先要先说一下GDT(Global Descriptor Table)，它是全局描述符表。GDT只有一张，位置任意，通过LGDT指令被存储在GDTR寄存器。\n\n- Selector\n\n   由GDTR访问全局描述符表是通过“段选择子”（实模式下的段寄存器）来完成的。\n\n- LDT\n\n   局部描述符表LDT(Local Descriptor Table)。和GDT类似，直观上与GDT结构相同（其段选择子TI置位），功能上隶属于GDT。GDT只有一张，LDT有多张，每个任务可以有一张。\n\n如果第一次听到上面几个名词，可能还是比较懵逼。我们看看它是怎么运作的。\n\n1. 进行一系列初始化，包括定义GDT，LDT，选择子等\n2. 系统默认进入实模式\n3. 加载GDT，进入保护模式\n4. 加载不同的LDT，以进入不同的子任务\n5. 退出保护模式，反回实模式。\n\n上面只列出了关键步骤，实际上还有很多细节问题，这里只是简单记录其大致思想，所以没有提。\n\n不管怎么说，姑且是跨入了保护模式的大门。\n\n# Day4:\n\n### 特权级\n\n在IA32分段机制中，特权级有4个特权级别，\n\n- LEVEL 0: 内核\n- LEVEL 1, 2: 服务\n- LEVEL 3: 应用程序\n\n处理器通过识别CPL(current privilege level)、DPL(descriptor privilege level)、RPL(requested privilege level)这三个特权级进行特权级检验。\n\nCPL一般被存储在cs和ss的第0位和第1位。CPL等于所在代码段的特权级。当遇到一致代码段时，CPL不改变。（一致代码段能被小于等于它的特权的代码访问）\n\nDPL是段或门的特权级，写在描述符的属性中。\n\nRPL是通过选择子的第0位和第1位表现的。\n\n简单而言，只要CPL和RPL都小于被访问的数据段的DPL就可以了。\n\n### 门\n\n特权级转移可以分为两大类。jmp和call的直接转移；通过描述符间接转移。由于直接转移有诸多的限制，我们常常使用间接转移。\n\n其中，间接转移又分为：\n\n- 指向一个包含目标代码段选择子的门描述符\n- 指向一个包含目标代码段选择子的TSS\n- 指向一个任务门，它又指向一个包含目标代码段选择子的TSS\n\n门描述符分为四种：\n\n- 调用门 Call gate\n- 中断门 Interrupt gate\n- 陷阱门 Trap gate\n- 任务门 Task gate\n\n# Day5:\n\n### 页表\n\n实模式下，int 15h 获得内存信息\n\n页表这一块看的有点心急，感觉理解不是很到位。以后等弄的更清楚了再来总结。\n\n中途调试的时候总是出问题，没想到最后发现一开始32位代码的权限就定义错了。从现在出错的经历来看，os如果崩了的话，一般是权限问题（可能是因为我现在写的内容不多吧）。所以务必小心检查权限。\n\n书上的代码有一点不是很理解，在PagingDemo它使用了大量的push却没有pop。据我的理解的话，push是把数据存到栈中，而无法改变栈外的内存，它也没有使用ret之类的与栈相关的指令，目前不是很理解。\n\n不理解细节也没办法，先试着看看后面的内容吧。\n\n### 中断和异常\n\nIDT，中断描述符表。IDT中的描述符可以是：\n\n- 中断门描述符\n- 陷阱门描述符\n- 任务门描述符","source":"_posts/learning-OS-and-building-LorriOS.md","raw":"---\ntitle: learning OS and building LorriOS\ndate: 2016-12-28 15:00:08\ncategories: [programming, unfinished]\ntags: [OS, kernel]\n---\n\n暂时用以记录操作系统的学习，以及开发自己的一个toy OS，作为一个项目日志?(如果能成功的话。。)。写这个东西的目的还是给我自己看的（估计其他人也会看的一头雾水吧，笑），毕竟人不太可能一次就找到正确的道路，所以日志写起来可能非常乱糟糟。所以说这只是一个记录，没有什么真正的参考价值。等这个toy os完成的差不多了，我应该会再来总结和记录一下。\n\n另外，下面的DayN并不是真正的天数，毕竟平时也要上课，不可能连续进行。所以大概是按每一次尝试，来进行划分的。\n\n----\n\n刚开始浏览了一下操作系统的基本知识，按考研复习的来吧，然后看的忽然有点跃跃欲试就想能不能写一个简单的OS。\n\n# Day1:\n\n一开始从《30天自制操作系统》开始看，以前有一点汇编基础所以看起来感觉还是可以接受的。\n\n看到第三天就下不去了，倒不是因为内容看不懂，而是环境的问题吧。作者是基于win，用了很多小程序，我用的是os x，很多时候要找一些替代方法。参考网上linux的解决方案，毕竟os x还是不太一样，到下面这一步就是不行，把haribote.bin写到myos.img。\n\n```shell\n# makefile\nmkdir -p /tmp/floppy\nmount -o loop myos.img /tmp/floppy -o fat=12 # 这一条在mac不适用\nsleep 1\ncp haribote.bin /tmp/floppy\nsleep 1\numount /tmp/floppy\n```\n\nOs x 上貌似不能直接mount，当然我也尝试了一些其他的办法，最终失败，感觉不太想再花时间在细枝末节上，打算回法国后在ubuntu下开发，或者和书上保持一样，在win下开发。\n\n# Day2:\n\n第二天开始阅读《ORANGE'S：一个操作系统的实现》，并打算先阅读，等了解大致情况再动手，不然也只是抄代码，并且在一知半解的情况下容易卡在一些细枝末节的地方。\n\n同时也可以参考UnixV6，这个是MIT用于教学写的一个类unix的OS，有配套的课程。\n\n两天下来感觉mac用于web开发十分方便，但是内核开发感觉网上的文档、案例偏少，当然主要也是我比较弱，不能够举一反三。一般来说，要不是面向初学者如《30天》而采用win，要不就是使用linux（果然linux才是王道= =）\n\n下面是在mac上编译uv6的配置（没有测试，纯搬运）\n\n>### Configuration\n>\n>1.  Install [Xcode](http://itunes.apple.com/us/app/xcode/id497799835).  After installing Xcode install the Command Line Tools from the Downloads section of Xcode's preferences.  I've installed Xcode Version 4.5 (4G182).\n>2.  Install [Homebrew](http://mxcl.github.com/homebrew/)\n>3.  Install pre-requisites for building xv6\n>    ```bash\n>        $ brew install glib gmp mpfr pkgconfig ppl\n>        $ brew install libmpc --use-llvm\n>        $ brew install qemu --use-gcc\n>    ```\n>4.  Install GNU binutils\n>    ```bash\n>        $ cd /tmp\n>        $ curl -O http://ftp.gnu.org/gnu/binutils/binutils-2.22.tar.gz\n>        $ tar -xvzf binutils-2.22.tar.gz\n>        $ ./configure --target=i386-jos-elf --disable-nls --prefix=/opt/gnu\n>        $ make\n>    ```\n>5.  Install GCC 4.5 via Homebrew\n>    ```bash\n>        $ cd /tmp\n>        $ curl -O http://ftp.gnu.org/gnu/gcc/gcc-4.7.2/gcc-4.7.2.tar.gz\n>        $ cd gcc-4.7.2\n>        $ ./configure --target=i386-jos-elf --disable-nls --without-headers --with-newlib --disable-threads --disable-shared --disable-libmudflap --disable-libssp --with-system-zlib --disable-lto --with-gmp=/usr/local --enable-languages=c --prefix=/opt/gnu\n>        $ LDFLAGS=-L/usr/lib make\n>        $ make install\n>    ```\n>\n>### Install and build xv6 with GCC\n>\n>```bash\n>$ git clone git://pdos.csail.mit.edu/xv6/xv6.git\n>cd xv6\n>make qemu-nox\n>```\n\n# Day3:\n\n目前跟着ORANGE，暂时比较顺利，开发环境仍然是mac。基于freedos下成功进入了保护模式。\n\n下面就保护模式做一点笔记。\n\n关于保护模式网上的资料很多，在为什么需要保护模式这个问题上，这里有一个非常直接的要求——我们的系统要运行在32位上，实模式仅支持16位寻址。当然保护模式远远不止如此，但是对于初学者（比如现在的我，囧），它应该是最大的用途之一。\n\n- GDT\n\n   首先要先说一下GDT(Global Descriptor Table)，它是全局描述符表。GDT只有一张，位置任意，通过LGDT指令被存储在GDTR寄存器。\n\n- Selector\n\n   由GDTR访问全局描述符表是通过“段选择子”（实模式下的段寄存器）来完成的。\n\n- LDT\n\n   局部描述符表LDT(Local Descriptor Table)。和GDT类似，直观上与GDT结构相同（其段选择子TI置位），功能上隶属于GDT。GDT只有一张，LDT有多张，每个任务可以有一张。\n\n如果第一次听到上面几个名词，可能还是比较懵逼。我们看看它是怎么运作的。\n\n1. 进行一系列初始化，包括定义GDT，LDT，选择子等\n2. 系统默认进入实模式\n3. 加载GDT，进入保护模式\n4. 加载不同的LDT，以进入不同的子任务\n5. 退出保护模式，反回实模式。\n\n上面只列出了关键步骤，实际上还有很多细节问题，这里只是简单记录其大致思想，所以没有提。\n\n不管怎么说，姑且是跨入了保护模式的大门。\n\n# Day4:\n\n### 特权级\n\n在IA32分段机制中，特权级有4个特权级别，\n\n- LEVEL 0: 内核\n- LEVEL 1, 2: 服务\n- LEVEL 3: 应用程序\n\n处理器通过识别CPL(current privilege level)、DPL(descriptor privilege level)、RPL(requested privilege level)这三个特权级进行特权级检验。\n\nCPL一般被存储在cs和ss的第0位和第1位。CPL等于所在代码段的特权级。当遇到一致代码段时，CPL不改变。（一致代码段能被小于等于它的特权的代码访问）\n\nDPL是段或门的特权级，写在描述符的属性中。\n\nRPL是通过选择子的第0位和第1位表现的。\n\n简单而言，只要CPL和RPL都小于被访问的数据段的DPL就可以了。\n\n### 门\n\n特权级转移可以分为两大类。jmp和call的直接转移；通过描述符间接转移。由于直接转移有诸多的限制，我们常常使用间接转移。\n\n其中，间接转移又分为：\n\n- 指向一个包含目标代码段选择子的门描述符\n- 指向一个包含目标代码段选择子的TSS\n- 指向一个任务门，它又指向一个包含目标代码段选择子的TSS\n\n门描述符分为四种：\n\n- 调用门 Call gate\n- 中断门 Interrupt gate\n- 陷阱门 Trap gate\n- 任务门 Task gate\n\n# Day5:\n\n### 页表\n\n实模式下，int 15h 获得内存信息\n\n页表这一块看的有点心急，感觉理解不是很到位。以后等弄的更清楚了再来总结。\n\n中途调试的时候总是出问题，没想到最后发现一开始32位代码的权限就定义错了。从现在出错的经历来看，os如果崩了的话，一般是权限问题（可能是因为我现在写的内容不多吧）。所以务必小心检查权限。\n\n书上的代码有一点不是很理解，在PagingDemo它使用了大量的push却没有pop。据我的理解的话，push是把数据存到栈中，而无法改变栈外的内存，它也没有使用ret之类的与栈相关的指令，目前不是很理解。\n\n不理解细节也没办法，先试着看看后面的内容吧。\n\n### 中断和异常\n\nIDT，中断描述符表。IDT中的描述符可以是：\n\n- 中断门描述符\n- 陷阱门描述符\n- 任务门描述符","slug":"learning-OS-and-building-LorriOS","published":1,"updated":"2017-01-10T11:58:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjhz001gzemmu0xkjxqd","content":"<p>暂时用以记录操作系统的学习，以及开发自己的一个toy OS，作为一个项目日志?(如果能成功的话。。)。写这个东西的目的还是给我自己看的（估计其他人也会看的一头雾水吧，笑），毕竟人不太可能一次就找到正确的道路，所以日志写起来可能非常乱糟糟。所以说这只是一个记录，没有什么真正的参考价值。等这个toy os完成的差不多了，我应该会再来总结和记录一下。</p>\n<p>另外，下面的DayN并不是真正的天数，毕竟平时也要上课，不可能连续进行。所以大概是按每一次尝试，来进行划分的。</p>\n<hr>\n<p>刚开始浏览了一下操作系统的基本知识，按考研复习的来吧，然后看的忽然有点跃跃欲试就想能不能写一个简单的OS。</p>\n<h1 id=\"Day1\"><a href=\"#Day1\" class=\"headerlink\" title=\"Day1:\"></a>Day1:</h1><p>一开始从《30天自制操作系统》开始看，以前有一点汇编基础所以看起来感觉还是可以接受的。</p>\n<p>看到第三天就下不去了，倒不是因为内容看不懂，而是环境的问题吧。作者是基于win，用了很多小程序，我用的是os x，很多时候要找一些替代方法。参考网上linux的解决方案，毕竟os x还是不太一样，到下面这一步就是不行，把haribote.bin写到myos.img。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"># makefile</div><div class=\"line\">mkdir -p /tmp/floppy</div><div class=\"line\">mount -o loop myos.img /tmp/floppy -o fat=12 # 这一条在mac不适用</div><div class=\"line\">sleep 1</div><div class=\"line\">cp haribote.bin /tmp/floppy</div><div class=\"line\">sleep 1</div><div class=\"line\">umount /tmp/floppy</div></pre></td></tr></table></figure>\n<p>Os x 上貌似不能直接mount，当然我也尝试了一些其他的办法，最终失败，感觉不太想再花时间在细枝末节上，打算回法国后在ubuntu下开发，或者和书上保持一样，在win下开发。</p>\n<h1 id=\"Day2\"><a href=\"#Day2\" class=\"headerlink\" title=\"Day2:\"></a>Day2:</h1><p>第二天开始阅读《ORANGE’S：一个操作系统的实现》，并打算先阅读，等了解大致情况再动手，不然也只是抄代码，并且在一知半解的情况下容易卡在一些细枝末节的地方。</p>\n<p>同时也可以参考UnixV6，这个是MIT用于教学写的一个类unix的OS，有配套的课程。</p>\n<p>两天下来感觉mac用于web开发十分方便，但是内核开发感觉网上的文档、案例偏少，当然主要也是我比较弱，不能够举一反三。一般来说，要不是面向初学者如《30天》而采用win，要不就是使用linux（果然linux才是王道= =）</p>\n<p>下面是在mac上编译uv6的配置（没有测试，纯搬运）</p>\n<blockquote>\n<h3 id=\"Configuration\"><a href=\"#Configuration\" class=\"headerlink\" title=\"Configuration\"></a>Configuration</h3><ol>\n<li>Install <a href=\"http://itunes.apple.com/us/app/xcode/id497799835\" target=\"_blank\" rel=\"external\">Xcode</a>.  After installing Xcode install the Command Line Tools from the Downloads section of Xcode’s preferences.  I’ve installed Xcode Version 4.5 (4G182).</li>\n<li>Install <a href=\"http://mxcl.github.com/homebrew/\" target=\"_blank\" rel=\"external\">Homebrew</a></li>\n<li><p>Install pre-requisites for building xv6</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;        $ brew install glib gmp mpfr pkgconfig ppl</div><div class=\"line\">&gt;        $ brew install libmpc --use-llvm</div><div class=\"line\">&gt;        $ brew install qemu --use-gcc</div><div class=\"line\">&gt;</div></pre></td></tr></table></figure>\n</li>\n<li><p>Install GNU binutils</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;        $ <span class=\"built_in\">cd</span> /tmp</div><div class=\"line\">&gt;        $ curl -O http://ftp.gnu.org/gnu/binutils/binutils-2.22.tar.gz</div><div class=\"line\">&gt;        $ tar -xvzf binutils-2.22.tar.gz</div><div class=\"line\">&gt;        $ ./configure --target=i386-jos-elf --disable-nls --prefix=/opt/gnu</div><div class=\"line\">&gt;        $ make</div><div class=\"line\">&gt;</div></pre></td></tr></table></figure>\n</li>\n<li><p>Install GCC 4.5 via Homebrew</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;        $ <span class=\"built_in\">cd</span> /tmp</div><div class=\"line\">&gt;        $ curl -O http://ftp.gnu.org/gnu/gcc/gcc-4.7.2/gcc-4.7.2.tar.gz</div><div class=\"line\">&gt;        $ <span class=\"built_in\">cd</span> gcc-4.7.2</div><div class=\"line\">&gt;        $ ./configure --target=i386-jos-elf --disable-nls --without-headers --with-newlib --disable-threads --disable-shared --disable-libmudflap --disable-libssp --with-system-zlib --disable-lto --with-gmp=/usr/<span class=\"built_in\">local</span> --enable-languages=c --prefix=/opt/gnu</div><div class=\"line\">&gt;        $ LDFLAGS=-L/usr/lib make</div><div class=\"line\">&gt;        $ make install</div><div class=\"line\">&gt;</div></pre></td></tr></table></figure>\n</li>\n</ol>\n</blockquote>\n<p>&gt;</p>\n<blockquote>\n<h3 id=\"Install-and-build-xv6-with-GCC\"><a href=\"#Install-and-build-xv6-with-GCC\" class=\"headerlink\" title=\"Install and build xv6 with GCC\"></a>Install and build xv6 with GCC</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;$ git <span class=\"built_in\">clone</span> git://pdos.csail.mit.edu/xv6/xv6.git</div><div class=\"line\">&gt;<span class=\"built_in\">cd</span> xv6</div><div class=\"line\">&gt;make qemu-nox</div><div class=\"line\">&gt;</div></pre></td></tr></table></figure>\n</blockquote>\n<h1 id=\"Day3\"><a href=\"#Day3\" class=\"headerlink\" title=\"Day3:\"></a>Day3:</h1><p>目前跟着ORANGE，暂时比较顺利，开发环境仍然是mac。基于freedos下成功进入了保护模式。</p>\n<p>下面就保护模式做一点笔记。</p>\n<p>关于保护模式网上的资料很多，在为什么需要保护模式这个问题上，这里有一个非常直接的要求——我们的系统要运行在32位上，实模式仅支持16位寻址。当然保护模式远远不止如此，但是对于初学者（比如现在的我，囧），它应该是最大的用途之一。</p>\n<ul>\n<li><p>GDT</p>\n<p> 首先要先说一下GDT(Global Descriptor Table)，它是全局描述符表。GDT只有一张，位置任意，通过LGDT指令被存储在GDTR寄存器。</p>\n</li>\n<li><p>Selector</p>\n<p> 由GDTR访问全局描述符表是通过“段选择子”（实模式下的段寄存器）来完成的。</p>\n</li>\n<li><p>LDT</p>\n<p> 局部描述符表LDT(Local Descriptor Table)。和GDT类似，直观上与GDT结构相同（其段选择子TI置位），功能上隶属于GDT。GDT只有一张，LDT有多张，每个任务可以有一张。</p>\n</li>\n</ul>\n<p>如果第一次听到上面几个名词，可能还是比较懵逼。我们看看它是怎么运作的。</p>\n<ol>\n<li>进行一系列初始化，包括定义GDT，LDT，选择子等</li>\n<li>系统默认进入实模式</li>\n<li>加载GDT，进入保护模式</li>\n<li>加载不同的LDT，以进入不同的子任务</li>\n<li>退出保护模式，反回实模式。</li>\n</ol>\n<p>上面只列出了关键步骤，实际上还有很多细节问题，这里只是简单记录其大致思想，所以没有提。</p>\n<p>不管怎么说，姑且是跨入了保护模式的大门。</p>\n<h1 id=\"Day4\"><a href=\"#Day4\" class=\"headerlink\" title=\"Day4:\"></a>Day4:</h1><h3 id=\"特权级\"><a href=\"#特权级\" class=\"headerlink\" title=\"特权级\"></a>特权级</h3><p>在IA32分段机制中，特权级有4个特权级别，</p>\n<ul>\n<li>LEVEL 0: 内核</li>\n<li>LEVEL 1, 2: 服务</li>\n<li>LEVEL 3: 应用程序</li>\n</ul>\n<p>处理器通过识别CPL(current privilege level)、DPL(descriptor privilege level)、RPL(requested privilege level)这三个特权级进行特权级检验。</p>\n<p>CPL一般被存储在cs和ss的第0位和第1位。CPL等于所在代码段的特权级。当遇到一致代码段时，CPL不改变。（一致代码段能被小于等于它的特权的代码访问）</p>\n<p>DPL是段或门的特权级，写在描述符的属性中。</p>\n<p>RPL是通过选择子的第0位和第1位表现的。</p>\n<p>简单而言，只要CPL和RPL都小于被访问的数据段的DPL就可以了。</p>\n<h3 id=\"门\"><a href=\"#门\" class=\"headerlink\" title=\"门\"></a>门</h3><p>特权级转移可以分为两大类。jmp和call的直接转移；通过描述符间接转移。由于直接转移有诸多的限制，我们常常使用间接转移。</p>\n<p>其中，间接转移又分为：</p>\n<ul>\n<li>指向一个包含目标代码段选择子的门描述符</li>\n<li>指向一个包含目标代码段选择子的TSS</li>\n<li>指向一个任务门，它又指向一个包含目标代码段选择子的TSS</li>\n</ul>\n<p>门描述符分为四种：</p>\n<ul>\n<li>调用门 Call gate</li>\n<li>中断门 Interrupt gate</li>\n<li>陷阱门 Trap gate</li>\n<li>任务门 Task gate</li>\n</ul>\n<h1 id=\"Day5\"><a href=\"#Day5\" class=\"headerlink\" title=\"Day5:\"></a>Day5:</h1><h3 id=\"页表\"><a href=\"#页表\" class=\"headerlink\" title=\"页表\"></a>页表</h3><p>实模式下，int 15h 获得内存信息</p>\n<p>页表这一块看的有点心急，感觉理解不是很到位。以后等弄的更清楚了再来总结。</p>\n<p>中途调试的时候总是出问题，没想到最后发现一开始32位代码的权限就定义错了。从现在出错的经历来看，os如果崩了的话，一般是权限问题（可能是因为我现在写的内容不多吧）。所以务必小心检查权限。</p>\n<p>书上的代码有一点不是很理解，在PagingDemo它使用了大量的push却没有pop。据我的理解的话，push是把数据存到栈中，而无法改变栈外的内存，它也没有使用ret之类的与栈相关的指令，目前不是很理解。</p>\n<p>不理解细节也没办法，先试着看看后面的内容吧。</p>\n<h3 id=\"中断和异常\"><a href=\"#中断和异常\" class=\"headerlink\" title=\"中断和异常\"></a>中断和异常</h3><p>IDT，中断描述符表。IDT中的描述符可以是：</p>\n<ul>\n<li>中断门描述符</li>\n<li>陷阱门描述符</li>\n<li>任务门描述符</li>\n</ul>\n","excerpt":"","more":"<p>暂时用以记录操作系统的学习，以及开发自己的一个toy OS，作为一个项目日志?(如果能成功的话。。)。写这个东西的目的还是给我自己看的（估计其他人也会看的一头雾水吧，笑），毕竟人不太可能一次就找到正确的道路，所以日志写起来可能非常乱糟糟。所以说这只是一个记录，没有什么真正的参考价值。等这个toy os完成的差不多了，我应该会再来总结和记录一下。</p>\n<p>另外，下面的DayN并不是真正的天数，毕竟平时也要上课，不可能连续进行。所以大概是按每一次尝试，来进行划分的。</p>\n<hr>\n<p>刚开始浏览了一下操作系统的基本知识，按考研复习的来吧，然后看的忽然有点跃跃欲试就想能不能写一个简单的OS。</p>\n<h1 id=\"Day1\"><a href=\"#Day1\" class=\"headerlink\" title=\"Day1:\"></a>Day1:</h1><p>一开始从《30天自制操作系统》开始看，以前有一点汇编基础所以看起来感觉还是可以接受的。</p>\n<p>看到第三天就下不去了，倒不是因为内容看不懂，而是环境的问题吧。作者是基于win，用了很多小程序，我用的是os x，很多时候要找一些替代方法。参考网上linux的解决方案，毕竟os x还是不太一样，到下面这一步就是不行，把haribote.bin写到myos.img。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\"># makefile</div><div class=\"line\">mkdir -p /tmp/floppy</div><div class=\"line\">mount -o loop myos.img /tmp/floppy -o fat=12 # 这一条在mac不适用</div><div class=\"line\">sleep 1</div><div class=\"line\">cp haribote.bin /tmp/floppy</div><div class=\"line\">sleep 1</div><div class=\"line\">umount /tmp/floppy</div></pre></td></tr></table></figure>\n<p>Os x 上貌似不能直接mount，当然我也尝试了一些其他的办法，最终失败，感觉不太想再花时间在细枝末节上，打算回法国后在ubuntu下开发，或者和书上保持一样，在win下开发。</p>\n<h1 id=\"Day2\"><a href=\"#Day2\" class=\"headerlink\" title=\"Day2:\"></a>Day2:</h1><p>第二天开始阅读《ORANGE’S：一个操作系统的实现》，并打算先阅读，等了解大致情况再动手，不然也只是抄代码，并且在一知半解的情况下容易卡在一些细枝末节的地方。</p>\n<p>同时也可以参考UnixV6，这个是MIT用于教学写的一个类unix的OS，有配套的课程。</p>\n<p>两天下来感觉mac用于web开发十分方便，但是内核开发感觉网上的文档、案例偏少，当然主要也是我比较弱，不能够举一反三。一般来说，要不是面向初学者如《30天》而采用win，要不就是使用linux（果然linux才是王道= =）</p>\n<p>下面是在mac上编译uv6的配置（没有测试，纯搬运）</p>\n<blockquote>\n<h3 id=\"Configuration\"><a href=\"#Configuration\" class=\"headerlink\" title=\"Configuration\"></a>Configuration</h3><ol>\n<li>Install <a href=\"http://itunes.apple.com/us/app/xcode/id497799835\">Xcode</a>.  After installing Xcode install the Command Line Tools from the Downloads section of Xcode’s preferences.  I’ve installed Xcode Version 4.5 (4G182).</li>\n<li>Install <a href=\"http://mxcl.github.com/homebrew/\">Homebrew</a></li>\n<li><p>Install pre-requisites for building xv6</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;        $ brew install glib gmp mpfr pkgconfig ppl</div><div class=\"line\">&gt;        $ brew install libmpc --use-llvm</div><div class=\"line\">&gt;        $ brew install qemu --use-gcc</div><div class=\"line\">&gt;</div></pre></td></tr></table></figure>\n</li>\n<li><p>Install GNU binutils</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;        $ <span class=\"built_in\">cd</span> /tmp</div><div class=\"line\">&gt;        $ curl -O http://ftp.gnu.org/gnu/binutils/binutils-2.22.tar.gz</div><div class=\"line\">&gt;        $ tar -xvzf binutils-2.22.tar.gz</div><div class=\"line\">&gt;        $ ./configure --target=i386-jos-elf --disable-nls --prefix=/opt/gnu</div><div class=\"line\">&gt;        $ make</div><div class=\"line\">&gt;</div></pre></td></tr></table></figure>\n</li>\n<li><p>Install GCC 4.5 via Homebrew</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;        $ <span class=\"built_in\">cd</span> /tmp</div><div class=\"line\">&gt;        $ curl -O http://ftp.gnu.org/gnu/gcc/gcc-4.7.2/gcc-4.7.2.tar.gz</div><div class=\"line\">&gt;        $ <span class=\"built_in\">cd</span> gcc-4.7.2</div><div class=\"line\">&gt;        $ ./configure --target=i386-jos-elf --disable-nls --without-headers --with-newlib --disable-threads --disable-shared --disable-libmudflap --disable-libssp --with-system-zlib --disable-lto --with-gmp=/usr/<span class=\"built_in\">local</span> --enable-languages=c --prefix=/opt/gnu</div><div class=\"line\">&gt;        $ LDFLAGS=-L/usr/lib make</div><div class=\"line\">&gt;        $ make install</div><div class=\"line\">&gt;</div></pre></td></tr></table></figure>\n</li>\n</ol>\n</blockquote>\n<p>&gt;</p>\n<blockquote>\n<h3 id=\"Install-and-build-xv6-with-GCC\"><a href=\"#Install-and-build-xv6-with-GCC\" class=\"headerlink\" title=\"Install and build xv6 with GCC\"></a>Install and build xv6 with GCC</h3><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div></pre></td><td class=\"code\"><pre><div class=\"line\">&gt;$ git <span class=\"built_in\">clone</span> git://pdos.csail.mit.edu/xv6/xv6.git</div><div class=\"line\">&gt;<span class=\"built_in\">cd</span> xv6</div><div class=\"line\">&gt;make qemu-nox</div><div class=\"line\">&gt;</div></pre></td></tr></table></figure>\n</blockquote>\n<h1 id=\"Day3\"><a href=\"#Day3\" class=\"headerlink\" title=\"Day3:\"></a>Day3:</h1><p>目前跟着ORANGE，暂时比较顺利，开发环境仍然是mac。基于freedos下成功进入了保护模式。</p>\n<p>下面就保护模式做一点笔记。</p>\n<p>关于保护模式网上的资料很多，在为什么需要保护模式这个问题上，这里有一个非常直接的要求——我们的系统要运行在32位上，实模式仅支持16位寻址。当然保护模式远远不止如此，但是对于初学者（比如现在的我，囧），它应该是最大的用途之一。</p>\n<ul>\n<li><p>GDT</p>\n<p> 首先要先说一下GDT(Global Descriptor Table)，它是全局描述符表。GDT只有一张，位置任意，通过LGDT指令被存储在GDTR寄存器。</p>\n</li>\n<li><p>Selector</p>\n<p> 由GDTR访问全局描述符表是通过“段选择子”（实模式下的段寄存器）来完成的。</p>\n</li>\n<li><p>LDT</p>\n<p> 局部描述符表LDT(Local Descriptor Table)。和GDT类似，直观上与GDT结构相同（其段选择子TI置位），功能上隶属于GDT。GDT只有一张，LDT有多张，每个任务可以有一张。</p>\n</li>\n</ul>\n<p>如果第一次听到上面几个名词，可能还是比较懵逼。我们看看它是怎么运作的。</p>\n<ol>\n<li>进行一系列初始化，包括定义GDT，LDT，选择子等</li>\n<li>系统默认进入实模式</li>\n<li>加载GDT，进入保护模式</li>\n<li>加载不同的LDT，以进入不同的子任务</li>\n<li>退出保护模式，反回实模式。</li>\n</ol>\n<p>上面只列出了关键步骤，实际上还有很多细节问题，这里只是简单记录其大致思想，所以没有提。</p>\n<p>不管怎么说，姑且是跨入了保护模式的大门。</p>\n<h1 id=\"Day4\"><a href=\"#Day4\" class=\"headerlink\" title=\"Day4:\"></a>Day4:</h1><h3 id=\"特权级\"><a href=\"#特权级\" class=\"headerlink\" title=\"特权级\"></a>特权级</h3><p>在IA32分段机制中，特权级有4个特权级别，</p>\n<ul>\n<li>LEVEL 0: 内核</li>\n<li>LEVEL 1, 2: 服务</li>\n<li>LEVEL 3: 应用程序</li>\n</ul>\n<p>处理器通过识别CPL(current privilege level)、DPL(descriptor privilege level)、RPL(requested privilege level)这三个特权级进行特权级检验。</p>\n<p>CPL一般被存储在cs和ss的第0位和第1位。CPL等于所在代码段的特权级。当遇到一致代码段时，CPL不改变。（一致代码段能被小于等于它的特权的代码访问）</p>\n<p>DPL是段或门的特权级，写在描述符的属性中。</p>\n<p>RPL是通过选择子的第0位和第1位表现的。</p>\n<p>简单而言，只要CPL和RPL都小于被访问的数据段的DPL就可以了。</p>\n<h3 id=\"门\"><a href=\"#门\" class=\"headerlink\" title=\"门\"></a>门</h3><p>特权级转移可以分为两大类。jmp和call的直接转移；通过描述符间接转移。由于直接转移有诸多的限制，我们常常使用间接转移。</p>\n<p>其中，间接转移又分为：</p>\n<ul>\n<li>指向一个包含目标代码段选择子的门描述符</li>\n<li>指向一个包含目标代码段选择子的TSS</li>\n<li>指向一个任务门，它又指向一个包含目标代码段选择子的TSS</li>\n</ul>\n<p>门描述符分为四种：</p>\n<ul>\n<li>调用门 Call gate</li>\n<li>中断门 Interrupt gate</li>\n<li>陷阱门 Trap gate</li>\n<li>任务门 Task gate</li>\n</ul>\n<h1 id=\"Day5\"><a href=\"#Day5\" class=\"headerlink\" title=\"Day5:\"></a>Day5:</h1><h3 id=\"页表\"><a href=\"#页表\" class=\"headerlink\" title=\"页表\"></a>页表</h3><p>实模式下，int 15h 获得内存信息</p>\n<p>页表这一块看的有点心急，感觉理解不是很到位。以后等弄的更清楚了再来总结。</p>\n<p>中途调试的时候总是出问题，没想到最后发现一开始32位代码的权限就定义错了。从现在出错的经历来看，os如果崩了的话，一般是权限问题（可能是因为我现在写的内容不多吧）。所以务必小心检查权限。</p>\n<p>书上的代码有一点不是很理解，在PagingDemo它使用了大量的push却没有pop。据我的理解的话，push是把数据存到栈中，而无法改变栈外的内存，它也没有使用ret之类的与栈相关的指令，目前不是很理解。</p>\n<p>不理解细节也没办法，先试着看看后面的内容吧。</p>\n<h3 id=\"中断和异常\"><a href=\"#中断和异常\" class=\"headerlink\" title=\"中断和异常\"></a>中断和异常</h3><p>IDT，中断描述符表。IDT中的描述符可以是：</p>\n<ul>\n<li>中断门描述符</li>\n<li>陷阱门描述符</li>\n<li>任务门描述符</li>\n</ul>\n"},{"title":"解决hexo使用公式冲突问题 hexo with latex","date":"2016-11-30T21:19:02.000Z","_content":"\n在hexo中使用大量公式的同学一定会发现，在hexo很多公式的渲染不正常。这是由于markdown渲染器和latex渲染器冲突的问题（具体说，就是公式中的特殊字符首先被markdown渲染器转义了）。我们可以通过更换Markdown渲染插件来解决这个问题。\n\nGoogle了一些博文，在[如何处理Hexo和MathJax的兼容问题](http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/)这篇文章中发现了一个符合要求的插件：[hexo-renderer-kramed](https://github.com/sun11/hexo-renderer-kramed)。作者fork了 hexo-renderer-marked 项目，并且只对MathJax支持进行了改进，其他特性完全一致。\n\n简单粗暴的讲，卸载原渲染器，安装我们需要的渲染器。\n\n依次运行下列语句即可。\n\n```\n$ npm uninstall hexo-renderer-marked --save\n$ npm install hexo-renderer-kramed --save\n```\n\n现在公式的显示已经正常。\n\n注：传说行内代码渲染仍然有问题，在代码块中工作正常。","source":"_posts/hexo-with-latex.md","raw":"---\ntitle: 解决hexo使用公式冲突问题 hexo with latex\ndate: 2016-11-30 22:19:02\ncategories: other\ntags: [hexo, latex, mathjax, marked]\n---\n\n在hexo中使用大量公式的同学一定会发现，在hexo很多公式的渲染不正常。这是由于markdown渲染器和latex渲染器冲突的问题（具体说，就是公式中的特殊字符首先被markdown渲染器转义了）。我们可以通过更换Markdown渲染插件来解决这个问题。\n\nGoogle了一些博文，在[如何处理Hexo和MathJax的兼容问题](http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/)这篇文章中发现了一个符合要求的插件：[hexo-renderer-kramed](https://github.com/sun11/hexo-renderer-kramed)。作者fork了 hexo-renderer-marked 项目，并且只对MathJax支持进行了改进，其他特性完全一致。\n\n简单粗暴的讲，卸载原渲染器，安装我们需要的渲染器。\n\n依次运行下列语句即可。\n\n```\n$ npm uninstall hexo-renderer-marked --save\n$ npm install hexo-renderer-kramed --save\n```\n\n现在公式的显示已经正常。\n\n注：传说行内代码渲染仍然有问题，在代码块中工作正常。","slug":"hexo-with-latex","published":1,"updated":"2016-11-30T21:45:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkji1001kzemmbkke3hyx","content":"<p>在hexo中使用大量公式的同学一定会发现，在hexo很多公式的渲染不正常。这是由于markdown渲染器和latex渲染器冲突的问题（具体说，就是公式中的特殊字符首先被markdown渲染器转义了）。我们可以通过更换Markdown渲染插件来解决这个问题。</p>\n<p>Google了一些博文，在<a href=\"http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/\" target=\"_blank\" rel=\"external\">如何处理Hexo和MathJax的兼容问题</a>这篇文章中发现了一个符合要求的插件：<a href=\"https://github.com/sun11/hexo-renderer-kramed\" target=\"_blank\" rel=\"external\">hexo-renderer-kramed</a>。作者fork了 hexo-renderer-marked 项目，并且只对MathJax支持进行了改进，其他特性完全一致。</p>\n<p>简单粗暴的讲，卸载原渲染器，安装我们需要的渲染器。</p>\n<p>依次运行下列语句即可。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ npm uninstall hexo-renderer-marked --save</div><div class=\"line\">$ npm install hexo-renderer-kramed --save</div></pre></td></tr></table></figure>\n<p>现在公式的显示已经正常。</p>\n<p>注：传说行内代码渲染仍然有问题，在代码块中工作正常。</p>\n","excerpt":"","more":"<p>在hexo中使用大量公式的同学一定会发现，在hexo很多公式的渲染不正常。这是由于markdown渲染器和latex渲染器冲突的问题（具体说，就是公式中的特殊字符首先被markdown渲染器转义了）。我们可以通过更换Markdown渲染插件来解决这个问题。</p>\n<p>Google了一些博文，在<a href=\"http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/\">如何处理Hexo和MathJax的兼容问题</a>这篇文章中发现了一个符合要求的插件：<a href=\"https://github.com/sun11/hexo-renderer-kramed\">hexo-renderer-kramed</a>。作者fork了 hexo-renderer-marked 项目，并且只对MathJax支持进行了改进，其他特性完全一致。</p>\n<p>简单粗暴的讲，卸载原渲染器，安装我们需要的渲染器。</p>\n<p>依次运行下列语句即可。</p>\n<figure class=\"highlight plain\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div></pre></td><td class=\"code\"><pre><div class=\"line\">$ npm uninstall hexo-renderer-marked --save</div><div class=\"line\">$ npm install hexo-renderer-kramed --save</div></pre></td></tr></table></figure>\n<p>现在公式的显示已经正常。</p>\n<p>注：传说行内代码渲染仍然有问题，在代码块中工作正常。</p>\n"},{"title":"企业管理复习笔记","date":"2016-12-10T16:48:37.000Z","_content":"\nThis is the note of learning \"Management of the firm\", with the book of GESTION (ecole centrale paris).\n\n# The firm and the management\n\n## the firm\n\n1. the definition of the firm\n\n   - The company is an economic entity or a place of creation of value\n   - It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.\n   - It uses (destroys) resources (mobilized from partners)\n   - it generates positive or negative externalities on its environment\n2. the different types of resources used by the company\n\n   - The work, provided by employees who sell their working time\n   - Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:\n     1. Tangible resources (实体资源)\n     2. Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands\n     3. the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment\n3. the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)\n\n   - Design or R&D\n   - Manufacturing or production\n   - Marketing / sales\n   - Finance\n\n\n4. the importance of the company's relations with its partners in the framework of contracts and with its stakeholders more generally.\n\n   - The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the company's share capital\n   - With the sectoral communities (suppliers, distributors ...), economic (financiers, prescribers, ...) and social (legislation, populations);\n\n\n## The management\n\n1. the definitions of management\n\n   - Manages a planning / organization function and a control function (animation and evaluation) of the activity.\n   - POCCC: prevoir, organiser, commander, coordonner, controle\n\n2. the difference between the operational mode and the strategic management mode\n\n   - manage operationally :\n\n     to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.\n\n   - manage strategically:\n\n     to make sure that you do the right things (doing the right thing)\n\n     That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the company's balance sheet (stock).\n\n# Marketing\n\n**Things important:**\n\n- PESTEL:\n  - ​Policy, especially government stability and regulations.\n  - Economic, in particular state of the economic situation and economic situation\n  - Sociocultural, particularly demography and changing lifestyles.\n  - Technological, in particular public and private R&D expenditure.\n  - Ecological, in particular legislation on the protection of the environment\n  - Legal, in particular the law of competition and the law of labor.\n\n- SWOT model: \n  - Strengths - Internal\n  - Weaknesses - Internal\n  - Opportunities - External\n  - Threats - External\n\n- Marketing mix (营销组合)\n\n  4P => 4C: \n\n  - Product => Consumer wants and needs\n  - Price => Cost\n  - Promotion => communication\n  - Place (distribution) => Convenience\n\n1. the definition of marketing\n\n   - Aggregate of methods to adapt its offer to changing demand\n     - Assess and anticipate relevant changes \n     - Understand customers' needs and desires\n     - Act on supply and its perception\n   - But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.\n\n\n2. The difference between marketing and sales\n\n   - The marketing aims to facilitate and accompany the act of sale,\n\n   - The marketing Collects / Synthesizes Customer and Market Information\n\n   - The marketing helps to define offers (products / services) adapted to the customers\n\n   - The sales representative is in charge of the act of sale and the relationship with customers\n\n     Marketing provides elements for sales support.\n\n3. ​The distinction between strategic and operational marketing\n\n   - Strategic marketing is devoted to the conception of the offer: \n\n     It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.\n\n   - Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.\n\n4. Market segmentation\n\n   The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups\n\n# Strategy\n\n**things important:**\n\n- Tools and Analysis Methods\n\n| Level              | Internal Analysis                        | External Analysis                        |\n| ------------------ | ---------------------------------------- | ---------------------------------------- |\n| Corporate strategy | <p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p> | PESTEL                                   |\n| Business strategy  | <p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p> | <p>Porter’s 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p> |\n\n- **Porter’s 5 forces mode**\n\n  - Suppliers                ->     induxtry competitors\n  - Potential entrants ->\n  - Buyers                     ->\n  - Substitutes             ->\n\n- Strategic group map\n\n  Something like that below:\n\n  ^(high)\n\n  |            O\n\n  |                                                   O\n\n  |(low)———————————————————————>(high)\n\n- Product life circle (PLC)\n\n  1. market development\n  2. growth\n  3. maturity\n  4. decline\n\n- Key success factors\n\n  The factors we must have to compete in a market.\n\n  The rule of the game common to all players\n\n  The necessary conditions to compete in a market.\n\n  1. Segnentation \n  2. DAS (战略分析方法)\n  3. Stracgical activities areas\n\n- **Value chain analysis**\n\n| Support activities     |\n| ---------------------- |\n| Firm infrastructure    |\n| HR                     |\n| Technology Development |\n| Procurement            |\n\n  **Primary activities:**\n\n| Inbound logistics | Outbound logistics | Operations | Marketing | Service | Design |\n| ----------------- | ------------------ | ---------- | --------- | ------- | ------ |\n| ……                | ……                 | ……         | ……        | ……      | ……     |\n\n- BCG matrix\n\n  market growth\n\n  ^(high)\n\n  |                       **Star**                                    **?**\n\n  |\n\n  |                        **Cow**                                   **Dog**(狗带)\n\n  |                                                \n\n  |(low)(high)———————————————————————>(low) market share\n\n1. Definition of strategy\n\n   A firm’s theory about how to excel in the game it is playing\n\n   A firm’s theory about how to create a unique position in the markets and industries within which it is operating\n\n2. Competitive advantage: doing different things\n\n3. Resource-based view (internal analysis)\n\n   - Human \n   - Physical \n   - Financial \n   - Organizational \n\n# Development of the firm\n\nGrowth orientations:\n\n1. Integration — 一体化\n2. Diversification — 多样化\n3. International strategies — 国际战略\n\nModes of growth:\n\n1. Internal = organic growth\n   - Based on own funds\n   - Slower\n2. External\n   - Rapid market share, or competency gain\n   - Accelerator to grow internationally\n\n# Organizational structure\n\n1. Simple structure\n\n   Owner/Director -> Employees\n\n   - Taylorism\n   - Fayol\n\n2. Complex structure\n\n   - Functional\n\n     Ex: Finance, R&D, Communication, IT\n\n     - Advantages:\n\n       – Specialization\n\n       – Accumulation of experience\n\n     - Disadvantages:\n\n       – Coordination and collaboration\n\n   - Divisional\n\n     每个产品都有自己独立的研发销售部门。\n\n     - Advantages\n\n       – Coordination between functions\n\n       – Responsibility of results better defined\n\n     - Disadvantages\n\n       – Problem of reinventing the wheel\n\n       – Internal competition\n\n   - Staff and line\n\n     专门分出一个“staff”来协调各部门。\n\n     - Advantages:\n\n       – Specialized expertise\n\n     - Disadvantages:\n\n       – Conflict between staff and line\n\n   - Matrix \n\n     产品部门和各专业职能垂直构建。\n\n     - Advantages\n\n       – Specialization and coordination are facilitated\n\n     - Disadvantages\n\n       – Each employee has two bosses  \n\n       – Decision making\n","source":"_posts/management-of-the-firm.md","raw":"---\ntitle: 企业管理复习笔记\ndate: 2016-12-10 17:48:37\ncategories: other\ntags: [management, firm]\n---\n\nThis is the note of learning \"Management of the firm\", with the book of GESTION (ecole centrale paris).\n\n# The firm and the management\n\n## the firm\n\n1. the definition of the firm\n\n   - The company is an economic entity or a place of creation of value\n   - It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.\n   - It uses (destroys) resources (mobilized from partners)\n   - it generates positive or negative externalities on its environment\n2. the different types of resources used by the company\n\n   - The work, provided by employees who sell their working time\n   - Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:\n     1. Tangible resources (实体资源)\n     2. Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands\n     3. the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment\n3. the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)\n\n   - Design or R&D\n   - Manufacturing or production\n   - Marketing / sales\n   - Finance\n\n\n4. the importance of the company's relations with its partners in the framework of contracts and with its stakeholders more generally.\n\n   - The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the company's share capital\n   - With the sectoral communities (suppliers, distributors ...), economic (financiers, prescribers, ...) and social (legislation, populations);\n\n\n## The management\n\n1. the definitions of management\n\n   - Manages a planning / organization function and a control function (animation and evaluation) of the activity.\n   - POCCC: prevoir, organiser, commander, coordonner, controle\n\n2. the difference between the operational mode and the strategic management mode\n\n   - manage operationally :\n\n     to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.\n\n   - manage strategically:\n\n     to make sure that you do the right things (doing the right thing)\n\n     That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the company's balance sheet (stock).\n\n# Marketing\n\n**Things important:**\n\n- PESTEL:\n  - ​Policy, especially government stability and regulations.\n  - Economic, in particular state of the economic situation and economic situation\n  - Sociocultural, particularly demography and changing lifestyles.\n  - Technological, in particular public and private R&D expenditure.\n  - Ecological, in particular legislation on the protection of the environment\n  - Legal, in particular the law of competition and the law of labor.\n\n- SWOT model: \n  - Strengths - Internal\n  - Weaknesses - Internal\n  - Opportunities - External\n  - Threats - External\n\n- Marketing mix (营销组合)\n\n  4P => 4C: \n\n  - Product => Consumer wants and needs\n  - Price => Cost\n  - Promotion => communication\n  - Place (distribution) => Convenience\n\n1. the definition of marketing\n\n   - Aggregate of methods to adapt its offer to changing demand\n     - Assess and anticipate relevant changes \n     - Understand customers' needs and desires\n     - Act on supply and its perception\n   - But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.\n\n\n2. The difference between marketing and sales\n\n   - The marketing aims to facilitate and accompany the act of sale,\n\n   - The marketing Collects / Synthesizes Customer and Market Information\n\n   - The marketing helps to define offers (products / services) adapted to the customers\n\n   - The sales representative is in charge of the act of sale and the relationship with customers\n\n     Marketing provides elements for sales support.\n\n3. ​The distinction between strategic and operational marketing\n\n   - Strategic marketing is devoted to the conception of the offer: \n\n     It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.\n\n   - Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.\n\n4. Market segmentation\n\n   The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups\n\n# Strategy\n\n**things important:**\n\n- Tools and Analysis Methods\n\n| Level              | Internal Analysis                        | External Analysis                        |\n| ------------------ | ---------------------------------------- | ---------------------------------------- |\n| Corporate strategy | <p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p> | PESTEL                                   |\n| Business strategy  | <p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p> | <p>Porter’s 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p> |\n\n- **Porter’s 5 forces mode**\n\n  - Suppliers                ->     induxtry competitors\n  - Potential entrants ->\n  - Buyers                     ->\n  - Substitutes             ->\n\n- Strategic group map\n\n  Something like that below:\n\n  ^(high)\n\n  |            O\n\n  |                                                   O\n\n  |(low)———————————————————————>(high)\n\n- Product life circle (PLC)\n\n  1. market development\n  2. growth\n  3. maturity\n  4. decline\n\n- Key success factors\n\n  The factors we must have to compete in a market.\n\n  The rule of the game common to all players\n\n  The necessary conditions to compete in a market.\n\n  1. Segnentation \n  2. DAS (战略分析方法)\n  3. Stracgical activities areas\n\n- **Value chain analysis**\n\n| Support activities     |\n| ---------------------- |\n| Firm infrastructure    |\n| HR                     |\n| Technology Development |\n| Procurement            |\n\n  **Primary activities:**\n\n| Inbound logistics | Outbound logistics | Operations | Marketing | Service | Design |\n| ----------------- | ------------------ | ---------- | --------- | ------- | ------ |\n| ……                | ……                 | ……         | ……        | ……      | ……     |\n\n- BCG matrix\n\n  market growth\n\n  ^(high)\n\n  |                       **Star**                                    **?**\n\n  |\n\n  |                        **Cow**                                   **Dog**(狗带)\n\n  |                                                \n\n  |(low)(high)———————————————————————>(low) market share\n\n1. Definition of strategy\n\n   A firm’s theory about how to excel in the game it is playing\n\n   A firm’s theory about how to create a unique position in the markets and industries within which it is operating\n\n2. Competitive advantage: doing different things\n\n3. Resource-based view (internal analysis)\n\n   - Human \n   - Physical \n   - Financial \n   - Organizational \n\n# Development of the firm\n\nGrowth orientations:\n\n1. Integration — 一体化\n2. Diversification — 多样化\n3. International strategies — 国际战略\n\nModes of growth:\n\n1. Internal = organic growth\n   - Based on own funds\n   - Slower\n2. External\n   - Rapid market share, or competency gain\n   - Accelerator to grow internationally\n\n# Organizational structure\n\n1. Simple structure\n\n   Owner/Director -> Employees\n\n   - Taylorism\n   - Fayol\n\n2. Complex structure\n\n   - Functional\n\n     Ex: Finance, R&D, Communication, IT\n\n     - Advantages:\n\n       – Specialization\n\n       – Accumulation of experience\n\n     - Disadvantages:\n\n       – Coordination and collaboration\n\n   - Divisional\n\n     每个产品都有自己独立的研发销售部门。\n\n     - Advantages\n\n       – Coordination between functions\n\n       – Responsibility of results better defined\n\n     - Disadvantages\n\n       – Problem of reinventing the wheel\n\n       – Internal competition\n\n   - Staff and line\n\n     专门分出一个“staff”来协调各部门。\n\n     - Advantages:\n\n       – Specialized expertise\n\n     - Disadvantages:\n\n       – Conflict between staff and line\n\n   - Matrix \n\n     产品部门和各专业职能垂直构建。\n\n     - Advantages\n\n       – Specialization and coordination are facilitated\n\n     - Disadvantages\n\n       – Each employee has two bosses  \n\n       – Decision making\n","slug":"management-of-the-firm","published":1,"updated":"2016-12-13T21:26:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkji2001ozemmm3klcc44","content":"<p>This is the note of learning “Management of the firm”, with the book of GESTION (ecole centrale paris).</p>\n<h1 id=\"The-firm-and-the-management\"><a href=\"#The-firm-and-the-management\" class=\"headerlink\" title=\"The firm and the management\"></a>The firm and the management</h1><h2 id=\"the-firm\"><a href=\"#the-firm\" class=\"headerlink\" title=\"the firm\"></a>the firm</h2><ol>\n<li><p>the definition of the firm</p>\n<ul>\n<li>The company is an economic entity or a place of creation of value</li>\n<li>It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.</li>\n<li>It uses (destroys) resources (mobilized from partners)</li>\n<li>it generates positive or negative externalities on its environment</li>\n</ul>\n</li>\n<li><p>the different types of resources used by the company</p>\n<ul>\n<li>The work, provided by employees who sell their working time</li>\n<li>Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:<ol>\n<li>Tangible resources (实体资源)</li>\n<li>Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands</li>\n<li>the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)</p>\n<ul>\n<li>Design or R&amp;D</li>\n<li>Manufacturing or production</li>\n<li>Marketing / sales</li>\n<li>Finance</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>the importance of the company’s relations with its partners in the framework of contracts and with its stakeholders more generally.</p>\n<ul>\n<li>The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the company’s share capital</li>\n<li>With the sectoral communities (suppliers, distributors …), economic (financiers, prescribers, …) and social (legislation, populations);</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"The-management\"><a href=\"#The-management\" class=\"headerlink\" title=\"The management\"></a>The management</h2><ol>\n<li><p>the definitions of management</p>\n<ul>\n<li>Manages a planning / organization function and a control function (animation and evaluation) of the activity.</li>\n<li>POCCC: prevoir, organiser, commander, coordonner, controle</li>\n</ul>\n</li>\n<li><p>the difference between the operational mode and the strategic management mode</p>\n<ul>\n<li><p>manage operationally :</p>\n<p>to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.</p>\n</li>\n<li><p>manage strategically:</p>\n<p>to make sure that you do the right things (doing the right thing)</p>\n<p>That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the company’s balance sheet (stock).</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Marketing\"><a href=\"#Marketing\" class=\"headerlink\" title=\"Marketing\"></a>Marketing</h1><p><strong>Things important:</strong></p>\n<ul>\n<li><p>PESTEL:</p>\n<ul>\n<li>​Policy, especially government stability and regulations.</li>\n<li>Economic, in particular state of the economic situation and economic situation</li>\n<li>Sociocultural, particularly demography and changing lifestyles.</li>\n<li>Technological, in particular public and private R&amp;D expenditure.</li>\n<li>Ecological, in particular legislation on the protection of the environment</li>\n<li>Legal, in particular the law of competition and the law of labor.</li>\n</ul>\n</li>\n<li><p>SWOT model: </p>\n<ul>\n<li>Strengths - Internal</li>\n<li>Weaknesses - Internal</li>\n<li>Opportunities - External</li>\n<li>Threats - External</li>\n</ul>\n</li>\n<li><p>Marketing mix (营销组合)</p>\n<p>4P =&gt; 4C: </p>\n<ul>\n<li>Product =&gt; Consumer wants and needs</li>\n<li>Price =&gt; Cost</li>\n<li>Promotion =&gt; communication</li>\n<li>Place (distribution) =&gt; Convenience</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li><p>the definition of marketing</p>\n<ul>\n<li>Aggregate of methods to adapt its offer to changing demand<ul>\n<li>Assess and anticipate relevant changes </li>\n<li>Understand customers’ needs and desires</li>\n<li>Act on supply and its perception</li>\n</ul>\n</li>\n<li>But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>The difference between marketing and sales</p>\n<ul>\n<li><p>The marketing aims to facilitate and accompany the act of sale,</p>\n</li>\n<li><p>The marketing Collects / Synthesizes Customer and Market Information</p>\n</li>\n<li><p>The marketing helps to define offers (products / services) adapted to the customers</p>\n</li>\n<li><p>The sales representative is in charge of the act of sale and the relationship with customers</p>\n<p>Marketing provides elements for sales support.</p>\n</li>\n</ul>\n</li>\n<li><p>​The distinction between strategic and operational marketing</p>\n<ul>\n<li><p>Strategic marketing is devoted to the conception of the offer: </p>\n<p>It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.</p>\n</li>\n<li><p>Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.</p>\n</li>\n</ul>\n</li>\n<li><p>Market segmentation</p>\n<p>The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups</p>\n</li>\n</ol>\n<h1 id=\"Strategy\"><a href=\"#Strategy\" class=\"headerlink\" title=\"Strategy\"></a>Strategy</h1><p><strong>things important:</strong></p>\n<ul>\n<li>Tools and Analysis Methods</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Level</th>\n<th>Internal Analysis</th>\n<th>External Analysis</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Corporate strategy</td>\n<td><p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p></td>\n<td>PESTEL</td>\n</tr>\n<tr>\n<td>Business strategy</td>\n<td><p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p></td>\n<td><p>Porter’s 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p><strong>Porter’s 5 forces mode</strong></p>\n<ul>\n<li>Suppliers                -&gt;     induxtry competitors</li>\n<li>Potential entrants -&gt;</li>\n<li>Buyers                     -&gt;</li>\n<li>Substitutes             -&gt;</li>\n</ul>\n</li>\n<li><p>Strategic group map</p>\n<p>Something like that below:</p>\n<p>^(high)</p>\n<p>|            O</p>\n<p>|                                                   O</p>\n<p>|(low)———————————————————————&gt;(high)</p>\n</li>\n<li><p>Product life circle (PLC)</p>\n<ol>\n<li>market development</li>\n<li>growth</li>\n<li>maturity</li>\n<li>decline</li>\n</ol>\n</li>\n<li><p>Key success factors</p>\n<p>The factors we must have to compete in a market.</p>\n<p>The rule of the game common to all players</p>\n<p>The necessary conditions to compete in a market.</p>\n<ol>\n<li>Segnentation </li>\n<li>DAS (战略分析方法)</li>\n<li>Stracgical activities areas</li>\n</ol>\n</li>\n<li><p><strong>Value chain analysis</strong></p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Support activities</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Firm infrastructure</td>\n</tr>\n<tr>\n<td>HR</td>\n</tr>\n<tr>\n<td>Technology Development</td>\n</tr>\n<tr>\n<td>Procurement</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>  <strong>Primary activities:</strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Inbound logistics</th>\n<th>Outbound logistics</th>\n<th>Operations</th>\n<th>Marketing</th>\n<th>Service</th>\n<th>Design</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>……</td>\n<td>……</td>\n<td>……</td>\n<td>……</td>\n<td>……</td>\n<td>……</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p>BCG matrix</p>\n<p>market growth</p>\n<p>^(high)</p>\n<p>|                       <strong>Star</strong>                                    <strong>?</strong></p>\n<p>|</p>\n<p>|                        <strong>Cow</strong>                                   <strong>Dog</strong>(狗带)</p>\n<p>|                                                </p>\n<p>|(low)(high)———————————————————————&gt;(low) market share</p>\n</li>\n</ul>\n<ol>\n<li><p>Definition of strategy</p>\n<p>A firm’s theory about how to excel in the game it is playing</p>\n<p>A firm’s theory about how to create a unique position in the markets and industries within which it is operating</p>\n</li>\n<li><p>Competitive advantage: doing different things</p>\n</li>\n<li><p>Resource-based view (internal analysis)</p>\n<ul>\n<li>Human </li>\n<li>Physical </li>\n<li>Financial </li>\n<li>Organizational </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Development-of-the-firm\"><a href=\"#Development-of-the-firm\" class=\"headerlink\" title=\"Development of the firm\"></a>Development of the firm</h1><p>Growth orientations:</p>\n<ol>\n<li>Integration — 一体化</li>\n<li>Diversification — 多样化</li>\n<li>International strategies — 国际战略</li>\n</ol>\n<p>Modes of growth:</p>\n<ol>\n<li>Internal = organic growth<ul>\n<li>Based on own funds</li>\n<li>Slower</li>\n</ul>\n</li>\n<li>External<ul>\n<li>Rapid market share, or competency gain</li>\n<li>Accelerator to grow internationally</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Organizational-structure\"><a href=\"#Organizational-structure\" class=\"headerlink\" title=\"Organizational structure\"></a>Organizational structure</h1><ol>\n<li><p>Simple structure</p>\n<p>Owner/Director -&gt; Employees</p>\n<ul>\n<li>Taylorism</li>\n<li>Fayol</li>\n</ul>\n</li>\n<li><p>Complex structure</p>\n<ul>\n<li><p>Functional</p>\n<p>Ex: Finance, R&amp;D, Communication, IT</p>\n<ul>\n<li><p>Advantages:</p>\n<p>– Specialization</p>\n<p>– Accumulation of experience</p>\n</li>\n<li><p>Disadvantages:</p>\n<p>– Coordination and collaboration</p>\n</li>\n</ul>\n</li>\n<li><p>Divisional</p>\n<p>每个产品都有自己独立的研发销售部门。</p>\n<ul>\n<li><p>Advantages</p>\n<p>– Coordination between functions</p>\n<p>– Responsibility of results better defined</p>\n</li>\n<li><p>Disadvantages</p>\n<p>– Problem of reinventing the wheel</p>\n<p>– Internal competition</p>\n</li>\n</ul>\n</li>\n<li><p>Staff and line</p>\n<p>专门分出一个“staff”来协调各部门。</p>\n<ul>\n<li><p>Advantages:</p>\n<p>– Specialized expertise</p>\n</li>\n<li><p>Disadvantages:</p>\n<p>– Conflict between staff and line</p>\n</li>\n</ul>\n</li>\n<li><p>Matrix </p>\n<p>产品部门和各专业职能垂直构建。</p>\n<ul>\n<li><p>Advantages</p>\n<p>– Specialization and coordination are facilitated</p>\n</li>\n<li><p>Disadvantages</p>\n<p>– Each employee has two bosses  </p>\n<p>– Decision making</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<p>This is the note of learning “Management of the firm”, with the book of GESTION (ecole centrale paris).</p>\n<h1 id=\"The-firm-and-the-management\"><a href=\"#The-firm-and-the-management\" class=\"headerlink\" title=\"The firm and the management\"></a>The firm and the management</h1><h2 id=\"the-firm\"><a href=\"#the-firm\" class=\"headerlink\" title=\"the firm\"></a>the firm</h2><ol>\n<li><p>the definition of the firm</p>\n<ul>\n<li>The company is an economic entity or a place of creation of value</li>\n<li>It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.</li>\n<li>It uses (destroys) resources (mobilized from partners)</li>\n<li>it generates positive or negative externalities on its environment</li>\n</ul>\n</li>\n<li><p>the different types of resources used by the company</p>\n<ul>\n<li>The work, provided by employees who sell their working time</li>\n<li>Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:<ol>\n<li>Tangible resources (实体资源)</li>\n<li>Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands</li>\n<li>the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)</p>\n<ul>\n<li>Design or R&amp;D</li>\n<li>Manufacturing or production</li>\n<li>Marketing / sales</li>\n<li>Finance</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>the importance of the company’s relations with its partners in the framework of contracts and with its stakeholders more generally.</p>\n<ul>\n<li>The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the company’s share capital</li>\n<li>With the sectoral communities (suppliers, distributors …), economic (financiers, prescribers, …) and social (legislation, populations);</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"The-management\"><a href=\"#The-management\" class=\"headerlink\" title=\"The management\"></a>The management</h2><ol>\n<li><p>the definitions of management</p>\n<ul>\n<li>Manages a planning / organization function and a control function (animation and evaluation) of the activity.</li>\n<li>POCCC: prevoir, organiser, commander, coordonner, controle</li>\n</ul>\n</li>\n<li><p>the difference between the operational mode and the strategic management mode</p>\n<ul>\n<li><p>manage operationally :</p>\n<p>to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.</p>\n</li>\n<li><p>manage strategically:</p>\n<p>to make sure that you do the right things (doing the right thing)</p>\n<p>That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the company’s balance sheet (stock).</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Marketing\"><a href=\"#Marketing\" class=\"headerlink\" title=\"Marketing\"></a>Marketing</h1><p><strong>Things important:</strong></p>\n<ul>\n<li><p>PESTEL:</p>\n<ul>\n<li>​Policy, especially government stability and regulations.</li>\n<li>Economic, in particular state of the economic situation and economic situation</li>\n<li>Sociocultural, particularly demography and changing lifestyles.</li>\n<li>Technological, in particular public and private R&amp;D expenditure.</li>\n<li>Ecological, in particular legislation on the protection of the environment</li>\n<li>Legal, in particular the law of competition and the law of labor.</li>\n</ul>\n</li>\n<li><p>SWOT model: </p>\n<ul>\n<li>Strengths - Internal</li>\n<li>Weaknesses - Internal</li>\n<li>Opportunities - External</li>\n<li>Threats - External</li>\n</ul>\n</li>\n<li><p>Marketing mix (营销组合)</p>\n<p>4P =&gt; 4C: </p>\n<ul>\n<li>Product =&gt; Consumer wants and needs</li>\n<li>Price =&gt; Cost</li>\n<li>Promotion =&gt; communication</li>\n<li>Place (distribution) =&gt; Convenience</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li><p>the definition of marketing</p>\n<ul>\n<li>Aggregate of methods to adapt its offer to changing demand<ul>\n<li>Assess and anticipate relevant changes </li>\n<li>Understand customers’ needs and desires</li>\n<li>Act on supply and its perception</li>\n</ul>\n</li>\n<li>But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.</li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>The difference between marketing and sales</p>\n<ul>\n<li><p>The marketing aims to facilitate and accompany the act of sale,</p>\n</li>\n<li><p>The marketing Collects / Synthesizes Customer and Market Information</p>\n</li>\n<li><p>The marketing helps to define offers (products / services) adapted to the customers</p>\n</li>\n<li><p>The sales representative is in charge of the act of sale and the relationship with customers</p>\n<p>Marketing provides elements for sales support.</p>\n</li>\n</ul>\n</li>\n<li><p>​The distinction between strategic and operational marketing</p>\n<ul>\n<li><p>Strategic marketing is devoted to the conception of the offer: </p>\n<p>It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.</p>\n</li>\n<li><p>Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.</p>\n</li>\n</ul>\n</li>\n<li><p>Market segmentation</p>\n<p>The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups</p>\n</li>\n</ol>\n<h1 id=\"Strategy\"><a href=\"#Strategy\" class=\"headerlink\" title=\"Strategy\"></a>Strategy</h1><p><strong>things important:</strong></p>\n<ul>\n<li>Tools and Analysis Methods</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Level</th>\n<th>Internal Analysis</th>\n<th>External Analysis</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Corporate strategy</td>\n<td><p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p></td>\n<td>PESTEL</td>\n</tr>\n<tr>\n<td>Business strategy</td>\n<td><p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p></td>\n<td><p>Porter’s 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p></td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p><strong>Porter’s 5 forces mode</strong></p>\n<ul>\n<li>Suppliers                -&gt;     induxtry competitors</li>\n<li>Potential entrants -&gt;</li>\n<li>Buyers                     -&gt;</li>\n<li>Substitutes             -&gt;</li>\n</ul>\n</li>\n<li><p>Strategic group map</p>\n<p>Something like that below:</p>\n<p>^(high)</p>\n<p>|            O</p>\n<p>|                                                   O</p>\n<p>|(low)———————————————————————&gt;(high)</p>\n</li>\n<li><p>Product life circle (PLC)</p>\n<ol>\n<li>market development</li>\n<li>growth</li>\n<li>maturity</li>\n<li>decline</li>\n</ol>\n</li>\n<li><p>Key success factors</p>\n<p>The factors we must have to compete in a market.</p>\n<p>The rule of the game common to all players</p>\n<p>The necessary conditions to compete in a market.</p>\n<ol>\n<li>Segnentation </li>\n<li>DAS (战略分析方法)</li>\n<li>Stracgical activities areas</li>\n</ol>\n</li>\n<li><p><strong>Value chain analysis</strong></p>\n</li>\n</ul>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Support activities</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>Firm infrastructure</td>\n</tr>\n<tr>\n<td>HR</td>\n</tr>\n<tr>\n<td>Technology Development</td>\n</tr>\n<tr>\n<td>Procurement</td>\n</tr>\n</tbody>\n</table>\n</div>\n<p>  <strong>Primary activities:</strong></p>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>Inbound logistics</th>\n<th>Outbound logistics</th>\n<th>Operations</th>\n<th>Marketing</th>\n<th>Service</th>\n<th>Design</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>……</td>\n<td>……</td>\n<td>……</td>\n<td>……</td>\n<td>……</td>\n<td>……</td>\n</tr>\n</tbody>\n</table>\n</div>\n<ul>\n<li><p>BCG matrix</p>\n<p>market growth</p>\n<p>^(high)</p>\n<p>|                       <strong>Star</strong>                                    <strong>?</strong></p>\n<p>|</p>\n<p>|                        <strong>Cow</strong>                                   <strong>Dog</strong>(狗带)</p>\n<p>|                                                </p>\n<p>|(low)(high)———————————————————————&gt;(low) market share</p>\n</li>\n</ul>\n<ol>\n<li><p>Definition of strategy</p>\n<p>A firm’s theory about how to excel in the game it is playing</p>\n<p>A firm’s theory about how to create a unique position in the markets and industries within which it is operating</p>\n</li>\n<li><p>Competitive advantage: doing different things</p>\n</li>\n<li><p>Resource-based view (internal analysis)</p>\n<ul>\n<li>Human </li>\n<li>Physical </li>\n<li>Financial </li>\n<li>Organizational </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Development-of-the-firm\"><a href=\"#Development-of-the-firm\" class=\"headerlink\" title=\"Development of the firm\"></a>Development of the firm</h1><p>Growth orientations:</p>\n<ol>\n<li>Integration — 一体化</li>\n<li>Diversification — 多样化</li>\n<li>International strategies — 国际战略</li>\n</ol>\n<p>Modes of growth:</p>\n<ol>\n<li>Internal = organic growth<ul>\n<li>Based on own funds</li>\n<li>Slower</li>\n</ul>\n</li>\n<li>External<ul>\n<li>Rapid market share, or competency gain</li>\n<li>Accelerator to grow internationally</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Organizational-structure\"><a href=\"#Organizational-structure\" class=\"headerlink\" title=\"Organizational structure\"></a>Organizational structure</h1><ol>\n<li><p>Simple structure</p>\n<p>Owner/Director -&gt; Employees</p>\n<ul>\n<li>Taylorism</li>\n<li>Fayol</li>\n</ul>\n</li>\n<li><p>Complex structure</p>\n<ul>\n<li><p>Functional</p>\n<p>Ex: Finance, R&amp;D, Communication, IT</p>\n<ul>\n<li><p>Advantages:</p>\n<p>– Specialization</p>\n<p>– Accumulation of experience</p>\n</li>\n<li><p>Disadvantages:</p>\n<p>– Coordination and collaboration</p>\n</li>\n</ul>\n</li>\n<li><p>Divisional</p>\n<p>每个产品都有自己独立的研发销售部门。</p>\n<ul>\n<li><p>Advantages</p>\n<p>– Coordination between functions</p>\n<p>– Responsibility of results better defined</p>\n</li>\n<li><p>Disadvantages</p>\n<p>– Problem of reinventing the wheel</p>\n<p>– Internal competition</p>\n</li>\n</ul>\n</li>\n<li><p>Staff and line</p>\n<p>专门分出一个“staff”来协调各部门。</p>\n<ul>\n<li><p>Advantages:</p>\n<p>– Specialized expertise</p>\n</li>\n<li><p>Disadvantages:</p>\n<p>– Conflict between staff and line</p>\n</li>\n</ul>\n</li>\n<li><p>Matrix </p>\n<p>产品部门和各专业职能垂直构建。</p>\n<ul>\n<li><p>Advantages</p>\n<p>– Specialization and coordination are facilitated</p>\n</li>\n<li><p>Disadvantages</p>\n<p>– Each employee has two bosses  </p>\n<p>– Decision making</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n"},{"title":"proba-ch2 随机变量","date":"2016-12-01T11:17:33.000Z","_content":"\n- ​\n\n$$\n\\pi-system\n$$\n\n- R上的概率测度\n\n  - 分布函数 la fonction de repartition\n    $$\n    F:x\\xrightarrow{}F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] }{f(t).\\lambda(dt)}\n    $$\n\n  - 定理\n\n    如果F是分布函数，则当且仅当满足以下三个条件。\n    $$\n    (i) F 递增\\\\(ii)F 右连续\\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}\n    $$\n\n  - 性质\n    $$\n    P(\\{x\\}) = F(x) - F(x-)\n    $$\n\n- R^N上的概率测度\n\n  -  定义\n  $$\n    F:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )\n  $$\n\n  - 定义\n    $$\n    P(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}\n    $$\n\n- 随机变量\n\n  - 定义\n    $$\n    Soit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}\n    $$\n    X就是一个随机变量\n\n  - 定义 tribu engendree par X\n    $$\n    X^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)\n    $$\n\n- 随机变量的loi\n\n  - 定义\n    $$\n    \\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))\n    $$\n\n- 积分\n\n  - 数学期望定义\n    $$\n    E[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}\n    $$\n\n  - 定理\n    $$\n    (X_n)_{n\\in N} 是随机变量\n    $$\n\n    - 单调趋向性：若Xn非负且趋于X，则\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n    - Fatou引理：若Xn非负\n      $$\n      E[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}\n      $$\n\n    - convergence dominee: 若limXn = X p.s 若存在Z in L1，且|Xn|<=Z，则\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n  - 性质(Inegalite de Markov)\n\n    若X是随机变量并admettant un moment d'ordre 1, 对于实数a>0\n    $$\n    P(|X| \\geq a) \\leq \\frac{E[|X|]}{a}\n    $$\n\n  - 转化定理\n    $$\n    E[h(X)] = \\int_E{h(x)P_X(dx)}\n    $$\n\n  - 定义\n  $$\n  un\\ moment\\ d'ordre\\ n: \\int_\\Omega{|X|^ndP} < \\infty\n  $$\n\n  - 性质，若0<p<q，可以得到Lq被Lp包含。\n\n  - 定义方差，前面说过了\n\n    - $$\n      Var(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}\n      $$\n\n    - 若X几乎处处等于同一个常数，当仅当Var(X) = 0\n\n  - 定理，与离散相似的\n    $$\n    E[h(X)] = \\int_E{h(x)f_X(dx)}\n    $$\n    特别的\n    $$\n    P(X \\in A) = E[1_{\\{X\\in A\\}}] = \\int_A{f_X(dx)}\n    $$\n\n- Vecteurs aleatoires\n\n  X = (X1,…,XN) 与多元离散随机变量类似。\n\n  - 协方差\n    $$\n    Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]\n    $$\n\n    - 性质\n      $$\n      Cov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)\n      $$\n\n  - 相关系数\n    $$\n    \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1\n    $$\n\n  - 改变变量\n    $$\n    \\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)\n    $$\n\n  - 边际概率，顾名思义，略\n\n- 独立变量\n\n  定义略\n\n  - 定理，满足下列条件之一，则XY独立\n\n    1. 对于所有A，B\n    $$\n      P(X \\in A, Y\\in B) = P(X\\in A)\n    $$\n\n    2. 对于所有f，g\n    $$\n      E[f(X)g(Y)] = E[f(X)] E[g(Y)]\n    $$\n\n    3. 对于所有f，g，f(X)和g(Y)是独立的\n\n  - 性质\n    $$\n    \\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.\n    $$\n    $$\n    \\text{注：对于XY相互独立，} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\n    P_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)\n    $$\n\n  - 定理，对于随机变量XY，他们相互独立，当且仅当\n    $$\n    \\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)\n    $$\n\n  - 定理，对于(X,Y)在lebesgue测度上绝对连续，XY相互独立当且仅当\n    $$\n    \\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)\n    $$\n\n  - 性质，XY admettant un moment d'ordre 1, 相互独立，则\n\n  - $$\n    E[XY]=E[X]E[Y]\n    $$\n\n  - 性质，XY admettant un moment d'ordre 2, Cov(X,Y)=0, 则\n\n  - $$\n    Var(X+Y) =Var(X) + Var(Y)\n    $$\n\n    ​\n","source":"_posts/proba-ch2.md","raw":"---\ntitle: proba-ch2 随机变量\ndate: 2016-12-01 12:17:33\ncategories: math\ntags: [probability, math, aleatoire]\n---\n\n- ​\n\n$$\n\\pi-system\n$$\n\n- R上的概率测度\n\n  - 分布函数 la fonction de repartition\n    $$\n    F:x\\xrightarrow{}F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] }{f(t).\\lambda(dt)}\n    $$\n\n  - 定理\n\n    如果F是分布函数，则当且仅当满足以下三个条件。\n    $$\n    (i) F 递增\\\\(ii)F 右连续\\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}\n    $$\n\n  - 性质\n    $$\n    P(\\{x\\}) = F(x) - F(x-)\n    $$\n\n- R^N上的概率测度\n\n  -  定义\n  $$\n    F:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )\n  $$\n\n  - 定义\n    $$\n    P(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}\n    $$\n\n- 随机变量\n\n  - 定义\n    $$\n    Soit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}\n    $$\n    X就是一个随机变量\n\n  - 定义 tribu engendree par X\n    $$\n    X^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)\n    $$\n\n- 随机变量的loi\n\n  - 定义\n    $$\n    \\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))\n    $$\n\n- 积分\n\n  - 数学期望定义\n    $$\n    E[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}\n    $$\n\n  - 定理\n    $$\n    (X_n)_{n\\in N} 是随机变量\n    $$\n\n    - 单调趋向性：若Xn非负且趋于X，则\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n    - Fatou引理：若Xn非负\n      $$\n      E[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}\n      $$\n\n    - convergence dominee: 若limXn = X p.s 若存在Z in L1，且|Xn|<=Z，则\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n  - 性质(Inegalite de Markov)\n\n    若X是随机变量并admettant un moment d'ordre 1, 对于实数a>0\n    $$\n    P(|X| \\geq a) \\leq \\frac{E[|X|]}{a}\n    $$\n\n  - 转化定理\n    $$\n    E[h(X)] = \\int_E{h(x)P_X(dx)}\n    $$\n\n  - 定义\n  $$\n  un\\ moment\\ d'ordre\\ n: \\int_\\Omega{|X|^ndP} < \\infty\n  $$\n\n  - 性质，若0<p<q，可以得到Lq被Lp包含。\n\n  - 定义方差，前面说过了\n\n    - $$\n      Var(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}\n      $$\n\n    - 若X几乎处处等于同一个常数，当仅当Var(X) = 0\n\n  - 定理，与离散相似的\n    $$\n    E[h(X)] = \\int_E{h(x)f_X(dx)}\n    $$\n    特别的\n    $$\n    P(X \\in A) = E[1_{\\{X\\in A\\}}] = \\int_A{f_X(dx)}\n    $$\n\n- Vecteurs aleatoires\n\n  X = (X1,…,XN) 与多元离散随机变量类似。\n\n  - 协方差\n    $$\n    Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]\n    $$\n\n    - 性质\n      $$\n      Cov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)\n      $$\n\n  - 相关系数\n    $$\n    \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1\n    $$\n\n  - 改变变量\n    $$\n    \\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)\n    $$\n\n  - 边际概率，顾名思义，略\n\n- 独立变量\n\n  定义略\n\n  - 定理，满足下列条件之一，则XY独立\n\n    1. 对于所有A，B\n    $$\n      P(X \\in A, Y\\in B) = P(X\\in A)\n    $$\n\n    2. 对于所有f，g\n    $$\n      E[f(X)g(Y)] = E[f(X)] E[g(Y)]\n    $$\n\n    3. 对于所有f，g，f(X)和g(Y)是独立的\n\n  - 性质\n    $$\n    \\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.\n    $$\n    $$\n    \\text{注：对于XY相互独立，} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\n    P_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)\n    $$\n\n  - 定理，对于随机变量XY，他们相互独立，当且仅当\n    $$\n    \\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)\n    $$\n\n  - 定理，对于(X,Y)在lebesgue测度上绝对连续，XY相互独立当且仅当\n    $$\n    \\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)\n    $$\n\n  - 性质，XY admettant un moment d'ordre 1, 相互独立，则\n\n  - $$\n    E[XY]=E[X]E[Y]\n    $$\n\n  - 性质，XY admettant un moment d'ordre 2, Cov(X,Y)=0, 则\n\n  - $$\n    Var(X+Y) =Var(X) + Var(Y)\n    $$\n\n    ​\n","slug":"proba-ch2","published":1,"updated":"2016-12-01T13:44:00.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkji4001rzemmeys0t28x","content":"<ul>\n<li>​</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\pi-system</script><ul>\n<li><p>R上的概率测度</p>\n<ul>\n<li><p>分布函数 la fonction de repartition</p>\n<script type=\"math/tex; mode=display\">\nF:x\\xrightarrow{}F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] }{f(t).\\lambda(dt)}</script></li>\n<li><p>定理</p>\n<p>如果F是分布函数，则当且仅当满足以下三个条件。</p>\n<script type=\"math/tex; mode=display\">\n(i) F 递增\\\\(ii)F 右连续\\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}</script></li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\nP(\\{x\\}) = F(x) - F(x-)</script></li>\n</ul>\n</li>\n<li><p>R^N上的概率测度</p>\n<ul>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nF:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )</script></li>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nP(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}</script></li>\n</ul>\n</li>\n<li><p>随机变量</p>\n<ul>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nSoit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}</script><p>X就是一个随机变量</p>\n</li>\n<li><p>定义 tribu engendree par X</p>\n<script type=\"math/tex; mode=display\">\nX^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)</script></li>\n</ul>\n</li>\n<li><p>随机变量的loi</p>\n<ul>\n<li>定义<script type=\"math/tex; mode=display\">\n\\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))</script></li>\n</ul>\n</li>\n<li><p>积分</p>\n<ul>\n<li><p>数学期望定义</p>\n<script type=\"math/tex; mode=display\">\nE[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}</script></li>\n<li><p>定理</p>\n<script type=\"math/tex; mode=display\">\n(X_n)_{n\\in N} 是随机变量</script><ul>\n<li><p>单调趋向性：若Xn非负且趋于X，则</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]</script></li>\n<li><p>Fatou引理：若Xn非负</p>\n<script type=\"math/tex; mode=display\">\nE[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}</script></li>\n<li><p>convergence dominee: 若limXn = X p.s 若存在Z in L1，且|Xn|&lt;=Z，则</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]</script></li>\n</ul>\n</li>\n<li><p>性质(Inegalite de Markov)</p>\n<p>若X是随机变量并admettant un moment d’ordre 1, 对于实数a&gt;0</p>\n<script type=\"math/tex; mode=display\">\nP(|X| \\geq a) \\leq \\frac{E[|X|]}{a}</script></li>\n<li><p>转化定理</p>\n<script type=\"math/tex; mode=display\">\nE[h(X)] = \\int_E{h(x)P_X(dx)}</script></li>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nun\\ moment\\ d'ordre\\ n: \\int_\\Omega{|X|^ndP} < \\infty</script></li>\n<li><p>性质，若0&lt;p&lt;q，可以得到Lq被Lp包含。</p>\n</li>\n<li><p>定义方差，前面说过了</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\nVar(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}</script></li>\n<li><p>若X几乎处处等于同一个常数，当仅当Var(X) = 0</p>\n</li>\n</ul>\n</li>\n<li><p>定理，与离散相似的</p>\n<script type=\"math/tex; mode=display\">\nE[h(X)] = \\int_E{h(x)f_X(dx)}</script><p>特别的</p>\n<script type=\"math/tex; mode=display\">\nP(X \\in A) = E[1_{\\{X\\in A\\}}] = \\int_A{f_X(dx)}</script></li>\n</ul>\n</li>\n<li><p>Vecteurs aleatoires</p>\n<p>X = (X1,…,XN) 与多元离散随机变量类似。</p>\n<ul>\n<li><p>协方差</p>\n<script type=\"math/tex; mode=display\">\nCov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]</script><ul>\n<li>性质<script type=\"math/tex; mode=display\">\nCov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)</script></li>\n</ul>\n</li>\n<li><p>相关系数</p>\n<script type=\"math/tex; mode=display\">\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1</script></li>\n<li><p>改变变量</p>\n<script type=\"math/tex; mode=display\">\n\\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)</script></li>\n<li><p>边际概率，顾名思义，略</p>\n</li>\n</ul>\n</li>\n<li><p>独立变量</p>\n<p>定义略</p>\n<ul>\n<li><p>定理，满足下列条件之一，则XY独立</p>\n<ol>\n<li><p>对于所有A，B</p>\n<script type=\"math/tex; mode=display\">\nP(X \\in A, Y\\in B) = P(X\\in A)</script></li>\n<li><p>对于所有f，g</p>\n<script type=\"math/tex; mode=display\">\nE[f(X)g(Y)] = E[f(X)] E[g(Y)]</script></li>\n<li><p>对于所有f，g，f(X)和g(Y)是独立的</p>\n</li>\n</ol>\n</li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\n\\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.</script><script type=\"math/tex; mode=display\">\n\\text{注：对于XY相互独立，} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\nP_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)</script></li>\n<li><p>定理，对于随机变量XY，他们相互独立，当且仅当</p>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)</script></li>\n<li><p>定理，对于(X,Y)在lebesgue测度上绝对连续，XY相互独立当且仅当</p>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)</script></li>\n<li><p>性质，XY admettant un moment d’ordre 1, 相互独立，则</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\nE[XY]=E[X]E[Y]</script></li>\n<li><p>性质，XY admettant un moment d’ordre 2, Cov(X,Y)=0, 则</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\nVar(X+Y) =Var(X) + Var(Y)</script><p>​</p>\n</li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<ul>\n<li>​</li>\n</ul>\n<script type=\"math/tex; mode=display\">\n\\pi-system</script><ul>\n<li><p>R上的概率测度</p>\n<ul>\n<li><p>分布函数 la fonction de repartition</p>\n<script type=\"math/tex; mode=display\">\nF:x\\xrightarrow{}F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] }{f(t).\\lambda(dt)}</script></li>\n<li><p>定理</p>\n<p>如果F是分布函数，则当且仅当满足以下三个条件。</p>\n<script type=\"math/tex; mode=display\">\n(i) F 递增\\\\(ii)F 右连续\\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}</script></li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\nP(\\{x\\}) = F(x) - F(x-)</script></li>\n</ul>\n</li>\n<li><p>R^N上的概率测度</p>\n<ul>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nF:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )</script></li>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nP(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}</script></li>\n</ul>\n</li>\n<li><p>随机变量</p>\n<ul>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nSoit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}</script><p>X就是一个随机变量</p>\n</li>\n<li><p>定义 tribu engendree par X</p>\n<script type=\"math/tex; mode=display\">\nX^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)</script></li>\n</ul>\n</li>\n<li><p>随机变量的loi</p>\n<ul>\n<li>定义<script type=\"math/tex; mode=display\">\n\\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))</script></li>\n</ul>\n</li>\n<li><p>积分</p>\n<ul>\n<li><p>数学期望定义</p>\n<script type=\"math/tex; mode=display\">\nE[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}</script></li>\n<li><p>定理</p>\n<script type=\"math/tex; mode=display\">\n(X_n)_{n\\in N} 是随机变量</script><ul>\n<li><p>单调趋向性：若Xn非负且趋于X，则</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]</script></li>\n<li><p>Fatou引理：若Xn非负</p>\n<script type=\"math/tex; mode=display\">\nE[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}</script></li>\n<li><p>convergence dominee: 若limXn = X p.s 若存在Z in L1，且|Xn|&lt;=Z，则</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]</script></li>\n</ul>\n</li>\n<li><p>性质(Inegalite de Markov)</p>\n<p>若X是随机变量并admettant un moment d’ordre 1, 对于实数a&gt;0</p>\n<script type=\"math/tex; mode=display\">\nP(|X| \\geq a) \\leq \\frac{E[|X|]}{a}</script></li>\n<li><p>转化定理</p>\n<script type=\"math/tex; mode=display\">\nE[h(X)] = \\int_E{h(x)P_X(dx)}</script></li>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nun\\ moment\\ d'ordre\\ n: \\int_\\Omega{|X|^ndP} < \\infty</script></li>\n<li><p>性质，若0&lt;p&lt;q，可以得到Lq被Lp包含。</p>\n</li>\n<li><p>定义方差，前面说过了</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\nVar(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}</script></li>\n<li><p>若X几乎处处等于同一个常数，当仅当Var(X) = 0</p>\n</li>\n</ul>\n</li>\n<li><p>定理，与离散相似的</p>\n<script type=\"math/tex; mode=display\">\nE[h(X)] = \\int_E{h(x)f_X(dx)}</script><p>特别的</p>\n<script type=\"math/tex; mode=display\">\nP(X \\in A) = E[1_{\\{X\\in A\\}}] = \\int_A{f_X(dx)}</script></li>\n</ul>\n</li>\n<li><p>Vecteurs aleatoires</p>\n<p>X = (X1,…,XN) 与多元离散随机变量类似。</p>\n<ul>\n<li><p>协方差</p>\n<script type=\"math/tex; mode=display\">\nCov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]</script><ul>\n<li>性质<script type=\"math/tex; mode=display\">\nCov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)</script></li>\n</ul>\n</li>\n<li><p>相关系数</p>\n<script type=\"math/tex; mode=display\">\n\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1</script></li>\n<li><p>改变变量</p>\n<script type=\"math/tex; mode=display\">\n\\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)</script></li>\n<li><p>边际概率，顾名思义，略</p>\n</li>\n</ul>\n</li>\n<li><p>独立变量</p>\n<p>定义略</p>\n<ul>\n<li><p>定理，满足下列条件之一，则XY独立</p>\n<ol>\n<li><p>对于所有A，B</p>\n<script type=\"math/tex; mode=display\">\nP(X \\in A, Y\\in B) = P(X\\in A)</script></li>\n<li><p>对于所有f，g</p>\n<script type=\"math/tex; mode=display\">\nE[f(X)g(Y)] = E[f(X)] E[g(Y)]</script></li>\n<li><p>对于所有f，g，f(X)和g(Y)是独立的</p>\n</li>\n</ol>\n</li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\n\\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.</script><script type=\"math/tex; mode=display\">\n\\text{注：对于XY相互独立，} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\nP_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)</script></li>\n<li><p>定理，对于随机变量XY，他们相互独立，当且仅当</p>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)</script></li>\n<li><p>定理，对于(X,Y)在lebesgue测度上绝对连续，XY相互独立当且仅当</p>\n<script type=\"math/tex; mode=display\">\n\\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)</script></li>\n<li><p>性质，XY admettant un moment d’ordre 1, 相互独立，则</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\nE[XY]=E[X]E[Y]</script></li>\n<li><p>性质，XY admettant un moment d’ordre 2, Cov(X,Y)=0, 则</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\nVar(X+Y) =Var(X) + Var(Y)</script><p>​</p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"participe présent et gérondif","date":"2016-12-06T11:31:56.000Z","_content":"\n# 现在分词(le participe présent)\n\n## 1. 构成\n现在分词没有人称和数的变化。反身动词的现在分词仍然保留原反身动词的反身代词。\n\n去掉直陈式第一人称复数的词尾-ons，另加-ant \n\n- faire : nous faisons \n\n特殊情况：\n- etre-etant \n- savoir-sachant\n\n## 2. 简述用法\n1. 用作定语，紧接在被修饰词之后，相当于qui引导的从句\n   - L'étranger cherche à trouver quelqu'un **connaissant** (=qui conaisse) à la fois français et l'anglais.\n2. 表原因、时间等，作为状语\n   - **Voyant**(=Comme elle voit) que tout le monde est dejà assis,elle va vite à sa place.\n   - **Ayant**(=Comme il a) mal à la tete,il décide de rester au lit.\n\n## 3. 细分\n### I. 现在分词形容词特性的表现\n许多现在分词已经转化成形容词，有性数变化，可以作为定于或表语。\n1. 动词形容词表示一种状态或性质，后不跟宾语或状语\n   - Ses yeux **brillants** disent la convoitises. 他那双闪光的眼睛流露出他贪婪的本性。\n   - Je l'ai trouvé toute **tremblante**. 我发现她浑身颤抖。\n\n2. 在一些习惯性搭配中表示一些潜在的主语\n\n   - Une seance **payante** (=où l'on paie) 一场要收费的演出。\n   - une collation **soupante** (=si copieuse qu'elle tient lieu de souper) 一顿丰盛的小吃\n\n   这里分词的主语与它的被修饰语不同。\n\n3. 少数已变成了纯粹的形容词，书写有所区别\n\n| 现在分词       | 形容词       |\n| ---------- | --------- |\n| provoquant | provocant |\n| fatiguant  | fatigant  |\n| vaquant    | vacant    |\n| naviguant  | navigant  |\n\n\n### II. 现在分词动词特性的表现\n\n现在分词具有动词的性质，可以有宾语或状语。\n\n1. 代替qui引导的关系从句\n   - C'est un film **captivant** les spectateurs. 这是一部非常吸引观众的影片。\n   - Je le vois **lisant**. 我看见他在念书。\n2. 起状语作用\n   - **Prenant** l'escabeau, il s'offoree d'atteindre le dernier rayon. 他拿了一把小梯子乡尽力够上最后一格。\n   - **Croyant** le bureau vide, il entra. 他以为办公室没人所以就进去了。\n3. 表示并列动作\n   - Le train repartit, **courant** vers le Midi. 火车又开动了，向南方驶去。\n4. 依附于另一主语，构成独立分词从句\n   - Midi **sonnant**, on se met à table. 钟敲十二时，我们都上桌用餐。\n\n\n\n\n# 副动词(le gérondif)\n\n## 1. 构成\n副动词没有人称、性数变化\n\n在现在分词前加en就构成副动词 \n\n- faire : en faisant\n\n注：ayant、étant前不能用en，不能构成副动词。\n\n## 2. 用法\n1. 时间状语，表示动作的同时性\n   - N'oubliez pas de fermer la port **en sortant**.出去时别忘了关门。\n   - Ne lis pas **en mangeant**. 不要以便吃饭以一边看书\n2. 方式状语\n   - Elle arriva **en courant**. 她跑来了\n3. 条件状语\n   - **En se levant** plus tot le matin, il n'arrivera pas en retard. 如果早上起的早点，他就不会迟到了。\n4. 让步状语\n   - **En voyant** critiquant, il n'avait nulle intention de nous décourager. 他尽管批评了我们，但毫无使我们气馁之意。\n5. 原因状语\n   - **En voyant** son embarras, l'agent se fit plus aimable. 警察见他不知所措，就变得更加和蔼了。\n\n**\\*副动词表示的动作的延续**\n\n副动词可以和aller合用，表示延续发展的动作，介词en可以省略。\n\n- Sa vue va **en s'affaiblissant**. 他的视力日益衰退。\n\n## 3. 副动词的强化\n\n1. Tous + 副动词表示强化，这种结构常见于书面。\n2. Rien que + 副动词表示“只要…”\n\n\n\n\n\n# 现在分词和副动词的异同\n\n## 共同点\n\n它们在作状语时应和主体谓语共一个主语，并和主体谓语发生的时间同步。\n\n## 不同点\n\n1. 现在分词动作的施动者不一定是该句的主语，而副动词一定是所在句子的主语。\n\n\\*在一些从古法语流传迄今的成语、谚语等之中，副动词也可能拥有不同的主语，而这种主语是不明显的。\n\n- La fortune vient **en dormant**. 飞来横财。\n\n\n2. 见具体用法\n\n","source":"_posts/participe-present-et-gerondif.md","raw":"---\ntitle: participe présent et gérondif\ndate: 2016-12-06 12:31:56\ncategories: francais\ntags: [francais, language]\n---\n\n# 现在分词(le participe présent)\n\n## 1. 构成\n现在分词没有人称和数的变化。反身动词的现在分词仍然保留原反身动词的反身代词。\n\n去掉直陈式第一人称复数的词尾-ons，另加-ant \n\n- faire : nous faisons \n\n特殊情况：\n- etre-etant \n- savoir-sachant\n\n## 2. 简述用法\n1. 用作定语，紧接在被修饰词之后，相当于qui引导的从句\n   - L'étranger cherche à trouver quelqu'un **connaissant** (=qui conaisse) à la fois français et l'anglais.\n2. 表原因、时间等，作为状语\n   - **Voyant**(=Comme elle voit) que tout le monde est dejà assis,elle va vite à sa place.\n   - **Ayant**(=Comme il a) mal à la tete,il décide de rester au lit.\n\n## 3. 细分\n### I. 现在分词形容词特性的表现\n许多现在分词已经转化成形容词，有性数变化，可以作为定于或表语。\n1. 动词形容词表示一种状态或性质，后不跟宾语或状语\n   - Ses yeux **brillants** disent la convoitises. 他那双闪光的眼睛流露出他贪婪的本性。\n   - Je l'ai trouvé toute **tremblante**. 我发现她浑身颤抖。\n\n2. 在一些习惯性搭配中表示一些潜在的主语\n\n   - Une seance **payante** (=où l'on paie) 一场要收费的演出。\n   - une collation **soupante** (=si copieuse qu'elle tient lieu de souper) 一顿丰盛的小吃\n\n   这里分词的主语与它的被修饰语不同。\n\n3. 少数已变成了纯粹的形容词，书写有所区别\n\n| 现在分词       | 形容词       |\n| ---------- | --------- |\n| provoquant | provocant |\n| fatiguant  | fatigant  |\n| vaquant    | vacant    |\n| naviguant  | navigant  |\n\n\n### II. 现在分词动词特性的表现\n\n现在分词具有动词的性质，可以有宾语或状语。\n\n1. 代替qui引导的关系从句\n   - C'est un film **captivant** les spectateurs. 这是一部非常吸引观众的影片。\n   - Je le vois **lisant**. 我看见他在念书。\n2. 起状语作用\n   - **Prenant** l'escabeau, il s'offoree d'atteindre le dernier rayon. 他拿了一把小梯子乡尽力够上最后一格。\n   - **Croyant** le bureau vide, il entra. 他以为办公室没人所以就进去了。\n3. 表示并列动作\n   - Le train repartit, **courant** vers le Midi. 火车又开动了，向南方驶去。\n4. 依附于另一主语，构成独立分词从句\n   - Midi **sonnant**, on se met à table. 钟敲十二时，我们都上桌用餐。\n\n\n\n\n# 副动词(le gérondif)\n\n## 1. 构成\n副动词没有人称、性数变化\n\n在现在分词前加en就构成副动词 \n\n- faire : en faisant\n\n注：ayant、étant前不能用en，不能构成副动词。\n\n## 2. 用法\n1. 时间状语，表示动作的同时性\n   - N'oubliez pas de fermer la port **en sortant**.出去时别忘了关门。\n   - Ne lis pas **en mangeant**. 不要以便吃饭以一边看书\n2. 方式状语\n   - Elle arriva **en courant**. 她跑来了\n3. 条件状语\n   - **En se levant** plus tot le matin, il n'arrivera pas en retard. 如果早上起的早点，他就不会迟到了。\n4. 让步状语\n   - **En voyant** critiquant, il n'avait nulle intention de nous décourager. 他尽管批评了我们，但毫无使我们气馁之意。\n5. 原因状语\n   - **En voyant** son embarras, l'agent se fit plus aimable. 警察见他不知所措，就变得更加和蔼了。\n\n**\\*副动词表示的动作的延续**\n\n副动词可以和aller合用，表示延续发展的动作，介词en可以省略。\n\n- Sa vue va **en s'affaiblissant**. 他的视力日益衰退。\n\n## 3. 副动词的强化\n\n1. Tous + 副动词表示强化，这种结构常见于书面。\n2. Rien que + 副动词表示“只要…”\n\n\n\n\n\n# 现在分词和副动词的异同\n\n## 共同点\n\n它们在作状语时应和主体谓语共一个主语，并和主体谓语发生的时间同步。\n\n## 不同点\n\n1. 现在分词动作的施动者不一定是该句的主语，而副动词一定是所在句子的主语。\n\n\\*在一些从古法语流传迄今的成语、谚语等之中，副动词也可能拥有不同的主语，而这种主语是不明显的。\n\n- La fortune vient **en dormant**. 飞来横财。\n\n\n2. 见具体用法\n\n","slug":"participe-present-et-gerondif","published":1,"updated":"2016-12-13T21:28:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkji5001tzemmoqh46vcl","content":"<h1 id=\"现在分词-le-participe-present\"><a href=\"#现在分词-le-participe-present\" class=\"headerlink\" title=\"现在分词(le participe présent)\"></a>现在分词(le participe présent)</h1><h2 id=\"1-构成\"><a href=\"#1-构成\" class=\"headerlink\" title=\"1. 构成\"></a>1. 构成</h2><p>现在分词没有人称和数的变化。反身动词的现在分词仍然保留原反身动词的反身代词。</p>\n<p>去掉直陈式第一人称复数的词尾-ons，另加-ant </p>\n<ul>\n<li>faire : nous faisons </li>\n</ul>\n<p>特殊情况：</p>\n<ul>\n<li>etre-etant </li>\n<li>savoir-sachant</li>\n</ul>\n<h2 id=\"2-简述用法\"><a href=\"#2-简述用法\" class=\"headerlink\" title=\"2. 简述用法\"></a>2. 简述用法</h2><ol>\n<li>用作定语，紧接在被修饰词之后，相当于qui引导的从句<ul>\n<li>L’étranger cherche à trouver quelqu’un <strong>connaissant</strong> (=qui conaisse) à la fois français et l’anglais.</li>\n</ul>\n</li>\n<li>表原因、时间等，作为状语<ul>\n<li><strong>Voyant</strong>(=Comme elle voit) que tout le monde est dejà assis,elle va vite à sa place.</li>\n<li><strong>Ayant</strong>(=Comme il a) mal à la tete,il décide de rester au lit.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-细分\"><a href=\"#3-细分\" class=\"headerlink\" title=\"3. 细分\"></a>3. 细分</h2><h3 id=\"I-现在分词形容词特性的表现\"><a href=\"#I-现在分词形容词特性的表现\" class=\"headerlink\" title=\"I. 现在分词形容词特性的表现\"></a>I. 现在分词形容词特性的表现</h3><p>许多现在分词已经转化成形容词，有性数变化，可以作为定于或表语。</p>\n<ol>\n<li><p>动词形容词表示一种状态或性质，后不跟宾语或状语</p>\n<ul>\n<li>Ses yeux <strong>brillants</strong> disent la convoitises. 他那双闪光的眼睛流露出他贪婪的本性。</li>\n<li>Je l’ai trouvé toute <strong>tremblante</strong>. 我发现她浑身颤抖。</li>\n</ul>\n</li>\n<li><p>在一些习惯性搭配中表示一些潜在的主语</p>\n<ul>\n<li>Une seance <strong>payante</strong> (=où l’on paie) 一场要收费的演出。</li>\n<li>une collation <strong>soupante</strong> (=si copieuse qu’elle tient lieu de souper) 一顿丰盛的小吃</li>\n</ul>\n<p>这里分词的主语与它的被修饰语不同。</p>\n</li>\n<li><p>少数已变成了纯粹的形容词，书写有所区别</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>现在分词</th>\n<th>形容词</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>provoquant</td>\n<td>provocant</td>\n</tr>\n<tr>\n<td>fatiguant</td>\n<td>fatigant</td>\n</tr>\n<tr>\n<td>vaquant</td>\n<td>vacant</td>\n</tr>\n<tr>\n<td>naviguant</td>\n<td>navigant</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"II-现在分词动词特性的表现\"><a href=\"#II-现在分词动词特性的表现\" class=\"headerlink\" title=\"II. 现在分词动词特性的表现\"></a>II. 现在分词动词特性的表现</h3><p>现在分词具有动词的性质，可以有宾语或状语。</p>\n<ol>\n<li>代替qui引导的关系从句<ul>\n<li>C’est un film <strong>captivant</strong> les spectateurs. 这是一部非常吸引观众的影片。</li>\n<li>Je le vois <strong>lisant</strong>. 我看见他在念书。</li>\n</ul>\n</li>\n<li>起状语作用<ul>\n<li><strong>Prenant</strong> l’escabeau, il s’offoree d’atteindre le dernier rayon. 他拿了一把小梯子乡尽力够上最后一格。</li>\n<li><strong>Croyant</strong> le bureau vide, il entra. 他以为办公室没人所以就进去了。</li>\n</ul>\n</li>\n<li>表示并列动作<ul>\n<li>Le train repartit, <strong>courant</strong> vers le Midi. 火车又开动了，向南方驶去。</li>\n</ul>\n</li>\n<li>依附于另一主语，构成独立分词从句<ul>\n<li>Midi <strong>sonnant</strong>, on se met à table. 钟敲十二时，我们都上桌用餐。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"副动词-le-gerondif\"><a href=\"#副动词-le-gerondif\" class=\"headerlink\" title=\"副动词(le gérondif)\"></a>副动词(le gérondif)</h1><h2 id=\"1-构成-1\"><a href=\"#1-构成-1\" class=\"headerlink\" title=\"1. 构成\"></a>1. 构成</h2><p>副动词没有人称、性数变化</p>\n<p>在现在分词前加en就构成副动词 </p>\n<ul>\n<li>faire : en faisant</li>\n</ul>\n<p>注：ayant、étant前不能用en，不能构成副动词。</p>\n<h2 id=\"2-用法\"><a href=\"#2-用法\" class=\"headerlink\" title=\"2. 用法\"></a>2. 用法</h2><ol>\n<li>时间状语，表示动作的同时性<ul>\n<li>N’oubliez pas de fermer la port <strong>en sortant</strong>.出去时别忘了关门。</li>\n<li>Ne lis pas <strong>en mangeant</strong>. 不要以便吃饭以一边看书</li>\n</ul>\n</li>\n<li>方式状语<ul>\n<li>Elle arriva <strong>en courant</strong>. 她跑来了</li>\n</ul>\n</li>\n<li>条件状语<ul>\n<li><strong>En se levant</strong> plus tot le matin, il n’arrivera pas en retard. 如果早上起的早点，他就不会迟到了。</li>\n</ul>\n</li>\n<li>让步状语<ul>\n<li><strong>En voyant</strong> critiquant, il n’avait nulle intention de nous décourager. 他尽管批评了我们，但毫无使我们气馁之意。</li>\n</ul>\n</li>\n<li>原因状语<ul>\n<li><strong>En voyant</strong> son embarras, l’agent se fit plus aimable. 警察见他不知所措，就变得更加和蔼了。</li>\n</ul>\n</li>\n</ol>\n<p><strong>*副动词表示的动作的延续</strong></p>\n<p>副动词可以和aller合用，表示延续发展的动作，介词en可以省略。</p>\n<ul>\n<li>Sa vue va <strong>en s’affaiblissant</strong>. 他的视力日益衰退。</li>\n</ul>\n<h2 id=\"3-副动词的强化\"><a href=\"#3-副动词的强化\" class=\"headerlink\" title=\"3. 副动词的强化\"></a>3. 副动词的强化</h2><ol>\n<li>Tous + 副动词表示强化，这种结构常见于书面。</li>\n<li>Rien que + 副动词表示“只要…”</li>\n</ol>\n<h1 id=\"现在分词和副动词的异同\"><a href=\"#现在分词和副动词的异同\" class=\"headerlink\" title=\"现在分词和副动词的异同\"></a>现在分词和副动词的异同</h1><h2 id=\"共同点\"><a href=\"#共同点\" class=\"headerlink\" title=\"共同点\"></a>共同点</h2><p>它们在作状语时应和主体谓语共一个主语，并和主体谓语发生的时间同步。</p>\n<h2 id=\"不同点\"><a href=\"#不同点\" class=\"headerlink\" title=\"不同点\"></a>不同点</h2><ol>\n<li>现在分词动作的施动者不一定是该句的主语，而副动词一定是所在句子的主语。</li>\n</ol>\n<p>*在一些从古法语流传迄今的成语、谚语等之中，副动词也可能拥有不同的主语，而这种主语是不明显的。</p>\n<ul>\n<li>La fortune vient <strong>en dormant</strong>. 飞来横财。</li>\n</ul>\n<ol>\n<li>见具体用法</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"现在分词-le-participe-present\"><a href=\"#现在分词-le-participe-present\" class=\"headerlink\" title=\"现在分词(le participe présent)\"></a>现在分词(le participe présent)</h1><h2 id=\"1-构成\"><a href=\"#1-构成\" class=\"headerlink\" title=\"1. 构成\"></a>1. 构成</h2><p>现在分词没有人称和数的变化。反身动词的现在分词仍然保留原反身动词的反身代词。</p>\n<p>去掉直陈式第一人称复数的词尾-ons，另加-ant </p>\n<ul>\n<li>faire : nous faisons </li>\n</ul>\n<p>特殊情况：</p>\n<ul>\n<li>etre-etant </li>\n<li>savoir-sachant</li>\n</ul>\n<h2 id=\"2-简述用法\"><a href=\"#2-简述用法\" class=\"headerlink\" title=\"2. 简述用法\"></a>2. 简述用法</h2><ol>\n<li>用作定语，紧接在被修饰词之后，相当于qui引导的从句<ul>\n<li>L’étranger cherche à trouver quelqu’un <strong>connaissant</strong> (=qui conaisse) à la fois français et l’anglais.</li>\n</ul>\n</li>\n<li>表原因、时间等，作为状语<ul>\n<li><strong>Voyant</strong>(=Comme elle voit) que tout le monde est dejà assis,elle va vite à sa place.</li>\n<li><strong>Ayant</strong>(=Comme il a) mal à la tete,il décide de rester au lit.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-细分\"><a href=\"#3-细分\" class=\"headerlink\" title=\"3. 细分\"></a>3. 细分</h2><h3 id=\"I-现在分词形容词特性的表现\"><a href=\"#I-现在分词形容词特性的表现\" class=\"headerlink\" title=\"I. 现在分词形容词特性的表现\"></a>I. 现在分词形容词特性的表现</h3><p>许多现在分词已经转化成形容词，有性数变化，可以作为定于或表语。</p>\n<ol>\n<li><p>动词形容词表示一种状态或性质，后不跟宾语或状语</p>\n<ul>\n<li>Ses yeux <strong>brillants</strong> disent la convoitises. 他那双闪光的眼睛流露出他贪婪的本性。</li>\n<li>Je l’ai trouvé toute <strong>tremblante</strong>. 我发现她浑身颤抖。</li>\n</ul>\n</li>\n<li><p>在一些习惯性搭配中表示一些潜在的主语</p>\n<ul>\n<li>Une seance <strong>payante</strong> (=où l’on paie) 一场要收费的演出。</li>\n<li>une collation <strong>soupante</strong> (=si copieuse qu’elle tient lieu de souper) 一顿丰盛的小吃</li>\n</ul>\n<p>这里分词的主语与它的被修饰语不同。</p>\n</li>\n<li><p>少数已变成了纯粹的形容词，书写有所区别</p>\n</li>\n</ol>\n<div class=\"table-container\">\n<table>\n<thead>\n<tr>\n<th>现在分词</th>\n<th>形容词</th>\n</tr>\n</thead>\n<tbody>\n<tr>\n<td>provoquant</td>\n<td>provocant</td>\n</tr>\n<tr>\n<td>fatiguant</td>\n<td>fatigant</td>\n</tr>\n<tr>\n<td>vaquant</td>\n<td>vacant</td>\n</tr>\n<tr>\n<td>naviguant</td>\n<td>navigant</td>\n</tr>\n</tbody>\n</table>\n</div>\n<h3 id=\"II-现在分词动词特性的表现\"><a href=\"#II-现在分词动词特性的表现\" class=\"headerlink\" title=\"II. 现在分词动词特性的表现\"></a>II. 现在分词动词特性的表现</h3><p>现在分词具有动词的性质，可以有宾语或状语。</p>\n<ol>\n<li>代替qui引导的关系从句<ul>\n<li>C’est un film <strong>captivant</strong> les spectateurs. 这是一部非常吸引观众的影片。</li>\n<li>Je le vois <strong>lisant</strong>. 我看见他在念书。</li>\n</ul>\n</li>\n<li>起状语作用<ul>\n<li><strong>Prenant</strong> l’escabeau, il s’offoree d’atteindre le dernier rayon. 他拿了一把小梯子乡尽力够上最后一格。</li>\n<li><strong>Croyant</strong> le bureau vide, il entra. 他以为办公室没人所以就进去了。</li>\n</ul>\n</li>\n<li>表示并列动作<ul>\n<li>Le train repartit, <strong>courant</strong> vers le Midi. 火车又开动了，向南方驶去。</li>\n</ul>\n</li>\n<li>依附于另一主语，构成独立分词从句<ul>\n<li>Midi <strong>sonnant</strong>, on se met à table. 钟敲十二时，我们都上桌用餐。</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"副动词-le-gerondif\"><a href=\"#副动词-le-gerondif\" class=\"headerlink\" title=\"副动词(le gérondif)\"></a>副动词(le gérondif)</h1><h2 id=\"1-构成-1\"><a href=\"#1-构成-1\" class=\"headerlink\" title=\"1. 构成\"></a>1. 构成</h2><p>副动词没有人称、性数变化</p>\n<p>在现在分词前加en就构成副动词 </p>\n<ul>\n<li>faire : en faisant</li>\n</ul>\n<p>注：ayant、étant前不能用en，不能构成副动词。</p>\n<h2 id=\"2-用法\"><a href=\"#2-用法\" class=\"headerlink\" title=\"2. 用法\"></a>2. 用法</h2><ol>\n<li>时间状语，表示动作的同时性<ul>\n<li>N’oubliez pas de fermer la port <strong>en sortant</strong>.出去时别忘了关门。</li>\n<li>Ne lis pas <strong>en mangeant</strong>. 不要以便吃饭以一边看书</li>\n</ul>\n</li>\n<li>方式状语<ul>\n<li>Elle arriva <strong>en courant</strong>. 她跑来了</li>\n</ul>\n</li>\n<li>条件状语<ul>\n<li><strong>En se levant</strong> plus tot le matin, il n’arrivera pas en retard. 如果早上起的早点，他就不会迟到了。</li>\n</ul>\n</li>\n<li>让步状语<ul>\n<li><strong>En voyant</strong> critiquant, il n’avait nulle intention de nous décourager. 他尽管批评了我们，但毫无使我们气馁之意。</li>\n</ul>\n</li>\n<li>原因状语<ul>\n<li><strong>En voyant</strong> son embarras, l’agent se fit plus aimable. 警察见他不知所措，就变得更加和蔼了。</li>\n</ul>\n</li>\n</ol>\n<p><strong>*副动词表示的动作的延续</strong></p>\n<p>副动词可以和aller合用，表示延续发展的动作，介词en可以省略。</p>\n<ul>\n<li>Sa vue va <strong>en s’affaiblissant</strong>. 他的视力日益衰退。</li>\n</ul>\n<h2 id=\"3-副动词的强化\"><a href=\"#3-副动词的强化\" class=\"headerlink\" title=\"3. 副动词的强化\"></a>3. 副动词的强化</h2><ol>\n<li>Tous + 副动词表示强化，这种结构常见于书面。</li>\n<li>Rien que + 副动词表示“只要…”</li>\n</ol>\n<h1 id=\"现在分词和副动词的异同\"><a href=\"#现在分词和副动词的异同\" class=\"headerlink\" title=\"现在分词和副动词的异同\"></a>现在分词和副动词的异同</h1><h2 id=\"共同点\"><a href=\"#共同点\" class=\"headerlink\" title=\"共同点\"></a>共同点</h2><p>它们在作状语时应和主体谓语共一个主语，并和主体谓语发生的时间同步。</p>\n<h2 id=\"不同点\"><a href=\"#不同点\" class=\"headerlink\" title=\"不同点\"></a>不同点</h2><ol>\n<li>现在分词动作的施动者不一定是该句的主语，而副动词一定是所在句子的主语。</li>\n</ol>\n<p>*在一些从古法语流传迄今的成语、谚语等之中，副动词也可能拥有不同的主语，而这种主语是不明显的。</p>\n<ul>\n<li>La fortune vient <strong>en dormant</strong>. 飞来横财。</li>\n</ul>\n<ol>\n<li>见具体用法</li>\n</ol>\n"},{"title":"proba-ch3 实域概率和特征方程","date":"2016-12-01T13:54:10.000Z","_content":"\n1. 几种常见分布\n\n    若不在区间内，f=0\n\n   1. loi uniforme\n      $$\n      f(x)=\\frac{1}{b-a} si\\ x \\in [a,b]\n      $$\n\n   2. loi exponentielle\n      $$\n      f(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\n      E[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2\n      $$\n\n   3. Loi de weibull\n      $$\n      f(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\n      E[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}\n      $$\n\n   4. loi gamma\n      $$\n      f(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\n      E[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}\n      $$\n\n   5. loi normale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\n      E[X] = m, Var(X) = \\sigma^2\n      $$\n\n   6. Loi lognormale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\n      E[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)\n      $$\n\n   7. Loi du $ \\chi^2 $\n      $$\n      X = U_1^2+...+U_n^2 \\\\\n      U_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\n      E[X] = n, Var(X) = 2n\n      $$\n\n   8. Loi de Student\n      $$\n      X = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\n      U\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\n      Z\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}\n      $$\n\n2. 特征函数\n   $$\n   \\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\n   t \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}\n   $$\n   我们说特征函数是对X进行基于PX的傅立叶变换 = =好绕\n\n   若PX存在概率密度 $f \\in L^1$\n   $$\n   \\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}\n   $$\n\n   - 性质\n\n     - $$\n       \\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1\n       $$\n\n       $$\n       \\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)\n       $$\n\n       $$\n       \\varphi_X 是一个半正函数，即 \\\\\n       \\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0\n       $$\n\n   - 其他性质\n\n     - 特征函数连续\n\n     - PX以lebesgue测度绝对连续，则\n\n     - $$\n       \\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0\n       $$\n\n     - XY，它们拥有相同的P，当且仅当\n\n     - $$\n       \\varphi_X=\\varphi_Y\n       $$\n\n     - 逆变换\n\n     - $$\n       \\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt\n       $$\n\n   - 特征方程和独立性\n\n     - 定理\n       $$\n       X_1,...,X_N \\text{ 是独立的，当且仅当它们的特征方程满足：} \\\\\n       \\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\n       where\\ X = (X_1,...,X_N)\n       $$\n\n     - 性质\n       $$\n       X_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n       \\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n       \\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n       \\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }\n       $$\n\n\n","source":"_posts/proba-ch3.md","raw":"---\ntitle: proba-ch3 实域概率和特征方程\ndate: 2016-12-01 14:54:10\ncategories: math\ntags: [probability, math]\n---\n\n1. 几种常见分布\n\n    若不在区间内，f=0\n\n   1. loi uniforme\n      $$\n      f(x)=\\frac{1}{b-a} si\\ x \\in [a,b]\n      $$\n\n   2. loi exponentielle\n      $$\n      f(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\n      E[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2\n      $$\n\n   3. Loi de weibull\n      $$\n      f(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\n      E[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}\n      $$\n\n   4. loi gamma\n      $$\n      f(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\n      E[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}\n      $$\n\n   5. loi normale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\n      E[X] = m, Var(X) = \\sigma^2\n      $$\n\n   6. Loi lognormale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\n      E[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)\n      $$\n\n   7. Loi du $ \\chi^2 $\n      $$\n      X = U_1^2+...+U_n^2 \\\\\n      U_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\n      E[X] = n, Var(X) = 2n\n      $$\n\n   8. Loi de Student\n      $$\n      X = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\n      U\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\n      Z\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}\n      $$\n\n2. 特征函数\n   $$\n   \\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\n   t \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}\n   $$\n   我们说特征函数是对X进行基于PX的傅立叶变换 = =好绕\n\n   若PX存在概率密度 $f \\in L^1$\n   $$\n   \\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}\n   $$\n\n   - 性质\n\n     - $$\n       \\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1\n       $$\n\n       $$\n       \\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)\n       $$\n\n       $$\n       \\varphi_X 是一个半正函数，即 \\\\\n       \\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0\n       $$\n\n   - 其他性质\n\n     - 特征函数连续\n\n     - PX以lebesgue测度绝对连续，则\n\n     - $$\n       \\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0\n       $$\n\n     - XY，它们拥有相同的P，当且仅当\n\n     - $$\n       \\varphi_X=\\varphi_Y\n       $$\n\n     - 逆变换\n\n     - $$\n       \\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt\n       $$\n\n   - 特征方程和独立性\n\n     - 定理\n       $$\n       X_1,...,X_N \\text{ 是独立的，当且仅当它们的特征方程满足：} \\\\\n       \\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\n       where\\ X = (X_1,...,X_N)\n       $$\n\n     - 性质\n       $$\n       X_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n       \\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n       \\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n       \\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }\n       $$\n\n\n","slug":"proba-ch3","published":1,"updated":"2016-12-01T15:28:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkji7001xzemmvfnkkss1","content":"<ol>\n<li><p>几种常见分布</p>\n<p> 若不在区间内，f=0</p>\n<ol>\n<li><p>loi uniforme</p>\n<script type=\"math/tex; mode=display\">\nf(x)=\\frac{1}{b-a} si\\ x \\in [a,b]</script></li>\n<li><p>loi exponentielle</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\nE[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2</script></li>\n<li><p>Loi de weibull</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\nE[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}</script></li>\n<li><p>loi gamma</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\nE[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}</script></li>\n<li><p>loi normale</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\nE[X] = m, Var(X) = \\sigma^2</script></li>\n<li><p>Loi lognormale</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\nE[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)</script></li>\n<li><p>Loi du $ \\chi^2 $</p>\n<script type=\"math/tex; mode=display\">\nX = U_1^2+...+U_n^2 \\\\\nU_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\nE[X] = n, Var(X) = 2n</script></li>\n<li><p>Loi de Student</p>\n<script type=\"math/tex; mode=display\">\nX = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\nU\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\nZ\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}</script></li>\n</ol>\n</li>\n<li><p>特征函数</p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\nt \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}</script><p>我们说特征函数是对X进行基于PX的傅立叶变换 = =好绕</p>\n<p>若PX存在概率密度 $f \\in L^1$</p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}</script><ul>\n<li><p>性质</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\n\\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1</script><script type=\"math/tex; mode=display\">\n\\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)</script><script type=\"math/tex; mode=display\">\n\\varphi_X 是一个半正函数，即 \\\\\n\\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0</script></li>\n</ul>\n</li>\n<li><p>其他性质</p>\n<ul>\n<li><p>特征函数连续</p>\n</li>\n<li><p>PX以lebesgue测度绝对连续，则</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0</script></li>\n<li><p>XY，它们拥有相同的P，当且仅当</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\varphi_X=\\varphi_Y</script></li>\n<li><p>逆变换</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt</script></li>\n</ul>\n</li>\n<li><p>特征方程和独立性</p>\n<ul>\n<li><p>定理</p>\n<script type=\"math/tex; mode=display\">\nX_1,...,X_N \\text{ 是独立的，当且仅当它们的特征方程满足：} \\\\\n\\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\nwhere\\ X = (X_1,...,X_N)</script></li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\nX_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n\\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n\\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n\\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }</script></li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n","excerpt":"","more":"<ol>\n<li><p>几种常见分布</p>\n<p> 若不在区间内，f=0</p>\n<ol>\n<li><p>loi uniforme</p>\n<script type=\"math/tex; mode=display\">\nf(x)=\\frac{1}{b-a} si\\ x \\in [a,b]</script></li>\n<li><p>loi exponentielle</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\nE[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2</script></li>\n<li><p>Loi de weibull</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\nE[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}</script></li>\n<li><p>loi gamma</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\nE[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}</script></li>\n<li><p>loi normale</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\nE[X] = m, Var(X) = \\sigma^2</script></li>\n<li><p>Loi lognormale</p>\n<script type=\"math/tex; mode=display\">\nf(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\nE[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)</script></li>\n<li><p>Loi du $ \\chi^2 $</p>\n<script type=\"math/tex; mode=display\">\nX = U_1^2+...+U_n^2 \\\\\nU_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\nE[X] = n, Var(X) = 2n</script></li>\n<li><p>Loi de Student</p>\n<script type=\"math/tex; mode=display\">\nX = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\nU\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\nZ\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}</script></li>\n</ol>\n</li>\n<li><p>特征函数</p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\nt \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}</script><p>我们说特征函数是对X进行基于PX的傅立叶变换 = =好绕</p>\n<p>若PX存在概率密度 $f \\in L^1$</p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}</script><ul>\n<li><p>性质</p>\n<ul>\n<li><script type=\"math/tex; mode=display\">\n\\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1</script><script type=\"math/tex; mode=display\">\n\\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)</script><script type=\"math/tex; mode=display\">\n\\varphi_X 是一个半正函数，即 \\\\\n\\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0</script></li>\n</ul>\n</li>\n<li><p>其他性质</p>\n<ul>\n<li><p>特征函数连续</p>\n</li>\n<li><p>PX以lebesgue测度绝对连续，则</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0</script></li>\n<li><p>XY，它们拥有相同的P，当且仅当</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\varphi_X=\\varphi_Y</script></li>\n<li><p>逆变换</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt</script></li>\n</ul>\n</li>\n<li><p>特征方程和独立性</p>\n<ul>\n<li><p>定理</p>\n<script type=\"math/tex; mode=display\">\nX_1,...,X_N \\text{ 是独立的，当且仅当它们的特征方程满足：} \\\\\n\\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\nwhere\\ X = (X_1,...,X_N)</script></li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\nX_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n\\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n\\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n\\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }</script></li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n"},{"title":"proba-ch1 概率空间","date":"2016-12-01T11:17:29.000Z","_content":"\n- 一个基本的不等式，当\n\n\n$$\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}\n$$\n\n- 如果An递增\n\n$$\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- 如果An递减\n\n$$\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- 条件概率定义，略\n- 性质\n\n$$\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})\n$$\n\n- 定理(Equation de partition)\n\n$$\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}\n$$\n\n- 定理(de Bay)\n\n$$\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}\n$$\n\n- 两个独立事件概率，略\n\n- 定理\n\n  对一可数或有限事件集，P({wn}) = pn，若对pn求和，则P存在且唯一。\n\n- 均值定义，\n  $$\n  E[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}\n  $$\n\n- 方差定义\n\n$$\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)\n$$\n\n- 几种分布\n\n  - Loi discrete uniforme，\n\n  - $$\n    \\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}\n    $$\n\n    $$\n    E[X] = \\frac{n+1}{2}\n    $$\n\n  - Loi de Bernoulli，\n\n    $$\n    P(X=1) = p, t P(X=0) = 1-p\n    $$\n    $$\n    E[N] = p, Var(N) = p(1-p)\n    $$\n\n  - Loi binomiale 二项分布，略\n    $$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Loi geometrique \n    $$\n    P(N=n) = P^n(1-p),$$$$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Distribution de Poisson\n    $$\n    P(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},\n    $$\n    $$\n    E[X] = \\lambda, Var(X) = \\lambda\n    $$\n","source":"_posts/proba-ch1.md","raw":"---\ntitle: proba-ch1 概率空间\ndate: 2016-12-01 12:17:29\ncategories: math\ntags: [probability, math]\n---\n\n- 一个基本的不等式，当\n\n\n$$\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}\n$$\n\n- 如果An递增\n\n$$\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- 如果An递减\n\n$$\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- 条件概率定义，略\n- 性质\n\n$$\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})\n$$\n\n- 定理(Equation de partition)\n\n$$\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}\n$$\n\n- 定理(de Bay)\n\n$$\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}\n$$\n\n- 两个独立事件概率，略\n\n- 定理\n\n  对一可数或有限事件集，P({wn}) = pn，若对pn求和，则P存在且唯一。\n\n- 均值定义，\n  $$\n  E[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}\n  $$\n\n- 方差定义\n\n$$\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)\n$$\n\n- 几种分布\n\n  - Loi discrete uniforme，\n\n  - $$\n    \\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}\n    $$\n\n    $$\n    E[X] = \\frac{n+1}{2}\n    $$\n\n  - Loi de Bernoulli，\n\n    $$\n    P(X=1) = p, t P(X=0) = 1-p\n    $$\n    $$\n    E[N] = p, Var(N) = p(1-p)\n    $$\n\n  - Loi binomiale 二项分布，略\n    $$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Loi geometrique \n    $$\n    P(N=n) = P^n(1-p),$$$$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Distribution de Poisson\n    $$\n    P(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},\n    $$\n    $$\n    E[X] = \\lambda, Var(X) = \\lambda\n    $$\n","slug":"proba-ch1","published":1,"updated":"2016-12-01T11:19:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkji8001zzemm61amq2s6","content":"<ul>\n<li>一个基本的不等式，当</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}</script><ul>\n<li>如果An递增</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}</script><ul>\n<li>如果An递减</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}</script><ul>\n<li>条件概率定义，略</li>\n<li>性质</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})</script><ul>\n<li>定理(Equation de partition)</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}</script><ul>\n<li>定理(de Bay)</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}</script><ul>\n<li><p>两个独立事件概率，略</p>\n</li>\n<li><p>定理</p>\n<p>对一可数或有限事件集，P({wn}) = pn，若对pn求和，则P存在且唯一。</p>\n</li>\n<li><p>均值定义，</p>\n<script type=\"math/tex; mode=display\">\nE[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}</script></li>\n<li><p>方差定义</p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)</script><ul>\n<li><p>几种分布</p>\n<ul>\n<li><p>Loi discrete uniforme，</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}</script><script type=\"math/tex; mode=display\">\nE[X] = \\frac{n+1}{2}</script></li>\n<li><p>Loi de Bernoulli，</p>\n<script type=\"math/tex; mode=display\">\nP(X=1) = p, t P(X=0) = 1-p</script><script type=\"math/tex; mode=display\">\nE[N] = p, Var(N) = p(1-p)</script></li>\n<li><p>Loi binomiale 二项分布，略</p>\n<script type=\"math/tex; mode=display\">\nE[N] = np, Var(N) = np(1-p)</script></li>\n<li><p>Loi geometrique </p>\n<script type=\"math/tex; mode=display\">\nP(N=n) = P^n(1-p),$$</script><p>E[N] = np, Var(N) = np(1-p)<br>$$</p>\n</li>\n<li><p>Distribution de Poisson</p>\n<script type=\"math/tex; mode=display\">\nP(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},</script><script type=\"math/tex; mode=display\">\nE[X] = \\lambda, Var(X) = \\lambda</script></li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<ul>\n<li>一个基本的不等式，当</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}</script><ul>\n<li>如果An递增</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}</script><ul>\n<li>如果An递减</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}</script><ul>\n<li>条件概率定义，略</li>\n<li>性质</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})</script><ul>\n<li>定理(Equation de partition)</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}</script><ul>\n<li>定理(de Bay)</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}</script><ul>\n<li><p>两个独立事件概率，略</p>\n</li>\n<li><p>定理</p>\n<p>对一可数或有限事件集，P({wn}) = pn，若对pn求和，则P存在且唯一。</p>\n</li>\n<li><p>均值定义，</p>\n<script type=\"math/tex; mode=display\">\nE[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}</script></li>\n<li><p>方差定义</p>\n</li>\n</ul>\n<script type=\"math/tex; mode=display\">\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)</script><ul>\n<li><p>几种分布</p>\n<ul>\n<li><p>Loi discrete uniforme，</p>\n</li>\n<li><script type=\"math/tex; mode=display\">\n\\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}</script><script type=\"math/tex; mode=display\">\nE[X] = \\frac{n+1}{2}</script></li>\n<li><p>Loi de Bernoulli，</p>\n<script type=\"math/tex; mode=display\">\nP(X=1) = p, t P(X=0) = 1-p</script><script type=\"math/tex; mode=display\">\nE[N] = p, Var(N) = p(1-p)</script></li>\n<li><p>Loi binomiale 二项分布，略</p>\n<script type=\"math/tex; mode=display\">\nE[N] = np, Var(N) = np(1-p)</script></li>\n<li><p>Loi geometrique </p>\n<script type=\"math/tex; mode=display\">\nP(N=n) = P^n(1-p),$$</script><p>E[N] = np, Var(N) = np(1-p)<br>$$</p>\n</li>\n<li><p>Distribution de Poisson</p>\n<script type=\"math/tex; mode=display\">\nP(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},</script><script type=\"math/tex; mode=display\">\nE[X] = \\lambda, Var(X) = \\lambda</script></li>\n</ul>\n</li>\n</ul>\n"},{"title":"proba-ch6 条件期望","date":"2016-12-02T20:32:30.000Z","_content":"\n$$\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}\n$$\n\n$$\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}\n$$\n\n$$\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0\n$$\n\n$$\nE[X|Y] = \\psi(Y)\n$$\n\n- 定义\n  $$\n  \\mathcal{G} 是一个sous-tribu。\\\\\n  E[X|\\mathcal{G}] 是一个随机变量Y,满足 \\\\\n  Y \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP\n  $$\n\n- 定义 L2\n  $$\n  X \\in L^2, \\mathcal{G} 是一个sous-tribu \\\\\n  E[X|\\mathcal{G}] 是一个随机变量Y,满足 \\\\\n  \\forall Z \\in L^2, E[XZ] = E[YZ]\n  $$\n\n  - 性质\n    $$\n    E[E[X|\\mathcal{G}]] = E[X]\n    $$\n\n  - 性质\n    $$\n    若X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X是\\mathcal{G}可测的。\n    $$\n\n  - 性质\n    $$\n    X是\\mathcal{G}可测的, X,Y,XY \\in L^1 \\\\\n    \\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]\n    $$\n\n- 定义\n  $$\n  E[X|Y] = E[X|\\sigma(Y)]\n  $$\n\n  - 性质 若XY是实随机变量，则存在一个函数h\n    $$\n    E[X|Y] = h(Y)\n    $$\n","source":"_posts/proba-ch6.md","raw":"---\ntitle: proba-ch6 条件期望\ncategories: math\ntags:\n  - math\n  - probability\ndate: 2016-12-02 21:32:30\n---\n\n$$\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}\n$$\n\n$$\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}\n$$\n\n$$\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0\n$$\n\n$$\nE[X|Y] = \\psi(Y)\n$$\n\n- 定义\n  $$\n  \\mathcal{G} 是一个sous-tribu。\\\\\n  E[X|\\mathcal{G}] 是一个随机变量Y,满足 \\\\\n  Y \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP\n  $$\n\n- 定义 L2\n  $$\n  X \\in L^2, \\mathcal{G} 是一个sous-tribu \\\\\n  E[X|\\mathcal{G}] 是一个随机变量Y,满足 \\\\\n  \\forall Z \\in L^2, E[XZ] = E[YZ]\n  $$\n\n  - 性质\n    $$\n    E[E[X|\\mathcal{G}]] = E[X]\n    $$\n\n  - 性质\n    $$\n    若X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X是\\mathcal{G}可测的。\n    $$\n\n  - 性质\n    $$\n    X是\\mathcal{G}可测的, X,Y,XY \\in L^1 \\\\\n    \\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]\n    $$\n\n- 定义\n  $$\n  E[X|Y] = E[X|\\sigma(Y)]\n  $$\n\n  - 性质 若XY是实随机变量，则存在一个函数h\n    $$\n    E[X|Y] = h(Y)\n    $$\n","slug":"proba-ch6","published":1,"updated":"2016-12-02T21:09:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjia0023zemm5pr8k266","content":"<script type=\"math/tex; mode=display\">\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}</script><script type=\"math/tex; mode=display\">\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}</script><script type=\"math/tex; mode=display\">\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0</script><script type=\"math/tex; mode=display\">\nE[X|Y] = \\psi(Y)</script><ul>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{G} 是一个sous-tribu。\\\\\nE[X|\\mathcal{G}] 是一个随机变量Y,满足 \\\\\nY \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP</script></li>\n<li><p>定义 L2</p>\n<script type=\"math/tex; mode=display\">\nX \\in L^2, \\mathcal{G} 是一个sous-tribu \\\\\nE[X|\\mathcal{G}] 是一个随机变量Y,满足 \\\\\n\\forall Z \\in L^2, E[XZ] = E[YZ]</script><ul>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\nE[E[X|\\mathcal{G}]] = E[X]</script></li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\n若X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X是\\mathcal{G}可测的。</script></li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\nX是\\mathcal{G}可测的, X,Y,XY \\in L^1 \\\\\n\\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]</script></li>\n</ul>\n</li>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nE[X|Y] = E[X|\\sigma(Y)]</script><ul>\n<li>性质 若XY是实随机变量，则存在一个函数h<script type=\"math/tex; mode=display\">\nE[X|Y] = h(Y)</script></li>\n</ul>\n</li>\n</ul>\n","excerpt":"","more":"<script type=\"math/tex; mode=display\">\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}</script><script type=\"math/tex; mode=display\">\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}</script><script type=\"math/tex; mode=display\">\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0</script><script type=\"math/tex; mode=display\">\nE[X|Y] = \\psi(Y)</script><ul>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\n\\mathcal{G} 是一个sous-tribu。\\\\\nE[X|\\mathcal{G}] 是一个随机变量Y,满足 \\\\\nY \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP</script></li>\n<li><p>定义 L2</p>\n<script type=\"math/tex; mode=display\">\nX \\in L^2, \\mathcal{G} 是一个sous-tribu \\\\\nE[X|\\mathcal{G}] 是一个随机变量Y,满足 \\\\\n\\forall Z \\in L^2, E[XZ] = E[YZ]</script><ul>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\nE[E[X|\\mathcal{G}]] = E[X]</script></li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\n若X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X是\\mathcal{G}可测的。</script></li>\n<li><p>性质</p>\n<script type=\"math/tex; mode=display\">\nX是\\mathcal{G}可测的, X,Y,XY \\in L^1 \\\\\n\\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]</script></li>\n</ul>\n</li>\n<li><p>定义</p>\n<script type=\"math/tex; mode=display\">\nE[X|Y] = E[X|\\sigma(Y)]</script><ul>\n<li>性质 若XY是实随机变量，则存在一个函数h<script type=\"math/tex; mode=display\">\nE[X|Y] = h(Y)</script></li>\n</ul>\n</li>\n</ul>\n"},{"title":"Chrome插件开发 - Hello world","date":"2016-11-30T11:01:24.000Z","_content":"\n在学校选的projet是关于chrome插件开发的，这里记录一下。\n\n# Hello world!\n\n凡事先从hello world开始。\n\n1. 阅读chrome的开发手册，新建一个项目文件夹\n\n2. 我们需要manifest.json文件，告诉chrome我们的配置，去哪里找我们文件。\n\n   下面的写的是我们目前的设置，只写hello world的话只需要配置基本的设置以及default_popup。\n\n   ```json\n   {\n     \"manifest_version\": 2,\n     \"name\": \"TrelloGement\",\n     \"description\": \"Organiser ses recherches d'appartement sur Paris grâce à Trello!\",\n     \"version\": \"0.2.1\",\n     \"browser_action\": {\n       \"default_icon\": \"icon.png\",\n       \"default_popup\": \"popup.html\"\n     },\n     \"background\": {\n       \"scripts\": [\"background.js\", \"jquery-3.1.1.min.js\", \"client.js\"]\n     },\n     \"permissions\": [\"activeTab\", \"storage\", \"tabs\", \"https://api.trello.com/*\", \"https://trello.com/*\"]\n   }\n   ```\n\n3. 新建popup.html\n\n   ```html\n   <!DOCTYPE html>\n   <html lang=\"en\">\n   <head>\n   \t<meta charset=\"UTF-8\">\n   \t<title>Trellogement</title>\n   </head>\n   <body>\n     <h1> Hello, world! </h1>\n   </body>\n   </html>\n   ```\n\n4. 一个简单的Hello world就实现了，在chrome加载这个文件夹作为未打包的插件，在popup的位置点击可以看到“Hello, world!”\n\n","source":"_posts/projet-enjeu-plugin-chrome-101.md","raw":"---\ntitle: Chrome插件开发 - Hello world\ndate: 2016-11-30 12:01:24\ncategories: programming\ntags: [web, chrome]\n---\n\n在学校选的projet是关于chrome插件开发的，这里记录一下。\n\n# Hello world!\n\n凡事先从hello world开始。\n\n1. 阅读chrome的开发手册，新建一个项目文件夹\n\n2. 我们需要manifest.json文件，告诉chrome我们的配置，去哪里找我们文件。\n\n   下面的写的是我们目前的设置，只写hello world的话只需要配置基本的设置以及default_popup。\n\n   ```json\n   {\n     \"manifest_version\": 2,\n     \"name\": \"TrelloGement\",\n     \"description\": \"Organiser ses recherches d'appartement sur Paris grâce à Trello!\",\n     \"version\": \"0.2.1\",\n     \"browser_action\": {\n       \"default_icon\": \"icon.png\",\n       \"default_popup\": \"popup.html\"\n     },\n     \"background\": {\n       \"scripts\": [\"background.js\", \"jquery-3.1.1.min.js\", \"client.js\"]\n     },\n     \"permissions\": [\"activeTab\", \"storage\", \"tabs\", \"https://api.trello.com/*\", \"https://trello.com/*\"]\n   }\n   ```\n\n3. 新建popup.html\n\n   ```html\n   <!DOCTYPE html>\n   <html lang=\"en\">\n   <head>\n   \t<meta charset=\"UTF-8\">\n   \t<title>Trellogement</title>\n   </head>\n   <body>\n     <h1> Hello, world! </h1>\n   </body>\n   </html>\n   ```\n\n4. 一个简单的Hello world就实现了，在chrome加载这个文件夹作为未打包的插件，在popup的位置点击可以看到“Hello, world!”\n\n","slug":"projet-enjeu-plugin-chrome-101","published":1,"updated":"2016-11-30T11:19:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjib0025zemm2h8rbyiq","content":"<p>在学校选的projet是关于chrome插件开发的，这里记录一下。</p>\n<h1 id=\"Hello-world\"><a href=\"#Hello-world\" class=\"headerlink\" title=\"Hello world!\"></a>Hello world!</h1><p>凡事先从hello world开始。</p>\n<ol>\n<li><p>阅读chrome的开发手册，新建一个项目文件夹</p>\n</li>\n<li><p>我们需要manifest.json文件，告诉chrome我们的配置，去哪里找我们文件。</p>\n<p>下面的写的是我们目前的设置，只写hello world的话只需要配置基本的设置以及default_popup。</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  <span class=\"attr\">\"manifest_version\"</span>: <span class=\"number\">2</span>,</div><div class=\"line\">  <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"TrelloGement\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"Organiser ses recherches d'appartement sur Paris grâce à Trello!\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"version\"</span>: <span class=\"string\">\"0.2.1\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"browser_action\"</span>: &#123;</div><div class=\"line\">    <span class=\"attr\">\"default_icon\"</span>: <span class=\"string\">\"icon.png\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"default_popup\"</span>: <span class=\"string\">\"popup.html\"</span></div><div class=\"line\">  &#125;,</div><div class=\"line\">  <span class=\"attr\">\"background\"</span>: &#123;</div><div class=\"line\">    <span class=\"attr\">\"scripts\"</span>: [<span class=\"string\">\"background.js\"</span>, <span class=\"string\">\"jquery-3.1.1.min.js\"</span>, <span class=\"string\">\"client.js\"</span>]</div><div class=\"line\">  &#125;,</div><div class=\"line\">  <span class=\"attr\">\"permissions\"</span>: [<span class=\"string\">\"activeTab\"</span>, <span class=\"string\">\"storage\"</span>, <span class=\"string\">\"tabs\"</span>, <span class=\"string\">\"https://api.trello.com/*\"</span>, <span class=\"string\">\"https://trello.com/*\"</span>]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>新建popup.html</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&lt;!DOCTYPE html&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">\"en\"</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></div><div class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"UTF-8\"</span>&gt;</span></div><div class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>Trellogement<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">h1</span>&gt;</span> Hello, world! <span class=\"tag\">&lt;/<span class=\"name\">h1</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></div></pre></td></tr></table></figure>\n</li>\n<li><p>一个简单的Hello world就实现了，在chrome加载这个文件夹作为未打包的插件，在popup的位置点击可以看到“Hello, world!”</p>\n</li>\n</ol>\n","excerpt":"","more":"<p>在学校选的projet是关于chrome插件开发的，这里记录一下。</p>\n<h1 id=\"Hello-world\"><a href=\"#Hello-world\" class=\"headerlink\" title=\"Hello world!\"></a>Hello world!</h1><p>凡事先从hello world开始。</p>\n<ol>\n<li><p>阅读chrome的开发手册，新建一个项目文件夹</p>\n</li>\n<li><p>我们需要manifest.json文件，告诉chrome我们的配置，去哪里找我们文件。</p>\n<p>下面的写的是我们目前的设置，只写hello world的话只需要配置基本的设置以及default_popup。</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div><div class=\"line\">11</div><div class=\"line\">12</div><div class=\"line\">13</div><div class=\"line\">14</div></pre></td><td class=\"code\"><pre><div class=\"line\">&#123;</div><div class=\"line\">  <span class=\"attr\">\"manifest_version\"</span>: <span class=\"number\">2</span>,</div><div class=\"line\">  <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"TrelloGement\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"Organiser ses recherches d'appartement sur Paris grâce à Trello!\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"version\"</span>: <span class=\"string\">\"0.2.1\"</span>,</div><div class=\"line\">  <span class=\"attr\">\"browser_action\"</span>: &#123;</div><div class=\"line\">    <span class=\"attr\">\"default_icon\"</span>: <span class=\"string\">\"icon.png\"</span>,</div><div class=\"line\">    <span class=\"attr\">\"default_popup\"</span>: <span class=\"string\">\"popup.html\"</span></div><div class=\"line\">  &#125;,</div><div class=\"line\">  <span class=\"attr\">\"background\"</span>: &#123;</div><div class=\"line\">    <span class=\"attr\">\"scripts\"</span>: [<span class=\"string\">\"background.js\"</span>, <span class=\"string\">\"jquery-3.1.1.min.js\"</span>, <span class=\"string\">\"client.js\"</span>]</div><div class=\"line\">  &#125;,</div><div class=\"line\">  <span class=\"attr\">\"permissions\"</span>: [<span class=\"string\">\"activeTab\"</span>, <span class=\"string\">\"storage\"</span>, <span class=\"string\">\"tabs\"</span>, <span class=\"string\">\"https://api.trello.com/*\"</span>, <span class=\"string\">\"https://trello.com/*\"</span>]</div><div class=\"line\">&#125;</div></pre></td></tr></table></figure>\n</li>\n<li><p>新建popup.html</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><div class=\"line\">1</div><div class=\"line\">2</div><div class=\"line\">3</div><div class=\"line\">4</div><div class=\"line\">5</div><div class=\"line\">6</div><div class=\"line\">7</div><div class=\"line\">8</div><div class=\"line\">9</div><div class=\"line\">10</div></pre></td><td class=\"code\"><pre><div class=\"line\"><span class=\"meta\">&lt;!DOCTYPE html&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">\"en\"</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></div><div class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"UTF-8\"</span>&gt;</span></div><div class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>Trellogement<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></div><div class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">h1</span>&gt;</span> Hello, world! <span class=\"tag\">&lt;/<span class=\"name\">h1</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></div><div class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></div></pre></td></tr></table></figure>\n</li>\n<li><p>一个简单的Hello world就实现了，在chrome加载这个文件夹作为未打包的插件，在popup的位置点击可以看到“Hello, world!”</p>\n</li>\n</ol>\n"},{"title":"proba-ch4 高斯向量","date":"2016-12-01T15:28:52.000Z","_content":"\n定义\n\nUn vecteur aléatoire est dit gaussien si toute combinaison linéaire de ses composantes suit une loi gaussienne.\n\n也就是：\n$$\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}\n$$\n\n- 特征函数\n  $$\n  \\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n  => \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}\n  $$\n  $\\mu$, le vecteur moyenne, 平均向量\n\n  D, la matrice de covariances de X, 协方差矩阵\n\n- 理论，X=(X1,…,XN) 是高斯向量，则Xj相互独立当仅当其协方差矩阵D为对角线矩阵。（也就是只有自己和自己的协方差不为零）\n\n- Densite de la loi d'un vecteur gaussien\n  $$\n  D \\ne 0 \\\\\n  \\mathcal{N}(\\mu,D) \\text{在Lebesgue测度下，在}\\mathbb{R}^N\\text{上绝对连续} \\\\\n  x \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}\n  $$\n\n","source":"_posts/proba-ch4.md","raw":"---\ntitle: proba-ch4 高斯向量\ndate: 2016-12-01 16:28:52\ncategories: math\ntags: [probability, math, vector]\n---\n\n定义\n\nUn vecteur aléatoire est dit gaussien si toute combinaison linéaire de ses composantes suit une loi gaussienne.\n\n也就是：\n$$\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}\n$$\n\n- 特征函数\n  $$\n  \\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n  => \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}\n  $$\n  $\\mu$, le vecteur moyenne, 平均向量\n\n  D, la matrice de covariances de X, 协方差矩阵\n\n- 理论，X=(X1,…,XN) 是高斯向量，则Xj相互独立当仅当其协方差矩阵D为对角线矩阵。（也就是只有自己和自己的协方差不为零）\n\n- Densite de la loi d'un vecteur gaussien\n  $$\n  D \\ne 0 \\\\\n  \\mathcal{N}(\\mu,D) \\text{在Lebesgue测度下，在}\\mathbb{R}^N\\text{上绝对连续} \\\\\n  x \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}\n  $$\n\n","slug":"proba-ch4","published":1,"updated":"2016-12-19T13:11:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjid0029zemm8dxbsyqm","content":"<p>定义</p>\n<p>Un vecteur aléatoire est dit gaussien si toute combinaison linéaire de ses composantes suit une loi gaussienne.</p>\n<p>也就是：</p>\n<script type=\"math/tex; mode=display\">\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}</script><ul>\n<li><p>特征函数</p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n=> \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}</script><p>$\\mu$, le vecteur moyenne, 平均向量</p>\n<p>D, la matrice de covariances de X, 协方差矩阵</p>\n</li>\n<li><p>理论，X=(X1,…,XN) 是高斯向量，则Xj相互独立当仅当其协方差矩阵D为对角线矩阵。（也就是只有自己和自己的协方差不为零）</p>\n</li>\n<li><p>Densite de la loi d’un vecteur gaussien</p>\n<script type=\"math/tex; mode=display\">\nD \\ne 0 \\\\\n\\mathcal{N}(\\mu,D) \\text{在Lebesgue测度下，在}\\mathbb{R}^N\\text{上绝对连续} \\\\\nx \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}</script></li>\n</ul>\n","excerpt":"","more":"<p>定义</p>\n<p>Un vecteur aléatoire est dit gaussien si toute combinaison linéaire de ses composantes suit une loi gaussienne.</p>\n<p>也就是：</p>\n<script type=\"math/tex; mode=display\">\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}</script><ul>\n<li><p>特征函数</p>\n<script type=\"math/tex; mode=display\">\n\\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n=> \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}</script><p>$\\mu$, le vecteur moyenne, 平均向量</p>\n<p>D, la matrice de covariances de X, 协方差矩阵</p>\n</li>\n<li><p>理论，X=(X1,…,XN) 是高斯向量，则Xj相互独立当仅当其协方差矩阵D为对角线矩阵。（也就是只有自己和自己的协方差不为零）</p>\n</li>\n<li><p>Densite de la loi d’un vecteur gaussien</p>\n<script type=\"math/tex; mode=display\">\nD \\ne 0 \\\\\n\\mathcal{N}(\\mu,D) \\text{在Lebesgue测度下，在}\\mathbb{R}^N\\text{上绝对连续} \\\\\nx \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}</script></li>\n</ul>\n"},{"title":"proba-ch5 数列和随机变量系列","date":"2016-12-01T22:14:28.000Z","_content":"\n# 数列和随机变量系列\n\n1. 零一律\n\n   > **零一律**是概率论中的一个定律，它是安德雷·柯尔莫哥洛夫发现的，因此有时也叫柯尔莫哥洛夫零一律。其内容是：有些事件发生的概率不是几乎一（几乎肯定发生），就是几乎零（几乎肯定不发生）。这样的事件被称为“尾事件”。 — wiki\n\n   $$\n   (X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n   \\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n   \\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}\n   $$\n   - 定理(loi de zero-un)\n\n     如果存在一个事件A属于$\\mathcal{T}_{\\infty}$，则P(A)等于0或1。\n\n2. 不同定义\n\n   - convergence presque sure\n\n     定义，当存在一个事件满足以下条件\n     $$\n     \\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\n     $$\n     我们认为一个随机变量序列趋向(p.s.)一个随机变量。即\n     $$\n     P\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1\n     $$\n\n   - Convergence dans Lp\n\n     定义。首先Xn和X都在Lp空间下，并且其差值的绝对值的p次方的期望的极限等于零。- -|||\n\n     也就是\n     $$\n     \\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0\n     $$\n\n   - convergence en probabilite\n\n     定义，满足以下条件，称依概率收敛。\n     $$\n     \\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\n     ou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0\n     $$\n     定理，\n\n     1. 如果Xn趋向X(p.s.)，则fXn趋向fX(p.s.)\n     2. 如果Xn趋向X(P)，则fXn趋向fX(P)\n\n     定理，\n\n     Xn是实随机变量，以下关系等价\n     $$\n     X_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0\n     $$\n     定理，\n\n     Xn是实随机变量，则\n     $$\n     若X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\n     若X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\\n     $$\n     定理，\n\n     Xn是实随机变量，若Xn依概率收敛于X，我们能找到一个序列\n     $$\n     (X_{n_k})_{k \\in \\mathbb{N}}\n     $$\n     使得\n     $$\n     X_n \\to X, p.s.\n     $$\n     定理，\n\n     Xn是实随机变量，若Xn依概率收敛于X，并存在一个$Y \\in L^p, |X_n| \\le Y$，则\n     $$\n     X \\in L^p并且 X_n \\xrightarrow{L^p}X\n     $$\n\n\n\n\n\n3. 波莱尔－坎泰利引理\n\n   > 大致上，波莱尔－坎泰利引理说明了，如果有无穷个概率事件，它们发生的概率之和是有限的，那么其中的无限多个事件一同发生的概率是零。这个定理实际上是测度论的结论在概率论中的应用。 —wiki\n\n   1. 如果有无穷个概率事件，它们发生的概率之和是有限的，那么其中的无限多个事件一同发生的概率是零。\n   2. 如果有无穷个概率事件，无限多个事件一同发生的概率是零，那么它们发生的概率之和是有限的。\n\n4. 大数定律\n\n   > 在数学与统计学中，大数定律又称大数法则、大数律，是描述相当多次数重复实验的结果的定律。根据这个定律知道，样本数量越多，则其平均就越趋近期望值。 — wiki\n\n   - 强大数定律\n     $$\n     X_n \\in L^2 \\text{若它们独立同分布且在同一个概率空间，则} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.\n     $$\n\n   - 切比雪夫大数定律\n     $$\n     X_n  \\text{若它们独立同分布且在同一个概率空间，则} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ 当且仅当} E[X_i] \\text{对于所有i存在}\n     $$\n\n5. Convergence en loi\n\n   弱趋向：\n   $$\n   \\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}\n   $$\n   定义，若PXn弱趋向于PX，则Xn是 convergence en loi vers X。记为：\n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   定理，\n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]\n   $$\n   定理，\n   $$\n   X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   定理，si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.\n\n   - 离散变量的convergence en loi\n   - 分布函数的convergence en loi\n   - 特征函数的convergence en loi\n\n   均略=_=\n\n6. 中心极限定理\n   $$\n   若Var(X_n) < \\infty \\\\\n   记S_n = \\sum{Xi} \\\\\n   \\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)\n   $$\n   ​\n\n","source":"_posts/proba-ch5.md","raw":"---\ntitle: proba-ch5 数列和随机变量系列\ncategories: math\ntags:\n  - math\n  - probability\ndate: 2016-12-01 23:14:28\n---\n\n# 数列和随机变量系列\n\n1. 零一律\n\n   > **零一律**是概率论中的一个定律，它是安德雷·柯尔莫哥洛夫发现的，因此有时也叫柯尔莫哥洛夫零一律。其内容是：有些事件发生的概率不是几乎一（几乎肯定发生），就是几乎零（几乎肯定不发生）。这样的事件被称为“尾事件”。 — wiki\n\n   $$\n   (X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n   \\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n   \\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}\n   $$\n   - 定理(loi de zero-un)\n\n     如果存在一个事件A属于$\\mathcal{T}_{\\infty}$，则P(A)等于0或1。\n\n2. 不同定义\n\n   - convergence presque sure\n\n     定义，当存在一个事件满足以下条件\n     $$\n     \\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\n     $$\n     我们认为一个随机变量序列趋向(p.s.)一个随机变量。即\n     $$\n     P\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1\n     $$\n\n   - Convergence dans Lp\n\n     定义。首先Xn和X都在Lp空间下，并且其差值的绝对值的p次方的期望的极限等于零。- -|||\n\n     也就是\n     $$\n     \\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0\n     $$\n\n   - convergence en probabilite\n\n     定义，满足以下条件，称依概率收敛。\n     $$\n     \\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\n     ou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0\n     $$\n     定理，\n\n     1. 如果Xn趋向X(p.s.)，则fXn趋向fX(p.s.)\n     2. 如果Xn趋向X(P)，则fXn趋向fX(P)\n\n     定理，\n\n     Xn是实随机变量，以下关系等价\n     $$\n     X_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0\n     $$\n     定理，\n\n     Xn是实随机变量，则\n     $$\n     若X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\n     若X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\\n     $$\n     定理，\n\n     Xn是实随机变量，若Xn依概率收敛于X，我们能找到一个序列\n     $$\n     (X_{n_k})_{k \\in \\mathbb{N}}\n     $$\n     使得\n     $$\n     X_n \\to X, p.s.\n     $$\n     定理，\n\n     Xn是实随机变量，若Xn依概率收敛于X，并存在一个$Y \\in L^p, |X_n| \\le Y$，则\n     $$\n     X \\in L^p并且 X_n \\xrightarrow{L^p}X\n     $$\n\n\n\n\n\n3. 波莱尔－坎泰利引理\n\n   > 大致上，波莱尔－坎泰利引理说明了，如果有无穷个概率事件，它们发生的概率之和是有限的，那么其中的无限多个事件一同发生的概率是零。这个定理实际上是测度论的结论在概率论中的应用。 —wiki\n\n   1. 如果有无穷个概率事件，它们发生的概率之和是有限的，那么其中的无限多个事件一同发生的概率是零。\n   2. 如果有无穷个概率事件，无限多个事件一同发生的概率是零，那么它们发生的概率之和是有限的。\n\n4. 大数定律\n\n   > 在数学与统计学中，大数定律又称大数法则、大数律，是描述相当多次数重复实验的结果的定律。根据这个定律知道，样本数量越多，则其平均就越趋近期望值。 — wiki\n\n   - 强大数定律\n     $$\n     X_n \\in L^2 \\text{若它们独立同分布且在同一个概率空间，则} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.\n     $$\n\n   - 切比雪夫大数定律\n     $$\n     X_n  \\text{若它们独立同分布且在同一个概率空间，则} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ 当且仅当} E[X_i] \\text{对于所有i存在}\n     $$\n\n5. Convergence en loi\n\n   弱趋向：\n   $$\n   \\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}\n   $$\n   定义，若PXn弱趋向于PX，则Xn是 convergence en loi vers X。记为：\n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   定理，\n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]\n   $$\n   定理，\n   $$\n   X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   定理，si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.\n\n   - 离散变量的convergence en loi\n   - 分布函数的convergence en loi\n   - 特征函数的convergence en loi\n\n   均略=_=\n\n6. 中心极限定理\n   $$\n   若Var(X_n) < \\infty \\\\\n   记S_n = \\sum{Xi} \\\\\n   \\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)\n   $$\n   ​\n\n","slug":"proba-ch5","published":1,"updated":"2016-12-11T11:05:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ciz5zkjie002czemmhed2py6k","content":"<h1 id=\"数列和随机变量系列\"><a href=\"#数列和随机变量系列\" class=\"headerlink\" title=\"数列和随机变量系列\"></a>数列和随机变量系列</h1><ol>\n<li><p>零一律</p>\n<blockquote>\n<p><strong>零一律</strong>是概率论中的一个定律，它是安德雷·柯尔莫哥洛夫发现的，因此有时也叫柯尔莫哥洛夫零一律。其内容是：有些事件发生的概率不是几乎一（几乎肯定发生），就是几乎零（几乎肯定不发生）。这样的事件被称为“尾事件”。 — wiki</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\n(X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n\\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n\\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}</script><ul>\n<li><p>定理(loi de zero-un)</p>\n<p>如果存在一个事件A属于$\\mathcal{T}_{\\infty}$，则P(A)等于0或1。</p>\n</li>\n</ul>\n</li>\n<li><p>不同定义</p>\n<ul>\n<li><p>convergence presque sure</p>\n<p>定义，当存在一个事件满足以下条件</p>\n<script type=\"math/tex; mode=display\">\n\\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)</script><p>我们认为一个随机变量序列趋向(p.s.)一个随机变量。即</p>\n<script type=\"math/tex; mode=display\">\nP\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1</script></li>\n<li><p>Convergence dans Lp</p>\n<p>定义。首先Xn和X都在Lp空间下，并且其差值的绝对值的p次方的期望的极限等于零。- -|||</p>\n<p>也就是</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0</script></li>\n<li><p>convergence en probabilite</p>\n<p>定义，满足以下条件，称依概率收敛。</p>\n<script type=\"math/tex; mode=display\">\n\\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\nou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0</script><p>定理，</p>\n<ol>\n<li>如果Xn趋向X(p.s.)，则fXn趋向fX(p.s.)</li>\n<li>如果Xn趋向X(P)，则fXn趋向fX(P)</li>\n</ol>\n<p>定理，</p>\n<p>Xn是实随机变量，以下关系等价</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0</script><p>定理，</p>\n<p>Xn是实随机变量，则</p>\n<script type=\"math/tex; mode=display\">\n若X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\n若X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\</script><p>定理，</p>\n<p>Xn是实随机变量，若Xn依概率收敛于X，我们能找到一个序列</p>\n<script type=\"math/tex; mode=display\">\n(X_{n_k})_{k \\in \\mathbb{N}}</script><p>使得</p>\n<script type=\"math/tex; mode=display\">\nX_n \\to X, p.s.</script><p>定理，</p>\n<p>Xn是实随机变量，若Xn依概率收敛于X，并存在一个$Y \\in L^p, |X_n| \\le Y$，则</p>\n<script type=\"math/tex; mode=display\">\nX \\in L^p并且 X_n \\xrightarrow{L^p}X</script></li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>波莱尔－坎泰利引理</p>\n<blockquote>\n<p>大致上，波莱尔－坎泰利引理说明了，如果有无穷个概率事件，它们发生的概率之和是有限的，那么其中的无限多个事件一同发生的概率是零。这个定理实际上是测度论的结论在概率论中的应用。 —wiki</p>\n</blockquote>\n<ol>\n<li>如果有无穷个概率事件，它们发生的概率之和是有限的，那么其中的无限多个事件一同发生的概率是零。</li>\n<li>如果有无穷个概率事件，无限多个事件一同发生的概率是零，那么它们发生的概率之和是有限的。</li>\n</ol>\n</li>\n<li><p>大数定律</p>\n<blockquote>\n<p>在数学与统计学中，大数定律又称大数法则、大数律，是描述相当多次数重复实验的结果的定律。根据这个定律知道，样本数量越多，则其平均就越趋近期望值。 — wiki</p>\n</blockquote>\n<ul>\n<li><p>强大数定律</p>\n<script type=\"math/tex; mode=display\">\nX_n \\in L^2 \\text{若它们独立同分布且在同一个概率空间，则} \\\\\nlim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.</script></li>\n<li><p>切比雪夫大数定律</p>\n<script type=\"math/tex; mode=display\">\nX_n  \\text{若它们独立同分布且在同一个概率空间，则} \\\\\nlim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ 当且仅当} E[X_i] \\text{对于所有i存在}</script></li>\n</ul>\n</li>\n<li><p>Convergence en loi</p>\n<p>弱趋向：</p>\n<script type=\"math/tex; mode=display\">\n\\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}</script><p>定义，若PXn弱趋向于PX，则Xn是 convergence en loi vers X。记为：</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{\\mathcal{D}} X</script><p>定理，</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]</script><p>定理，</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X</script><p>定理，si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.</p>\n<ul>\n<li>离散变量的convergence en loi</li>\n<li>分布函数的convergence en loi</li>\n<li>特征函数的convergence en loi</li>\n</ul>\n<p>均略=_=</p>\n</li>\n<li><p>中心极限定理</p>\n<script type=\"math/tex; mode=display\">\n若Var(X_n) < \\infty \\\\\n记S_n = \\sum{Xi} \\\\\n\\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)</script><p>​</p>\n</li>\n</ol>\n","excerpt":"","more":"<h1 id=\"数列和随机变量系列\"><a href=\"#数列和随机变量系列\" class=\"headerlink\" title=\"数列和随机变量系列\"></a>数列和随机变量系列</h1><ol>\n<li><p>零一律</p>\n<blockquote>\n<p><strong>零一律</strong>是概率论中的一个定律，它是安德雷·柯尔莫哥洛夫发现的，因此有时也叫柯尔莫哥洛夫零一律。其内容是：有些事件发生的概率不是几乎一（几乎肯定发生），就是几乎零（几乎肯定不发生）。这样的事件被称为“尾事件”。 — wiki</p>\n</blockquote>\n<script type=\"math/tex; mode=display\">\n(X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n\\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n\\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}</script><ul>\n<li><p>定理(loi de zero-un)</p>\n<p>如果存在一个事件A属于$\\mathcal{T}_{\\infty}$，则P(A)等于0或1。</p>\n</li>\n</ul>\n</li>\n<li><p>不同定义</p>\n<ul>\n<li><p>convergence presque sure</p>\n<p>定义，当存在一个事件满足以下条件</p>\n<script type=\"math/tex; mode=display\">\n\\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)</script><p>我们认为一个随机变量序列趋向(p.s.)一个随机变量。即</p>\n<script type=\"math/tex; mode=display\">\nP\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1</script></li>\n<li><p>Convergence dans Lp</p>\n<p>定义。首先Xn和X都在Lp空间下，并且其差值的绝对值的p次方的期望的极限等于零。- -|||</p>\n<p>也就是</p>\n<script type=\"math/tex; mode=display\">\n\\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0</script></li>\n<li><p>convergence en probabilite</p>\n<p>定义，满足以下条件，称依概率收敛。</p>\n<script type=\"math/tex; mode=display\">\n\\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\nou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0</script><p>定理，</p>\n<ol>\n<li>如果Xn趋向X(p.s.)，则fXn趋向fX(p.s.)</li>\n<li>如果Xn趋向X(P)，则fXn趋向fX(P)</li>\n</ol>\n<p>定理，</p>\n<p>Xn是实随机变量，以下关系等价</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0</script><p>定理，</p>\n<p>Xn是实随机变量，则</p>\n<script type=\"math/tex; mode=display\">\n若X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\n若X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\</script><p>定理，</p>\n<p>Xn是实随机变量，若Xn依概率收敛于X，我们能找到一个序列</p>\n<script type=\"math/tex; mode=display\">\n(X_{n_k})_{k \\in \\mathbb{N}}</script><p>使得</p>\n<script type=\"math/tex; mode=display\">\nX_n \\to X, p.s.</script><p>定理，</p>\n<p>Xn是实随机变量，若Xn依概率收敛于X，并存在一个$Y \\in L^p, |X_n| \\le Y$，则</p>\n<script type=\"math/tex; mode=display\">\nX \\in L^p并且 X_n \\xrightarrow{L^p}X</script></li>\n</ul>\n</li>\n</ol>\n<ol>\n<li><p>波莱尔－坎泰利引理</p>\n<blockquote>\n<p>大致上，波莱尔－坎泰利引理说明了，如果有无穷个概率事件，它们发生的概率之和是有限的，那么其中的无限多个事件一同发生的概率是零。这个定理实际上是测度论的结论在概率论中的应用。 —wiki</p>\n</blockquote>\n<ol>\n<li>如果有无穷个概率事件，它们发生的概率之和是有限的，那么其中的无限多个事件一同发生的概率是零。</li>\n<li>如果有无穷个概率事件，无限多个事件一同发生的概率是零，那么它们发生的概率之和是有限的。</li>\n</ol>\n</li>\n<li><p>大数定律</p>\n<blockquote>\n<p>在数学与统计学中，大数定律又称大数法则、大数律，是描述相当多次数重复实验的结果的定律。根据这个定律知道，样本数量越多，则其平均就越趋近期望值。 — wiki</p>\n</blockquote>\n<ul>\n<li><p>强大数定律</p>\n<script type=\"math/tex; mode=display\">\nX_n \\in L^2 \\text{若它们独立同分布且在同一个概率空间，则} \\\\\nlim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.</script></li>\n<li><p>切比雪夫大数定律</p>\n<script type=\"math/tex; mode=display\">\nX_n  \\text{若它们独立同分布且在同一个概率空间，则} \\\\\nlim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ 当且仅当} E[X_i] \\text{对于所有i存在}</script></li>\n</ul>\n</li>\n<li><p>Convergence en loi</p>\n<p>弱趋向：</p>\n<script type=\"math/tex; mode=display\">\n\\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}</script><p>定义，若PXn弱趋向于PX，则Xn是 convergence en loi vers X。记为：</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{\\mathcal{D}} X</script><p>定理，</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]</script><p>定理，</p>\n<script type=\"math/tex; mode=display\">\nX_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X</script><p>定理，si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.</p>\n<ul>\n<li>离散变量的convergence en loi</li>\n<li>分布函数的convergence en loi</li>\n<li>特征函数的convergence en loi</li>\n</ul>\n<p>均略=_=</p>\n</li>\n<li><p>中心极限定理</p>\n<script type=\"math/tex; mode=display\">\n若Var(X_n) < \\infty \\\\\n记S_n = \\sum{Xi} \\\\\n\\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)</script><p>​</p>\n</li>\n</ol>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ciz5zkjgh0001zemmd8qr7rk1","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjh8000dzemmi8hs80er"},{"post_id":"ciz5zkjh00009zemmshinm0tf","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjhb000hzemmr0ip1yd7"},{"post_id":"ciz5zkjgn0003zemmxkk0vwkv","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjhc000kzemmod5truk8"},{"post_id":"ciz5zkjgu0007zemmcjopsnjo","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjhi000qzemmijg99t22"},{"post_id":"ciz5zkjhg000pzemmm182vl3p","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjhl000vzemm7ruze9ai"},{"post_id":"ciz5zkjhi000rzemm52qnyglq","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjhn000yzemm27okeddj"},{"post_id":"ciz5zkjh5000czemmcrpt8fzg","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjhq0013zemmlvnv59xy"},{"post_id":"ciz5zkjhl000wzemmnb73wevo","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjhs0017zemm7vrw8f20"},{"post_id":"ciz5zkjhn000zzemmvb3ut0jg","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjhv001bzemm3po53bo1"},{"post_id":"ciz5zkjhq0012zemmu4jbe80d","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjhz001ezemmsg4aovfn"},{"post_id":"ciz5zkjhr0016zemmdnt8olms","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkji0001hzemm0ctjadel"},{"post_id":"ciz5zkjhb000izemmdkpyr3gy","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkji1001lzemm8lnaaxlg"},{"post_id":"ciz5zkjhu001azemmo2xawczp","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkji3001pzemmt86pjktf"},{"post_id":"ciz5zkjhc000lzemm5cz049vw","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkji5001szemm5ejj5i7r"},{"post_id":"ciz5zkjhc000lzemm5cz049vw","category_id":"ciz5zkjhv001czemmv01pbazy","_id":"ciz5zkji6001uzemmla8zbp4o"},{"post_id":"ciz5zkjgw0008zemmccgenkxw","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkji8001yzemm8wyjs23w"},{"post_id":"ciz5zkjgw0008zemmccgenkxw","category_id":"ciz5zkji0001jzemm9rghc6kf","_id":"ciz5zkji90020zemmsd21hn7e"},{"post_id":"ciz5zkji4001rzemmeys0t28x","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjib0024zemmucwtec72"},{"post_id":"ciz5zkjhk000uzemm3qalyoib","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjic0026zemmqrw6m56k"},{"post_id":"ciz5zkjhk000uzemm3qalyoib","category_id":"ciz5zkjhv001czemmv01pbazy","_id":"ciz5zkjie002azemmgxz7osvj"},{"post_id":"ciz5zkji7001xzemmvfnkkss1","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjih002dzemmb14t6znd"},{"post_id":"ciz5zkjh9000ezemmyu65lo34","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjij002hzemme05r7gt6"},{"post_id":"ciz5zkjh9000ezemmyu65lo34","category_id":"ciz5zkji0001jzemm9rghc6kf","_id":"ciz5zkjij002jzemmjmmoz05o"},{"post_id":"ciz5zkji8001zzemm61amq2s6","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjik002nzemmq4513vot"},{"post_id":"ciz5zkjia0023zemm5pr8k266","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjik002pzemm9w4pu3i8"},{"post_id":"ciz5zkjhx001dzemm74loy1rx","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjil002tzemm8c7r58jc"},{"post_id":"ciz5zkjhx001dzemm74loy1rx","category_id":"ciz5zkji0001jzemm9rghc6kf","_id":"ciz5zkjil002uzemm3k851lrh"},{"post_id":"ciz5zkjib0025zemm2h8rbyiq","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjim002wzemmvs8xh58k"},{"post_id":"ciz5zkjid0029zemm8dxbsyqm","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjin002yzemmucz53xyq"},{"post_id":"ciz5zkjhz001gzemmu0xkjxqd","category_id":"ciz5zkjhe000mzemmgc43sdy7","_id":"ciz5zkjin0030zemmp2cz0dp4"},{"post_id":"ciz5zkjhz001gzemmu0xkjxqd","category_id":"ciz5zkji0001jzemm9rghc6kf","_id":"ciz5zkjio0033zemm6788b2f6"},{"post_id":"ciz5zkjie002czemmhed2py6k","category_id":"ciz5zkjgr0005zemmf1qlwykm","_id":"ciz5zkjio0034zemmxlwquq0q"},{"post_id":"ciz5zkji1001kzemmbkke3hyx","category_id":"ciz5zkjii002gzemmsf0z2y2z","_id":"ciz5zkjio0036zemma0xhlt0o"},{"post_id":"ciz5zkji2001ozemmm3klcc44","category_id":"ciz5zkjii002gzemmsf0z2y2z","_id":"ciz5zkjio0037zemmliel23jt"},{"post_id":"ciz5zkji5001tzemmoqh46vcl","category_id":"ciz5zkjil002szemmtayw8tgz","_id":"ciz5zkjip003azemm74iuw8dg"}],"PostTag":[{"post_id":"ciz5zkjgh0001zemmd8qr7rk1","tag_id":"ciz5zkjgt0006zemmoprirx3s","_id":"ciz5zkjhc000jzemmki4sc1sb"},{"post_id":"ciz5zkjgh0001zemmd8qr7rk1","tag_id":"ciz5zkjh2000bzemm3pjde34k","_id":"ciz5zkjhf000nzemm3zqftxn4"},{"post_id":"ciz5zkjgn0003zemmxkk0vwkv","tag_id":"ciz5zkjha000gzemmypsu6225","_id":"ciz5zkjhq0011zemma37gihab"},{"post_id":"ciz5zkjgn0003zemmxkk0vwkv","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjhr0015zemmfer5uaaz"},{"post_id":"ciz5zkjgn0003zemmxkk0vwkv","tag_id":"ciz5zkjhk000tzemmf3fg3b3p","_id":"ciz5zkjhu0019zemm1iqvhjne"},{"post_id":"ciz5zkjgu0007zemmcjopsnjo","tag_id":"ciz5zkjhp0010zemmiva9vi95","_id":"ciz5zkji0001izemmatdjmfy1"},{"post_id":"ciz5zkjgu0007zemmcjopsnjo","tag_id":"ciz5zkjht0018zemmuwumotgo","_id":"ciz5zkji1001mzemm1asdq1qi"},{"post_id":"ciz5zkjgw0008zemmccgenkxw","tag_id":"ciz5zkjhz001fzemmhh43cu7b","_id":"ciz5zkjie002bzemmcxe2gf35"},{"post_id":"ciz5zkjgw0008zemmccgenkxw","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjih002ezemm2o7o0eqb"},{"post_id":"ciz5zkjgw0008zemmccgenkxw","tag_id":"ciz5zkji6001vzemmt93kgq35","_id":"ciz5zkjij002izemm6easy7b4"},{"post_id":"ciz5zkjgw0008zemmccgenkxw","tag_id":"ciz5zkjia0021zemm2g4uxsz7","_id":"ciz5zkjij002kzemm1kyz577c"},{"post_id":"ciz5zkjh00009zemmshinm0tf","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjik002ozemmiu78i9pf"},{"post_id":"ciz5zkjh00009zemmshinm0tf","tag_id":"ciz5zkjii002fzemm9a9hlfmz","_id":"ciz5zkjik002qzemm87m4lieh"},{"post_id":"ciz5zkjh5000czemmcrpt8fzg","tag_id":"ciz5zkji6001vzemmt93kgq35","_id":"ciz5zkjim002xzemmlioe5b4y"},{"post_id":"ciz5zkjh5000czemmcrpt8fzg","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjin002zzemmy4znhanh"},{"post_id":"ciz5zkjh9000ezemmyu65lo34","tag_id":"ciz5zkjim002vzemm2ef0m1c4","_id":"ciz5zkjin0032zemmyziowkrd"},{"post_id":"ciz5zkjhb000izemmdkpyr3gy","tag_id":"ciz5zkji6001vzemmt93kgq35","_id":"ciz5zkjip0039zemmmp434hsn"},{"post_id":"ciz5zkjhb000izemmdkpyr3gy","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjip003bzemm1e67dlk2"},{"post_id":"ciz5zkjhc000lzemm5cz049vw","tag_id":"ciz5zkjht0018zemmuwumotgo","_id":"ciz5zkjiq003ezemm1dfi1qal"},{"post_id":"ciz5zkjhc000lzemm5cz049vw","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjiq003fzemmc4ys5gfn"},{"post_id":"ciz5zkjhg000pzemmm182vl3p","tag_id":"ciz5zkji6001vzemmt93kgq35","_id":"ciz5zkjir003jzemmasqo26jq"},{"post_id":"ciz5zkjhg000pzemmm182vl3p","tag_id":"ciz5zkjiq003gzemmfc0eiuli","_id":"ciz5zkjis003kzemm2ghcztx1"},{"post_id":"ciz5zkjhg000pzemmm182vl3p","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjis003mzemmitw8myw2"},{"post_id":"ciz5zkjhi000rzemm52qnyglq","tag_id":"ciz5zkji6001vzemmt93kgq35","_id":"ciz5zkjj0003ozemmagyyvhdr"},{"post_id":"ciz5zkjhi000rzemm52qnyglq","tag_id":"ciz5zkjis003lzemmcsxaaki0","_id":"ciz5zkjj0003pzemmb6fqn6y9"},{"post_id":"ciz5zkjhk000uzemm3qalyoib","tag_id":"ciz5zkjit003nzemme9tp306v","_id":"ciz5zkjj3003szemm4zjwv7mx"},{"post_id":"ciz5zkjhk000uzemm3qalyoib","tag_id":"ciz5zkjhk000tzemmf3fg3b3p","_id":"ciz5zkjj3003tzemm9s2wru2y"},{"post_id":"ciz5zkjhk000uzemm3qalyoib","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjj3003vzemmsrlti39c"},{"post_id":"ciz5zkjhk000uzemm3qalyoib","tag_id":"ciz5zkjgt0006zemmoprirx3s","_id":"ciz5zkjj3003wzemmqqfz0yci"},{"post_id":"ciz5zkjhl000wzemmnb73wevo","tag_id":"ciz5zkji6001vzemmt93kgq35","_id":"ciz5zkjj4003zzemmhyo8y8t0"},{"post_id":"ciz5zkjhl000wzemmnb73wevo","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjj40040zemm8dddvg1h"},{"post_id":"ciz5zkjhl000wzemmnb73wevo","tag_id":"ciz5zkjj3003xzemm0hr2uj8p","_id":"ciz5zkjj40042zemmknj2xf1j"},{"post_id":"ciz5zkjhn000zzemmvb3ut0jg","tag_id":"ciz5zkjj4003yzemmnqkquh5o","_id":"ciz5zkjj50045zemmcd29u7qn"},{"post_id":"ciz5zkjhn000zzemmvb3ut0jg","tag_id":"ciz5zkji6001vzemmt93kgq35","_id":"ciz5zkjj50046zemm0qhxmqjj"},{"post_id":"ciz5zkjhn000zzemmvb3ut0jg","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjj50048zemmdxgv5kk0"},{"post_id":"ciz5zkjhq0012zemmu4jbe80d","tag_id":"ciz5zkjim002vzemm2ef0m1c4","_id":"ciz5zkjj5004bzemmb3rhbnhf"},{"post_id":"ciz5zkjhq0012zemmu4jbe80d","tag_id":"ciz5zkjj50047zemmu2ezf519","_id":"ciz5zkjj5004czemmuuu0h3o5"},{"post_id":"ciz5zkjhq0012zemmu4jbe80d","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjj6004ezemmwxndm9zq"},{"post_id":"ciz5zkjhr0016zemmdnt8olms","tag_id":"ciz5zkjim002vzemm2ef0m1c4","_id":"ciz5zkjj7004izemmd0ctg97o"},{"post_id":"ciz5zkjhr0016zemmdnt8olms","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjj7004jzemmkl7713sv"},{"post_id":"ciz5zkjhr0016zemmdnt8olms","tag_id":"ciz5zkjj6004fzemmv3m590mv","_id":"ciz5zkjj7004lzemmqmdq12fg"},{"post_id":"ciz5zkjhr0016zemmdnt8olms","tag_id":"ciz5zkjj6004gzemm64gtncbu","_id":"ciz5zkjj7004mzemmcbse5aan"},{"post_id":"ciz5zkjhu001azemmo2xawczp","tag_id":"ciz5zkjim002vzemm2ef0m1c4","_id":"ciz5zkjj8004ozemm5vc4vg0j"},{"post_id":"ciz5zkjhu001azemmo2xawczp","tag_id":"ciz5zkji1001nzemmmz18j6n4","_id":"ciz5zkjj8004pzemmjz68rsr3"},{"post_id":"ciz5zkjhx001dzemm74loy1rx","tag_id":"ciz5zkjhz001fzemmhh43cu7b","_id":"ciz5zkjj8004rzemmcmhfexq8"},{"post_id":"ciz5zkjhz001gzemmu0xkjxqd","tag_id":"ciz5zkjj8004qzemmoeuruz7m","_id":"ciz5zkjj9004uzemmp70l3ngd"},{"post_id":"ciz5zkjhz001gzemmu0xkjxqd","tag_id":"ciz5zkjj8004szemmj2p6pd17","_id":"ciz5zkjj9004vzemm0eguir7m"},{"post_id":"ciz5zkji1001kzemmbkke3hyx","tag_id":"ciz5zkjj8004tzemmes8p3f8h","_id":"ciz5zkjj90050zemmnh8a0xj6"},{"post_id":"ciz5zkji1001kzemmbkke3hyx","tag_id":"ciz5zkjj9004wzemmv592rcfl","_id":"ciz5zkjj90051zemma4rawn64"},{"post_id":"ciz5zkji1001kzemmbkke3hyx","tag_id":"ciz5zkjj9004xzemm2eddjkq0","_id":"ciz5zkjj90053zemmt675hrv9"},{"post_id":"ciz5zkji1001kzemmbkke3hyx","tag_id":"ciz5zkjj9004yzemmgvtzjsie","_id":"ciz5zkjj90054zemmvz48i8wg"},{"post_id":"ciz5zkji2001ozemmm3klcc44","tag_id":"ciz5zkjj9004zzemm92prz78f","_id":"ciz5zkjja0056zemmsa8rn0rf"},{"post_id":"ciz5zkji2001ozemmm3klcc44","tag_id":"ciz5zkjj90052zemmcnui9b8w","_id":"ciz5zkjja0057zemm27xylc7l"},{"post_id":"ciz5zkji4001rzemmeys0t28x","tag_id":"ciz5zkjii002fzemm9a9hlfmz","_id":"ciz5zkjja005azemmaw7jzmke"},{"post_id":"ciz5zkji4001rzemmeys0t28x","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjja005bzemmphkziez7"},{"post_id":"ciz5zkji4001rzemmeys0t28x","tag_id":"ciz5zkjja0058zemmyp996jxc","_id":"ciz5zkjja005dzemm7isnwmia"},{"post_id":"ciz5zkji5001tzemmoqh46vcl","tag_id":"ciz5zkjja0059zemmi4dmbph4","_id":"ciz5zkjjb005fzemmnu35lky8"},{"post_id":"ciz5zkji5001tzemmoqh46vcl","tag_id":"ciz5zkjja005czemmq7jsop7i","_id":"ciz5zkjjc005gzemm20p1nrew"},{"post_id":"ciz5zkji7001xzemmvfnkkss1","tag_id":"ciz5zkjii002fzemm9a9hlfmz","_id":"ciz5zkjjc005izemmgya609jy"},{"post_id":"ciz5zkji7001xzemmvfnkkss1","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjjc005jzemmcdt47clq"},{"post_id":"ciz5zkji8001zzemm61amq2s6","tag_id":"ciz5zkjii002fzemm9a9hlfmz","_id":"ciz5zkjjc005lzemmxoejwher"},{"post_id":"ciz5zkji8001zzemm61amq2s6","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjjc005mzemm1jm8d30x"},{"post_id":"ciz5zkjia0023zemm5pr8k266","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjjd005ozemmmrnnfgby"},{"post_id":"ciz5zkjia0023zemm5pr8k266","tag_id":"ciz5zkjii002fzemm9a9hlfmz","_id":"ciz5zkjjd005pzemmaqj2xc3e"},{"post_id":"ciz5zkjib0025zemm2h8rbyiq","tag_id":"ciz5zkjjc005nzemmbeiczjzv","_id":"ciz5zkjje005szemmnbnmwwmg"},{"post_id":"ciz5zkjib0025zemm2h8rbyiq","tag_id":"ciz5zkjjd005qzemmswyarger","_id":"ciz5zkjje005tzemmn33q4793"},{"post_id":"ciz5zkjid0029zemm8dxbsyqm","tag_id":"ciz5zkjii002fzemm9a9hlfmz","_id":"ciz5zkjjf005wzemmzydq0cpp"},{"post_id":"ciz5zkjid0029zemm8dxbsyqm","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjjf005xzemm3ftdrixt"},{"post_id":"ciz5zkjid0029zemm8dxbsyqm","tag_id":"ciz5zkjje005uzemmgsiknc8o","_id":"ciz5zkjjf005yzemmjavlylgo"},{"post_id":"ciz5zkjie002czemmhed2py6k","tag_id":"ciz5zkjhf000ozemm6jynbtds","_id":"ciz5zkjjf005zzemm73j6ersm"},{"post_id":"ciz5zkjie002czemmhed2py6k","tag_id":"ciz5zkjii002fzemm9a9hlfmz","_id":"ciz5zkjjf0060zemmas473mez"}],"Tag":[{"name":"EDP","_id":"ciz5zkjgt0006zemmoprirx3s"},{"name":"matrix","_id":"ciz5zkjh2000bzemm3pjde34k"},{"name":"Hilbert","_id":"ciz5zkjha000gzemmypsu6225"},{"name":"math","_id":"ciz5zkjhf000ozemm6jynbtds"},{"name":"analyse","_id":"ciz5zkjhk000tzemmf3fg3b3p"},{"name":"Bayes","_id":"ciz5zkjhp0010zemmiva9vi95"},{"name":"statistic","_id":"ciz5zkjht0018zemmuwumotgo"},{"name":"machine-learning","_id":"ciz5zkjhz001fzemmhh43cu7b"},{"name":"programming","_id":"ciz5zkji1001nzemmmz18j6n4"},{"name":"algo","_id":"ciz5zkji6001vzemmt93kgq35"},{"name":"CNN","_id":"ciz5zkjia0021zemm2g4uxsz7"},{"name":"probability","_id":"ciz5zkjii002fzemm9a9hlfmz"},{"name":"datamining","_id":"ciz5zkjim002vzemm2ef0m1c4"},{"name":"compression","_id":"ciz5zkjiq003gzemmfc0eiuli"},{"name":"data-structure","_id":"ciz5zkjis003lzemmcsxaaki0"},{"name":"Sobolev","_id":"ciz5zkjit003nzemme9tp306v"},{"name":"complexity","_id":"ciz5zkjj3003xzemm0hr2uj8p"},{"name":"graph","_id":"ciz5zkjj4003yzemmnqkquh5o"},{"name":"qualitative-induction","_id":"ciz5zkjj50047zemmu2ezf519"},{"name":"classification","_id":"ciz5zkjj6004fzemmv3m590mv"},{"name":"prediction","_id":"ciz5zkjj6004gzemm64gtncbu"},{"name":"OS","_id":"ciz5zkjj8004qzemmoeuruz7m"},{"name":"kernel","_id":"ciz5zkjj8004szemmj2p6pd17"},{"name":"hexo","_id":"ciz5zkjj8004tzemmes8p3f8h"},{"name":"latex","_id":"ciz5zkjj9004wzemmv592rcfl"},{"name":"mathjax","_id":"ciz5zkjj9004xzemm2eddjkq0"},{"name":"marked","_id":"ciz5zkjj9004yzemmgvtzjsie"},{"name":"management","_id":"ciz5zkjj9004zzemm92prz78f"},{"name":"firm","_id":"ciz5zkjj90052zemmcnui9b8w"},{"name":"aleatoire","_id":"ciz5zkjja0058zemmyp996jxc"},{"name":"francais","_id":"ciz5zkjja0059zemmi4dmbph4"},{"name":"language","_id":"ciz5zkjja005czemmq7jsop7i"},{"name":"web","_id":"ciz5zkjjc005nzemmbeiczjzv"},{"name":"chrome","_id":"ciz5zkjjd005qzemmswyarger"},{"name":"vector","_id":"ciz5zkjje005uzemmgsiknc8o"}]}}