{"meta":{"version":1,"warehouse":"4.0.0"},"models":{"Asset":[{"_id":"source/CNAME","path":"CNAME","modified":0,"renderable":0},{"_id":"source/baidu_verify_TcRbK06C8G.html","path":"baidu_verify_TcRbK06C8G.html","modified":0,"renderable":0},{"_id":"source/baidu_verify_eUOah4Iuy2.html","path":"baidu_verify_eUOah4Iuy2.html","modified":0,"renderable":0},{"_id":"source/about/resume-Jue.Wang.pdf","path":"about/resume-Jue.Wang.pdf","modified":0,"renderable":0},{"_id":"themes/theme-icarus/source/css/cyberpunk.styl","path":"css/cyberpunk.styl","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/css/default.styl","path":"css/default.styl","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/css/style.styl","path":"css/style.styl","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/img/avatar.png","path":"img/avatar.png","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/img/favicon.svg","path":"img/favicon.svg","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/img/logo.svg","path":"img/logo.svg","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/img/og_image.png","path":"img/og_image.png","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/img/razor-bottom-black.svg","path":"img/razor-bottom-black.svg","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/img/razor-top-black.svg","path":"img/razor-top-black.svg","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/js/animation.js","path":"js/animation.js","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/js/back_to_top.js","path":"js/back_to_top.js","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/js/column.js","path":"js/column.js","modified":0,"renderable":1},{"_id":"themes/theme-icarus/source/js/main.js","path":"js/main.js","modified":0,"renderable":1}],"Cache":[{"_id":"source/CNAME","hash":"584ac3adaeb479e7552e94ce2d7b42f3814d180e","modified":1581306453090},{"_id":"source/baidu_verify_TcRbK06C8G.html","hash":"e68267f32b8f78af851edccc9c01f6597fcc50b8","modified":1520891053690},{"_id":"source/_data/recommended_posts.json","hash":"a1c68e96cf5df3fddef415bc4214f82522242c71","modified":1523870065240},{"_id":"source/baidu_verify_eUOah4Iuy2.html","hash":"fe1eac761615be2ba4f62006849696dffa0e9b9f","modified":1520868387919},{"_id":"source/about-zh/index.md","hash":"2264b074699446b897a2e1345fd195b600f54a87","modified":1623203363109},{"_id":"source/about/.DS_Store","hash":"70254de4df8040a49427f48db94e96921c7a30f3","modified":1612420918618},{"_id":"source/about/index.md","hash":"668b0423565241c0555723ac8cf47ef95616435c","modified":1637226627259},{"_id":"source/about/resume-Jue.Wang.pdf","hash":"2b91dcdc01832142e6a24bb6f8e38723c789d510","modified":1628407300267},{"_id":"source/tags/index.md","hash":"fa774b869f2d5acee7c55cc2e2a33ea69e3c6953","modified":1520718447796},{"_id":"source/_posts/Bayes-estimation.md","hash":"3e5aad795853e179d954d3205db4e7b2289908a9","modified":1483807698000},{"_id":"source/_posts/EDP-basic-matrix-review.md","hash":"c1fbeae751298cce65cc1985c9690442e015336b","modified":1486464009000},{"_id":"source/_posts/EDP-basic-models.md","hash":"80c26fd753d9e2648551ee0afc29dca700bcd40d","modified":1488798686000},{"_id":"source/_posts/EDP-finite-element-method.md","hash":"b94164cd9990c46a88bcfaf364c99235f9e3630c","modified":1490993312000},{"_id":"source/_posts/Hands-on-Scrapy.md","hash":"5f8b0cbc7126f9e21a2fedb93944cf5e9f647b59","modified":1498140911000},{"_id":"source/_posts/Hilbert-space.md","hash":"3c6db443cefd12c241cbb609a6b75e7765101f9a","modified":1486817852000},{"_id":"source/_posts/Generative-Adversarial-Network.md","hash":"d4529ae15957921f1d52ba3ee9ceeb72ec6fcf8e","modified":1604373963479},{"_id":"source/.DS_Store","hash":"c2d3f70bf8c66bcbe7b5c921b343de266b2216a5","modified":1637227148211},{"_id":"source/_posts/ML-CNN.md","hash":"ef69323536f07aab053cd6d2895c486ad8f21ac9","modified":1581257192526},{"_id":"source/_posts/Method-of-programming-facing-to-exams.md","hash":"1a8fd1060250aede23ca2874e6128a18d349f844","modified":1480502724000},{"_id":"source/_posts/MongoDB-Docker-and-Python.md","hash":"c18c88e9b8c0e3c851ebc5fdb03c7208151154ce","modified":1498115279000},{"_id":"source/_posts/Note-of-NLP.md","hash":"bf0a5c3d8ad8149978bdef469deef2d33d26bc35","modified":1498641238000},{"_id":"source/_posts/Note-of-datamining.md","hash":"33cfd2f704bd9ae07d4ead3c17696e0a1a52400e","modified":1481058293000},{"_id":"source/_posts/Note-of-knowledge-graph.md","hash":"1807aafc17a5b04a03842cb403395c4f9f0ad49e","modified":1498369219000},{"_id":"source/_posts/Note-of-learning-Algo.md","hash":"b7b7e260aaeb65905941d8b4bd4571e1574b7c55","modified":1480503398000},{"_id":"source/_posts/Note-of-probability.md","hash":"ad5d49330cc0839512071921029120eda20f715c","modified":1480947409000},{"_id":"source/_posts/Note-of-statistic.md","hash":"4b9ce4b578af1309675aaa85a8d39c9634a632db","modified":1485626526000},{"_id":"source/_posts/.DS_Store","hash":"ce4ed11b971875e5bd9a780269d26d959cc000c0","modified":1637227153588},{"_id":"source/_posts/OS-notes.md","hash":"bc3910e673839fe47e8d3263d8a120b20a78597f","modified":1492368056000},{"_id":"source/_posts/QuadTree.md","hash":"0710c38532531abb236221ee2b0c06c00efbbf65","modified":1604373962624},{"_id":"source/_posts/Sobolev-space.md","hash":"ccf8b23ac2f15a49576f204f3b309f6c94493017","modified":1486831727000},{"_id":"source/_posts/[2017.12.10]Entity-resolution.md","hash":"16f28c7814d71616705dba24cceff08615abc5d4","modified":1517051250140},{"_id":"source/_posts/[2018.1.14]Models-for-relation-extraction.md","hash":"9fae07ef6801998f2c8667f72ac52b590e49862a","modified":1604373973796},{"_id":"source/_posts/[2017.12.17]Relation-Classification-via-Attention-Model.md","hash":"b38160535bd679994cee6af3c6d3395ed03585d2","modified":1604373974244},{"_id":"source/_posts/[2018.1.21]Event-detection-and-co-referentce.md","hash":"be995f237ed57a26bfef64a555b8deef9620d85c","modified":1604373973403},{"_id":"source/_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction.md","hash":"bb7d4473bd0ae982781e2fa17f7df2954febbdb6","modified":1604373972997},{"_id":"source/_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction.md","hash":"4c408a3fd5298309d963ccef2641e53454569f7b","modified":1604373972569},{"_id":"source/_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion.md","hash":"978c1e51fa66641d7a8264ae7091c673f5bc1077","modified":1604373972121},{"_id":"source/_posts/[2018.2.5]Nested-LSTMs.md","hash":"9fb4297d8822d133413a8e764692081f9d14c474","modified":1604373971654},{"_id":"source/_posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing.md","hash":"2af7564cbf24ec89e4469fc0e7fc696eb86f3d9a","modified":1604373971105},{"_id":"source/_posts/[2018.3.20]Event-detection.md","hash":"ec08168a14951d66a84cda970fa4f325b29dc354","modified":1604373967533},{"_id":"source/_posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data.md","hash":"c4b83bb355e71bd98832626f863bb4e2cdf17537","modified":1604373967006},{"_id":"source/_posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization.md","hash":"bcad6c0f7095dd819ed262656d7afb7625bfd26b","modified":1604373966064},{"_id":"source/_posts/[2018.5.10]Knowledge-Graph-Augmented-Neural-Networks-for-NLP.md","hash":"97b81e12e2c7e49fab06e623e6f12310ce76d3d6","modified":1604373965090},{"_id":"source/_posts/[2018.8.22]RegEx-with-NN.md","hash":"048012f06570a0a060e151c0d86001bc801f08cb","modified":1604373964399},{"_id":"source/_posts/[2018.9]nlp-short-reviews-week-1.md","hash":"3acad7f585faaa598bfae6ecb4613055def2aa3f","modified":1538791834775},{"_id":"source/_posts/about.md","hash":"e2a7279868df08390fe0636177fecab26271b195","modified":1637227099227},{"_id":"source/_posts/complexity.md","hash":"884bea5a67590cca6019d9a12442352f0e5aa284","modified":1480502588000},{"_id":"source/_posts/compression.md","hash":"6c09d635d6e901b27df17fe64aa759930e9e4ada","modified":1480502772000},{"_id":"source/_posts/datamining-class-pred.md","hash":"bed4bfa4b40d639d5a22a25c135d2ac7fb65eda2","modified":1482767562000},{"_id":"source/_posts/datamining-pretreatment.md","hash":"c274b6cd8f6388eae82e6786eae0da41b0a20a1c","modified":1481228966000},{"_id":"source/_posts/datamining-qualitative-induction.md","hash":"732e1ebd08758c64a7325b269d7f788671221e1b","modified":1482476111000},{"_id":"source/_posts/graph.md","hash":"fb81eb7a78b150f0133ada157a40e8437d3a135c","modified":1486814910000},{"_id":"source/_posts/hexo-with-latex.md","hash":"8bb31822f906a82bc52db60a54d08e6e85c9a94e","modified":1480542334000},{"_id":"source/_posts/intro-about-KG.md","hash":"08ca28433ce06cdfe5188e402e7eacb3390067ac","modified":1530451665722},{"_id":"source/_posts/learning-OS-and-building-LorriOS.md","hash":"62c7e96f2a44fe667c35e3074986dc8c60551010","modified":1492441961000},{"_id":"source/_posts/machine-learning.md","hash":"5304e7f0e49d9060a8bf3556e1c5a940e249d37c","modified":1481576860000},{"_id":"source/_posts/management-of-the-firm.md","hash":"720d9655a8216e9732a4af5e20cc76e88e7cde5b","modified":1481664406000},{"_id":"source/_posts/participe-present-et-gerondif.md","hash":"754b1e438f2f1c593b0a33993af2b8788db80232","modified":1481664512000},{"_id":"source/_posts/proba-ch1.md","hash":"dba3dc8fb9720b16d533037452729bd83b6599c5","modified":1480591178000},{"_id":"source/_posts/proba-ch2.md","hash":"62fb75ec16f81340349fa4d5e9a5f4b4a0e4b3e1","modified":1520973329109},{"_id":"source/_posts/proba-ch3.md","hash":"c83c5d8f3c8b9631fb804fa14bca32b7c8f3df98","modified":1480606117000},{"_id":"source/_posts/proba-ch4.md","hash":"7cd6e2d4d3b7fb4e5f8547082cea9611aa13e542","modified":1482153097000},{"_id":"source/_posts/proba-ch5.md","hash":"ccd8f72481bdf1b8ad53605254a3d3d43c3f3787","modified":1481454317000},{"_id":"source/_posts/proba-ch6.md","hash":"25e4cdddd7bcf976a6491622111db0c7a195e2c3","modified":1480712994000},{"_id":"source/_posts/projet-enjeu-plugin-chrome-101.md","hash":"2b82eded6334d7d1afd6a427c6db2bf71431b4de","modified":1480504742000},{"_id":"source/_posts/resume-Jue.Wang.pdf","hash":"2b91dcdc01832142e6a24bb6f8e38723c789d510","modified":1628407300267},{"_id":"source/_posts/update-rss.md","hash":"73fae345273458857740a546b139668f7321678e","modified":1604373960854},{"_id":"source/_posts/vps-cheatsheet.md","hash":"450b60f634d03a66cc2525700dc35ec9d3d56d1a","modified":1581255832811},{"_id":"source/categories/index.md","hash":"d923d9de1c6af59ea3bd15493b0182e94ea9a4a2","modified":1520718469441},{"_id":"themes/theme-icarus/layout/comment/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127087},{"_id":"themes/theme-icarus/layout/donate/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127089},{"_id":"themes/theme-icarus/layout/misc/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127090},{"_id":"themes/theme-icarus/layout/search/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127090},{"_id":"themes/theme-icarus/layout/share/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127090},{"_id":"themes/theme-icarus/include/schema/comment/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127077},{"_id":"themes/theme-icarus/include/schema/donate/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127079},{"_id":"themes/theme-icarus/include/schema/misc/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127080},{"_id":"themes/theme-icarus/include/schema/search/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127080},{"_id":"themes/theme-icarus/include/schema/share/.gitkeep","hash":"da39a3ee5e6b4b0d3255bfef95601890afd80709","modified":1628406127080},{"_id":"themes/theme-icarus/.eslintignore","hash":"5410a1bef9807f666cd92a0d2020f700e67e4096","modified":1628406127075},{"_id":"themes/theme-icarus/.eslintrc.json","hash":"43c7740158c8690242720b4ff7fa11426fc20c79","modified":1628406127075},{"_id":"themes/theme-icarus/.npmignore","hash":"42242c8da7a020a3295e7dd3d18bf022cb08b661","modified":1628406127075},{"_id":"themes/theme-icarus/CONTRIBUTING.md","hash":"70254c6778c1e41bb2ff222bbf3a70b2239b9bc1","modified":1628406127075},{"_id":"themes/theme-icarus/LICENSE","hash":"86037e5335a49321fa73b7815cab542057fac944","modified":1628406127075},{"_id":"themes/theme-icarus/README.md","hash":"32f9f4fc8cd7ec60b30544bd2e558b593519ae5d","modified":1628406127076},{"_id":"themes/theme-icarus/_config.yml","hash":"eb2e6af82c5bd306ef8638e00f843650445f6967","modified":1628406456256},{"_id":"themes/theme-icarus/package.json","hash":"653d306a010f669192883483414da500d48cf592","modified":1628406127091},{"_id":"themes/theme-icarus/include/config.js","hash":"1ff0f174e9670074ad2bee890d5b6da486800c9a","modified":1628406127076},{"_id":"themes/theme-icarus/include/dependency.js","hash":"d30dbcefd58619f6705d6369b644bc7ba44d2421","modified":1628406127076},{"_id":"themes/theme-icarus/include/register.js","hash":"a974b56a1fbb254f1ae048cc2221363faaccec25","modified":1628406127077},{"_id":"themes/theme-icarus/layout/.DS_Store","hash":"df2fbeb1400acda0909a32c1cf6bf492f1121e07","modified":1637223606753},{"_id":"themes/theme-icarus/layout/archive.jsx","hash":"05677e93d4a43f417dbbf0d63ca37a99e6349e3b","modified":1628406127087},{"_id":"themes/theme-icarus/layout/categories.jsx","hash":"b8ad43e28a4990d222bfbb95b032f88555492347","modified":1628406127087},{"_id":"themes/theme-icarus/layout/category.jsx","hash":"fd15e4eac32de9ac8687aeb3dbe179ab61375700","modified":1628406127087},{"_id":"themes/theme-icarus/layout/index.jsx","hash":"0a84a2348394fa9fc5080dd396bd28d357594f47","modified":1628406127089},{"_id":"themes/theme-icarus/layout/layout.jsx","hash":"a5829907b219e95266f7ed5ee6203e60e2273f93","modified":1628406127089},{"_id":"themes/theme-icarus/layout/page.jsx","hash":"d26c2db57e5a88d6483a03aeb51cda9d191d8cea","modified":1628406127090},{"_id":"themes/theme-icarus/layout/post.jsx","hash":"d26c2db57e5a88d6483a03aeb51cda9d191d8cea","modified":1628406127090},{"_id":"themes/theme-icarus/layout/tag.jsx","hash":"d2f18cac32ca2725d34ccff3f2051c623be6c892","modified":1628406127091},{"_id":"themes/theme-icarus/layout/tags.jsx","hash":"2c42cb64778235dd220c563a27a92108ddc50cc4","modified":1628406127091},{"_id":"themes/theme-icarus/languages/de.yml","hash":"78421f09961ca0b24756a0688fb2cb2e2696e25f","modified":1628406127085},{"_id":"themes/theme-icarus/languages/en.yml","hash":"3d674204d9f723c829226da745afddd180c1131d","modified":1628406127085},{"_id":"themes/theme-icarus/languages/es.yml","hash":"38579b8fad4b6997362acc770615bcd85ff20f68","modified":1628406127085},{"_id":"themes/theme-icarus/languages/fr.yml","hash":"06d5c819d6108a42b28cff7b52e5410d0bed55d1","modified":1628406127085},{"_id":"themes/theme-icarus/languages/id.yml","hash":"5e48b1d62378cadeb64b88349477726a5c1bae47","modified":1628406127085},{"_id":"themes/theme-icarus/languages/ja.yml","hash":"801d9930fef48d6a3f80470d5bed4f3eb78147e6","modified":1628406127085},{"_id":"themes/theme-icarus/languages/ko.yml","hash":"e3374265377809c1518114cf352b595840c0b416","modified":1628406127086},{"_id":"themes/theme-icarus/languages/pl.yml","hash":"2e7debb44cd91096f30efc87bf8d6b1d0d0214c9","modified":1628406127086},{"_id":"themes/theme-icarus/languages/pt-BR.yml","hash":"ee8f73350e4c6e2f63b7fc72b34472a6b1e21244","modified":1628406127086},{"_id":"themes/theme-icarus/languages/ru.yml","hash":"9d91358c2acbe7a0f2a25daf7f65b999ff32d068","modified":1628406127086},{"_id":"themes/theme-icarus/languages/tk.yml","hash":"ca583168bd2025124a1cd0e977da475d7a7496fd","modified":1628406127086},{"_id":"themes/theme-icarus/languages/tr.yml","hash":"74e438bb42619666050192d6f3dc39023777eee2","modified":1628406127086},{"_id":"themes/theme-icarus/languages/vn.yml","hash":"5f2fffa642110c81d8f529949711c9d19ad6bbbe","modified":1628406127086},{"_id":"themes/theme-icarus/languages/zh-CN.yml","hash":"02475ba14afc70dfeaf5678467cee307835e4efa","modified":1628406127087},{"_id":"themes/theme-icarus/languages/zh-TW.yml","hash":"a6826e0c8cdb9ad286324b682b466a9e2ad78e6f","modified":1628406127087},{"_id":"themes/theme-icarus/scripts/index.js","hash":"0c666db6fcb4ffc4d300f4e108c00ee42b1cbbe6","modified":1628406127091},{"_id":"themes/theme-icarus/include/migration/head.js","hash":"269ba172013cbd2f10b9bc51af0496628081329b","modified":1628406127076},{"_id":"themes/theme-icarus/include/migration/v2_v3.js","hash":"3ccb2d2ce11018bebd7172da66faecc3983bff00","modified":1628406127076},{"_id":"themes/theme-icarus/include/migration/v3_v4.js","hash":"9faf2184d7fe87debfbe007f3fc9079dcbcafcfe","modified":1628406127077},{"_id":"themes/theme-icarus/include/schema/config.json","hash":"ac633f9d349bca4f089d59d2c3738b57376f1b31","modified":1628406127079},{"_id":"themes/theme-icarus/include/style/article.styl","hash":"105c983871b6c9148d97a0f756886e56411572bd","modified":1628406127080},{"_id":"themes/theme-icarus/include/style/card.styl","hash":"f78674422eb408cd17c17bbdc3ee1ebe4a453e05","modified":1628406127082},{"_id":"themes/theme-icarus/include/style/base.styl","hash":"2bca6ad099949d52236c87db8db1002ffb99774c","modified":1628406127081},{"_id":"themes/theme-icarus/include/style/button.styl","hash":"0fb35b4786be1b387c751fa2849bc71523fcedd4","modified":1628406127082},{"_id":"themes/theme-icarus/include/style/codeblock.styl","hash":"30bee4cf6792e9665eb648cc20b352d9eaff1207","modified":1628406127083},{"_id":"themes/theme-icarus/include/style/donate.styl","hash":"8d0af00628c13134b5f30a558608e7bebf18c2ec","modified":1628406127083},{"_id":"themes/theme-icarus/include/style/footer.styl","hash":"a4ad715dee38b249538ac6cce94efc9b355a904b","modified":1628406127083},{"_id":"themes/theme-icarus/include/style/navbar.styl","hash":"ecc73c8ad504c0fa4bb910eb51500c14e0a8d662","modified":1628406127083},{"_id":"themes/theme-icarus/include/style/helper.styl","hash":"9f3393e6122cc9f351091bfab960674e962da343","modified":1628406127083},{"_id":"themes/theme-icarus/include/style/pagination.styl","hash":"b81bcd7ff915b4e9299533addc01bc4575ec35e3","modified":1628406127084},{"_id":"themes/theme-icarus/include/style/plugin.styl","hash":"679b61b5fc5b3281735a21c37aeb64229d9c51ea","modified":1628406127084},{"_id":"themes/theme-icarus/include/style/responsive.styl","hash":"207083fe287612cddee6608b541861b14ac8de81","modified":1628406127084},{"_id":"themes/theme-icarus/include/style/search.styl","hash":"416737e1da4e7e907bd03609b0fee9e2aacfe56c","modified":1628406127084},{"_id":"themes/theme-icarus/include/style/timeline.styl","hash":"ea61798a09bffdda07efb93c2ff800b63bddc4c4","modified":1628406127084},{"_id":"themes/theme-icarus/include/style/widget.styl","hash":"c746902251136544eb3fe523235b3183f4189460","modified":1628406127084},{"_id":"themes/theme-icarus/include/util/console.js","hash":"59cf9d277d3ac85a496689bd811b1c316001641d","modified":1628406127084},{"_id":"themes/theme-icarus/layout/common/comment.jsx","hash":"427089c33002707b76e2f38709459a6824fd0f9b","modified":1628406127088},{"_id":"themes/theme-icarus/layout/common/donates.jsx","hash":"889fb0a7ccc502f0a43b4a18eb330e351e50493c","modified":1628406127088},{"_id":"themes/theme-icarus/layout/common/article.jsx","hash":"16513ab1745533d0f4cdbdee323339ebab6d02c1","modified":1628406127087},{"_id":"themes/theme-icarus/layout/common/footer.jsx","hash":"a52571e3a3ed7314164798f58932cc1cd997d0b8","modified":1642474663120},{"_id":"themes/theme-icarus/layout/common/head.jsx","hash":"5625c4040a885aaf150f35fe9d07d844d7f94a27","modified":1628406127088},{"_id":"themes/theme-icarus/layout/common/navbar.jsx","hash":"fcd9fd4624dee49207ef09ea2a1c63f524f3710c","modified":1628406127088},{"_id":"themes/theme-icarus/layout/common/plugins.jsx","hash":"f6826c1a5f5f59f4a0aa00c63bdb0ad4ff4eab69","modified":1628406127088},{"_id":"themes/theme-icarus/layout/common/scripts.jsx","hash":"0fe1fddab431fb9f63906d8c480d5cd6b33abc32","modified":1628406127089},{"_id":"themes/theme-icarus/layout/common/search.jsx","hash":"6f244a37293031670a2964fe424ecd062e591d7b","modified":1628406127089},{"_id":"themes/theme-icarus/layout/common/share.jsx","hash":"c9fb0319ad5e5a10ad3636b26a6c2afed14c590f","modified":1628406127089},{"_id":"themes/theme-icarus/layout/common/widgets.jsx","hash":"689cf4a6b79337b11d1d56afa9dda09223a809a1","modified":1628406127089},{"_id":"themes/theme-icarus/layout/plugin/animejs.jsx","hash":"e2aa27c3501a58ef1e91e511557b77395c2c02aa","modified":1628406127090},{"_id":"themes/theme-icarus/layout/plugin/back_to_top.jsx","hash":"7fc0c5aaabd7d0eaff04cb68ec139442dc3414e8","modified":1628406127090},{"_id":"themes/theme-icarus/layout/widget/profile.jsx","hash":"0d3a7fd922c12cc45d2c8d26a8f4d3a9a6ed0ae0","modified":1628406127091},{"_id":"themes/theme-icarus/source/css/cyberpunk.styl","hash":"ae17d3528df0c3f089df14a06b7bd82f1bc5fed9","modified":1628406127091},{"_id":"themes/theme-icarus/source/css/default.styl","hash":"b01da3028e5a1267a40aaae5c86a11187a2259e3","modified":1628406127092},{"_id":"themes/theme-icarus/source/css/style.styl","hash":"5b9815586e993a6ccbe8cdcfc0c65ea38fc315ac","modified":1628406127092},{"_id":"themes/theme-icarus/source/img/favicon.svg","hash":"16fd847265845063a16596761cddb32926073dd2","modified":1628406127094},{"_id":"themes/theme-icarus/source/img/logo.svg","hash":"e9b5c1438ddb576693a15d0713b2a1d9ceda4be9","modified":1628406127094},{"_id":"themes/theme-icarus/source/img/razor-bottom-black.svg","hash":"a3eda07b1c605b456da9cdf335a1075db5e5d72c","modified":1628406127095},{"_id":"themes/theme-icarus/source/img/og_image.png","hash":"b03f163096ca9c350ec962feee9836277b5c2509","modified":1628406127094},{"_id":"themes/theme-icarus/source/img/razor-top-black.svg","hash":"201f1171a43ce667a39091fe47c0f278857f18f0","modified":1628406127095},{"_id":"themes/theme-icarus/source/js/.eslintrc.json","hash":"6bf0641cb69dffac97f69baea192d7fa3ab612cb","modified":1628406127095},{"_id":"themes/theme-icarus/source/js/animation.js","hash":"12cedd5caaf9109eed97e50eeab8f883f6e49be3","modified":1628406127095},{"_id":"themes/theme-icarus/source/js/back_to_top.js","hash":"d91f10c08c726135a13dfa1f422c49d8764ef03f","modified":1628406127095},{"_id":"themes/theme-icarus/source/js/column.js","hash":"0baee024ab67474c073a4c41b495f3e7f0df4505","modified":1628406127095},{"_id":"themes/theme-icarus/source/js/main.js","hash":"13e4b1c4fa287f3db61aae329ad093a81992f23d","modified":1628406127095},{"_id":"themes/theme-icarus/include/schema/common/article.json","hash":"8d78149f44629d0848921c6fb9c008b03cef3116","modified":1628406127077},{"_id":"themes/theme-icarus/include/schema/common/comment.json","hash":"7d744391a8abee9a2c450b6fdd36a3866a488025","modified":1628406127077},{"_id":"themes/theme-icarus/include/schema/common/donates.json","hash":"ae86e6f177bedf4afbe638502c12635027539305","modified":1628406127078},{"_id":"themes/theme-icarus/include/schema/common/footer.json","hash":"09d706cbb94d6da9a0d15c719ce7139325cae1c7","modified":1628406127078},{"_id":"themes/theme-icarus/include/schema/common/head.json","hash":"98889f059c635e6bdbd51effd04cf1cf44968a66","modified":1628406127078},{"_id":"themes/theme-icarus/include/schema/common/navbar.json","hash":"6691e587284c4cf450e0288680d5ff0f3565f090","modified":1628406127078},{"_id":"themes/theme-icarus/include/schema/common/plugins.json","hash":"6036a805749816416850d944f7d64aaae62e5e75","modified":1628406127078},{"_id":"themes/theme-icarus/include/schema/common/providers.json","hash":"97ec953d497fb53594227ae98acaef8a8baa91da","modified":1628406127078},{"_id":"themes/theme-icarus/include/schema/common/search.json","hash":"985fbcbf47054af714ead1a124869d54f2a8b607","modified":1628406127079},{"_id":"themes/theme-icarus/include/schema/common/share.json","hash":"cf4f9ff4fb27c3541b35f57db355c228fa6873e4","modified":1628406127079},{"_id":"themes/theme-icarus/include/schema/common/sidebar.json","hash":"eb241beaec4c73e3085dfb3139ce72e827e20549","modified":1628406127079},{"_id":"themes/theme-icarus/include/schema/common/widgets.json","hash":"cadd9dc942740ecd5037d3943e72f8b6a8399bbe","modified":1628406127079},{"_id":"themes/theme-icarus/include/schema/plugin/animejs.json","hash":"e62ab6e20bd8862efa1ed32e7c0db0f8acbcfdec","modified":1628406127080},{"_id":"themes/theme-icarus/include/schema/plugin/back_to_top.json","hash":"dc0febab7e7b67075d0ad3f80f5ec8b798b68dea","modified":1628406127080},{"_id":"themes/theme-icarus/include/schema/widget/profile.json","hash":"690ee1b0791cab47ea03cf42b5b4932ed2aa5675","modified":1628406127080},{"_id":"themes/theme-icarus/source/img/avatar.png","hash":"63ac9405ec373c2d98e05ecd18a7c748d8b6b68a","modified":1628406127094},{"_id":"public/baidusitemap.xml","hash":"58277b18b56241552052776d3963833aeb33f3b9","modified":1637227270456},{"_id":"public/atom.xml","hash":"ab549dc29efc4c4626e6b68cc347f66efdaf957f","modified":1637227270456},{"_id":"public/sitemap.xml","hash":"c66bb644b7a1160d66597891050ca10df1719028","modified":1637227270456},{"_id":"public/js/algolia.js","hash":"a8df0c0abeeb4ee1d2d720161f3aea7339380704","modified":1637227270456},{"_id":"public/js/google_cse.js","hash":"1a9881669dfdeb2b3214074eee0d3e01e52db2c4","modified":1637227270456},{"_id":"public/js/insight.js","hash":"86bbdb7305d9bf19ad62d2ca2cf169fc8d9f9d31","modified":1637227270456},{"_id":"public/js/toc.js","hash":"da6fb757a1b083b8ed138bf29aad3a7bf8ec4f11","modified":1637227270456},{"_id":"public/content.json","hash":"6f678daf59a5118d82b903100c5c5f550dd50fd5","modified":1637227270456},{"_id":"public/manifest.json","hash":"5aab5ffbd3a78aba97c48ca85b69aee90f63cdd7","modified":1637227270456},{"_id":"public/about-zh/index.html","hash":"0a47c5d35cfc9ed0d22b4d83fe79fd89369d2e8e","modified":1637227270456},{"_id":"public/tags/index.html","hash":"8998e5a97394427b8f2a8387e4211cdc5e568b8c","modified":1637227270456},{"_id":"public/about/index.html","hash":"3e6297185ee6ba00e6604d3bc77628506754a7f5","modified":1637227270456},{"_id":"public/categories/index.html","hash":"5ae6a68122b95f59d094fe0aa6d4224a0c953bf2","modified":1637227270456},{"_id":"public/posts/about/index.html","hash":"b0be535960f32153ac36d48f6eba5906fc4e360d","modified":1637227270456},{"_id":"public/posts/vps-cheatsheet/index.html","hash":"6c13f45d753d4a28637e957eb826b1cb4569106a","modified":1637227270456},{"_id":"public/posts/[2018.9]nlp-short-reviews-week-1/index.html","hash":"65ee96e04c2ad06357a26c0a8e4b9b1fe7e4650a","modified":1637227270456},{"_id":"public/posts/[2018.8.22]RegEx-with-NN/index.html","hash":"7084ded1598d8bd578f6842071e570f4ccab8c69","modified":1637227270456},{"_id":"public/posts/intro-about-KG/index.html","hash":"4fe558151772c51ffd3016946e090ace32697207","modified":1637227270456},{"_id":"public/posts/update-rss/index.html","hash":"281dd22ff5a267ca007832b37dc6d406d2817da9","modified":1637227270456},{"_id":"public/posts/[2018.5.10]Knowledge-Graph-Augmented-Neural-Networks-for-NLP/index.html","hash":"f223d0b4ae199b79a588a9456514b08523eade5b","modified":1637227270456},{"_id":"public/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/index.html","hash":"c87b065ce9f7495fb0f06e2854a77b0c4e4a882e","modified":1637227270456},{"_id":"public/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/index.html","hash":"5bbdc951622ae07614d292a8a5b07f2a4bda55f2","modified":1637227270456},{"_id":"public/posts/[2018.3.20]Event-detection/index.html","hash":"24a39005038b037e9e6dc70f77d744ea7e004e62","modified":1637227270456},{"_id":"public/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/index.html","hash":"0322990f27c6fb1851e2ce58179f08717608cd95","modified":1637227270456},{"_id":"public/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/index.html","hash":"5f1b26bf453172c239fdffd7b1ccc59bbeff9271","modified":1637227270456},{"_id":"public/posts/[2018.2.5]Nested-LSTMs/index.html","hash":"1849d1395df6013d02f2120689f829b7eb01ebab","modified":1637227270456},{"_id":"public/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/index.html","hash":"7d29dc048dc76e86e65af96b265657bea67e767f","modified":1637227270456},{"_id":"public/posts/[2018.1.14]Models-for-relation-extraction/index.html","hash":"ffd0142ec8369d491aa00822c2f0f822778b06a4","modified":1637227270456},{"_id":"public/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/index.html","hash":"57773bb33a97004ec2bd04a7cb37f91a3b380730","modified":1637227270456},{"_id":"public/posts/[2018.1.21]Event-detection-and-co-referentce/index.html","hash":"cd08eda5f2f4f9f626c79177736e2f0b0bcba68e","modified":1637227270456},{"_id":"public/posts/[2017.12.17]Relation-Classification-via-Attention-Model/index.html","hash":"a822903be38b2a41e5eb3c0465f6a5255037132b","modified":1637227270456},{"_id":"public/posts/[2017.12.10]Entity-resolution/index.html","hash":"9d5fb61394cc2f636eeb5d2161a549333e18a2f6","modified":1637227270456},{"_id":"public/posts/Note-of-NLP/index.html","hash":"f70a4d47a19198865fe44d74c02bd49990606dc0","modified":1637227270456},{"_id":"public/posts/Generative-Adversarial-Network/index.html","hash":"547f6345fac2ea5f5234559658d633943f0b5369","modified":1637227270456},{"_id":"public/posts/Note-of-knowledge-graph/index.html","hash":"17b46574d708a43ea5a5f94de7c53111bf7f5562","modified":1637227270456},{"_id":"public/posts/MongoDB-Docker-and-Python/index.html","hash":"669b6831db5b19c56cd5926c26c1f7328f1a6647","modified":1637227270456},{"_id":"public/posts/Hands-on-Scrapy/index.html","hash":"e7997077e0f5f83beaf87b398070ff4403d33436","modified":1637227270456},{"_id":"public/posts/OS-notes/index.html","hash":"6ee694c13055ed89c29b0f6477a1b6ca52d6d6d7","modified":1637227270456},{"_id":"public/posts/EDP-finite-element-method/index.html","hash":"a27c3d5f9c1b8eac95c530f0db6b8125dfa1236c","modified":1637227270456},{"_id":"public/posts/EDP-basic-models/index.html","hash":"ee5b9fa0d51131e23a825b27bfd91a0754420275","modified":1637227270456},{"_id":"public/posts/Sobolev-space/index.html","hash":"28a3fca9830b4a4e7baa8ec01580dcb08845cf04","modified":1637227270456},{"_id":"public/posts/Hilbert-space/index.html","hash":"c844210eb37271dc29d929654955359999f0efcc","modified":1637227270456},{"_id":"public/posts/EDP-basic-matrix-review/index.html","hash":"51f9616ab1a1e908e4109e219c46562bcb05f751","modified":1637227270456},{"_id":"public/posts/Note-of-statistic/index.html","hash":"374230c86209783c333463144bbe2a85fa84ca28","modified":1637227270456},{"_id":"public/posts/Bayes-estimation/index.html","hash":"a3c402d0bd04411e484f4bc2f0b89e508a5213a6","modified":1637227270456},{"_id":"public/posts/learning-OS-and-building-LorriOS/index.html","hash":"3f9c6a26d0b7c4ae64f3c8018aa980f92afd7718","modified":1637227270456},{"_id":"public/posts/datamining-class-pred/index.html","hash":"6f7c1b131d9b753a8d0b3d0ee5aa1163cada6188","modified":1637227270456},{"_id":"public/posts/QuadTree/index.html","hash":"cad8cc22c092199c223f1d1d395ebdf73af053e9","modified":1637227270456},{"_id":"public/posts/management-of-the-firm/index.html","hash":"28ea1682b05d61abf41da918c70ce3ec8e13ca4d","modified":1637227270456},{"_id":"public/posts/machine-learning/index.html","hash":"a5a651419545df707e1bd695bf297ea50fa8a97b","modified":1637227270456},{"_id":"public/posts/ML-CNN/index.html","hash":"22b6e07aaf5d5f1b8b614a4edbcf4a389bf51ce4","modified":1637227270456},{"_id":"public/posts/datamining-qualitative-induction/index.html","hash":"0aa7ec6ded26c2ffd1e0535f41fcfbeb53d363ff","modified":1637227270456},{"_id":"public/posts/datamining-pretreatment/index.html","hash":"19e6dc1cb9b8e2bde4fd79ca7451386f8e5dd8b8","modified":1637227270456},{"_id":"public/posts/Note-of-datamining/index.html","hash":"644aede4350c55c56778f411ab9c1f030585fe7c","modified":1637227270456},{"_id":"public/posts/participe-present-et-gerondif/index.html","hash":"cc3e140f64feb3a153ebcabe1ced5a1476364434","modified":1637227270456},{"_id":"public/posts/proba-ch6/index.html","hash":"36743c09560ae1cb1b732c7bd4cfeeb79798aa8f","modified":1637227270456},{"_id":"public/posts/proba-ch5/index.html","hash":"e7bbdd8b79fe6f21644d7856d6deb887f44c5c28","modified":1637227270456},{"_id":"public/posts/proba-ch4/index.html","hash":"2e5f6f0794b9f2a3787ccf6d806c87754fbb6e20","modified":1637227270456},{"_id":"public/posts/proba-ch3/index.html","hash":"8094d48220f99c63a8834e90ce65509b3348514b","modified":1637227270456},{"_id":"public/posts/proba-ch2/index.html","hash":"523ee4cd3f06e27459d705dfe7c6e10020de55f0","modified":1637227270456},{"_id":"public/posts/proba-ch1/index.html","hash":"9a88069ea2801c640e8e00f78e659252427ac495","modified":1637227270456},{"_id":"public/posts/hexo-with-latex/index.html","hash":"461cb5050efce08d7c9ff46d8a92baa4305918e9","modified":1637227270456},{"_id":"public/posts/Note-of-probability/index.html","hash":"f16ace3eb8e09e4c824f6313a755b7420e376f63","modified":1637227270456},{"_id":"public/posts/projet-enjeu-plugin-chrome-101/index.html","hash":"0d7ca2669e3a47f9a145e09ff76050842a136382","modified":1637227270456},{"_id":"public/posts/graph/index.html","hash":"f01cbfb396d581e1add5a6260f4e8d97bc33e38d","modified":1637227270456},{"_id":"public/posts/compression/index.html","hash":"c527fa4b3ed050d747ef06967d7608f928333ab5","modified":1637227270456},{"_id":"public/posts/Method-of-programming-facing-to-exams/index.html","hash":"75dc56094462fc1e27d6a660e6a2024e9f3819d9","modified":1637227270456},{"_id":"public/posts/Note-of-learning-Algo/index.html","hash":"bb339417b544780ed0a5efbaa64438febf3e222b","modified":1637227270456},{"_id":"public/posts/complexity/index.html","hash":"3b0bf0f0a630a872110f0459f914bf94659e80ee","modified":1637227270456},{"_id":"public/archives/index.html","hash":"e010e702cbfd6b906539ecdc02a8af5d0a712491","modified":1637227270456},{"_id":"public/archives/page/2/index.html","hash":"d5edf94ccd31986fe83474773ea66b2e6a5358a8","modified":1637227270456},{"_id":"public/archives/page/3/index.html","hash":"ba0d4077d22db465c359e6e9a83be69d962d7642","modified":1637227270456},{"_id":"public/archives/page/4/index.html","hash":"0e99555b44b10533831455cfed1ffb80327751b8","modified":1637227270456},{"_id":"public/archives/page/5/index.html","hash":"49a1d0e0256df52ee3acf07a96dfa3aa247a0fea","modified":1637227270456},{"_id":"public/archives/page/6/index.html","hash":"578e682c9021c2c07d97bd9e35d7932d25609b3c","modified":1637227270456},{"_id":"public/archives/2016/index.html","hash":"f942c1d8bf38bf30086918a9d0060af8ceb6f9cb","modified":1637227270456},{"_id":"public/archives/2016/page/2/index.html","hash":"2535018e0c5003282bbc154d11b1580ba2f46c89","modified":1637227270456},{"_id":"public/archives/2016/page/3/index.html","hash":"84e0e9161d49b6df76443b1133b76ce102009b9f","modified":1637227270456},{"_id":"public/archives/2016/11/index.html","hash":"f178094b7a25a657b490676045f8d7c9d5b39b82","modified":1637227270456},{"_id":"public/archives/2016/12/index.html","hash":"ac4156d6190c59e967bdcdc695764a43f2ba44e9","modified":1637227270456},{"_id":"public/archives/2016/12/page/2/index.html","hash":"8b6aed56e946c68da1ac3951404936c5729ac547","modified":1637227270456},{"_id":"public/archives/2017/index.html","hash":"402dbf08420a59f038bdc3ed598c023e8eee57fa","modified":1637227270456},{"_id":"public/archives/2017/page/2/index.html","hash":"25dbb783450869d5ce1b631a471a830b9a102735","modified":1637227270456},{"_id":"public/archives/2017/01/index.html","hash":"f61ce1d9f5e1be64194e247a0c0b3b418deb62d9","modified":1637227270456},{"_id":"public/archives/2017/02/index.html","hash":"6d6540b80210582150f9a792fd8576e6ae59e108","modified":1637227270456},{"_id":"public/archives/2017/03/index.html","hash":"8c6d6d22505af94fc58ed6bcd16450650eb721f4","modified":1637227270456},{"_id":"public/archives/2017/04/index.html","hash":"4d7109ced1c274e6dac1b6c82372206b7b53f1c2","modified":1637227270456},{"_id":"public/archives/2017/06/index.html","hash":"19c1ac5d3502d76f2bff662e3fead267ad317f18","modified":1637227270456},{"_id":"public/archives/2017/12/index.html","hash":"c2a91e1a27b76e47f297f8c7f79dae3f1ea6780e","modified":1637227270456},{"_id":"public/archives/2018/index.html","hash":"0d84ae82701be3a647c1fa1a6587993980a5227b","modified":1637227270456},{"_id":"public/archives/2018/page/2/index.html","hash":"b4baf28f3cdb45141df83fb5ef3a969c1f2ccc25","modified":1637227270456},{"_id":"public/archives/2018/01/index.html","hash":"43bcd08a922bb87ce34a0e61dd5eda2505280edc","modified":1637227270456},{"_id":"public/archives/2018/02/index.html","hash":"7f7a64dd9ed67f56a778e6886f67400ddecced34","modified":1637227270456},{"_id":"public/archives/2018/03/index.html","hash":"f1dcfe05bf38a7315ba314337a2de3f8ed6736a7","modified":1637227270456},{"_id":"public/archives/2018/04/index.html","hash":"914fafa7eb8ea4c3c785203478901b07facebadb","modified":1637227270456},{"_id":"public/archives/2018/05/index.html","hash":"894b2e4aaa0e96f84c26149d0a88440508747ff6","modified":1637227270456},{"_id":"public/archives/2018/07/index.html","hash":"306fd2bacbc11c63aae88cf7ef36465ba17bb912","modified":1637227270456},{"_id":"public/archives/2018/08/index.html","hash":"ffae337111ef6fe0c124ccb53f312d00f35200af","modified":1637227270456},{"_id":"public/archives/2018/09/index.html","hash":"e1885ca3fb22e569a0b4e46dfa914f2506bcd18b","modified":1637227270456},{"_id":"public/archives/2020/index.html","hash":"fa7a5e9bf24dcdcbad82eec4d26802fc9e05da72","modified":1637227270456},{"_id":"public/archives/2020/02/index.html","hash":"ae34ba24afe3b89b6d0ecedfe0788e4d79122c63","modified":1637227270456},{"_id":"public/archives/2021/index.html","hash":"fd05b0a349dfe9af27b94df8568686ebfa4d0391","modified":1637227270456},{"_id":"public/archives/2021/06/index.html","hash":"3670caad27a00922c7af7197ddae6f332443a8a2","modified":1637227270456},{"_id":"public/categories/math/index.html","hash":"65838d132a2dc8f037d6a7e98ad2f870f20d6abc","modified":1637227270456},{"_id":"public/categories/math/page/2/index.html","hash":"9cd0ca258e2b300f2a502efc26363e4207b1a3c3","modified":1637227270456},{"_id":"public/categories/math/unfinished/index.html","hash":"65910e03110066551ea50b2ed3c08759f439d4e3","modified":1637227270456},{"_id":"public/categories/programming/index.html","hash":"928dfa46c900e9b60c5bddb83e174e734b7e9e22","modified":1637227270456},{"_id":"public/categories/programming/page/2/index.html","hash":"c3827abc70bb24783574bfe52b9f385b43cc43b0","modified":1637227270456},{"_id":"public/categories/programming/unfinished/index.html","hash":"d7a0f8377dde9d7335945eba65bbe9d13cfb8f80","modified":1637227270456},{"_id":"public/categories/research/index.html","hash":"128b3ed951cc7e9c3a61a5c718b8c29f166f94b9","modified":1637227270456},{"_id":"public/categories/research/page/2/index.html","hash":"8cc33083a00e1e879aa783700be200ee9e08ef8b","modified":1637227270456},{"_id":"public/categories/other/index.html","hash":"c84241fbae7c4193e94d2e240dcb20e14c662b02","modified":1637227270456},{"_id":"public/categories/francais/index.html","hash":"4cc03f5288a384475f53af75588c95c6c981e770","modified":1637227270456},{"_id":"public/index.html","hash":"624cb8b75e4c77de6677b2ce19238531ad1af5ec","modified":1637227270456},{"_id":"public/page/2/index.html","hash":"f08268bb1a323dcc4c36617c085b47103007fa06","modified":1637227270456},{"_id":"public/page/3/index.html","hash":"11d42c4fc3f4e4b99bf5f2c6e1c826e4d4908a60","modified":1637227270456},{"_id":"public/page/4/index.html","hash":"08998a47ce202ec814059e77ff1db6241ad307b1","modified":1637227270456},{"_id":"public/page/5/index.html","hash":"2b8254f86f43b4d354e2417f3a501a7f00e4f9ab","modified":1637227270456},{"_id":"public/page/6/index.html","hash":"514d23b4e3c0718ab3a17d42984bc0d2b822c558","modified":1637227270456},{"_id":"public/tags/Bayes/index.html","hash":"ed60aba2cd013a07969e8025d197431692c8bb1f","modified":1637227270456},{"_id":"public/tags/statistic/index.html","hash":"d5128782175d1895cd91cc70db1d285324e98d11","modified":1637227270456},{"_id":"public/tags/EDP/index.html","hash":"196aedf054ec4c07c7da8c92d94cfc78a3d062f0","modified":1637227270456},{"_id":"public/tags/matrix/index.html","hash":"2b626b53d705691d34c38ba4d99e975f336a4256","modified":1637227270456},{"_id":"public/tags/math/index.html","hash":"9dbfe39ed7c70e461c90809b124c9f47fd5a739e","modified":1637227270456},{"_id":"public/tags/math/page/2/index.html","hash":"3e532d46dc3194d3cd89e615f6e2138a35f02ef9","modified":1637227270456},{"_id":"public/tags/FEM/index.html","hash":"6642207f918745aa3a3faf5dcebff253e6b2d4b8","modified":1637227270456},{"_id":"public/tags/scrapy/index.html","hash":"0878cf3f0bc601a235f0557fd486fe2716e41513","modified":1637227270456},{"_id":"public/tags/python/index.html","hash":"51e5d0d8b2cc1a4525dcf4d3cc97b5ddf98659a5","modified":1637227270456},{"_id":"public/tags/spider/index.html","hash":"7f3b7ada967b9c660733ae1366c16e52a476c636","modified":1637227270456},{"_id":"public/tags/crawl/index.html","hash":"e123c78f2ba17560a8c58b7175142bfbb3747592","modified":1637227270456},{"_id":"public/tags/Hilbert/index.html","hash":"7246970b207d47a8125da5d09b4f38b01978ab7c","modified":1637227270456},{"_id":"public/tags/analyse/index.html","hash":"df4fe3db9bea8979025ca3af3c92ba9bef2a9294","modified":1637227270456},{"_id":"public/tags/GAN/index.html","hash":"d3597e060ee7eef2c49635f45a38a4aa4f1a2589","modified":1637227270456},{"_id":"public/tags/deep-learning/index.html","hash":"0784e8e4864b0cab96bfa5337d5637b85aecee30","modified":1637227270456},{"_id":"public/tags/machine-learning/index.html","hash":"9f17d51a01f5761833a4d1cb8b8a4de0e3eace6d","modified":1637227270456},{"_id":"public/tags/programming/index.html","hash":"b17206a84d435825909229fb0d091ab8617a504b","modified":1637227270456},{"_id":"public/tags/algo/index.html","hash":"2a01f2d7acd090c4961cef799e18ab513a73dd9f","modified":1637227270456},{"_id":"public/tags/CNN/index.html","hash":"ba7db07b11e3a72201f52c857c595ae2817a0263","modified":1637227270456},{"_id":"public/tags/mongo/index.html","hash":"a5e8569189ac733444e5b58f3feb352e706cb524","modified":1637227270456},{"_id":"public/tags/mongodb/index.html","hash":"3f93a843c1f3c216b6a220cf39794abd1536364f","modified":1637227270456},{"_id":"public/tags/docker/index.html","hash":"21579ea30b34b2240e914fd7783771aeb384240a","modified":1637227270456},{"_id":"public/tags/nlp/index.html","hash":"15aa927b00103284ce22868df7825417f3ca9081","modified":1637227270456},{"_id":"public/tags/datamining/index.html","hash":"c7bc8c12dd1e2a0e8a452107ecb888feb0f8dd6e","modified":1637227270456},{"_id":"public/tags/knowledge-graph/index.html","hash":"5382492c8072e8f2f03e767d81642bd8aca3ef64","modified":1637227270456},{"_id":"public/tags/probability/index.html","hash":"e59e3c4b2d04bc52fe0f389365cd37304e7d127d","modified":1637227270456},{"_id":"public/tags/OS/index.html","hash":"306cefb6096554f339dd69ddb2f22d0c604f521d","modified":1637227270456},{"_id":"public/tags/data-structure/index.html","hash":"0413a4c509bfe1b4951a1747f230a7c48909d35c","modified":1637227270456},{"_id":"public/tags/Sobolev/index.html","hash":"5cfaa8acac5361116237a45aaca9d5c0832225da","modified":1637227270456},{"_id":"public/tags/entity-resolution/index.html","hash":"80d1e8a13da332037872d1fa7f35fb72195aa955","modified":1637227270456},{"_id":"public/tags/sequence-labeling/index.html","hash":"bf1fddbc59aa9579437cd20b0b25d4f54f281664","modified":1637227270456},{"_id":"public/tags/relation-extraction/index.html","hash":"19ca9d64971a3b3921ce4dd9c9014576f5a0bf6a","modified":1637227270456},{"_id":"public/tags/LSTM/index.html","hash":"1de03a7f9a132423f508e0862ee40776adf6eb7f","modified":1637227270456},{"_id":"public/tags/RNN/index.html","hash":"2e2047d3282f2cb1966906b5a042f42904deb4e4","modified":1637227270456},{"_id":"public/tags/distant-supervision/index.html","hash":"cdc4e45a923f471c96af934bff71d906aeb41424","modified":1637227270456},{"_id":"public/tags/relation-classification/index.html","hash":"e5ea69955bb1dc82a226c9dfbaf37765a21e8bde","modified":1637227270456},{"_id":"public/tags/attention/index.html","hash":"421ca8cf77fa0dfbae873eb477cac0e0da7af917","modified":1637227270456},{"_id":"public/tags/event-detection/index.html","hash":"9b19e175b559d5e61dcf0fcea88c62cf97fc16ff","modified":1637227270456},{"_id":"public/tags/co-reference/index.html","hash":"9aee0d15d24eafe9f8833ab19899add4bb1011a2","modified":1637227270456},{"_id":"public/tags/convolution/index.html","hash":"09db848bca8e94a7205ced14c2c35a53ca554daa","modified":1637227270456},{"_id":"public/tags/BiLSTM/index.html","hash":"4801f0b5c840758589e357b7856cc6ee342d3e5f","modified":1637227270456},{"_id":"public/tags/event-extraction/index.html","hash":"1368925a9c50a76bb6c09298bb59f794a9e3154b","modified":1637227270456},{"_id":"public/tags/limited-supervision/index.html","hash":"bbdfc23142fdc2cd16878122b9668f522d2f0413","modified":1637227270456},{"_id":"public/tags/weak-supervision/index.html","hash":"07a177c4419f7508a56b927af57f6b3951496ff1","modified":1637227270456},{"_id":"public/tags/KGC/index.html","hash":"e7f46b00342dd2f15766c90b6d308180da7c6bce","modified":1637227270456},{"_id":"public/tags/neural-network/index.html","hash":"8b589634dc30fee557b0af0354a74a15e40963bb","modified":1637227270456},{"_id":"public/tags/reinforcement-learning/index.html","hash":"752711243308034be0cbd726e83a26d92c7cc011","modified":1637227270456},{"_id":"public/tags/summarization/index.html","hash":"26111dc4ce507870d366739e37b80c632812e66b","modified":1637227270456},{"_id":"public/tags/NLP/index.html","hash":"2c7e56a9abf9f9ff2f600d0e1e57ae8d31e4201f","modified":1637227270456},{"_id":"public/tags/regular-expression/index.html","hash":"c87ceb5a1312917298a9d6b2abe752c60b329189","modified":1637227270456},{"_id":"public/tags/review/index.html","hash":"b74c59d37a6ebcf3e827781546a8476f78f3ad2c","modified":1637227270456},{"_id":"public/tags/complexity/index.html","hash":"c6f067eb6f23be6b4c546dde82c94bbb9ff2d709","modified":1637227270456},{"_id":"public/tags/compression/index.html","hash":"1d8b0b9d030f1e1a561722f5c85eab8ca5692045","modified":1637227270456},{"_id":"public/tags/classification/index.html","hash":"20c54e2cd8e9408f331b8cdde17bf7defcda1ec6","modified":1637227270456},{"_id":"public/tags/prediction/index.html","hash":"4cc24f0693710e3fa0f0a735f7f0c36426661bea","modified":1637227270456},{"_id":"public/tags/qualitative-induction/index.html","hash":"f48c5a78e0a22b69700d5a4f5d911171a0127252","modified":1637227270456},{"_id":"public/tags/graph/index.html","hash":"c758d40eb9df4ad867374e458305b45a9e6660fe","modified":1637227270456},{"_id":"public/tags/hexo/index.html","hash":"e885e6a3b7f58cfa7a1b2f454653de1a9838651d","modified":1637227270456},{"_id":"public/tags/latex/index.html","hash":"03748f3b6dc80f3d80971f603193fd124e4ca0e2","modified":1637227270456},{"_id":"public/tags/mathjax/index.html","hash":"6c7c67401d02b8bc26aa0a81c53b27a74cbb61e5","modified":1637227270456},{"_id":"public/tags/marked/index.html","hash":"2f920b347377d29b5dc45892df8a4e95008727c7","modified":1637227270456},{"_id":"public/tags/knowledge-reasoning/index.html","hash":"c9e784eea78d0f09488f9b111a214b77f8194fbe","modified":1637227270456},{"_id":"public/tags/kernel/index.html","hash":"d8833f5064d5820378c272bd8bdd38fde87a8d51","modified":1637227270456},{"_id":"public/tags/management/index.html","hash":"c32f4d519e85f441f1bc04e690b16324b513bb59","modified":1637227270456},{"_id":"public/tags/firm/index.html","hash":"393c6d03177c0c73b15b7859ba13ea057c5699f7","modified":1637227270456},{"_id":"public/tags/francais/index.html","hash":"a65daad94c30312163d3f2b23e8eb080d4946344","modified":1637227270456},{"_id":"public/tags/language/index.html","hash":"cfb4179cda180be6f33ab6fdb1d23c668dbe6c36","modified":1637227270456},{"_id":"public/tags/aleatoire/index.html","hash":"299147b84e8ec88f1f53e97d30aa84964c88f83e","modified":1637227270456},{"_id":"public/tags/vector/index.html","hash":"df1a997b7500d94873afef3268d170a69f4cc7bc","modified":1637227270456},{"_id":"public/tags/web/index.html","hash":"dcc443fd7cb0f2fc39494482efa36f91d81d3b9c","modified":1637227270456},{"_id":"public/tags/chrome/index.html","hash":"d85cc862fa17249c31ed4a7091f3fa84eb03c77f","modified":1637227270456},{"_id":"public/tags/rss/index.html","hash":"172d3a410cf65f012f80d3306fea1b6d3517291c","modified":1637227270456},{"_id":"public/tags/vps/index.html","hash":"67715f6f801ac8a29235060991a693aa54735444","modified":1637227270456},{"_id":"public/baidu_verify_TcRbK06C8G.html","hash":"e68267f32b8f78af851edccc9c01f6597fcc50b8","modified":1637227270456},{"_id":"public/CNAME","hash":"584ac3adaeb479e7552e94ce2d7b42f3814d180e","modified":1637227270456},{"_id":"public/about/resume-Jue.Wang.pdf","hash":"2b91dcdc01832142e6a24bb6f8e38723c789d510","modified":1637227270456},{"_id":"public/baidu_verify_eUOah4Iuy2.html","hash":"fe1eac761615be2ba4f62006849696dffa0e9b9f","modified":1637227270456},{"_id":"public/img/logo.svg","hash":"e9b5c1438ddb576693a15d0713b2a1d9ceda4be9","modified":1637227270456},{"_id":"public/img/og_image.png","hash":"b03f163096ca9c350ec962feee9836277b5c2509","modified":1637227270456},{"_id":"public/img/favicon.svg","hash":"16fd847265845063a16596761cddb32926073dd2","modified":1637227270456},{"_id":"public/img/razor-bottom-black.svg","hash":"a3eda07b1c605b456da9cdf335a1075db5e5d72c","modified":1637227270456},{"_id":"public/img/razor-top-black.svg","hash":"201f1171a43ce667a39091fe47c0f278857f18f0","modified":1637227270456},{"_id":"public/js/animation.js","hash":"12cedd5caaf9109eed97e50eeab8f883f6e49be3","modified":1637227270456},{"_id":"public/js/column.js","hash":"0baee024ab67474c073a4c41b495f3e7f0df4505","modified":1637227270456},{"_id":"public/js/back_to_top.js","hash":"d91f10c08c726135a13dfa1f422c49d8764ef03f","modified":1637227270456},{"_id":"public/js/main.js","hash":"13e4b1c4fa287f3db61aae329ad093a81992f23d","modified":1637227270456},{"_id":"public/css/cyberpunk.css","hash":"073797b87e28376604d586c48beb66f6fe9cb504","modified":1637227270456},{"_id":"public/css/default.css","hash":"49786c0fefcaa20821d9853a4a6ca81904322793","modified":1637227270456},{"_id":"public/css/style.css","hash":"49786c0fefcaa20821d9853a4a6ca81904322793","modified":1637227270456},{"_id":"public/img/avatar.png","hash":"63ac9405ec373c2d98e05ecd18a7c748d8b6b68a","modified":1637227270456}],"Category":[{"name":"math","_id":"ckw4qufor0004gwtldwdudn8l"},{"name":"unfinished","parent":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufp2000mgwtl0radcg7s"},{"name":"programming","_id":"ckw4qufp5000tgwtl6ywt3c4w"},{"name":"unfinished","parent":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpn001zgwtlf76efbqh"},{"name":"research","_id":"ckw4qufpt002igwtl4r5aa33y"},{"name":"other","_id":"ckw4qufqj004ogwtlejyf8alu"},{"name":"francais","_id":"ckw4qufqq0054gwtl0f4z5t7h"}],"Data":[{"_id":"recommended_posts","data":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}],"Page":[{"title":"","date":"2020-12-28T08:00:00.000Z","_content":"\nHi ~ [Data Intelligence Lab](http://59.111.103.237:8081/)[](https://person.zju.edu.cn/en/should)\n\n Natural Language Processing  Data Mining   Information ExtractionNLP/NLP[](mailto:zjuwangjue@gmail.com)\n\n[](/about/resume-Jue.Wang.pdf)\n\n## \n\n- Jun 2021: I graduated from [CentraleSuplec](https://www.centralesupelec.fr/) with diplme d'Ingnieur (master degree), cheers!\n- Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.\n- Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.\n- Apr 2020: As the first author, I had one long paper accepted to ACL 2020.\n- Feb 2020: I had a remote internship at [StatNLP](https://statnlp-research.github.io/) under the guidance of [Prof. Wei Lu](https://istd.sutd.edu.sg/people/faculty/lu-wei).\n- Aug 2019: I was enrolled in ByteCamp hosted by [ByteDance](https://bytedance.com/en), where I mainly deal with Multimodal Classification.\n- July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.\n- Jun 2018 to Dec 2018: I did an internship in [Rokid](https://www.rokid.com/), where I mainly deal with Spoken Language Understanding.\n- Jun 2017 to Aug 2018: I did an research internship in [Data Intelligence Lab](http://59.111.103.237:8081/).\n\n## \n\n- **Zhejiang University**, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)\n- **Universite Paris Saclay (CentraleSupelec)**, Master (Engineer) in General Engineering, Sep 2016 - May 2021\n- **Zhejiang University**, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018\n\n## \n\nCollege of Computer Science and Technology, Zhejiang University\n\n38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027\n\nEmail: zjuwangjue@gmail.com\n\n\n\n---\n\n[Blog](https://blog.lorrin.info)([RSS](https://blog.lorrin.info/atom.xml)), [Github](https://github.com/LorrinWWW), [](https://www.zhihu.com/people/wang-jue-9/activities), ","source":"about-zh/index.md","raw":"---\ntitle: \"\"\ndate: 2020-12-28 16:00:00\n---\n\nHi ~ [Data Intelligence Lab](http://59.111.103.237:8081/)[](https://person.zju.edu.cn/en/should)\n\n Natural Language Processing  Data Mining   Information ExtractionNLP/NLP[](mailto:zjuwangjue@gmail.com)\n\n[](/about/resume-Jue.Wang.pdf)\n\n## \n\n- Jun 2021: I graduated from [CentraleSuplec](https://www.centralesupelec.fr/) with diplme d'Ingnieur (master degree), cheers!\n- Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.\n- Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.\n- Apr 2020: As the first author, I had one long paper accepted to ACL 2020.\n- Feb 2020: I had a remote internship at [StatNLP](https://statnlp-research.github.io/) under the guidance of [Prof. Wei Lu](https://istd.sutd.edu.sg/people/faculty/lu-wei).\n- Aug 2019: I was enrolled in ByteCamp hosted by [ByteDance](https://bytedance.com/en), where I mainly deal with Multimodal Classification.\n- July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.\n- Jun 2018 to Dec 2018: I did an internship in [Rokid](https://www.rokid.com/), where I mainly deal with Spoken Language Understanding.\n- Jun 2017 to Aug 2018: I did an research internship in [Data Intelligence Lab](http://59.111.103.237:8081/).\n\n## \n\n- **Zhejiang University**, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)\n- **Universite Paris Saclay (CentraleSupelec)**, Master (Engineer) in General Engineering, Sep 2016 - May 2021\n- **Zhejiang University**, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018\n\n## \n\nCollege of Computer Science and Technology, Zhejiang University\n\n38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027\n\nEmail: zjuwangjue@gmail.com\n\n\n\n---\n\n[Blog](https://blog.lorrin.info)([RSS](https://blog.lorrin.info/atom.xml)), [Github](https://github.com/LorrinWWW), [](https://www.zhihu.com/people/wang-jue-9/activities), ","updated":"2021-06-09T01:49:23.109Z","path":"about-zh/index.html","comments":1,"layout":"page","_id":"ckw4qufoj0000gwtl2hx86yv1","content":"<p>Hi ~ <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a><a href=\"https://person.zju.edu.cn/en/should\"></a></p>\n<p> Natural Language Processing  Data Mining   Information ExtractionNLP/NLP<a href=\"mailto:zjuwangjue@gmail.com\"></a></p>\n<p><a href=\"/about/resume-Jue.Wang.pdf\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>Jun 2021: I graduated from <a href=\"https://www.centralesupelec.fr/\">CentraleSuplec</a> with diplme dIngnieur (master degree), cheers!</li>\n<li>Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.</li>\n<li>Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.</li>\n<li>Apr 2020: As the first author, I had one long paper accepted to ACL 2020.</li>\n<li>Feb 2020: I had a remote internship at <a href=\"https://statnlp-research.github.io/\">StatNLP</a> under the guidance of <a href=\"https://istd.sutd.edu.sg/people/faculty/lu-wei\">Prof. Wei Lu</a>.</li>\n<li>Aug 2019: I was enrolled in ByteCamp hosted by <a href=\"https://bytedance.com/en\">ByteDance</a>, where I mainly deal with Multimodal Classification.</li>\n<li>July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.</li>\n<li>Jun 2018 to Dec 2018: I did an internship in <a href=\"https://www.rokid.com/\">Rokid</a>, where I mainly deal with Spoken Language Understanding.</li>\n<li>Jun 2017 to Aug 2018: I did an research internship in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a>.</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><strong>Zhejiang University</strong>, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)</li>\n<li><strong>Universite Paris Saclay (CentraleSupelec)</strong>, Master (Engineer) in General Engineering, Sep 2016 - May 2021</li>\n<li><strong>Zhejiang University</strong>, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>College of Computer Science and Technology, Zhejiang University</p>\n<p>38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027</p>\n<p>Email: <a href=\"mailto:zjuwangjue@gmail.com\">zjuwangjue@gmail.com</a></p>\n<hr>\n<p><a href=\"https://blog.lorrin.info/\">Blog</a>(<a href=\"https://blog.lorrin.info/atom.xml\">RSS</a>), <a href=\"https://github.com/LorrinWWW\">Github</a>, <a href=\"https://www.zhihu.com/people/wang-jue-9/activities\"></a>, </p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>Hi ~ <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a><a href=\"https://person.zju.edu.cn/en/should\"></a></p>\n<p> Natural Language Processing  Data Mining   Information ExtractionNLP/NLP<a href=\"mailto:zjuwangjue@gmail.com\"></a></p>\n<p><a href=\"/about/resume-Jue.Wang.pdf\"></a></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>Jun 2021: I graduated from <a href=\"https://www.centralesupelec.fr/\">CentraleSuplec</a> with diplme dIngnieur (master degree), cheers!</li>\n<li>Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.</li>\n<li>Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.</li>\n<li>Apr 2020: As the first author, I had one long paper accepted to ACL 2020.</li>\n<li>Feb 2020: I had a remote internship at <a href=\"https://statnlp-research.github.io/\">StatNLP</a> under the guidance of <a href=\"https://istd.sutd.edu.sg/people/faculty/lu-wei\">Prof. Wei Lu</a>.</li>\n<li>Aug 2019: I was enrolled in ByteCamp hosted by <a href=\"https://bytedance.com/en\">ByteDance</a>, where I mainly deal with Multimodal Classification.</li>\n<li>July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.</li>\n<li>Jun 2018 to Dec 2018: I did an internship in <a href=\"https://www.rokid.com/\">Rokid</a>, where I mainly deal with Spoken Language Understanding.</li>\n<li>Jun 2017 to Aug 2018: I did an research internship in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a>.</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><strong>Zhejiang University</strong>, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)</li>\n<li><strong>Universite Paris Saclay (CentraleSupelec)</strong>, Master (Engineer) in General Engineering, Sep 2016 - May 2021</li>\n<li><strong>Zhejiang University</strong>, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>College of Computer Science and Technology, Zhejiang University</p>\n<p>38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027</p>\n<p>Email: <a href=\"mailto:&#x7a;&#106;&#117;&#x77;&#97;&#x6e;&#103;&#106;&#x75;&#101;&#64;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#111;&#x6d;\">&#x7a;&#106;&#117;&#x77;&#97;&#x6e;&#103;&#106;&#x75;&#101;&#64;&#103;&#109;&#x61;&#105;&#108;&#x2e;&#x63;&#111;&#x6d;</a></p>\n<hr>\n<p><a href=\"https://blog.lorrin.info/\">Blog</a>(<a href=\"https://blog.lorrin.info/atom.xml\">RSS</a>), <a href=\"https://github.com/LorrinWWW\">Github</a>, <a href=\"https://www.zhihu.com/people/wang-jue-9/activities\"></a>, </p>\n"},{"title":"Jue Wang","date":"2021-06-01T08:00:00.000Z","_content":"\nHello, I am a PhD student in [Data Intelligence Lab](http://59.111.103.237:8081/) of Zhejiang University, advised by [Prof. Lidan Shou](https://person.zju.edu.cn/en/should).\n\nI work on Natural Language Processing and Data Mining. More specifically, my research interests lie in Information Extraction (e.g., Named Entity Recognition and Relation Extraction), NLP in low-resource scenarios (e.g., Weak/Semi-Supervised Learning), and Efficient Algorithms for NLP (e.g., Knowledge Distillation and Network Pruning). If you want to get in touch, please [send me an email](mailto:zjuwangjue@gmail.com). \n\nMy [resume](resume-Jue.Wang.pdf). \n\n## Updates\n\n- Jun 2021: I graduated from [CentraleSuplec](https://www.centralesupelec.fr/) with diplme d'Ingnieur (master degree), cheers!\n- Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.\n- Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.\n- Apr 2020: As the first author, I had one long paper accepted to ACL 2020.\n- Feb 2020: I had a remote internship at [StatNLP](https://statnlp-research.github.io/) under the guidance of [Prof. Wei Lu](https://istd.sutd.edu.sg/people/faculty/lu-wei).\n- Aug 2019: I was enrolled in ByteCamp hosted by [ByteDance](https://bytedance.com/en), where I mainly deal with Multimodal Classification.\n- July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.\n- Jun 2018 to Dec 2018: I did an internship in [Rokid](https://www.rokid.com/), where I mainly deal with Spoken Language Understanding.\n- Jun 2017 to Aug 2018: I did an research internship in [Data Intelligence Lab](http://59.111.103.237:8081/).\n\n## Education\n\n- **Zhejiang University**, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)\n- **Universite Paris Saclay (CentraleSupelec)**, Master (Engineer) in General Engineering, Sep 2016 - May 2021\n- **Zhejiang University**, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018\n\n## Contact\n\nCollege of Computer Science and Technology, Zhejiang University\n\n38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027\n\nEmail: zjuwangjue@gmail.com\n\n\n\n([](/about-zh))\n\n---\n\n[Blog](https://blog.lorrin.info)([RSS](https://blog.lorrin.info/atom.xml)), [Github](https://github.com/LorrinWWW), [](https://www.zhihu.com/people/wang-jue-9/activities), ","source":"about/index.md","raw":"---\ntitle: \"Jue Wang\"\ndate: 2021-6-1 16:00:00\n---\n\nHello, I am a PhD student in [Data Intelligence Lab](http://59.111.103.237:8081/) of Zhejiang University, advised by [Prof. Lidan Shou](https://person.zju.edu.cn/en/should).\n\nI work on Natural Language Processing and Data Mining. More specifically, my research interests lie in Information Extraction (e.g., Named Entity Recognition and Relation Extraction), NLP in low-resource scenarios (e.g., Weak/Semi-Supervised Learning), and Efficient Algorithms for NLP (e.g., Knowledge Distillation and Network Pruning). If you want to get in touch, please [send me an email](mailto:zjuwangjue@gmail.com). \n\nMy [resume](resume-Jue.Wang.pdf). \n\n## Updates\n\n- Jun 2021: I graduated from [CentraleSuplec](https://www.centralesupelec.fr/) with diplme d'Ingnieur (master degree), cheers!\n- Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.\n- Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.\n- Apr 2020: As the first author, I had one long paper accepted to ACL 2020.\n- Feb 2020: I had a remote internship at [StatNLP](https://statnlp-research.github.io/) under the guidance of [Prof. Wei Lu](https://istd.sutd.edu.sg/people/faculty/lu-wei).\n- Aug 2019: I was enrolled in ByteCamp hosted by [ByteDance](https://bytedance.com/en), where I mainly deal with Multimodal Classification.\n- July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.\n- Jun 2018 to Dec 2018: I did an internship in [Rokid](https://www.rokid.com/), where I mainly deal with Spoken Language Understanding.\n- Jun 2017 to Aug 2018: I did an research internship in [Data Intelligence Lab](http://59.111.103.237:8081/).\n\n## Education\n\n- **Zhejiang University**, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)\n- **Universite Paris Saclay (CentraleSupelec)**, Master (Engineer) in General Engineering, Sep 2016 - May 2021\n- **Zhejiang University**, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018\n\n## Contact\n\nCollege of Computer Science and Technology, Zhejiang University\n\n38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027\n\nEmail: zjuwangjue@gmail.com\n\n\n\n([](/about-zh))\n\n---\n\n[Blog](https://blog.lorrin.info)([RSS](https://blog.lorrin.info/atom.xml)), [Github](https://github.com/LorrinWWW), [](https://www.zhihu.com/people/wang-jue-9/activities), ","updated":"2021-11-18T09:10:27.259Z","path":"about/index.html","comments":1,"layout":"page","_id":"ckw4qufop0002gwtl1mor8n7u","content":"<p>Hello, I am a PhD student in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a> of Zhejiang University, advised by <a href=\"https://person.zju.edu.cn/en/should\">Prof. Lidan Shou</a>.</p>\n<p>I work on Natural Language Processing and Data Mining. More specifically, my research interests lie in Information Extraction (e.g., Named Entity Recognition and Relation Extraction), NLP in low-resource scenarios (e.g., Weak/Semi-Supervised Learning), and Efficient Algorithms for NLP (e.g., Knowledge Distillation and Network Pruning). If you want to get in touch, please <a href=\"mailto:zjuwangjue@gmail.com\">send me an email</a>. </p>\n<p>My <a href=\"resume-Jue.Wang.pdf\">resume</a>. </p>\n<h2 id=\"Updates\"><a href=\"#Updates\" class=\"headerlink\" title=\"Updates\"></a>Updates</h2><ul>\n<li>Jun 2021: I graduated from <a href=\"https://www.centralesupelec.fr/\">CentraleSuplec</a> with diplme dIngnieur (master degree), cheers!</li>\n<li>Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.</li>\n<li>Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.</li>\n<li>Apr 2020: As the first author, I had one long paper accepted to ACL 2020.</li>\n<li>Feb 2020: I had a remote internship at <a href=\"https://statnlp-research.github.io/\">StatNLP</a> under the guidance of <a href=\"https://istd.sutd.edu.sg/people/faculty/lu-wei\">Prof. Wei Lu</a>.</li>\n<li>Aug 2019: I was enrolled in ByteCamp hosted by <a href=\"https://bytedance.com/en\">ByteDance</a>, where I mainly deal with Multimodal Classification.</li>\n<li>July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.</li>\n<li>Jun 2018 to Dec 2018: I did an internship in <a href=\"https://www.rokid.com/\">Rokid</a>, where I mainly deal with Spoken Language Understanding.</li>\n<li>Jun 2017 to Aug 2018: I did an research internship in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a>.</li>\n</ul>\n<h2 id=\"Education\"><a href=\"#Education\" class=\"headerlink\" title=\"Education\"></a>Education</h2><ul>\n<li><strong>Zhejiang University</strong>, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)</li>\n<li><strong>Universite Paris Saclay (CentraleSupelec)</strong>, Master (Engineer) in General Engineering, Sep 2016 - May 2021</li>\n<li><strong>Zhejiang University</strong>, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018</li>\n</ul>\n<h2 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h2><p>College of Computer Science and Technology, Zhejiang University</p>\n<p>38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027</p>\n<p>Email: <a href=\"mailto:zjuwangjue@gmail.com\">zjuwangjue@gmail.com</a></p>\n<p>(<a href=\"/about-zh\"></a>)</p>\n<hr>\n<p><a href=\"https://blog.lorrin.info/\">Blog</a>(<a href=\"https://blog.lorrin.info/atom.xml\">RSS</a>), <a href=\"https://github.com/LorrinWWW\">Github</a>, <a href=\"https://www.zhihu.com/people/wang-jue-9/activities\"></a>, </p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>Hello, I am a PhD student in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a> of Zhejiang University, advised by <a href=\"https://person.zju.edu.cn/en/should\">Prof. Lidan Shou</a>.</p>\n<p>I work on Natural Language Processing and Data Mining. More specifically, my research interests lie in Information Extraction (e.g., Named Entity Recognition and Relation Extraction), NLP in low-resource scenarios (e.g., Weak/Semi-Supervised Learning), and Efficient Algorithms for NLP (e.g., Knowledge Distillation and Network Pruning). If you want to get in touch, please <a href=\"mailto:zjuwangjue@gmail.com\">send me an email</a>. </p>\n<p>My <a href=\"resume-Jue.Wang.pdf\">resume</a>. </p>\n<h2 id=\"Updates\"><a href=\"#Updates\" class=\"headerlink\" title=\"Updates\"></a>Updates</h2><ul>\n<li>Jun 2021: I graduated from <a href=\"https://www.centralesupelec.fr/\">CentraleSuplec</a> with diplme dIngnieur (master degree), cheers!</li>\n<li>Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.</li>\n<li>Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.</li>\n<li>Apr 2020: As the first author, I had one long paper accepted to ACL 2020.</li>\n<li>Feb 2020: I had a remote internship at <a href=\"https://statnlp-research.github.io/\">StatNLP</a> under the guidance of <a href=\"https://istd.sutd.edu.sg/people/faculty/lu-wei\">Prof. Wei Lu</a>.</li>\n<li>Aug 2019: I was enrolled in ByteCamp hosted by <a href=\"https://bytedance.com/en\">ByteDance</a>, where I mainly deal with Multimodal Classification.</li>\n<li>July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.</li>\n<li>Jun 2018 to Dec 2018: I did an internship in <a href=\"https://www.rokid.com/\">Rokid</a>, where I mainly deal with Spoken Language Understanding.</li>\n<li>Jun 2017 to Aug 2018: I did an research internship in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a>.</li>\n</ul>\n<h2 id=\"Education\"><a href=\"#Education\" class=\"headerlink\" title=\"Education\"></a>Education</h2><ul>\n<li><strong>Zhejiang University</strong>, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)</li>\n<li><strong>Universite Paris Saclay (CentraleSupelec)</strong>, Master (Engineer) in General Engineering, Sep 2016 - May 2021</li>\n<li><strong>Zhejiang University</strong>, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018</li>\n</ul>\n<h2 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h2><p>College of Computer Science and Technology, Zhejiang University</p>\n<p>38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027</p>\n<p>Email: <a href=\"mailto:&#122;&#106;&#117;&#119;&#x61;&#x6e;&#103;&#x6a;&#x75;&#x65;&#x40;&#103;&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;&#111;&#109;\">&#122;&#106;&#117;&#119;&#x61;&#x6e;&#103;&#x6a;&#x75;&#x65;&#x40;&#103;&#x6d;&#97;&#105;&#x6c;&#x2e;&#99;&#111;&#109;</a></p>\n<p>(<a href=\"/about-zh\"></a>)</p>\n<hr>\n<p><a href=\"https://blog.lorrin.info/\">Blog</a>(<a href=\"https://blog.lorrin.info/atom.xml\">RSS</a>), <a href=\"https://github.com/LorrinWWW\">Github</a>, <a href=\"https://www.zhihu.com/people/wang-jue-9/activities\"></a>, </p>\n"},{"title":"tags","date":"2016-11-27T05:15:12.000Z","type":"tags","layout":"tags","_content":"","source":"tags/index.md","raw":"---\ntitle: tags\ndate: 2016-11-27 13:15:12\ntype: \"tags\"\nlayout: \"tags\"\n---\n","updated":"2018-03-10T21:47:27.796Z","path":"tags/index.html","comments":1,"_id":"ckw4qufos0006gwtl0lkj9jd7","content":"","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":""},{"title":"categories","date":"2016-11-27T05:13:12.000Z","type":"categories","layout":"categories","_content":"","source":"categories/index.md","raw":"---\ntitle: categories\ndate: 2016-11-27 13:13:12\ntype: \"categories\" \nlayout: \"categories\"\n---\n","updated":"2018-03-10T21:47:49.441Z","path":"categories/index.html","comments":1,"_id":"ckw4qufou0008gwtl4chcawnh","content":"","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":""}],"Post":[{"title":" Bayes estimation","date":"2017-01-07T08:46:31.000Z","_content":"\n\n\n\n\n$\\theta$$\\theta$$\\theta$\n\n## \n\n\n\n\n\n98%5% \n98%5% \n\n1+1=\n\n1% \n$$\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}\n$$\n\n$$\np(|)=\\frac{p(|)p()}{p()}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324\n$$\n\n\n\n## \n\n\n$$\n\\theta: \\pi(\\theta)\n$$\n\n$$\n\\widetilde{X} = \\{ X_1,...,X_n \\}\n$$\n\n$$\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)\n$$\n\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}\n$$\nT\n$$\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)\n$$\n\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )\n$$\n\n\n- \n- \n- \n\n\n\n\n\n- x\n- ","source":"_posts/Bayes-estimation.md","raw":"---\ntitle:  Bayes estimation\ndate: 2017-01-07 16:46:31\ncategories: [math]\ntags: [Bayes, statistic]\n---\n\n\n\n\n\n$\\theta$$\\theta$$\\theta$\n\n## \n\n\n\n\n\n98%5% \n98%5% \n\n1+1=\n\n1% \n$$\np(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}\n$$\n\n$$\np(|)=\\frac{p(|)p()}{p()}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324\n$$\n\n\n\n## \n\n\n$$\n\\theta: \\pi(\\theta)\n$$\n\n$$\n\\widetilde{X} = \\{ X_1,...,X_n \\}\n$$\n\n$$\np(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)\n$$\n\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\\\\n= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}\n$$\nT\n$$\np(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)\n$$\n\n$$\n\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )\n$$\n\n\n- \n- \n- \n\n\n\n\n\n- x\n- ","slug":"Bayes-estimation","published":1,"updated":"2017-01-07T16:48:18.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufom0001gwtl4ehk83to","content":"<p></p>\n<p></p>\n<p>$\\theta$$\\theta$$\\theta$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p></p>\n<p>98%5%<br>98%5% </p>\n<p>1+1=</p>\n<p>1%<br>$$<br>p(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}<br>$$</p>\n<p>$$<br>p(|)=\\frac{p(|)p()}{p()}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324<br>$$</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br>$$<br>\\theta: \\pi(\\theta)<br>$$<br><br>$$<br>\\widetilde{X} = { X_1,,X_n }<br>$$<br><br>$$<br>p(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)<br>$$<br><br>$$<br>\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\<br>= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}<br>$$<br>T<br>$$<br>p(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)<br>$$<br><br>$$<br>\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )<br>$$<br></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<p></p>\n<ul>\n<li>x</li>\n<li></li>\n</ul>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p></p>\n<p></p>\n<p>$\\theta$$\\theta$$\\theta$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<p></p>\n<p>98%5%<br>98%5% </p>\n<p>1+1=</p>\n<p>1%<br>$$<br>p(y_i|x) = \\frac{p(x|y_i)p(y_i)}{p(x)}<br>$$</p>\n<p>$$<br>p(|)=\\frac{p(|)p()}{p()}=\\frac{0.95\\times 0.01}{0.95 \\times 0.01 + 0.02 \\times 0.99} = 0.324<br>$$</p>\n<p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br>$$<br>\\theta: \\pi(\\theta)<br>$$<br><br>$$<br>\\widetilde{X} = { X_1,,X_n }<br>$$<br><br>$$<br>p(\\widetilde{x},\\theta) = p(\\widetilde{x} |\\theta)\\pi(\\theta)<br>$$<br><br>$$<br>\\pi(\\theta|\\widetilde{x} ) = \\frac{p(\\widetilde{x} ,\\theta)}{p(\\widetilde{x})} \\<br>= \\frac{p(\\widetilde{x} |\\theta)\\pi(\\theta)}{\\int{p(\\widetilde{x} |\\theta)\\pi(\\theta) d\\theta}}<br>$$<br>T<br>$$<br>p(\\widetilde{x}|\\theta) = p(\\widetilde{x} |T = t)p_T(t|\\theta) \\varpropto p_T(t|\\theta)<br>$$<br><br>$$<br>\\pi(\\theta|\\widetilde{x} ) = \\pi(\\theta|t )<br>$$<br></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p></p>\n<p></p>\n<ul>\n<li>x</li>\n<li></li>\n</ul>\n"},{"title":"EDP","date":"2017-02-07T02:22:27.000Z","_content":"\n## \n\n1. A est une matrice hermitienne <=> A=A* et donc A est normale\n2. A est une matrice  unitaire () <=> A^-1 = A* et donc A est normale\n3. A est une matrice orthogonale <=> A=A^T\n\n\n\n## Schur\n\n$$\nA = [a_{ij}]_{n\\times n} , \\lambda_i , x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n,A \\\\\nA = SDS^{-1}\n$$\n\n**A***n**n*U*n*T\n$$\nA = UTU^{-1}\n$$\n\n## \n\n$$\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}\n$$\n\nU\n\n\n\n## Cholesky\n\n\n\n1. une matrice hermitienneHermitiankxy(x*)Ay\n2. Positive-definiteAx(x^T)Ax((x*)Ax>0)\n\nL A = LL*\n\n\n\n## QR\n\nA = QR*Q**Q*T*Q*=*I**R*\n\n","source":"_posts/EDP-basic-matrix-review.md","raw":"---\ntitle: 'EDP'\ndate: 2017-02-07 10:22:27\ncategories: [math]\ntags: [EDP, matrix]\n---\n\n## \n\n1. A est une matrice hermitienne <=> A=A* et donc A est normale\n2. A est une matrice  unitaire () <=> A^-1 = A* et donc A est normale\n3. A est une matrice orthogonale <=> A=A^T\n\n\n\n## Schur\n\n$$\nA = [a_{ij}]_{n\\times n} , \\lambda_i , x_i \\\\\nS = [x_1,...,x_n], D = diag[\\lambda_1,...,\\lambda_n] \\\\\n,A \\\\\nA = SDS^{-1}\n$$\n\n**A***n**n*U*n*T\n$$\nA = UTU^{-1}\n$$\n\n## \n\n$$\nUU^* = I \\\\\ni.e. \\to U^*= U^{-1}\n$$\n\nU\n\n\n\n## Cholesky\n\n\n\n1. une matrice hermitienneHermitiankxy(x*)Ay\n2. Positive-definiteAx(x^T)Ax((x*)Ax>0)\n\nL A = LL*\n\n\n\n## QR\n\nA = QR*Q**Q*T*Q*=*I**R*\n\n","slug":"EDP-basic-matrix-review","published":1,"updated":"2017-02-07T10:40:09.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufop0003gwtl3dk5e0gb","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>A est une matrice hermitienne &lt;=&gt; A=A* et donc A est normale</li>\n<li>A est une matrice  unitaire () &lt;=&gt; A^-1 = A* et donc A est normale</li>\n<li>A est une matrice orthogonale &lt;=&gt; A=A^T</li>\n</ol>\n<h2 id=\"Schur\"><a href=\"#Schur\" class=\"headerlink\" title=\"Schur\"></a>Schur</h2><p>$$<br>A = [a_{ij}]_{n\\times n} , \\lambda_i , x_i \\<br>S = [x_1,,x_n], D = diag[\\lambda_1,,\\lambda_n] \\<br>,A \\<br>A = SDS^{-1}<br>$$</p>\n<p><strong>A</strong><em>n</em><em>n</em>U<em>n</em>T<br>$$<br>A = UTU^{-1}<br>$$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$$<br>UU^* = I \\<br>i.e. \\to U^*= U^{-1}<br>$$</p>\n<p>U</p>\n<h2 id=\"Cholesky\"><a href=\"#Cholesky\" class=\"headerlink\" title=\"Cholesky\"></a>Cholesky</h2><p></p>\n<ol>\n<li>une matrice hermitienneHermitiankxy(x*)Ay</li>\n<li>Positive-definiteAx(x^T)Ax((x*)Ax&gt;0)</li>\n</ol>\n<p>L A = LL*</p>\n<h2 id=\"QR\"><a href=\"#QR\" class=\"headerlink\" title=\"QR\"></a>QR</h2><p>A = QR<em>Q</em><em>Q</em>T<em>Q</em>&nbsp;=&nbsp;<em>I</em><em>R</em></p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li>A est une matrice hermitienne &lt;=&gt; A=A* et donc A est normale</li>\n<li>A est une matrice  unitaire () &lt;=&gt; A^-1 = A* et donc A est normale</li>\n<li>A est une matrice orthogonale &lt;=&gt; A=A^T</li>\n</ol>\n<h2 id=\"Schur\"><a href=\"#Schur\" class=\"headerlink\" title=\"Schur\"></a>Schur</h2><p>$$<br>A = [a_{ij}]_{n\\times n} , \\lambda_i , x_i \\<br>S = [x_1,,x_n], D = diag[\\lambda_1,,\\lambda_n] \\<br>,A \\<br>A = SDS^{-1}<br>$$</p>\n<p><strong>A</strong><em>n</em><em>n</em>U<em>n</em>T<br>$$<br>A = UTU^{-1}<br>$$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$$<br>UU^* = I \\<br>i.e. \\to U^*= U^{-1}<br>$$</p>\n<p>U</p>\n<h2 id=\"Cholesky\"><a href=\"#Cholesky\" class=\"headerlink\" title=\"Cholesky\"></a>Cholesky</h2><p></p>\n<ol>\n<li>une matrice hermitienneHermitiankxy(x*)Ay</li>\n<li>Positive-definiteAx(x^T)Ax((x*)Ax&gt;0)</li>\n</ol>\n<p>L A = LL*</p>\n<h2 id=\"QR\"><a href=\"#QR\" class=\"headerlink\" title=\"QR\"></a>QR</h2><p>A = QR<em>Q</em><em>Q</em>T<em>Q</em>=<em>I</em><em>R</em></p>\n"},{"title":"EDP basic models","date":"2017-03-06T02:04:58.000Z","_content":"\n# Examples of moedels\n\n1.    Problem of Cauchy\n\n      **Nomenclature** : problem of Cauchy\n\n      **Equation** : system of 2 differential equations of order 2\n\n      **Conditions** : initials (all the data from the same point) i.e. fix time\n\n      $$\n      \\begin{equation}\n        \\begin{cases}\n          \\frac{dS}{dt}(t) = F(S,R)  ,  \\\\\n          \\frac{dR}{dt}(t) = G(S,R) ,  \\\\\n          S(0) = S^0 \\\\\n          R(0) = R^0\n        \\end{cases}\n      \\end{equation}\n      $$\n\n2.    Problem of Dirichlet\n\n      **Nomenclature** : problem of Dirichlet\n\n      **Equation** : scalar differential equation of order 2.\n\n      **Conditions** : prescribed value at the edge\n\n      $$\n      \\begin{equation}\n        \\begin{cases}\n      - \\frac{d}{dx} ( k \\frac{d\\theta}{dx})(x) + \\theta(x) = f(x) 0<x<L, \\\\\n        \\theta(0) = \\theta_0, \\theta(L) = \\theta_L \\\\\n     \\end{cases}\n   \\end{equation}\n$$\n\n   **Remark:**\n\n   - kles differences finies et les elements finis.\n   - **$\\theta(L)$$\\theta'(0)$$\\theta'(0)$$\\theta(L)=\\theta(L) = \\theta_L$\n\n### Physic examples\n\n- Fluide environnant au repos\n$$\n  \\rho c_v \\partial_t{\\theta} - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n$$\n  - init condition:\n$$\n    \\theta(0,.) = \\theta_0\n    $$\n\n-   condition at the edges could be:\n\n    - condition of Dirichlet:\n      $$\n      \\theta(t,.) = g(t)\n      $$\n\n    - Condition of Neumann:\n      $$\n      \\overrightarrow{grad}(\\theta)(t,.) \\cdot \\vec{n}= h(t)\n      $$\n\n    - Condition of Dirichlet and Neumann: Mix\n\n-   Fluide environnant en mouvement a une vitesse $\\vec u(t,x)$\n    $$\n    \\rho c_v \\partial_t{\\theta} - div(\\rho c_v \\theta \\vec u) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n    $$\n    si le fluide est incompressible i.e $\\partial_t \\rho = 0$ soit encore $div(\\vec u) = 0$ (), alors:\n    $$\n    \\rho c_v \\partial_t{\\theta} - \\vec u \\cdot div(\\rho c_v \\theta ) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n    $$\n    \n\n    ","source":"_posts/EDP-basic-models.md","raw":"---\ntitle: EDP basic models\ncategories: [math]\ntags:\n  - math\n  - EDP\ndate: 2017-03-06 10:04:58\n---\n\n# Examples of moedels\n\n1.    Problem of Cauchy\n\n      **Nomenclature** : problem of Cauchy\n\n      **Equation** : system of 2 differential equations of order 2\n\n      **Conditions** : initials (all the data from the same point) i.e. fix time\n\n      $$\n      \\begin{equation}\n        \\begin{cases}\n          \\frac{dS}{dt}(t) = F(S,R)  ,  \\\\\n          \\frac{dR}{dt}(t) = G(S,R) ,  \\\\\n          S(0) = S^0 \\\\\n          R(0) = R^0\n        \\end{cases}\n      \\end{equation}\n      $$\n\n2.    Problem of Dirichlet\n\n      **Nomenclature** : problem of Dirichlet\n\n      **Equation** : scalar differential equation of order 2.\n\n      **Conditions** : prescribed value at the edge\n\n      $$\n      \\begin{equation}\n        \\begin{cases}\n      - \\frac{d}{dx} ( k \\frac{d\\theta}{dx})(x) + \\theta(x) = f(x) 0<x<L, \\\\\n        \\theta(0) = \\theta_0, \\theta(L) = \\theta_L \\\\\n     \\end{cases}\n   \\end{equation}\n$$\n\n   **Remark:**\n\n   - kles differences finies et les elements finis.\n   - **$\\theta(L)$$\\theta'(0)$$\\theta'(0)$$\\theta(L)=\\theta(L) = \\theta_L$\n\n### Physic examples\n\n- Fluide environnant au repos\n$$\n  \\rho c_v \\partial_t{\\theta} - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n$$\n  - init condition:\n$$\n    \\theta(0,.) = \\theta_0\n    $$\n\n-   condition at the edges could be:\n\n    - condition of Dirichlet:\n      $$\n      \\theta(t,.) = g(t)\n      $$\n\n    - Condition of Neumann:\n      $$\n      \\overrightarrow{grad}(\\theta)(t,.) \\cdot \\vec{n}= h(t)\n      $$\n\n    - Condition of Dirichlet and Neumann: Mix\n\n-   Fluide environnant en mouvement a une vitesse $\\vec u(t,x)$\n    $$\n    \\rho c_v \\partial_t{\\theta} - div(\\rho c_v \\theta \\vec u) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n    $$\n    si le fluide est incompressible i.e $\\partial_t \\rho = 0$ soit encore $div(\\vec u) = 0$ (), alors:\n    $$\n    \\rho c_v \\partial_t{\\theta} - \\vec u \\cdot div(\\rho c_v \\theta ) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f\n    $$\n    \n\n    ","slug":"EDP-basic-models","published":1,"updated":"2017-03-06T11:11:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufot0007gwtldi2mbss0","content":"<h1 id=\"Examples-of-moedels\"><a href=\"#Examples-of-moedels\" class=\"headerlink\" title=\"Examples of moedels\"></a>Examples of moedels</h1><ol>\n<li><p>Problem of Cauchy</p>\n<p>   <strong>Nomenclature</strong> : problem of Cauchy</p>\n<p>   <strong>Equation</strong> : system of 2 differential equations of order 2</p>\n<p>   <strong>Conditions</strong> : initials (all the data from the same point) i.e. fix time</p>\n<p>   $$<br>   \\begin{equation}</p>\n<pre><code> \\begin{cases}\n   \\frac{dS}{dt}(t) = F(S,R)  ,  \\\\\n   \\frac{dR}{dt}(t) = G(S,R) ,  \\\\\n   S(0) = S^0 \\\\\n   R(0) = R^0\n \\end{cases}\n</code></pre>\n<p>   \\end{equation}<br>   $$</p>\n</li>\n<li><p>Problem of Dirichlet</p>\n<p>   <strong>Nomenclature</strong> : problem of Dirichlet</p>\n<p>   <strong>Equation</strong> : scalar differential equation of order 2.</p>\n<p>   <strong>Conditions</strong> : prescribed value at the edge</p>\n<p>   $$<br>   \\begin{equation}</p>\n<pre><code> \\begin{cases}\n</code></pre>\n<ul>\n<li>\\frac{d}{dx} ( k \\frac{d\\theta}{dx})(x) + \\theta(x) = f(x) 0&lt;x&lt;L, \\<br>\\theta(0) = \\theta_0, \\theta(L) = \\theta_L \\<br>\\end{cases}<br>\\end{equation}<br>$$</li>\n</ul>\n</li>\n</ol>\n<p>   <strong>Remark:</strong></p>\n<ul>\n<li>kles differences finies et les elements finis.</li>\n<li><em></em>$\\theta(L)$$\\theta(0)$$\\theta(0)$$\\theta(L)=\\theta(L) = \\theta_L$</li>\n</ul>\n<h3 id=\"Physic-examples\"><a href=\"#Physic-examples\" class=\"headerlink\" title=\"Physic examples\"></a>Physic examples</h3><ul>\n<li><p>Fluide environnant au repos<br>$$<br>\\rho c_v \\partial_t{\\theta} - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f<br>$$</p>\n<ul>\n<li>init condition:<br>$$<br>\\theta(0,.) = \\theta_0<br>$$</li>\n</ul>\n</li>\n<li><p>condition at the edges could be:</p>\n<ul>\n<li><p>condition of Dirichlet:<br>$$<br>\\theta(t,.) = g(t)<br>$$</p>\n</li>\n<li><p>Condition of Neumann:<br>$$<br>\\overrightarrow{grad}(\\theta)(t,.) \\cdot \\vec{n}= h(t)<br>$$</p>\n</li>\n<li><p>Condition of Dirichlet and Neumann: Mix</p>\n</li>\n</ul>\n</li>\n<li><p>Fluide environnant en mouvement a une vitesse $\\vec u(t,x)$<br>  $$<br>  \\rho c_v \\partial_t{\\theta} - div(\\rho c_v \\theta \\vec u) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f<br>  $$<br>  si le fluide est incompressible i.e $\\partial_t \\rho = 0$ soit encore $div(\\vec u) = 0$ (), alors:<br>  $$<br>  \\rho c_v \\partial_t{\\theta} - \\vec u \\cdot div(\\rho c_v \\theta ) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f<br>  $$<br>  </p>\n<p>  </p>\n</li>\n</ul>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"Examples-of-moedels\"><a href=\"#Examples-of-moedels\" class=\"headerlink\" title=\"Examples of moedels\"></a>Examples of moedels</h1><ol>\n<li><p>Problem of Cauchy</p>\n<p>   <strong>Nomenclature</strong> : problem of Cauchy</p>\n<p>   <strong>Equation</strong> : system of 2 differential equations of order 2</p>\n<p>   <strong>Conditions</strong> : initials (all the data from the same point) i.e. fix time</p>\n<p>   $$<br>   \\begin{equation}</p>\n<pre><code> \\begin&#123;cases&#125;\n   \\frac&#123;dS&#125;&#123;dt&#125;(t) = F(S,R)  ,  \\\\\n   \\frac&#123;dR&#125;&#123;dt&#125;(t) = G(S,R) ,  \\\\\n   S(0) = S^0 \\\\\n   R(0) = R^0\n \\end&#123;cases&#125;\n</code></pre>\n<p>   \\end{equation}<br>   $$</p>\n</li>\n<li><p>Problem of Dirichlet</p>\n<p>   <strong>Nomenclature</strong> : problem of Dirichlet</p>\n<p>   <strong>Equation</strong> : scalar differential equation of order 2.</p>\n<p>   <strong>Conditions</strong> : prescribed value at the edge</p>\n<p>   $$<br>   \\begin{equation}</p>\n<pre><code> \\begin&#123;cases&#125;\n</code></pre>\n<ul>\n<li>\\frac{d}{dx} ( k \\frac{d\\theta}{dx})(x) + \\theta(x) = f(x) 0&lt;x&lt;L, \\<br>\\theta(0) = \\theta_0, \\theta(L) = \\theta_L \\<br>\\end{cases}<br>\\end{equation}<br>$$</li>\n</ul>\n</li>\n</ol>\n<p>   <strong>Remark:</strong></p>\n<ul>\n<li>kles differences finies et les elements finis.</li>\n<li><em></em>$\\theta(L)$$\\theta(0)$$\\theta(0)$$\\theta(L)=\\theta(L) = \\theta_L$</li>\n</ul>\n<h3 id=\"Physic-examples\"><a href=\"#Physic-examples\" class=\"headerlink\" title=\"Physic examples\"></a>Physic examples</h3><ul>\n<li><p>Fluide environnant au repos<br>$$<br>\\rho c_v \\partial_t{\\theta} - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f<br>$$</p>\n<ul>\n<li>init condition:<br>$$<br>\\theta(0,.) = \\theta_0<br>$$</li>\n</ul>\n</li>\n<li><p>condition at the edges could be:</p>\n<ul>\n<li><p>condition of Dirichlet:<br>$$<br>\\theta(t,.) = g(t)<br>$$</p>\n</li>\n<li><p>Condition of Neumann:<br>$$<br>\\overrightarrow{grad}(\\theta)(t,.) \\cdot \\vec{n}= h(t)<br>$$</p>\n</li>\n<li><p>Condition of Dirichlet and Neumann: Mix</p>\n</li>\n</ul>\n</li>\n<li><p>Fluide environnant en mouvement a une vitesse $\\vec u(t,x)$<br>  $$<br>  \\rho c_v \\partial_t{\\theta} - div(\\rho c_v \\theta \\vec u) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f<br>  $$<br>  si le fluide est incompressible i.e $\\partial_t \\rho = 0$ soit encore $div(\\vec u) = 0$ (), alors:<br>  $$<br>  \\rho c_v \\partial_t{\\theta} - \\vec u \\cdot div(\\rho c_v \\theta ) - div(k\\cdot\\overrightarrow{grad}(\\theta)) = f<br>  $$<br>  </p>\n<p>  </p>\n</li>\n</ul>\n"},{"title":"EDP finite element method","date":"2017-03-31T14:42:08.000Z","_content":"\n","source":"_posts/EDP-finite-element-method.md","raw":"---\ntitle: EDP finite element method\ncategories: [math, unfinished]\ntags:\n  - math\n  - FEM\ndate: 2017-03-31 22:42:08\n---\n\n","slug":"EDP-finite-element-method","published":1,"updated":"2017-03-31T20:48:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufou0009gwtlab327nnk","content":"","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":""},{"title":"Hands on Scrapy","date":"2017-06-21T12:00:27.000Z","_content":"\n# \n\n## \n\n```bash\nscrapy startproject <project_name> [project_dir]\n```\n\n\n\n```\n author.json\n runSpider.py\n scrapy.cfg\n projectname\n     __init__.py\n     items.py\n     middlewares.py\n     pipelines.py\n     settings.py      // \n     spiders          // \n         __init__.py\n         spider0.py\n         spider1.py\n```\n\n## \n\n\n\n```python\nfrom scrapy.spiders import CrawlSpider\nfrom scrapy.selector import Selector\nfrom scrapy.http import Request, FormRequest\n\nfrom tutorial.settings import *\n\nclass SampleSpider(CrawlSpider):\n    name = 'sampleSpider'\n    allowed_domains = ['sample.com']\n    start_url = 'https://sample.xxx.xx.x.x.x.xxx'\n\n    def __init__(self):\n        self.headers = HEADER\n    \n    def start_requests(self):\n        return [Request(\n            \"https://sample.com/signin\",\n            meta = {'cookiejar' : 1},\n            callback = self.post_login\n        )]\n\n    def post_login(self, response):\n        return [FormRequest(\n            'https://www.sample.com/login/',\n            method='POST',\n            meta={'cookiejar': response.meta['cookiejar']},\n            formdata = {\n                'email':'xxxx',\n                'password':'yyyy',\n            },\n            callback = self.after_login\n        )]\n\n    def after_login(self, response):\n        return [Request(\n            self.start_url,\n            meta={'cookiejar': response.meta['cookiejar']},\n            callback=self.parse,\n            errback=self.parse_err,\n        )]\n    \n    def parse(self, response):\n        # do something\n        pass\n\n    def parse_err(self, response):\n        print('eeeerrrrrrooooooorrrrrr!!!!!!')\n\n```\n\n## \n\n#### \n\n- CSS Selector\n- XPath\n\nCSSgoogle\n\n```python\nquery = 'h1.title::text'\nresponse.css(query).extract()[0]\nresponse.css(query).extract_first()\n# response.css(query).extract_first().strip() # strip\n```\n\n#### BeautifulSoup\n\njs\n\n#### lxml\n\nXMLHTML\n\n## Item\n\n\n\nItemLoader\n\n#### Item Pipeline\n\nItemItem Pipelinereturn Itempipeline\n\n- Item\n\n  ```python\n  from scrapy.exceptions import DropItem\n\n  class PricePipeline(object):\n\n      vat_factor = 1.15\n\n      def process_item(self, item, spider):\n          if item['price']:\n              if item['price_excludes_vat']:\n                  item['price'] = item['price'] * self.vat_factor\n              return item\n          else:\n              raise DropItem(\"Missing price in %s\" % item)\n  ```\n\n- JSON\n\n  ```python\n  import json\n\n  class JsonWriterPipeline(object):\n\n      def open_spider(self, spider):\n          self.file = open('items.jl', 'w')\n\n      def close_spider(self, spider):\n          self.file.close()\n\n      def process_item(self, item, spider):\n          line = json.dumps(dict(item)) + \"\\n\"\n          self.file.write(line)\n          return item\n  ```\n\n- MongoDB\n\n  ```python\n  import pymongo\n\n  class MongoPipeline(object):\n\n      collection_name = 'scrapy_items'\n\n      def __init__(self, mongo_uri, mongo_db):\n          self.mongo_uri = mongo_uri\n          self.mongo_db = mongo_db\n\n      @classmethod\n      def from_crawler(cls, crawler):\n          return cls(\n              mongo_uri=crawler.settings.get('MONGO_URI'),\n              mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')\n          )\n\n      def open_spider(self, spider):\n          self.client = pymongo.MongoClient(self.mongo_uri)\n          self.db = self.client[self.mongo_db]\n\n      def close_spider(self, spider):\n          self.client.close()\n\n      def process_item(self, item, spider):\n          self.db[self.collection_name].insert_one(dict(item))\n          return item\n  ```\n\n\n\n# \n\n## \n\n- POST\n\n  1. chrome\"network\"\n  2. network()\n  3. headersform data\n  4. (Request url)\n\n  \n\n  pilcookie\n\n- Cookie\n\n  1. network\n  2. headerscookies\n  3. cookiesRequest\n\n\n## CrawlSpider\n\nSpiderCrawSpiderparse\n\nCrawlSpiderRuleparsefollowcallback\n\ncallbackparseCrawlSpider","source":"_posts/Hands-on-Scrapy.md","raw":"---\ntitle: Hands on Scrapy\ndate: 2017-06-21 20:00:27\ncategories: [programming]\ntags: [scrapy, python, spider, crawl]\n---\n\n# \n\n## \n\n```bash\nscrapy startproject <project_name> [project_dir]\n```\n\n\n\n```\n author.json\n runSpider.py\n scrapy.cfg\n projectname\n     __init__.py\n     items.py\n     middlewares.py\n     pipelines.py\n     settings.py      // \n     spiders          // \n         __init__.py\n         spider0.py\n         spider1.py\n```\n\n## \n\n\n\n```python\nfrom scrapy.spiders import CrawlSpider\nfrom scrapy.selector import Selector\nfrom scrapy.http import Request, FormRequest\n\nfrom tutorial.settings import *\n\nclass SampleSpider(CrawlSpider):\n    name = 'sampleSpider'\n    allowed_domains = ['sample.com']\n    start_url = 'https://sample.xxx.xx.x.x.x.xxx'\n\n    def __init__(self):\n        self.headers = HEADER\n    \n    def start_requests(self):\n        return [Request(\n            \"https://sample.com/signin\",\n            meta = {'cookiejar' : 1},\n            callback = self.post_login\n        )]\n\n    def post_login(self, response):\n        return [FormRequest(\n            'https://www.sample.com/login/',\n            method='POST',\n            meta={'cookiejar': response.meta['cookiejar']},\n            formdata = {\n                'email':'xxxx',\n                'password':'yyyy',\n            },\n            callback = self.after_login\n        )]\n\n    def after_login(self, response):\n        return [Request(\n            self.start_url,\n            meta={'cookiejar': response.meta['cookiejar']},\n            callback=self.parse,\n            errback=self.parse_err,\n        )]\n    \n    def parse(self, response):\n        # do something\n        pass\n\n    def parse_err(self, response):\n        print('eeeerrrrrrooooooorrrrrr!!!!!!')\n\n```\n\n## \n\n#### \n\n- CSS Selector\n- XPath\n\nCSSgoogle\n\n```python\nquery = 'h1.title::text'\nresponse.css(query).extract()[0]\nresponse.css(query).extract_first()\n# response.css(query).extract_first().strip() # strip\n```\n\n#### BeautifulSoup\n\njs\n\n#### lxml\n\nXMLHTML\n\n## Item\n\n\n\nItemLoader\n\n#### Item Pipeline\n\nItemItem Pipelinereturn Itempipeline\n\n- Item\n\n  ```python\n  from scrapy.exceptions import DropItem\n\n  class PricePipeline(object):\n\n      vat_factor = 1.15\n\n      def process_item(self, item, spider):\n          if item['price']:\n              if item['price_excludes_vat']:\n                  item['price'] = item['price'] * self.vat_factor\n              return item\n          else:\n              raise DropItem(\"Missing price in %s\" % item)\n  ```\n\n- JSON\n\n  ```python\n  import json\n\n  class JsonWriterPipeline(object):\n\n      def open_spider(self, spider):\n          self.file = open('items.jl', 'w')\n\n      def close_spider(self, spider):\n          self.file.close()\n\n      def process_item(self, item, spider):\n          line = json.dumps(dict(item)) + \"\\n\"\n          self.file.write(line)\n          return item\n  ```\n\n- MongoDB\n\n  ```python\n  import pymongo\n\n  class MongoPipeline(object):\n\n      collection_name = 'scrapy_items'\n\n      def __init__(self, mongo_uri, mongo_db):\n          self.mongo_uri = mongo_uri\n          self.mongo_db = mongo_db\n\n      @classmethod\n      def from_crawler(cls, crawler):\n          return cls(\n              mongo_uri=crawler.settings.get('MONGO_URI'),\n              mongo_db=crawler.settings.get('MONGO_DATABASE', 'items')\n          )\n\n      def open_spider(self, spider):\n          self.client = pymongo.MongoClient(self.mongo_uri)\n          self.db = self.client[self.mongo_db]\n\n      def close_spider(self, spider):\n          self.client.close()\n\n      def process_item(self, item, spider):\n          self.db[self.collection_name].insert_one(dict(item))\n          return item\n  ```\n\n\n\n# \n\n## \n\n- POST\n\n  1. chrome\"network\"\n  2. network()\n  3. headersform data\n  4. (Request url)\n\n  \n\n  pilcookie\n\n- Cookie\n\n  1. network\n  2. headerscookies\n  3. cookiesRequest\n\n\n## CrawlSpider\n\nSpiderCrawSpiderparse\n\nCrawlSpiderRuleparsefollowcallback\n\ncallbackparseCrawlSpider","slug":"Hands-on-Scrapy","published":1,"updated":"2017-06-22T14:15:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufov000agwtleg6gd9g5","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scrapy startproject &lt;project_name&gt; [project_dir]</span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> author.json</span><br><span class=\"line\"> runSpider.py</span><br><span class=\"line\"> scrapy.cfg</span><br><span class=\"line\"> projectname</span><br><span class=\"line\">     __init__.py</span><br><span class=\"line\">     items.py</span><br><span class=\"line\">     middlewares.py</span><br><span class=\"line\">     pipelines.py</span><br><span class=\"line\">     settings.py      // </span><br><span class=\"line\">     spiders          // </span><br><span class=\"line\">         __init__.py</span><br><span class=\"line\">         spider0.py</span><br><span class=\"line\">         spider1.py</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scrapy.spiders <span class=\"keyword\">import</span> CrawlSpider</span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy.selector <span class=\"keyword\">import</span> Selector</span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy.http <span class=\"keyword\">import</span> Request, FormRequest</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> tutorial.settings <span class=\"keyword\">import</span> *</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SampleSpider</span>(<span class=\"params\">CrawlSpider</span>):</span></span><br><span class=\"line\">    name = <span class=\"string\">'sampleSpider'</span></span><br><span class=\"line\">    allowed_domains = [<span class=\"string\">'sample.com'</span>]</span><br><span class=\"line\">    start_url = <span class=\"string\">'https://sample.xxx.xx.x.x.x.xxx'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self</span>):</span></span><br><span class=\"line\">        self.headers = HEADER</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">start_requests</span>(<span class=\"params\">self</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> [Request(</span><br><span class=\"line\">            <span class=\"string\">\"https://sample.com/signin\"</span>,</span><br><span class=\"line\">            meta = {<span class=\"string\">'cookiejar'</span> : <span class=\"number\">1</span>},</span><br><span class=\"line\">            callback = self.post_login</span><br><span class=\"line\">        )]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">post_login</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> [FormRequest(</span><br><span class=\"line\">            <span class=\"string\">'https://www.sample.com/login/'</span>,</span><br><span class=\"line\">            method=<span class=\"string\">'POST'</span>,</span><br><span class=\"line\">            meta={<span class=\"string\">'cookiejar'</span>: response.meta[<span class=\"string\">'cookiejar'</span>]},</span><br><span class=\"line\">            formdata = {</span><br><span class=\"line\">                <span class=\"string\">'email'</span>:<span class=\"string\">'xxxx'</span>,</span><br><span class=\"line\">                <span class=\"string\">'password'</span>:<span class=\"string\">'yyyy'</span>,</span><br><span class=\"line\">            },</span><br><span class=\"line\">            callback = self.after_login</span><br><span class=\"line\">        )]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">after_login</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> [Request(</span><br><span class=\"line\">            self.start_url,</span><br><span class=\"line\">            meta={<span class=\"string\">'cookiejar'</span>: response.meta[<span class=\"string\">'cookiejar'</span>]},</span><br><span class=\"line\">            callback=self.parse,</span><br><span class=\"line\">            errback=self.parse_err,</span><br><span class=\"line\">        )]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># do something</span></span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_err</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">'eeeerrrrrrooooooorrrrrr!!!!!!'</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><ul>\n<li>CSS Selector</li>\n<li>XPath</li>\n</ul>\n<p>CSSgoogle</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">query = <span class=\"string\">'h1.title::text'</span></span><br><span class=\"line\">response.css(query).extract()[<span class=\"number\">0</span>]</span><br><span class=\"line\">response.css(query).extract_first()</span><br><span class=\"line\"><span class=\"comment\"># response.css(query).extract_first().strip() # strip</span></span><br></pre></td></tr></tbody></table></figure>\n\n<h4 id=\"BeautifulSoup\"><a href=\"#BeautifulSoup\" class=\"headerlink\" title=\"BeautifulSoup\"></a>BeautifulSoup</h4><p>js</p>\n<h4 id=\"lxml\"><a href=\"#lxml\" class=\"headerlink\" title=\"lxml\"></a>lxml</h4><p>XMLHTML</p>\n<h2 id=\"Item\"><a href=\"#Item\" class=\"headerlink\" title=\"Item\"></a>Item</h2><p></p>\n<p>ItemLoader</p>\n<h4 id=\"Item-Pipeline\"><a href=\"#Item-Pipeline\" class=\"headerlink\" title=\"Item Pipeline\"></a>Item Pipeline</h4><p>ItemItem Pipelinereturn Itempipeline</p>\n<ul>\n<li><p>Item</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scrapy.exceptions <span class=\"keyword\">import</span> DropItem</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PricePipeline</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    vat_factor = <span class=\"number\">1.15</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span>(<span class=\"params\">self, item, spider</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> item[<span class=\"string\">'price'</span>]:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> item[<span class=\"string\">'price_excludes_vat'</span>]:</span><br><span class=\"line\">                item[<span class=\"string\">'price'</span>] = item[<span class=\"string\">'price'</span>] * self.vat_factor</span><br><span class=\"line\">            <span class=\"keyword\">return</span> item</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> DropItem(<span class=\"string\">\"Missing price in %s\"</span> % item)</span><br></pre></td></tr></tbody></table></figure></li>\n<li><p>JSON</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JsonWriterPipeline</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        self.file = <span class=\"built_in\">open</span>(<span class=\"string\">'items.jl'</span>, <span class=\"string\">'w'</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        self.file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span>(<span class=\"params\">self, item, spider</span>):</span></span><br><span class=\"line\">        line = json.dumps(<span class=\"built_in\">dict</span>(item)) + <span class=\"string\">\"\\n\"</span></span><br><span class=\"line\">        self.file.write(line)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item</span><br></pre></td></tr></tbody></table></figure></li>\n<li><p>MongoDB</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pymongo</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MongoPipeline</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    collection_name = <span class=\"string\">'scrapy_items'</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, mongo_uri, mongo_db</span>):</span></span><br><span class=\"line\">        self.mongo_uri = mongo_uri</span><br><span class=\"line\">        self.mongo_db = mongo_db</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @classmethod</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">from_crawler</span>(<span class=\"params\">cls, crawler</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> cls(</span><br><span class=\"line\">            mongo_uri=crawler.settings.get(<span class=\"string\">'MONGO_URI'</span>),</span><br><span class=\"line\">            mongo_db=crawler.settings.get(<span class=\"string\">'MONGO_DATABASE'</span>, <span class=\"string\">'items'</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        self.client = pymongo.MongoClient(self.mongo_uri)</span><br><span class=\"line\">        self.db = self.client[self.mongo_db]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        self.client.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span>(<span class=\"params\">self, item, spider</span>):</span></span><br><span class=\"line\">        self.db[self.collection_name].insert_one(<span class=\"built_in\">dict</span>(item))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item</span><br></pre></td></tr></tbody></table></figure></li>\n</ul>\n<p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>POST</p>\n<ol>\n<li>chromenetwork</li>\n<li>network()</li>\n<li>headersform data</li>\n<li>(Request url)</li>\n</ol>\n<p></p>\n<p>pilcookie</p>\n</li>\n<li><p>Cookie</p>\n<ol>\n<li>network</li>\n<li>headerscookies</li>\n<li>cookiesRequest</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"CrawlSpider\"><a href=\"#CrawlSpider\" class=\"headerlink\" title=\"CrawlSpider\"></a>CrawlSpider</h2><p>SpiderCrawSpiderparse</p>\n<p>CrawlSpiderRuleparsefollowcallback</p>\n<p>callbackparseCrawlSpider</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">scrapy startproject &lt;project_name&gt; [project_dir]</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"> author.json</span><br><span class=\"line\"> runSpider.py</span><br><span class=\"line\"> scrapy.cfg</span><br><span class=\"line\"> projectname</span><br><span class=\"line\">     __init__.py</span><br><span class=\"line\">     items.py</span><br><span class=\"line\">     middlewares.py</span><br><span class=\"line\">     pipelines.py</span><br><span class=\"line\">     settings.py      // </span><br><span class=\"line\">     spiders          // </span><br><span class=\"line\">         __init__.py</span><br><span class=\"line\">         spider0.py</span><br><span class=\"line\">         spider1.py</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br><span class=\"line\">33</span><br><span class=\"line\">34</span><br><span class=\"line\">35</span><br><span class=\"line\">36</span><br><span class=\"line\">37</span><br><span class=\"line\">38</span><br><span class=\"line\">39</span><br><span class=\"line\">40</span><br><span class=\"line\">41</span><br><span class=\"line\">42</span><br><span class=\"line\">43</span><br><span class=\"line\">44</span><br><span class=\"line\">45</span><br><span class=\"line\">46</span><br><span class=\"line\">47</span><br><span class=\"line\">48</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scrapy.spiders <span class=\"keyword\">import</span> CrawlSpider</span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy.selector <span class=\"keyword\">import</span> Selector</span><br><span class=\"line\"><span class=\"keyword\">from</span> scrapy.http <span class=\"keyword\">import</span> Request, FormRequest</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">from</span> tutorial.settings <span class=\"keyword\">import</span> *</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">SampleSpider</span>(<span class=\"params\">CrawlSpider</span>):</span></span><br><span class=\"line\">    name = <span class=\"string\">&#x27;sampleSpider&#x27;</span></span><br><span class=\"line\">    allowed_domains = [<span class=\"string\">&#x27;sample.com&#x27;</span>]</span><br><span class=\"line\">    start_url = <span class=\"string\">&#x27;https://sample.xxx.xx.x.x.x.xxx&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self</span>):</span></span><br><span class=\"line\">        self.headers = HEADER</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">start_requests</span>(<span class=\"params\">self</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> [Request(</span><br><span class=\"line\">            <span class=\"string\">&quot;https://sample.com/signin&quot;</span>,</span><br><span class=\"line\">            meta = &#123;<span class=\"string\">&#x27;cookiejar&#x27;</span> : <span class=\"number\">1</span>&#125;,</span><br><span class=\"line\">            callback = self.post_login</span><br><span class=\"line\">        )]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">post_login</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> [FormRequest(</span><br><span class=\"line\">            <span class=\"string\">&#x27;https://www.sample.com/login/&#x27;</span>,</span><br><span class=\"line\">            method=<span class=\"string\">&#x27;POST&#x27;</span>,</span><br><span class=\"line\">            meta=&#123;<span class=\"string\">&#x27;cookiejar&#x27;</span>: response.meta[<span class=\"string\">&#x27;cookiejar&#x27;</span>]&#125;,</span><br><span class=\"line\">            formdata = &#123;</span><br><span class=\"line\">                <span class=\"string\">&#x27;email&#x27;</span>:<span class=\"string\">&#x27;xxxx&#x27;</span>,</span><br><span class=\"line\">                <span class=\"string\">&#x27;password&#x27;</span>:<span class=\"string\">&#x27;yyyy&#x27;</span>,</span><br><span class=\"line\">            &#125;,</span><br><span class=\"line\">            callback = self.after_login</span><br><span class=\"line\">        )]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">after_login</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> [Request(</span><br><span class=\"line\">            self.start_url,</span><br><span class=\"line\">            meta=&#123;<span class=\"string\">&#x27;cookiejar&#x27;</span>: response.meta[<span class=\"string\">&#x27;cookiejar&#x27;</span>]&#125;,</span><br><span class=\"line\">            callback=self.parse,</span><br><span class=\"line\">            errback=self.parse_err,</span><br><span class=\"line\">        )]</span><br><span class=\"line\">    </span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"comment\"># do something</span></span><br><span class=\"line\">        <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">parse_err</span>(<span class=\"params\">self, response</span>):</span></span><br><span class=\"line\">        <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;eeeerrrrrrooooooorrrrrr!!!!!!&#x27;</span>)</span><br><span class=\"line\"></span><br></pre></td></tr></table></figure>\n\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><ul>\n<li>CSS Selector</li>\n<li>XPath</li>\n</ul>\n<p>CSSgoogle</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">query = <span class=\"string\">&#x27;h1.title::text&#x27;</span></span><br><span class=\"line\">response.css(query).extract()[<span class=\"number\">0</span>]</span><br><span class=\"line\">response.css(query).extract_first()</span><br><span class=\"line\"><span class=\"comment\"># response.css(query).extract_first().strip() # strip</span></span><br></pre></td></tr></table></figure>\n\n<h4 id=\"BeautifulSoup\"><a href=\"#BeautifulSoup\" class=\"headerlink\" title=\"BeautifulSoup\"></a>BeautifulSoup</h4><p>js</p>\n<h4 id=\"lxml\"><a href=\"#lxml\" class=\"headerlink\" title=\"lxml\"></a>lxml</h4><p>XMLHTML</p>\n<h2 id=\"Item\"><a href=\"#Item\" class=\"headerlink\" title=\"Item\"></a>Item</h2><p></p>\n<p>ItemLoader</p>\n<h4 id=\"Item-Pipeline\"><a href=\"#Item-Pipeline\" class=\"headerlink\" title=\"Item Pipeline\"></a>Item Pipeline</h4><p>ItemItem Pipelinereturn Itempipeline</p>\n<ul>\n<li><p>Item</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> scrapy.exceptions <span class=\"keyword\">import</span> DropItem</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">PricePipeline</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    vat_factor = <span class=\"number\">1.15</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span>(<span class=\"params\">self, item, spider</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">if</span> item[<span class=\"string\">&#x27;price&#x27;</span>]:</span><br><span class=\"line\">            <span class=\"keyword\">if</span> item[<span class=\"string\">&#x27;price_excludes_vat&#x27;</span>]:</span><br><span class=\"line\">                item[<span class=\"string\">&#x27;price&#x27;</span>] = item[<span class=\"string\">&#x27;price&#x27;</span>] * self.vat_factor</span><br><span class=\"line\">            <span class=\"keyword\">return</span> item</span><br><span class=\"line\">        <span class=\"keyword\">else</span>:</span><br><span class=\"line\">            <span class=\"keyword\">raise</span> DropItem(<span class=\"string\">&quot;Missing price in %s&quot;</span> % item)</span><br></pre></td></tr></table></figure></li>\n<li><p>JSON</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> json</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">JsonWriterPipeline</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        self.file = <span class=\"built_in\">open</span>(<span class=\"string\">&#x27;items.jl&#x27;</span>, <span class=\"string\">&#x27;w&#x27;</span>)</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        self.file.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span>(<span class=\"params\">self, item, spider</span>):</span></span><br><span class=\"line\">        line = json.dumps(<span class=\"built_in\">dict</span>(item)) + <span class=\"string\">&quot;\\n&quot;</span></span><br><span class=\"line\">        self.file.write(line)</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item</span><br></pre></td></tr></table></figure></li>\n<li><p>MongoDB</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">import</span> pymongo</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"class\"><span class=\"keyword\">class</span> <span class=\"title\">MongoPipeline</span>(<span class=\"params\"><span class=\"built_in\">object</span></span>):</span></span><br><span class=\"line\"></span><br><span class=\"line\">    collection_name = <span class=\"string\">&#x27;scrapy_items&#x27;</span></span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">__init__</span>(<span class=\"params\">self, mongo_uri, mongo_db</span>):</span></span><br><span class=\"line\">        self.mongo_uri = mongo_uri</span><br><span class=\"line\">        self.mongo_db = mongo_db</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"meta\">    @classmethod</span></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">from_crawler</span>(<span class=\"params\">cls, crawler</span>):</span></span><br><span class=\"line\">        <span class=\"keyword\">return</span> cls(</span><br><span class=\"line\">            mongo_uri=crawler.settings.get(<span class=\"string\">&#x27;MONGO_URI&#x27;</span>),</span><br><span class=\"line\">            mongo_db=crawler.settings.get(<span class=\"string\">&#x27;MONGO_DATABASE&#x27;</span>, <span class=\"string\">&#x27;items&#x27;</span>)</span><br><span class=\"line\">        )</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">open_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        self.client = pymongo.MongoClient(self.mongo_uri)</span><br><span class=\"line\">        self.db = self.client[self.mongo_db]</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">close_spider</span>(<span class=\"params\">self, spider</span>):</span></span><br><span class=\"line\">        self.client.close()</span><br><span class=\"line\"></span><br><span class=\"line\">    <span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">process_item</span>(<span class=\"params\">self, item, spider</span>):</span></span><br><span class=\"line\">        self.db[self.collection_name].insert_one(<span class=\"built_in\">dict</span>(item))</span><br><span class=\"line\">        <span class=\"keyword\">return</span> item</span><br></pre></td></tr></table></figure></li>\n</ul>\n<p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>POST</p>\n<ol>\n<li>chromenetwork</li>\n<li>network()</li>\n<li>headersform data</li>\n<li>(Request url)</li>\n</ol>\n<p></p>\n<p>pilcookie</p>\n</li>\n<li><p>Cookie</p>\n<ol>\n<li>network</li>\n<li>headerscookies</li>\n<li>cookiesRequest</li>\n</ol>\n</li>\n</ul>\n<h2 id=\"CrawlSpider\"><a href=\"#CrawlSpider\" class=\"headerlink\" title=\"CrawlSpider\"></a>CrawlSpider</h2><p>SpiderCrawSpiderparse</p>\n<p>CrawlSpiderRuleparsefollowcallback</p>\n<p>callbackparseCrawlSpider</p>\n"},{"title":"Hilbert space","date":"2017-02-11T05:10:06.000Z","_content":"\n#  Hilbert space\n\n## \n\nwiki:\n\n>********\n\n\n\n### \n\n- \n\n  \n\n- \n\n  \n\n- (complet)\n\n  \n\n- \n\n  \n\n### \n\n- \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n(( +   =  + ) +  = ) +  = \n\n## \n\n- \n\n  \n\n- \n\n- \n\n  L^2:\n\n  \n  $$\n  (f|g) = \\int{\\overline{f}g}\n  $$\n  .\n\n- \n\n  H^sW^(s,2)\n\n## \n\n- 1\n- \n- H\n\n## \n\n- (produit scalaire)\n\n  \n\n$$\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0\n$$\n","source":"_posts/Hilbert-space.md","raw":"---\ntitle: Hilbert space\ndate: 2017-02-11 13:10:06\ncategories: [math]\ntags: [Hilbert, math, analyse]\n---\n\n#  Hilbert space\n\n## \n\nwiki:\n\n>********\n\n\n\n### \n\n- \n\n  \n\n- \n\n  \n\n- (complet)\n\n  \n\n- \n\n  \n\n### \n\n- \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n(( +   =  + ) +  = ) +  = \n\n## \n\n- \n\n  \n\n- \n\n- \n\n  L^2:\n\n  \n  $$\n  (f|g) = \\int{\\overline{f}g}\n  $$\n  .\n\n- \n\n  H^sW^(s,2)\n\n## \n\n- 1\n- \n- H\n\n## \n\n- (produit scalaire)\n\n  \n\n$$\n\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\\\\n\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\\\\n\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\\\\n\\varphi (x,x) = 0 \\Longrightarrow x = 0\n$$\n","slug":"Hilbert-space","published":1,"updated":"2017-02-11T12:57:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufox000dgwtldq2v1h0p","content":"<h1 id=\"-Hilbert-space\"><a href=\"#-Hilbert-space\" class=\"headerlink\" title=\" Hilbert space\"></a> Hilbert space</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>wiki:</p>\n<blockquote>\n<p><strong></strong><strong></strong></p>\n</blockquote>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p>(complet)</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n<p>(( +   =  + ) +  = ) +  = </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n<p>L^2:</p>\n<p><br>$$<br>(f|g) = \\int{\\overline{f}g}<br>$$<br>.</p>\n</li>\n<li><p></p>\n<p>H^sW^(s,2)</p>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>1</li>\n<li></li>\n<li>H</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>(produit scalaire)</p>\n<p></p>\n</li>\n</ul>\n<p>$$<br>\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\<br>\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\<br>\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\<br>\\varphi (x,x) = 0 \\Longrightarrow x = 0<br>$$</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"-Hilbert-space\"><a href=\"#-Hilbert-space\" class=\"headerlink\" title=\" Hilbert space\"></a> Hilbert space</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>wiki:</p>\n<blockquote>\n<p><strong></strong><strong></strong></p>\n</blockquote>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p>(complet)</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><ul>\n<li><p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n<p>(( +   =  + ) +  = ) +  = </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n<p>L^2:</p>\n<p><br>$$<br>(f|g) = \\int{\\overline{f}g}<br>$$<br>.</p>\n</li>\n<li><p></p>\n<p>H^sW^(s,2)</p>\n</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li>1</li>\n<li></li>\n<li>H</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p>(produit scalaire)</p>\n<p></p>\n</li>\n</ul>\n<p>$$<br>\\forall (x,y) \\in H^2 \\qquad \\varphi(y,x) = \\overline{\\varphi(x,y)} \\<br>\\forall (x,y,z) \\in H^3, \\forall(\\lambda,\\mu) \\in \\mathbb{C}^2 \\qquad \\varphi(z,\\lambda x+\\mu y) = \\lambda\\varphi(z,x) + \\mu \\varphi(z,y) \\<br>\\forall x \\in H^2 \\qquad \\varphi(x,x) \\ge 0 \\<br>\\varphi (x,x) = 0 \\Longrightarrow x = 0<br>$$</p>\n"},{"title":"Generative Adversarial Network","date":"2017-06-25T06:41:15.000Z","typora-copy-images-to":"ipic","_content":"\n# Generative Adversarial Network\n\n## Generater\n\n1. Auto encoder\n\n   input => nn encoder => code => nn decoder => output\n\n   Output compared with input as close as possible\n\n   [code => nn decoder => output] := a generater\n\n2. VAE\n\n   Auto-encoder Variational Bayes:\n\n   input => nn encoder \n\n   => {\n\n       code : [$m_i$],\n\n       variation : [$\\sigma_i$],\n\n       error : [$e_i$],\n\n   } \n\n   => {$c_i = exp(\\sigma_i) \\times e_i + m_i$}\n\n   => nn decoder => output\n\n   The goal is to monimize the expression as followed:\n   $$\n   \\sum(exp(\\sigma_i) - (1+\\sigma_i) + (m_i)^2)\n   $$\n\n\n\n\n\n## GAN\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202530.png\" width=\"70%\">\n\n(true or false)\n\n$P_{data}(x; \\theta) , P_G(x;\\theta)$\n\n- Generator G\n\n  - G is a function, input z, output x\n  - Given a prior distribution $P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G\n\n- Discriminator D\n\n  - D is a function, input x, output scalar\n  - Evaluate the \"difference\" between $P_G(x)$ and $P_{data}(x)$\n\n- Function V(G, D)\n  $$\n  G^* = {arg} {min}_G {max}_D V(G,D)\n  $$\n\n\n\n\nG*DGV$P_{data}$$P_G$GGD\n\nV\n$$\nV = E_{x~P_{data}}[logD(x)]+ E_{x~P_G}[log(1-D(x))] \\\\\n= \\int_x P_{data}(x)logD(x)dx +\\int_xP_G(x)log(1-D(X))dx \\\\\n= \\int_x[P_{data}(x)logD(x) + P_G(x)log(1-D(x))]dx\n$$\nV\n$$\nP_{data}(x)logD(x) + P_G(x)log(1-D(x))\n$$\ni.e. find D* maximizing: $f(D) = alog(D)+blog(1-D)$\n$$\n=> D^* = \\frac{a}{a+b} = \\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}\n$$\n\n$$\nmax_D V(G,D) = V(G, D^*) \\\\\n= -2log2 + \\int_x P_{data}(x) log\\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\ + \\int_x P_{data}(x) log\\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\\n= -2log2 + KL(P_{data}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\ \n+ KL(P_{G}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\\n= -2log2 + 2JSD(P_{data}(X||P_G(x))\n$$\n\n$$\nKL := KL divergence \\\\\nJSD(P||Q) = \\frac{1}{2}(KL(P||M) + KL(Q||M)), M= \\frac{P+Q}{2}\n$$\n$max_D(G,D)$$P_G = P_{data}$\n\n### ****\n\n- Given $G_0$\n- Find $D_0^*$ maximizing $V(G_0,D)$\n- $\\theta_G \\leftarrow \\theta_G - \\eta \\partial V(G, D_0^*)/ \\partial \\theta_G $ => Obtain G1\n- Find $D_1^*$ maximizing $V(G_1,D)$\n- ...\n\n#### \n\n\n\nmV\n$$\nV = \\frac{1}{m}\\sum logD(x_i) + \\frac{1}{m} \\sum log(1-D(x_i^G)) \\\\\nwhere \\{x_1, ..., x_m\\}  from P_{data}(x), \\{x_1^G,...,x_m^G\\} from P_G(x)\n$$\n","source":"_posts/Generative-Adversarial-Network.md","raw":"---\ntitle: Generative Adversarial Network\ndate: 2017-06-25 14:41:15\ncategories: [programming]\ntags: [GAN, deep-learning]\ntypora-copy-images-to: ipic\n---\n\n# Generative Adversarial Network\n\n## Generater\n\n1. Auto encoder\n\n   input => nn encoder => code => nn decoder => output\n\n   Output compared with input as close as possible\n\n   [code => nn decoder => output] := a generater\n\n2. VAE\n\n   Auto-encoder Variational Bayes:\n\n   input => nn encoder \n\n   => {\n\n       code : [$m_i$],\n\n       variation : [$\\sigma_i$],\n\n       error : [$e_i$],\n\n   } \n\n   => {$c_i = exp(\\sigma_i) \\times e_i + m_i$}\n\n   => nn decoder => output\n\n   The goal is to monimize the expression as followed:\n   $$\n   \\sum(exp(\\sigma_i) - (1+\\sigma_i) + (m_i)^2)\n   $$\n\n\n\n\n\n## GAN\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202530.png\" width=\"70%\">\n\n(true or false)\n\n$P_{data}(x; \\theta) , P_G(x;\\theta)$\n\n- Generator G\n\n  - G is a function, input z, output x\n  - Given a prior distribution $P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G\n\n- Discriminator D\n\n  - D is a function, input x, output scalar\n  - Evaluate the \"difference\" between $P_G(x)$ and $P_{data}(x)$\n\n- Function V(G, D)\n  $$\n  G^* = {arg} {min}_G {max}_D V(G,D)\n  $$\n\n\n\n\nG*DGV$P_{data}$$P_G$GGD\n\nV\n$$\nV = E_{x~P_{data}}[logD(x)]+ E_{x~P_G}[log(1-D(x))] \\\\\n= \\int_x P_{data}(x)logD(x)dx +\\int_xP_G(x)log(1-D(X))dx \\\\\n= \\int_x[P_{data}(x)logD(x) + P_G(x)log(1-D(x))]dx\n$$\nV\n$$\nP_{data}(x)logD(x) + P_G(x)log(1-D(x))\n$$\ni.e. find D* maximizing: $f(D) = alog(D)+blog(1-D)$\n$$\n=> D^* = \\frac{a}{a+b} = \\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}\n$$\n\n$$\nmax_D V(G,D) = V(G, D^*) \\\\\n= -2log2 + \\int_x P_{data}(x) log\\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\ + \\int_x P_{data}(x) log\\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\\\\n= -2log2 + KL(P_{data}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\ \n+ KL(P_{G}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\\\\n= -2log2 + 2JSD(P_{data}(X||P_G(x))\n$$\n\n$$\nKL := KL divergence \\\\\nJSD(P||Q) = \\frac{1}{2}(KL(P||M) + KL(Q||M)), M= \\frac{P+Q}{2}\n$$\n$max_D(G,D)$$P_G = P_{data}$\n\n### ****\n\n- Given $G_0$\n- Find $D_0^*$ maximizing $V(G_0,D)$\n- $\\theta_G \\leftarrow \\theta_G - \\eta \\partial V(G, D_0^*)/ \\partial \\theta_G $ => Obtain G1\n- Find $D_1^*$ maximizing $V(G_1,D)$\n- ...\n\n#### \n\n\n\nmV\n$$\nV = \\frac{1}{m}\\sum logD(x_i) + \\frac{1}{m} \\sum log(1-D(x_i^G)) \\\\\nwhere \\{x_1, ..., x_m\\}  from P_{data}(x), \\{x_1^G,...,x_m^G\\} from P_G(x)\n$$\n","slug":"Generative-Adversarial-Network","published":1,"updated":"2020-11-03T03:26:03.479Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufoy000egwtlcr1j4206","content":"<h1 id=\"Generative-Adversarial-Network\"><a href=\"#Generative-Adversarial-Network\" class=\"headerlink\" title=\"Generative Adversarial Network\"></a>Generative Adversarial Network</h1><h2 id=\"Generater\"><a href=\"#Generater\" class=\"headerlink\" title=\"Generater\"></a>Generater</h2><ol>\n<li><p>Auto encoder</p>\n<p>input =&gt; nn encoder =&gt; code =&gt; nn decoder =&gt; output</p>\n<p>Output compared with input as close as possible</p>\n<p>[code =&gt; nn decoder =&gt; output] := a generater</p>\n</li>\n<li><p>VAE</p>\n<p>Auto-encoder Variational Bayes:</p>\n<p>input =&gt; nn encoder </p>\n<p>=&gt; {</p>\n<p>    code : [$m_i$],</p>\n<p>    variation : [$\\sigma_i$],</p>\n<p>    error : [$e_i$],</p>\n<p>} </p>\n<p>=&gt; {$c_i = exp(\\sigma_i) \\times e_i + m_i$}</p>\n<p>=&gt; nn decoder =&gt; output</p>\n<p>The goal is to monimize the expression as followed:<br>$$<br>\\sum(exp(\\sigma_i) - (1+\\sigma_i) + (m_i)^2)<br>$$</p>\n</li>\n</ol>\n<h2 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN\"></a>GAN</h2><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202530.png\" width=\"70%\">\n\n<p>(true or false)</p>\n<p>$P_{data}(x; \\theta) , P_G(x;\\theta)$</p>\n<ul>\n<li><p>Generator G</p>\n<ul>\n<li>G is a function, input z, output x</li>\n<li>Given a prior distribution $P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G</li>\n</ul>\n</li>\n<li><p>Discriminator D</p>\n<ul>\n<li>D is a function, input x, output scalar</li>\n<li>Evaluate the difference between $P_G(x)$ and $P_{data}(x)$</li>\n</ul>\n</li>\n<li><p>Function V(G, D)<br>$$<br>G^* = {arg} {min}_G {max}_D V(G,D)<br>$$</p>\n</li>\n</ul>\n<p>G*DGV$P_{data}$$P_G$GGD</p>\n<p>V<br>$$<br>V = E_{x<del>P_{data}}[logD(x)]+ E_{x</del>P_G}[log(1-D(x))] \\<br>= \\int_x P_{data}(x)logD(x)dx +\\int_xP_G(x)log(1-D(X))dx \\<br>= \\int_x[P_{data}(x)logD(x) + P_G(x)log(1-D(x))]dx<br>$$<br>V<br>$$<br>P_{data}(x)logD(x) + P_G(x)log(1-D(x))<br>$$<br>i.e. find D* maximizing: $f(D) = alog(D)+blog(1-D)$<br>$$<br>=&gt; D^* = \\frac{a}{a+b} = \\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}<br>$$<br><br>$$<br>max_D V(G,D) = V(G, D^*) \\<br>= -2log2 + \\int_x P_{data}(x) log\\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\ + \\int_x P_{data}(x) log\\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\<br>= -2log2 + KL(P_{data}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\ </p>\n<ul>\n<li>KL(P_{G}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\<br>= -2log2 + 2JSD(P_{data}(X||P_G(x))<br>$$<br><br>$$<br>KL := KL divergence \\<br>JSD(P||Q) = \\frac{1}{2}(KL(P||M) + KL(Q||M)), M= \\frac{P+Q}{2}<br>$$<br>$max_D(G,D)$$P_G = P_{data}$</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><strong></strong></h3><ul>\n<li>Given $G_0$</li>\n<li>Find $D_0^*$ maximizing $V(G_0,D)$</li>\n<li>$\\theta_G \\leftarrow \\theta_G - \\eta \\partial V(G, D_0^*)/ \\partial \\theta_G $ =&gt; Obtain G1</li>\n<li>Find $D_1^*$ maximizing $V(G_1,D)$</li>\n<li></li>\n</ul>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p>mV<br>$$<br>V = \\frac{1}{m}\\sum logD(x_i) + \\frac{1}{m} \\sum log(1-D(x_i^G)) \\<br>where {x_1, , x_m}  from P_{data}(x), {x_1^G,,x_m^G} from P_G(x)<br>$$</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"Generative-Adversarial-Network\"><a href=\"#Generative-Adversarial-Network\" class=\"headerlink\" title=\"Generative Adversarial Network\"></a>Generative Adversarial Network</h1><h2 id=\"Generater\"><a href=\"#Generater\" class=\"headerlink\" title=\"Generater\"></a>Generater</h2><ol>\n<li><p>Auto encoder</p>\n<p>input =&gt; nn encoder =&gt; code =&gt; nn decoder =&gt; output</p>\n<p>Output compared with input as close as possible</p>\n<p>[code =&gt; nn decoder =&gt; output] := a generater</p>\n</li>\n<li><p>VAE</p>\n<p>Auto-encoder Variational Bayes:</p>\n<p>input =&gt; nn encoder </p>\n<p>=&gt; {</p>\n<p>    code : [$m_i$],</p>\n<p>    variation : [$\\sigma_i$],</p>\n<p>    error : [$e_i$],</p>\n<p>} </p>\n<p>=&gt; {$c_i = exp(\\sigma_i) \\times e_i + m_i$}</p>\n<p>=&gt; nn decoder =&gt; output</p>\n<p>The goal is to monimize the expression as followed:<br>$$<br>\\sum(exp(\\sigma_i) - (1+\\sigma_i) + (m_i)^2)<br>$$</p>\n</li>\n</ol>\n<h2 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN\"></a>GAN</h2><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202530.png\" width=\"70%\">\n\n<p>(true or false)</p>\n<p>$P_{data}(x; \\theta) , P_G(x;\\theta)$</p>\n<ul>\n<li><p>Generator G</p>\n<ul>\n<li>G is a function, input z, output x</li>\n<li>Given a prior distribution $P_{prior}(z)$, a probability distribution $P_G(x)$ is defined by function G</li>\n</ul>\n</li>\n<li><p>Discriminator D</p>\n<ul>\n<li>D is a function, input x, output scalar</li>\n<li>Evaluate the difference between $P_G(x)$ and $P_{data}(x)$</li>\n</ul>\n</li>\n<li><p>Function V(G, D)<br>$$<br>G^* = {arg} {min}_G {max}_D V(G,D)<br>$$</p>\n</li>\n</ul>\n<p>G*DGV$P_{data}$$P_G$GGD</p>\n<p>V<br>$$<br>V = E_{x<del>P_{data}}[logD(x)]+ E_{x</del>P_G}[log(1-D(x))] \\<br>= \\int_x P_{data}(x)logD(x)dx +\\int_xP_G(x)log(1-D(X))dx \\<br>= \\int_x[P_{data}(x)logD(x) + P_G(x)log(1-D(x))]dx<br>$$<br>V<br>$$<br>P_{data}(x)logD(x) + P_G(x)log(1-D(x))<br>$$<br>i.e. find D* maximizing: $f(D) = alog(D)+blog(1-D)$<br>$$<br>=&gt; D^* = \\frac{a}{a+b} = \\frac{P_{data}(x)}{P_{data}(x)+P_{G}(x)}<br>$$<br><br>$$<br>max_D V(G,D) = V(G, D^*) \\<br>= -2log2 + \\int_x P_{data}(x) log\\frac{P_{data}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\ + \\int_x P_{data}(x) log\\frac{P_{G}(x)}{(P_{data}(x)+P_{G}(x))/2}dx \\<br>= -2log2 + KL(P_{data}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\ </p>\n<ul>\n<li>KL(P_{G}(x) ||\\frac{P_{data}(x)+P_{G}(x)}{2}) \\<br>= -2log2 + 2JSD(P_{data}(X||P_G(x))<br>$$<br><br>$$<br>KL := KL divergence \\<br>JSD(P||Q) = \\frac{1}{2}(KL(P||M) + KL(Q||M)), M= \\frac{P+Q}{2}<br>$$<br>$max_D(G,D)$$P_G = P_{data}$</li>\n</ul>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a><strong></strong></h3><ul>\n<li>Given $G_0$</li>\n<li>Find $D_0^*$ maximizing $V(G_0,D)$</li>\n<li>$\\theta_G \\leftarrow \\theta_G - \\eta \\partial V(G, D_0^*)/ \\partial \\theta_G $ =&gt; Obtain G1</li>\n<li>Find $D_1^*$ maximizing $V(G_1,D)$</li>\n<li></li>\n</ul>\n<h4 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h4><p></p>\n<p>mV<br>$$<br>V = \\frac{1}{m}\\sum logD(x_i) + \\frac{1}{m} \\sum log(1-D(x_i^G)) \\<br>where {x_1, , x_m}  from P_{data}(x), {x_1^G,,x_m^G} from P_G(x)<br>$$</p>\n"},{"title":"ML CNN","date":"2016-12-14T02:34:43.000Z","_content":"\n\n\n(CNN)(RNN)\n\n# \n\n \n\n## \n\n\n$$\nx = [x_0,x_1,...,x_n]^T\n$$\n\n$$\nz = [z_0,z_1,...,z_m]^T\n$$\n\n$$\nW_{m \\times n}\n$$\n\n$$\nb = [b_0,b_1,...,b_m]^T\n$$\n\n$$\nW * x + b = z\n$$\n\n## \n\n****()\n\n\n\n\n\n1. sigmoid\n\n    sigmoid\n\n   \n   $$\n   f(x) = \\frac{1}{1+e^{-x}}\n   $$\n   R(0, 1)\n\n2. \n   $$\n   f(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n   $$\n   (-1,1)sigmoid\n\n","source":"_posts/ML-CNN.md","raw":"---\ntitle: ML CNN\ndate: 2016-12-14 10:34:43\ncategories: [programming, unfinished]\ntags: [machine-learning, programming, algo, CNN]\n---\n\n\n\n(CNN)(RNN)\n\n# \n\n \n\n## \n\n\n$$\nx = [x_0,x_1,...,x_n]^T\n$$\n\n$$\nz = [z_0,z_1,...,z_m]^T\n$$\n\n$$\nW_{m \\times n}\n$$\n\n$$\nb = [b_0,b_1,...,b_m]^T\n$$\n\n$$\nW * x + b = z\n$$\n\n## \n\n****()\n\n\n\n\n\n1. sigmoid\n\n    sigmoid\n\n   \n   $$\n   f(x) = \\frac{1}{1+e^{-x}}\n   $$\n   R(0, 1)\n\n2. \n   $$\n   f(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}\n   $$\n   (-1,1)sigmoid\n\n","slug":"ML-CNN","published":1,"updated":"2020-02-09T14:06:32.526Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufp0000igwtlg2ur61jm","content":"<p></p>\n<p>(CNN)(RNN)</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br>$$<br>x = [x_0,x_1,,x_n]^T<br>$$<br><br>$$<br>z = [z_0,z_1,,z_m]^T<br>$$<br><br>$$<br>W_{m \\times n}<br>$$<br><br>$$<br>b = [b_0,b_1,,b_m]^T<br>$$<br><br>$$<br>W * x + b = z<br>$$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong>()</p>\n<p></p>\n<p></p>\n<ol>\n<li><p>sigmoid</p>\n<p> sigmoid</p>\n<p><br>$$<br>f(x) = \\frac{1}{1+e^{-x}}<br>$$<br>R(0, 1)</p>\n</li>\n<li><p><br>$$<br>f(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}<br>$$<br>(-1,1)sigmoid</p>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p></p>\n<p>(CNN)(RNN)</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><br>$$<br>x = [x_0,x_1,,x_n]^T<br>$$<br><br>$$<br>z = [z_0,z_1,,z_m]^T<br>$$<br><br>$$<br>W_{m \\times n}<br>$$<br><br>$$<br>b = [b_0,b_1,,b_m]^T<br>$$<br><br>$$<br>W * x + b = z<br>$$</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p><strong></strong>()</p>\n<p></p>\n<p></p>\n<ol>\n<li><p>sigmoid</p>\n<p> sigmoid</p>\n<p><br>$$<br>f(x) = \\frac{1}{1+e^{-x}}<br>$$<br>R(0, 1)</p>\n</li>\n<li><p><br>$$<br>f(x) = \\frac{e^x - e^{-x}}{e^x+e^{-x}}<br>$$<br>(-1,1)sigmoid</p>\n</li>\n</ol>\n"},{"title":" Method of programming facing to exams","date":"2016-11-27T05:49:31.000Z","_content":"\n1. \n\n   \n\n2. \n\n   \n\n3. \n\n   ```Python\n   def merge(A, B):\n       # merge two small solved problems into one.\n       return merged\n\n   def divideConquer(S, divide, combine):\n       if len(S) == 1: return S\n       # divide a grand problems\n       L, R = divide(S)\n       A = divideConquer(L, divide, combine)\n       B = divideConquer(R, divide, combine)\n       return merge(A, B)\n   ```\n\n   \n\n4. \n\n   [](http://blog.csdn.net/littlethunder/article/details/26575417)\n\n   ```Python\n   def bag(n,c,w,v):  \n       res=[[-1 for j in range(c+1)] for i in range(n+1)]  \n       for j in range(c+1):  \n           res[0][j]=0  \n       for i in range(1,n+1):  \n           for j in range(1,c+1):  \n               res[i][j]=res[i-1][j]  \n               if j>=w[i-1] and res[i][j]<res[i-1][j-w[i-1]]+v[i-1]:  \n                   res[i][j]=res[i-1][j-w[i-1]]+v[i-1]  \n       return res  \n     \n   def show(n,c,w,res):  \n       print(':',res[n][c])  \n       x=[False for i in range(n)]  \n       j=c  \n       for i in range(1,n+1):  \n           if res[i][j]>res[i-1][j]:  \n               x[i-1]=True  \n               j-=w[i-1]  \n       print(':')  \n       for i in range(n):  \n           if x[i]:  \n               print('',i,',',end='')  \n       print('')  \n     \n   if __name__=='__main__':  \n       n=5  \n       c=10  \n       w=[2,2,6,5,4]  \n       v=[6,3,5,4,6]  \n       res=bag(n,c,w,v)  \n       show(n,c,w,res)\n   ```\n\n   ","source":"_posts/Method-of-programming-facing-to-exams.md","raw":"---\ntitle:  Method of programming facing to exams\ndate: 2016-11-27 13:49:31\ncategories: programming\ntags: [algo, programming]\n---\n\n1. \n\n   \n\n2. \n\n   \n\n3. \n\n   ```Python\n   def merge(A, B):\n       # merge two small solved problems into one.\n       return merged\n\n   def divideConquer(S, divide, combine):\n       if len(S) == 1: return S\n       # divide a grand problems\n       L, R = divide(S)\n       A = divideConquer(L, divide, combine)\n       B = divideConquer(R, divide, combine)\n       return merge(A, B)\n   ```\n\n   \n\n4. \n\n   [](http://blog.csdn.net/littlethunder/article/details/26575417)\n\n   ```Python\n   def bag(n,c,w,v):  \n       res=[[-1 for j in range(c+1)] for i in range(n+1)]  \n       for j in range(c+1):  \n           res[0][j]=0  \n       for i in range(1,n+1):  \n           for j in range(1,c+1):  \n               res[i][j]=res[i-1][j]  \n               if j>=w[i-1] and res[i][j]<res[i-1][j-w[i-1]]+v[i-1]:  \n                   res[i][j]=res[i-1][j-w[i-1]]+v[i-1]  \n       return res  \n     \n   def show(n,c,w,res):  \n       print(':',res[n][c])  \n       x=[False for i in range(n)]  \n       j=c  \n       for i in range(1,n+1):  \n           if res[i][j]>res[i-1][j]:  \n               x[i-1]=True  \n               j-=w[i-1]  \n       print(':')  \n       for i in range(n):  \n           if x[i]:  \n               print('',i,',',end='')  \n       print('')  \n     \n   if __name__=='__main__':  \n       n=5  \n       c=10  \n       w=[2,2,6,5,4]  \n       v=[6,3,5,4,6]  \n       res=bag(n,c,w,v)  \n       show(n,c,w,res)\n   ```\n\n   ","slug":"Method-of-programming-facing-to-exams","published":1,"updated":"2016-11-30T10:45:24.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufp2000kgwtl01ad8zyn","content":"<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">merge</span>(<span class=\"params\">A, B</span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># merge two small solved problems into one.</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> merged</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">divideConquer</span>(<span class=\"params\">S, divide, combine</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(S) == <span class=\"number\">1</span>: <span class=\"keyword\">return</span> S</span><br><span class=\"line\">    <span class=\"comment\"># divide a grand problems</span></span><br><span class=\"line\">    L, R = divide(S)</span><br><span class=\"line\">    A = divideConquer(L, divide, combine)</span><br><span class=\"line\">    B = divideConquer(R, divide, combine)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> merge(A, B)</span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n</li>\n<li><p></p>\n<p><a href=\"http://blog.csdn.net/littlethunder/article/details/26575417\"></a></p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bag</span>(<span class=\"params\">n,c,w,v</span>):</span>  </span><br><span class=\"line\">    res=[[-<span class=\"number\">1</span> <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(c+<span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n+<span class=\"number\">1</span>)]  </span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(c+<span class=\"number\">1</span>):  </span><br><span class=\"line\">        res[<span class=\"number\">0</span>][j]=<span class=\"number\">0</span>  </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,c+<span class=\"number\">1</span>):  </span><br><span class=\"line\">            res[i][j]=res[i-<span class=\"number\">1</span>][j]  </span><br><span class=\"line\">            <span class=\"keyword\">if</span> j&gt;=w[i-<span class=\"number\">1</span>] <span class=\"keyword\">and</span> res[i][j]&lt;res[i-<span class=\"number\">1</span>][j-w[i-<span class=\"number\">1</span>]]+v[i-<span class=\"number\">1</span>]:  </span><br><span class=\"line\">                res[i][j]=res[i-<span class=\"number\">1</span>][j-w[i-<span class=\"number\">1</span>]]+v[i-<span class=\"number\">1</span>]  </span><br><span class=\"line\">    <span class=\"keyword\">return</span> res  </span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">show</span>(<span class=\"params\">n,c,w,res</span>):</span>  </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">':'</span>,res[n][c])  </span><br><span class=\"line\">    x=[<span class=\"literal\">False</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n)]  </span><br><span class=\"line\">    j=c  </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </span><br><span class=\"line\">        <span class=\"keyword\">if</span> res[i][j]&gt;res[i-<span class=\"number\">1</span>][j]:  </span><br><span class=\"line\">            x[i-<span class=\"number\">1</span>]=<span class=\"literal\">True</span>  </span><br><span class=\"line\">            j-=w[i-<span class=\"number\">1</span>]  </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">':'</span>)  </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):  </span><br><span class=\"line\">        <span class=\"keyword\">if</span> x[i]:  </span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">''</span>,i,<span class=\"string\">','</span>,end=<span class=\"string\">''</span>)  </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">''</span>)  </span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__==<span class=\"string\">'__main__'</span>:  </span><br><span class=\"line\">    n=<span class=\"number\">5</span>  </span><br><span class=\"line\">    c=<span class=\"number\">10</span>  </span><br><span class=\"line\">    w=[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">6</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>]  </span><br><span class=\"line\">    v=[<span class=\"number\">6</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">6</span>]  </span><br><span class=\"line\">    res=bag(n,c,w,v)  </span><br><span class=\"line\">    show(n,c,w,res)</span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">merge</span>(<span class=\"params\">A, B</span>):</span></span><br><span class=\"line\">    <span class=\"comment\"># merge two small solved problems into one.</span></span><br><span class=\"line\">    <span class=\"keyword\">return</span> merged</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">divideConquer</span>(<span class=\"params\">S, divide, combine</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">if</span> <span class=\"built_in\">len</span>(S) == <span class=\"number\">1</span>: <span class=\"keyword\">return</span> S</span><br><span class=\"line\">    <span class=\"comment\"># divide a grand problems</span></span><br><span class=\"line\">    L, R = divide(S)</span><br><span class=\"line\">    A = divideConquer(L, divide, combine)</span><br><span class=\"line\">    B = divideConquer(R, divide, combine)</span><br><span class=\"line\">    <span class=\"keyword\">return</span> merge(A, B)</span><br></pre></td></tr></table></figure>\n\n<p></p>\n</li>\n<li><p></p>\n<p><a href=\"http://blog.csdn.net/littlethunder/article/details/26575417\"></a></p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br><span class=\"line\">24</span><br><span class=\"line\">25</span><br><span class=\"line\">26</span><br><span class=\"line\">27</span><br><span class=\"line\">28</span><br><span class=\"line\">29</span><br><span class=\"line\">30</span><br><span class=\"line\">31</span><br><span class=\"line\">32</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">bag</span>(<span class=\"params\">n,c,w,v</span>):</span>  </span><br><span class=\"line\">    res=[[-<span class=\"number\">1</span> <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(c+<span class=\"number\">1</span>)] <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n+<span class=\"number\">1</span>)]  </span><br><span class=\"line\">    <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(c+<span class=\"number\">1</span>):  </span><br><span class=\"line\">        res[<span class=\"number\">0</span>][j]=<span class=\"number\">0</span>  </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </span><br><span class=\"line\">        <span class=\"keyword\">for</span> j <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,c+<span class=\"number\">1</span>):  </span><br><span class=\"line\">            res[i][j]=res[i-<span class=\"number\">1</span>][j]  </span><br><span class=\"line\">            <span class=\"keyword\">if</span> j&gt;=w[i-<span class=\"number\">1</span>] <span class=\"keyword\">and</span> res[i][j]&lt;res[i-<span class=\"number\">1</span>][j-w[i-<span class=\"number\">1</span>]]+v[i-<span class=\"number\">1</span>]:  </span><br><span class=\"line\">                res[i][j]=res[i-<span class=\"number\">1</span>][j-w[i-<span class=\"number\">1</span>]]+v[i-<span class=\"number\">1</span>]  </span><br><span class=\"line\">    <span class=\"keyword\">return</span> res  </span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">show</span>(<span class=\"params\">n,c,w,res</span>):</span>  </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;:&#x27;</span>,res[n][c])  </span><br><span class=\"line\">    x=[<span class=\"literal\">False</span> <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n)]  </span><br><span class=\"line\">    j=c  </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(<span class=\"number\">1</span>,n+<span class=\"number\">1</span>):  </span><br><span class=\"line\">        <span class=\"keyword\">if</span> res[i][j]&gt;res[i-<span class=\"number\">1</span>][j]:  </span><br><span class=\"line\">            x[i-<span class=\"number\">1</span>]=<span class=\"literal\">True</span>  </span><br><span class=\"line\">            j-=w[i-<span class=\"number\">1</span>]  </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;:&#x27;</span>)  </span><br><span class=\"line\">    <span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):  </span><br><span class=\"line\">        <span class=\"keyword\">if</span> x[i]:  </span><br><span class=\"line\">            <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;&#x27;</span>,i,<span class=\"string\">&#x27;,&#x27;</span>,end=<span class=\"string\">&#x27;&#x27;</span>)  </span><br><span class=\"line\">    <span class=\"built_in\">print</span>(<span class=\"string\">&#x27;&#x27;</span>)  </span><br><span class=\"line\">  </span><br><span class=\"line\"><span class=\"keyword\">if</span> __name__==<span class=\"string\">&#x27;__main__&#x27;</span>:  </span><br><span class=\"line\">    n=<span class=\"number\">5</span>  </span><br><span class=\"line\">    c=<span class=\"number\">10</span>  </span><br><span class=\"line\">    w=[<span class=\"number\">2</span>,<span class=\"number\">2</span>,<span class=\"number\">6</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>]  </span><br><span class=\"line\">    v=[<span class=\"number\">6</span>,<span class=\"number\">3</span>,<span class=\"number\">5</span>,<span class=\"number\">4</span>,<span class=\"number\">6</span>]  </span><br><span class=\"line\">    res=bag(n,c,w,v)  </span><br><span class=\"line\">    show(n,c,w,res)</span><br></pre></td></tr></table></figure>\n\n<p></p>\n</li>\n</ol>\n"},{"title":"MongoDB, Docker and Python","date":"2017-06-22T06:53:44.000Z","_content":"\n## \n\n\n\n- Docker\n- Python\n  - pymongo\n\n## Docker\n\n--rm-d\n\n27017mongodb\n\n```Bash\ndocker run --name my-mongo -it -p 27017:27017 mongo\n```\n\n\n\n```Shell\ndocker start my-mongo\n```\n\n## Python\n\n```python\nfrom pymongo import MongoClient\n\n# connection\nclient = MongoClient()\nclient.server_info()\ndb = client.test\n\n# loop cursor\ncursor = db.cars.find()\nfor doc in cursor:\n    print(doc)\n\n# or just find one\ndb.cars.find_one()\n```","source":"_posts/MongoDB-Docker-and-Python.md","raw":"---\ntitle: 'MongoDB, Docker and Python'\ndate: 2017-06-22 14:53:44\ncategories: [programming]\ntags: [mongo, mongodb, docker, python]\n---\n\n## \n\n\n\n- Docker\n- Python\n  - pymongo\n\n## Docker\n\n--rm-d\n\n27017mongodb\n\n```Bash\ndocker run --name my-mongo -it -p 27017:27017 mongo\n```\n\n\n\n```Shell\ndocker start my-mongo\n```\n\n## Python\n\n```python\nfrom pymongo import MongoClient\n\n# connection\nclient = MongoClient()\nclient.server_info()\ndb = client.test\n\n# loop cursor\ncursor = db.cars.find()\nfor doc in cursor:\n    print(doc)\n\n# or just find one\ndb.cars.find_one()\n```","slug":"MongoDB-Docker-and-Python","published":1,"updated":"2017-06-22T07:07:59.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufp3000pgwtl2fv8cajr","content":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>Docker</li>\n<li>Python<ul>\n<li>pymongo</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Docker\"><a href=\"#Docker\" class=\"headerlink\" title=\"Docker\"></a>Docker</h2><p>rm-d</p>\n<p>27017mongodb</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run --name my-mongo -it -p 27017:27017 mongo</span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n<figure class=\"highlight shell\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker start my-mongo</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2><figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymongo <span class=\"keyword\">import</span> MongoClient</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># connection</span></span><br><span class=\"line\">client = MongoClient()</span><br><span class=\"line\">client.server_info()</span><br><span class=\"line\">db = client.test</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># loop cursor</span></span><br><span class=\"line\">cursor = db.cars.find()</span><br><span class=\"line\"><span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> cursor:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(doc)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># or just find one</span></span><br><span class=\"line\">db.cars.find_one()</span><br></pre></td></tr></tbody></table></figure>","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<ul>\n<li>Docker</li>\n<li>Python<ul>\n<li>pymongo</li>\n</ul>\n</li>\n</ul>\n<h2 id=\"Docker\"><a href=\"#Docker\" class=\"headerlink\" title=\"Docker\"></a>Docker</h2><p>rm-d</p>\n<p>27017mongodb</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker run --name my-mongo -it -p 27017:27017 mongo</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">docker start my-mongo</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Python\"><a href=\"#Python\" class=\"headerlink\" title=\"Python\"></a>Python</h2><figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"keyword\">from</span> pymongo <span class=\"keyword\">import</span> MongoClient</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># connection</span></span><br><span class=\"line\">client = MongoClient()</span><br><span class=\"line\">client.server_info()</span><br><span class=\"line\">db = client.test</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># loop cursor</span></span><br><span class=\"line\">cursor = db.cars.find()</span><br><span class=\"line\"><span class=\"keyword\">for</span> doc <span class=\"keyword\">in</span> cursor:</span><br><span class=\"line\">    <span class=\"built_in\">print</span>(doc)</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># or just find one</span></span><br><span class=\"line\">db.cars.find_one()</span><br></pre></td></tr></table></figure>"},{"title":"Note of NLP","date":"2017-06-26T12:52:45.000Z","_content":"\n# NLP\n\n1. \"One-hot\" representation\n\n   \n   $$\n   [0,0,0,0,0,0,0,0,0,1,0,0,0]\n   $$\n\n2. Main idea of word2vec\n\n   Two algorithms\n\n   1. Skip-grams\n   2. Continuous bag of words (CBOW)\n\n   Two training methods\n\n   1. Hierarchical softmax\n   2. Negative sampling\n\n## \n\n>[Zeng et al. 2014] [Santos et al. 2015]\n>\n>[Miwa et al. 2016]  LSTMLong-Short Term Memory LSTM  SemEval-2010 Task 8 \n>\n>--__\n\nRNNNLP[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) [](http://www.csdn.net/article/2015-08-28/2825569)\n\nLSTM[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)  [LSTM](http://blog.csdn.net/jerr__y/article/details/58598296)\n\n[LSTMtensorflow](http://blog.csdn.net/jerr__y/article/details/61195257)\n\n### GAN ?\n\nACGANDiscriminator\n\nInfoGAN\n\nGAN","source":"_posts/Note-of-NLP.md","raw":"---\ntitle: Note of NLP\ndate: 2017-06-26 20:52:45\ncategories: [programming]\ntags: [nlp, machine-learning, deep-learning]\n---\n\n# NLP\n\n1. \"One-hot\" representation\n\n   \n   $$\n   [0,0,0,0,0,0,0,0,0,1,0,0,0]\n   $$\n\n2. Main idea of word2vec\n\n   Two algorithms\n\n   1. Skip-grams\n   2. Continuous bag of words (CBOW)\n\n   Two training methods\n\n   1. Hierarchical softmax\n   2. Negative sampling\n\n## \n\n>[Zeng et al. 2014] [Santos et al. 2015]\n>\n>[Miwa et al. 2016]  LSTMLong-Short Term Memory LSTM  SemEval-2010 Task 8 \n>\n>--__\n\nRNNNLP[The Unreasonable Effectiveness of Recurrent Neural Networks](http://karpathy.github.io/2015/05/21/rnn-effectiveness/) [](http://www.csdn.net/article/2015-08-28/2825569)\n\nLSTM[Understanding LSTM Networks](http://colah.github.io/posts/2015-08-Understanding-LSTMs/)  [LSTM](http://blog.csdn.net/jerr__y/article/details/58598296)\n\n[LSTMtensorflow](http://blog.csdn.net/jerr__y/article/details/61195257)\n\n### GAN ?\n\nACGANDiscriminator\n\nInfoGAN\n\nGAN","slug":"Note-of-NLP","published":1,"updated":"2017-06-28T09:13:58.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufp4000rgwtlg65o8sme","content":"<h1 id=\"NLP\"><a href=\"#NLP\" class=\"headerlink\" title=\"NLP\"></a>NLP</h1><ol>\n<li><p>One-hot representation</p>\n<p><br>$$<br>[0,0,0,0,0,0,0,0,0,1,0,0,0]<br>$$</p>\n</li>\n<li><p>Main idea of word2vec</p>\n<p>Two algorithms</p>\n<ol>\n<li>Skip-grams</li>\n<li>Continuous bag of words (CBOW)</li>\n</ol>\n<p>Two training methods</p>\n<ol>\n<li>Hierarchical softmax</li>\n<li>Negative sampling</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><blockquote>\n<p>[Zeng et al. 2014] [Santos et al. 2015]</p>\n<p>[Miwa et al. 2016]  LSTMLong-Short Term Memory LSTM  SemEval-2010 Task 8 </p>\n<p>__</p>\n</blockquote>\n<p>RNNNLP<a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a> <a href=\"http://www.csdn.net/article/2015-08-28/2825569\"></a></p>\n<p>LSTM<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>  <a href=\"http://blog.csdn.net/jerr__y/article/details/58598296\">LSTM</a></p>\n<p><a href=\"http://blog.csdn.net/jerr__y/article/details/61195257\">LSTMtensorflow</a></p>\n<h3 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN ?\"></a>GAN ?</h3><p>ACGANDiscriminator</p>\n<p>InfoGAN</p>\n<p>GAN</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"NLP\"><a href=\"#NLP\" class=\"headerlink\" title=\"NLP\"></a>NLP</h1><ol>\n<li><p>One-hot representation</p>\n<p><br>$$<br>[0,0,0,0,0,0,0,0,0,1,0,0,0]<br>$$</p>\n</li>\n<li><p>Main idea of word2vec</p>\n<p>Two algorithms</p>\n<ol>\n<li>Skip-grams</li>\n<li>Continuous bag of words (CBOW)</li>\n</ol>\n<p>Two training methods</p>\n<ol>\n<li>Hierarchical softmax</li>\n<li>Negative sampling</li>\n</ol>\n</li>\n</ol>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><blockquote>\n<p>[Zeng et al. 2014] [Santos et al. 2015]</p>\n<p>[Miwa et al. 2016]  LSTMLong-Short Term Memory LSTM  SemEval-2010 Task 8 </p>\n<p>__</p>\n</blockquote>\n<p>RNNNLP<a href=\"http://karpathy.github.io/2015/05/21/rnn-effectiveness/\">The Unreasonable Effectiveness of Recurrent Neural Networks</a> <a href=\"http://www.csdn.net/article/2015-08-28/2825569\"></a></p>\n<p>LSTM<a href=\"http://colah.github.io/posts/2015-08-Understanding-LSTMs/\">Understanding LSTM Networks</a>  <a href=\"http://blog.csdn.net/jerr__y/article/details/58598296\">LSTM</a></p>\n<p><a href=\"http://blog.csdn.net/jerr__y/article/details/61195257\">LSTMtensorflow</a></p>\n<h3 id=\"GAN\"><a href=\"#GAN\" class=\"headerlink\" title=\"GAN ?\"></a>GAN ?</h3><p>ACGANDiscriminator</p>\n<p>InfoGAN</p>\n<p>GAN</p>\n"},{"title":" Note of datamining","date":"2016-12-06T07:35:24.000Z","_content":"\n# \n\n\n\n1.  - data clearing\n2.  - data integration\n3.  - data transformation\n4.  - data mining\n5.  - pattern evaluation\n6.  - knowledge presentation\n\n# \n\n1. \n\n   age(X, \"20-29\") ^ income(X, \"20K-30K\") => buys(X, \"MP3\")\n\n   [support = 2%, confidence = 60%]\n\n2. \n\n   \n\n   - \n   - \n   - \n   - \n\n3. \n\n   \n\n   \n\n4. \n\n   ()\n\n   \n\n   \n\n5. \n\n   \n\n   \n\n# \n\n\n\n\n\n1. ;\n2. ;\n3. ;\n4. \n\n# \n\n","source":"_posts/Note-of-datamining.md","raw":"---\ntitle:  Note of datamining\ndate: 2016-12-6 15:35:24\ncategories: [programming, unfinished]\ntags: [datamining]\n---\n\n# \n\n\n\n1.  - data clearing\n2.  - data integration\n3.  - data transformation\n4.  - data mining\n5.  - pattern evaluation\n6.  - knowledge presentation\n\n# \n\n1. \n\n   age(X, \"20-29\") ^ income(X, \"20K-30K\") => buys(X, \"MP3\")\n\n   [support = 2%, confidence = 60%]\n\n2. \n\n   \n\n   - \n   - \n   - \n   - \n\n3. \n\n   \n\n   \n\n4. \n\n   ()\n\n   \n\n   \n\n5. \n\n   \n\n   \n\n# \n\n\n\n\n\n1. ;\n2. ;\n3. ;\n4. \n\n# \n\n","slug":"Note-of-datamining","published":1,"updated":"2016-12-06T21:04:53.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufp6000vgwtl7kika36r","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li> - data clearing</li>\n<li> - data integration</li>\n<li> - data transformation</li>\n<li> - data mining</li>\n<li> - pattern evaluation</li>\n<li> - knowledge presentation</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>age(X, 20-29) ^ income(X, 20K-30K) =&gt; buys(X, MP3)</p>\n<p>[support = 2%, confidence = 60%]</p>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>()</p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<ol>\n<li>;</li>\n<li>;</li>\n<li>;</li>\n<li></li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li> - data clearing</li>\n<li> - data integration</li>\n<li> - data transformation</li>\n<li> - data mining</li>\n<li> - pattern evaluation</li>\n<li> - knowledge presentation</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>age(X, 20-29) ^ income(X, 20K-30K) =&gt; buys(X, MP3)</p>\n<p>[support = 2%, confidence = 60%]</p>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>()</p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<ol>\n<li>;</li>\n<li>;</li>\n<li>;</li>\n<li></li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n"},{"title":"Note of knowledge graph","date":"2017-06-25T03:21:18.000Z","_content":"\n#  Knowledge graph\n\nGoogle\n\n\n\n\n\n## 1.  information extraction\n\n(entity)(relationship)\n\n1.  entity extraction\n   - \n     - liuKnn\n     - lin\n   - \n     - 2012lingfreebaseStanford NER\n     - whitelaw\n     - \n2.  relationship extraction","source":"_posts/Note-of-knowledge-graph.md","raw":"---\ntitle: Note of knowledge graph\ndate: 2017-06-25 11:21:18\ncategories: [programming]\ntags: [knowledge-graph, machine-learning, datamining]\n---\n\n#  Knowledge graph\n\nGoogle\n\n\n\n\n\n## 1.  information extraction\n\n(entity)(relationship)\n\n1.  entity extraction\n   - \n     - liuKnn\n     - lin\n   - \n     - 2012lingfreebaseStanford NER\n     - whitelaw\n     - \n2.  relationship extraction","slug":"Note-of-knowledge-graph","published":1,"updated":"2017-06-25T05:40:19.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufp7000xgwtl0rnhe8o8","content":"<h1 id=\"-Knowledge-graph\"><a href=\"#-Knowledge-graph\" class=\"headerlink\" title=\" Knowledge graph\"></a> Knowledge graph</h1><p>Google</p>\n<p></p>\n<p></p>\n<h2 id=\"1--information-extraction\"><a href=\"#1--information-extraction\" class=\"headerlink\" title=\"1.  information extraction\"></a>1.  information extraction</h2><p>(entity)(relationship)</p>\n<ol>\n<li> entity extraction<ul>\n<li><ul>\n<li>liuKnn</li>\n<li>lin</li>\n</ul>\n</li>\n<li><ul>\n<li>2012lingfreebaseStanford NER</li>\n<li>whitelaw</li>\n<li></li>\n</ul>\n</li>\n</ul>\n</li>\n<li> relationship extraction</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"-Knowledge-graph\"><a href=\"#-Knowledge-graph\" class=\"headerlink\" title=\" Knowledge graph\"></a> Knowledge graph</h1><p>Google</p>\n<p></p>\n<p></p>\n<h2 id=\"1--information-extraction\"><a href=\"#1--information-extraction\" class=\"headerlink\" title=\"1.  information extraction\"></a>1.  information extraction</h2><p>(entity)(relationship)</p>\n<ol>\n<li> entity extraction<ul>\n<li><ul>\n<li>liuKnn</li>\n<li>lin</li>\n</ul>\n</li>\n<li><ul>\n<li>2012lingfreebaseStanford NER</li>\n<li>whitelaw</li>\n<li></li>\n</ul>\n</li>\n</ul>\n</li>\n<li> relationship extraction</li>\n</ol>\n"},{"title":" Note of learning Algo","date":"2016-11-27T04:38:32.000Z","_content":"\n# Data Structure\n\n{% post_link complexity How to calcul the complexity?  %} \n\n{% post_link compression How to make a compression?  %}\n\n1. The data : int, double, etc.\n2. The basic data structure\n   - Container\n   - Table \n   - Stack \n   - Queue \n   - List\n3. Tree\n   - Arbres binaires - \n     - ABR - \n   - Arbres n-aires\n4. Dictionary \n   - Hash table - Table de hachage - \n5. **Heap - Tas -  **\n   - \n   - \n6. Find-Union\n\n# Method of programming\n\n{% post_link Method-of-programming-facing-to-exams Savoir plus %}\n\n1. Echaustive / force brute - \n2. Try-error - Essai-erreur \n3. Glouton - \n4. Recursif - recursive - \n5. Divede merge - Diviser pour regner - \n6. Dynamic - Dynamique - \n\n# Graph\n\n{% post_link graph Savoir plus %}\n\n1. Traversal - parcours - \n   - BFS\n   - DFS\n2. Critical path method - plus court chemin\n   - Dijkstra\n   - Floyd\n   - Bellman-Ford\n3. Tree - arbre\n   - Prim\n   - Kruskal\n\n*backtracking\n\n*Branch and bound\n\n# Others\n\n1. \n   - \n   - fusion\n   - \n   - tas ","source":"_posts/Note-of-learning-Algo.md","raw":"---\ntitle:  Note of learning Algo\ndate: 2016-11-27 12:38:32\ncategories: programming\ntags: [algo, programming]\n---\n\n# Data Structure\n\n{% post_link complexity How to calcul the complexity?  %} \n\n{% post_link compression How to make a compression?  %}\n\n1. The data : int, double, etc.\n2. The basic data structure\n   - Container\n   - Table \n   - Stack \n   - Queue \n   - List\n3. Tree\n   - Arbres binaires - \n     - ABR - \n   - Arbres n-aires\n4. Dictionary \n   - Hash table - Table de hachage - \n5. **Heap - Tas -  **\n   - \n   - \n6. Find-Union\n\n# Method of programming\n\n{% post_link Method-of-programming-facing-to-exams Savoir plus %}\n\n1. Echaustive / force brute - \n2. Try-error - Essai-erreur \n3. Glouton - \n4. Recursif - recursive - \n5. Divede merge - Diviser pour regner - \n6. Dynamic - Dynamique - \n\n# Graph\n\n{% post_link graph Savoir plus %}\n\n1. Traversal - parcours - \n   - BFS\n   - DFS\n2. Critical path method - plus court chemin\n   - Dijkstra\n   - Floyd\n   - Bellman-Ford\n3. Tree - arbre\n   - Prim\n   - Kruskal\n\n*backtracking\n\n*Branch and bound\n\n# Others\n\n1. \n   - \n   - fusion\n   - \n   - tas ","slug":"Note-of-learning-Algo","published":1,"updated":"2016-11-30T10:56:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufp80011gwtl9j3b7d15","content":"<h1 id=\"Data-Structure\"><a href=\"#Data-Structure\" class=\"headerlink\" title=\"Data Structure\"></a>Data Structure</h1><a href=\"/posts/complexity/\" title=\"How to calcul the complexity?\">How to calcul the complexity?</a> \n\n<a href=\"/posts/compression/\" title=\"How to make a compression?\">How to make a compression?</a>\n\n<ol>\n<li>The data : int, double, etc.</li>\n<li>The basic data structure<ul>\n<li>Container</li>\n<li>Table </li>\n<li>Stack </li>\n<li>Queue </li>\n<li>List</li>\n</ul>\n</li>\n<li>Tree<ul>\n<li>Arbres binaires - <ul>\n<li>ABR - </li>\n</ul>\n</li>\n<li>Arbres n-aires</li>\n</ul>\n</li>\n<li>Dictionary <ul>\n<li>Hash table - Table de hachage - </li>\n</ul>\n</li>\n<li>**Heap - Tas -  **<ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li>Find-Union</li>\n</ol>\n<h1 id=\"Method-of-programming\"><a href=\"#Method-of-programming\" class=\"headerlink\" title=\"Method of programming\"></a>Method of programming</h1><a href=\"/posts/Method-of-programming-facing-to-exams/\" title=\"Savoir plus\">Savoir plus</a>\n\n<ol>\n<li>Echaustive / force brute - </li>\n<li>Try-error - Essai-erreur </li>\n<li>Glouton - </li>\n<li>Recursif - recursive - </li>\n<li>Divede merge - Diviser pour regner - </li>\n<li>Dynamic - Dynamique - </li>\n</ol>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><a href=\"/posts/graph/\" title=\"Savoir plus\">Savoir plus</a>\n\n<ol>\n<li>Traversal - parcours - <ul>\n<li>BFS</li>\n<li>DFS</li>\n</ul>\n</li>\n<li>Critical path method - plus court chemin<ul>\n<li>Dijkstra</li>\n<li>Floyd</li>\n<li>Bellman-Ford</li>\n</ul>\n</li>\n<li>Tree - arbre<ul>\n<li>Prim</li>\n<li>Kruskal</li>\n</ul>\n</li>\n</ol>\n<p>*backtracking</p>\n<p>*Branch and bound</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><ol>\n<li><ul>\n<li></li>\n<li>fusion</li>\n<li></li>\n<li>tas </li>\n</ul>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"Data-Structure\"><a href=\"#Data-Structure\" class=\"headerlink\" title=\"Data Structure\"></a>Data Structure</h1><a href=\"/posts/complexity/\" title=\"How to calcul the complexity?\">How to calcul the complexity?</a> \n\n<a href=\"/posts/compression/\" title=\"How to make a compression?\">How to make a compression?</a>\n\n<ol>\n<li>The data : int, double, etc.</li>\n<li>The basic data structure<ul>\n<li>Container</li>\n<li>Table </li>\n<li>Stack </li>\n<li>Queue </li>\n<li>List</li>\n</ul>\n</li>\n<li>Tree<ul>\n<li>Arbres binaires - <ul>\n<li>ABR - </li>\n</ul>\n</li>\n<li>Arbres n-aires</li>\n</ul>\n</li>\n<li>Dictionary <ul>\n<li>Hash table - Table de hachage - </li>\n</ul>\n</li>\n<li>**Heap - Tas -  **<ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li>Find-Union</li>\n</ol>\n<h1 id=\"Method-of-programming\"><a href=\"#Method-of-programming\" class=\"headerlink\" title=\"Method of programming\"></a>Method of programming</h1><a href=\"/posts/Method-of-programming-facing-to-exams/\" title=\"Savoir plus\">Savoir plus</a>\n\n<ol>\n<li>Echaustive / force brute - </li>\n<li>Try-error - Essai-erreur </li>\n<li>Glouton - </li>\n<li>Recursif - recursive - </li>\n<li>Divede merge - Diviser pour regner - </li>\n<li>Dynamic - Dynamique - </li>\n</ol>\n<h1 id=\"Graph\"><a href=\"#Graph\" class=\"headerlink\" title=\"Graph\"></a>Graph</h1><a href=\"/posts/graph/\" title=\"Savoir plus\">Savoir plus</a>\n\n<ol>\n<li>Traversal - parcours - <ul>\n<li>BFS</li>\n<li>DFS</li>\n</ul>\n</li>\n<li>Critical path method - plus court chemin<ul>\n<li>Dijkstra</li>\n<li>Floyd</li>\n<li>Bellman-Ford</li>\n</ul>\n</li>\n<li>Tree - arbre<ul>\n<li>Prim</li>\n<li>Kruskal</li>\n</ul>\n</li>\n</ol>\n<p>*backtracking</p>\n<p>*Branch and bound</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><ol>\n<li><ul>\n<li></li>\n<li>fusion</li>\n<li></li>\n<li>tas </li>\n</ul>\n</li>\n</ol>\n"},{"title":" Note of probability","date":"2016-11-30T11:35:53.000Z","_content":"\n\n\n\n\n# Part 1 \n\n{% post_link proba-ch1 Savoir plus  %}\n\n# Part 2 \n\n{% post_link proba-ch2 Savoir plus  %}\n\n# Part 3 \n\n{% post_link proba-ch3 Savoir plus  %}\n\n# Part 4 \n\n{% post_link proba-ch4 Savoir plus  %}\n\n# Part 5 \n\n{% post_link proba-ch5 Savoir plus  %}\n\n# Part 6 \n\n{% post_link proba-ch6 Savoir plus  %}\n","source":"_posts/Note-of-probability.md","raw":"---\ntitle:  Note of probability\ndate: 2016-11-30 19:35:53\ncategories: [math]\ntags: [math, probability]\n---\n\n\n\n\n\n# Part 1 \n\n{% post_link proba-ch1 Savoir plus  %}\n\n# Part 2 \n\n{% post_link proba-ch2 Savoir plus  %}\n\n# Part 3 \n\n{% post_link proba-ch3 Savoir plus  %}\n\n# Part 4 \n\n{% post_link proba-ch4 Savoir plus  %}\n\n# Part 5 \n\n{% post_link proba-ch5 Savoir plus  %}\n\n# Part 6 \n\n{% post_link proba-ch6 Savoir plus  %}\n","slug":"Note-of-probability","published":1,"updated":"2016-12-05T14:16:49.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufp90014gwtlg8dt7wef","content":"<p></p>\n<p></p>\n<h1 id=\"Part-1-\"><a href=\"#Part-1-\" class=\"headerlink\" title=\"Part 1 \"></a>Part 1 </h1><a href=\"/posts/proba-ch1/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-2-\"><a href=\"#Part-2-\" class=\"headerlink\" title=\"Part 2 \"></a>Part 2 </h1><a href=\"/posts/proba-ch2/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-3-\"><a href=\"#Part-3-\" class=\"headerlink\" title=\"Part 3 \"></a>Part 3 </h1><a href=\"/posts/proba-ch3/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-4-\"><a href=\"#Part-4-\" class=\"headerlink\" title=\"Part 4 \"></a>Part 4 </h1><a href=\"/posts/proba-ch4/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-5-\"><a href=\"#Part-5-\" class=\"headerlink\" title=\"Part 5 \"></a>Part 5 </h1><a href=\"/posts/proba-ch5/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-6-\"><a href=\"#Part-6-\" class=\"headerlink\" title=\"Part 6 \"></a>Part 6 </h1><a href=\"/posts/proba-ch6/\" title=\"Savoir plus\">Savoir plus</a>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p></p>\n<p></p>\n<h1 id=\"Part-1-\"><a href=\"#Part-1-\" class=\"headerlink\" title=\"Part 1 \"></a>Part 1 </h1><a href=\"/posts/proba-ch1/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-2-\"><a href=\"#Part-2-\" class=\"headerlink\" title=\"Part 2 \"></a>Part 2 </h1><a href=\"/posts/proba-ch2/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-3-\"><a href=\"#Part-3-\" class=\"headerlink\" title=\"Part 3 \"></a>Part 3 </h1><a href=\"/posts/proba-ch3/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-4-\"><a href=\"#Part-4-\" class=\"headerlink\" title=\"Part 4 \"></a>Part 4 </h1><a href=\"/posts/proba-ch4/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-5-\"><a href=\"#Part-5-\" class=\"headerlink\" title=\"Part 5 \"></a>Part 5 </h1><a href=\"/posts/proba-ch5/\" title=\"Savoir plus\">Savoir plus</a>\n\n<h1 id=\"Part-6-\"><a href=\"#Part-6-\" class=\"headerlink\" title=\"Part 6 \"></a>Part 6 </h1><a href=\"/posts/proba-ch6/\" title=\"Savoir plus\">Savoir plus</a>\n"},{"title":"Note of statistic","date":"2017-01-28T10:13:13.000Z","_content":"\n# \n\n### \n\n\n\n### Slutsky\n\nif\n$$\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c\n$$\nthen\n$$\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c\n$$\n\n# \n\n## un test de $\\chi^2$\n\n\n\n| Liste | a    | b    | c    |\n| ----- | ---- | ---- | ---- |\n| pi    | xx   | xx   | xx   |\n| npi   | xx   | xx   | xx   |\n| ni    | xx   | xx   | xx   |\n\n\n$$\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}\n$$\nn-1","source":"_posts/Note-of-statistic.md","raw":"---\ntitle: Note of statistic\ndate: 2017-01-28 18:13:13\ncategories: [math, unfinished]\ntags: [statistic, math]\n---\n\n# \n\n### \n\n\n\n### Slutsky\n\nif\n$$\n\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c\n$$\nthen\n$$\n\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c\n$$\n\n# \n\n## un test de $\\chi^2$\n\n\n\n| Liste | a    | b    | c    |\n| ----- | ---- | ---- | ---- |\n| pi    | xx   | xx   | xx   |\n| npi   | xx   | xx   | xx   |\n| ni    | xx   | xx   | xx   |\n\n\n$$\nT= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}\n$$\nn-1","slug":"Note-of-statistic","published":1,"updated":"2017-01-28T18:02:06.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpa0017gwtl2o49btu3","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<h3 id=\"Slutsky\"><a href=\"#Slutsky\" class=\"headerlink\" title=\"Slutsky\"></a>Slutsky</h3><p>if<br>$$<br>\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c<br>$$<br>then<br>$$<br>\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c<br>$$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"un-test-de-chi-2\"><a href=\"#un-test-de-chi-2\" class=\"headerlink\" title=\"un test de $\\chi^2$\"></a>un test de $\\chi^2$</h2><p></p>\n<table>\n<thead>\n<tr>\n<th>Liste</th>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>pi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>npi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>ni</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n</tbody></table>\n<p><br>$$<br>T= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}<br>$$<br>n-1</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<h3 id=\"Slutsky\"><a href=\"#Slutsky\" class=\"headerlink\" title=\"Slutsky\"></a>Slutsky</h3><p>if<br>$$<br>\\Upsilon_n \\to(loi) \\Upsilon \\text{ et } Z_n \\to (P)c<br>$$<br>then<br>$$<br>\\Upsilon_n + Z_n \\to(L) \\Upsilon+c \\text{ et } \\Upsilon_n Z_n \\to(L) \\Upsilon c<br>$$</p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"un-test-de-chi-2\"><a href=\"#un-test-de-chi-2\" class=\"headerlink\" title=\"un test de $\\chi^2$\"></a>un test de $\\chi^2$</h2><p></p>\n<table>\n<thead>\n<tr>\n<th>Liste</th>\n<th>a</th>\n<th>b</th>\n<th>c</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>pi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>npi</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n<tr>\n<td>ni</td>\n<td>xx</td>\n<td>xx</td>\n<td>xx</td>\n</tr>\n</tbody></table>\n<p><br>$$<br>T= \\sum_{j=1}^n{\\frac{(n_i-np_i)^2}{np_i}}<br>$$<br>n-1</p>\n"},{"title":"OS notes","date":"2017-04-15T10:59:08.000Z","_content":"\n# Operating System\n\nThis is the note or keywords of a course in udacity.\n\n## Overview\n\n- Processes and process management\n- Threads and concurrency\n- resource management\n- OS services\n- OS support for distributed services\n- Data cendter and cloud\n\n## Introduction\n\n### OS Elements\n\nAbstractions\n\n- Process, thread, file, socket, memory pape\n\nMechanisms\n\n- Create, schedule, open, write, allocate\n\nPolicies\n\n- Least - recently used (LRU) etc.\n\n\n### System call\n\nTwo ways for a user process to execute a priviledged call.\n\n- User process calls hardware directly, and that will cause a trap, the kernel check if it is legal\n- User process executes system call.\n\nuser/kernel transitions are not cheap!\n\n### OS services\n\n- Scheduler => CPU\n- Mem manager\n- Block device driver\n- file system\n- ...\n\n### Linux Architecture\n\nUser interface : **Users** <= user mode\n\nLibrary interface : **Standards utility programs** (shell, editor, compilors) <= user mode\n\nSystem call interface : **Standard licrary** (open, close, read, write, fork) <= user mode\n\n**Linux operating system** <= kernel mode\n\n**Hardware**\n\n## Processes and Process Management\n\nA process:\n\n- state of execution\n  - Program counter\n  - stack\n- parts and temporary holding area\n  - Data, register\n- May require special hardware\n  - IO devices\n\nProcess == state of a program when executing.\n\n### Process Control Block (PCB)\n\na data structure storing status of a process\n\n- PCB created when process is created\n- Certain filds are updated when process state changes\n- other fields change too frequently\n\n### Context switch\n\nHot cache, cold cache\n\n### CPU scheduler\n\nOS must \n\n- preempt\n- schedule\n- dispatch\n\n### Multi Processes\n\nP1(web server), P2(Database)\n\nInter - process communication (IPC) : \n\n- Message - passing IPC\n\n\n- Shared memory IPC","source":"_posts/OS-notes.md","raw":"---\ntitle: OS notes\ndate: 2017-04-15 18:59:08\ncategories: [programming, unfinished]\ntags: [OS]\n---\n\n# Operating System\n\nThis is the note or keywords of a course in udacity.\n\n## Overview\n\n- Processes and process management\n- Threads and concurrency\n- resource management\n- OS services\n- OS support for distributed services\n- Data cendter and cloud\n\n## Introduction\n\n### OS Elements\n\nAbstractions\n\n- Process, thread, file, socket, memory pape\n\nMechanisms\n\n- Create, schedule, open, write, allocate\n\nPolicies\n\n- Least - recently used (LRU) etc.\n\n\n### System call\n\nTwo ways for a user process to execute a priviledged call.\n\n- User process calls hardware directly, and that will cause a trap, the kernel check if it is legal\n- User process executes system call.\n\nuser/kernel transitions are not cheap!\n\n### OS services\n\n- Scheduler => CPU\n- Mem manager\n- Block device driver\n- file system\n- ...\n\n### Linux Architecture\n\nUser interface : **Users** <= user mode\n\nLibrary interface : **Standards utility programs** (shell, editor, compilors) <= user mode\n\nSystem call interface : **Standard licrary** (open, close, read, write, fork) <= user mode\n\n**Linux operating system** <= kernel mode\n\n**Hardware**\n\n## Processes and Process Management\n\nA process:\n\n- state of execution\n  - Program counter\n  - stack\n- parts and temporary holding area\n  - Data, register\n- May require special hardware\n  - IO devices\n\nProcess == state of a program when executing.\n\n### Process Control Block (PCB)\n\na data structure storing status of a process\n\n- PCB created when process is created\n- Certain filds are updated when process state changes\n- other fields change too frequently\n\n### Context switch\n\nHot cache, cold cache\n\n### CPU scheduler\n\nOS must \n\n- preempt\n- schedule\n- dispatch\n\n### Multi Processes\n\nP1(web server), P2(Database)\n\nInter - process communication (IPC) : \n\n- Message - passing IPC\n\n\n- Shared memory IPC","slug":"OS-notes","published":1,"updated":"2017-04-16T18:40:56.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpc001bgwtl809wau5y","content":"<h1 id=\"Operating-System\"><a href=\"#Operating-System\" class=\"headerlink\" title=\"Operating System\"></a>Operating System</h1><p>This is the note or keywords of a course in udacity.</p>\n<h2 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h2><ul>\n<li>Processes and process management</li>\n<li>Threads and concurrency</li>\n<li>resource management</li>\n<li>OS services</li>\n<li>OS support for distributed services</li>\n<li>Data cendter and cloud</li>\n</ul>\n<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h3 id=\"OS-Elements\"><a href=\"#OS-Elements\" class=\"headerlink\" title=\"OS Elements\"></a>OS Elements</h3><p>Abstractions</p>\n<ul>\n<li>Process, thread, file, socket, memory pape</li>\n</ul>\n<p>Mechanisms</p>\n<ul>\n<li>Create, schedule, open, write, allocate</li>\n</ul>\n<p>Policies</p>\n<ul>\n<li>Least - recently used (LRU) etc.</li>\n</ul>\n<h3 id=\"System-call\"><a href=\"#System-call\" class=\"headerlink\" title=\"System call\"></a>System call</h3><p>Two ways for a user process to execute a priviledged call.</p>\n<ul>\n<li>User process calls hardware directly, and that will cause a trap, the kernel check if it is legal</li>\n<li>User process executes system call.</li>\n</ul>\n<p>user/kernel transitions are not cheap!</p>\n<h3 id=\"OS-services\"><a href=\"#OS-services\" class=\"headerlink\" title=\"OS services\"></a>OS services</h3><ul>\n<li>Scheduler =&gt; CPU</li>\n<li>Mem manager</li>\n<li>Block device driver</li>\n<li>file system</li>\n<li></li>\n</ul>\n<h3 id=\"Linux-Architecture\"><a href=\"#Linux-Architecture\" class=\"headerlink\" title=\"Linux Architecture\"></a>Linux Architecture</h3><p>User interface : <strong>Users</strong> &lt;= user mode</p>\n<p>Library interface : <strong>Standards utility programs</strong> (shell, editor, compilors) &lt;= user mode</p>\n<p>System call interface : <strong>Standard licrary</strong> (open, close, read, write, fork) &lt;= user mode</p>\n<p><strong>Linux operating system</strong> &lt;= kernel mode</p>\n<p><strong>Hardware</strong></p>\n<h2 id=\"Processes-and-Process-Management\"><a href=\"#Processes-and-Process-Management\" class=\"headerlink\" title=\"Processes and Process Management\"></a>Processes and Process Management</h2><p>A process:</p>\n<ul>\n<li>state of execution<ul>\n<li>Program counter</li>\n<li>stack</li>\n</ul>\n</li>\n<li>parts and temporary holding area<ul>\n<li>Data, register</li>\n</ul>\n</li>\n<li>May require special hardware<ul>\n<li>IO devices</li>\n</ul>\n</li>\n</ul>\n<p>Process == state of a program when executing.</p>\n<h3 id=\"Process-Control-Block-PCB\"><a href=\"#Process-Control-Block-PCB\" class=\"headerlink\" title=\"Process Control Block (PCB)\"></a>Process Control Block (PCB)</h3><p>a data structure storing status of a process</p>\n<ul>\n<li>PCB created when process is created</li>\n<li>Certain filds are updated when process state changes</li>\n<li>other fields change too frequently</li>\n</ul>\n<h3 id=\"Context-switch\"><a href=\"#Context-switch\" class=\"headerlink\" title=\"Context switch\"></a>Context switch</h3><p>Hot cache, cold cache</p>\n<h3 id=\"CPU-scheduler\"><a href=\"#CPU-scheduler\" class=\"headerlink\" title=\"CPU scheduler\"></a>CPU scheduler</h3><p>OS must </p>\n<ul>\n<li>preempt</li>\n<li>schedule</li>\n<li>dispatch</li>\n</ul>\n<h3 id=\"Multi-Processes\"><a href=\"#Multi-Processes\" class=\"headerlink\" title=\"Multi Processes\"></a>Multi Processes</h3><p>P1(web server), P2(Database)</p>\n<p>Inter - process communication (IPC) : </p>\n<ul>\n<li>Message - passing IPC</li>\n</ul>\n<ul>\n<li>Shared memory IPC</li>\n</ul>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"Operating-System\"><a href=\"#Operating-System\" class=\"headerlink\" title=\"Operating System\"></a>Operating System</h1><p>This is the note or keywords of a course in udacity.</p>\n<h2 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h2><ul>\n<li>Processes and process management</li>\n<li>Threads and concurrency</li>\n<li>resource management</li>\n<li>OS services</li>\n<li>OS support for distributed services</li>\n<li>Data cendter and cloud</li>\n</ul>\n<h2 id=\"Introduction\"><a href=\"#Introduction\" class=\"headerlink\" title=\"Introduction\"></a>Introduction</h2><h3 id=\"OS-Elements\"><a href=\"#OS-Elements\" class=\"headerlink\" title=\"OS Elements\"></a>OS Elements</h3><p>Abstractions</p>\n<ul>\n<li>Process, thread, file, socket, memory pape</li>\n</ul>\n<p>Mechanisms</p>\n<ul>\n<li>Create, schedule, open, write, allocate</li>\n</ul>\n<p>Policies</p>\n<ul>\n<li>Least - recently used (LRU) etc.</li>\n</ul>\n<h3 id=\"System-call\"><a href=\"#System-call\" class=\"headerlink\" title=\"System call\"></a>System call</h3><p>Two ways for a user process to execute a priviledged call.</p>\n<ul>\n<li>User process calls hardware directly, and that will cause a trap, the kernel check if it is legal</li>\n<li>User process executes system call.</li>\n</ul>\n<p>user/kernel transitions are not cheap!</p>\n<h3 id=\"OS-services\"><a href=\"#OS-services\" class=\"headerlink\" title=\"OS services\"></a>OS services</h3><ul>\n<li>Scheduler =&gt; CPU</li>\n<li>Mem manager</li>\n<li>Block device driver</li>\n<li>file system</li>\n<li></li>\n</ul>\n<h3 id=\"Linux-Architecture\"><a href=\"#Linux-Architecture\" class=\"headerlink\" title=\"Linux Architecture\"></a>Linux Architecture</h3><p>User interface : <strong>Users</strong> &lt;= user mode</p>\n<p>Library interface : <strong>Standards utility programs</strong> (shell, editor, compilors) &lt;= user mode</p>\n<p>System call interface : <strong>Standard licrary</strong> (open, close, read, write, fork) &lt;= user mode</p>\n<p><strong>Linux operating system</strong> &lt;= kernel mode</p>\n<p><strong>Hardware</strong></p>\n<h2 id=\"Processes-and-Process-Management\"><a href=\"#Processes-and-Process-Management\" class=\"headerlink\" title=\"Processes and Process Management\"></a>Processes and Process Management</h2><p>A process:</p>\n<ul>\n<li>state of execution<ul>\n<li>Program counter</li>\n<li>stack</li>\n</ul>\n</li>\n<li>parts and temporary holding area<ul>\n<li>Data, register</li>\n</ul>\n</li>\n<li>May require special hardware<ul>\n<li>IO devices</li>\n</ul>\n</li>\n</ul>\n<p>Process == state of a program when executing.</p>\n<h3 id=\"Process-Control-Block-PCB\"><a href=\"#Process-Control-Block-PCB\" class=\"headerlink\" title=\"Process Control Block (PCB)\"></a>Process Control Block (PCB)</h3><p>a data structure storing status of a process</p>\n<ul>\n<li>PCB created when process is created</li>\n<li>Certain filds are updated when process state changes</li>\n<li>other fields change too frequently</li>\n</ul>\n<h3 id=\"Context-switch\"><a href=\"#Context-switch\" class=\"headerlink\" title=\"Context switch\"></a>Context switch</h3><p>Hot cache, cold cache</p>\n<h3 id=\"CPU-scheduler\"><a href=\"#CPU-scheduler\" class=\"headerlink\" title=\"CPU scheduler\"></a>CPU scheduler</h3><p>OS must </p>\n<ul>\n<li>preempt</li>\n<li>schedule</li>\n<li>dispatch</li>\n</ul>\n<h3 id=\"Multi-Processes\"><a href=\"#Multi-Processes\" class=\"headerlink\" title=\"Multi Processes\"></a>Multi Processes</h3><p>P1(web server), P2(Database)</p>\n<p>Inter - process communication (IPC) : </p>\n<ul>\n<li>Message - passing IPC</li>\n</ul>\n<ul>\n<li>Shared memory IPC</li>\n</ul>\n"},{"title":" QuadTree","date":"2016-12-13T10:45:37.000Z","_content":"\nECP\n\n\n\n \n\n```Python\n# =_=\n\"\"\"\n3-------2       \n|       |\n|       |\n|       |\n0-------1\n\n=>\n3---7---2\n|   |   |\n8---4---6\n|   |   |\n0---5---1\n\n=>\n...\n\"\"\"\n```\n\nO(logn)\n\n\n\npythonparaview= =\n\n![QTree](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/QTree.png?imageMogr2/thumbnail/!50p)\n\n","source":"_posts/QuadTree.md","raw":"---\ntitle:  QuadTree\ndate: 2016-12-13 18:45:37\ncategories: [programming]\ntags: [algo, data-structure]\n---\n\nECP\n\n\n\n \n\n```Python\n# =_=\n\"\"\"\n3-------2       \n|       |\n|       |\n|       |\n0-------1\n\n=>\n3---7---2\n|   |   |\n8---4---6\n|   |   |\n0---5---1\n\n=>\n...\n\"\"\"\n```\n\nO(logn)\n\n\n\npythonparaview= =\n\n![QTree](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/QTree.png?imageMogr2/thumbnail/!50p)\n\n","slug":"QuadTree","published":1,"updated":"2020-11-03T03:26:02.624Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpd001fgwtlc4g6f3la","content":"<p>ECP</p>\n<p></p>\n<p> </p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># =_=</span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br><span class=\"line\"><span class=\"string\">3-------2       </span></span><br><span class=\"line\"><span class=\"string\">|       |</span></span><br><span class=\"line\"><span class=\"string\">|       |</span></span><br><span class=\"line\"><span class=\"string\">|       |</span></span><br><span class=\"line\"><span class=\"string\">0-------1</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">=&gt;</span></span><br><span class=\"line\"><span class=\"string\">3---7---2</span></span><br><span class=\"line\"><span class=\"string\">|   |   |</span></span><br><span class=\"line\"><span class=\"string\">8---4---6</span></span><br><span class=\"line\"><span class=\"string\">|   |   |</span></span><br><span class=\"line\"><span class=\"string\">0---5---1</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">=&gt;</span></span><br><span class=\"line\"><span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"string\">\"\"\"</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p>O(logn)</p>\n<p>pythonparaview= =</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/QTree.png?imageMogr2/thumbnail/!50p\" alt=\"QTree\"></p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>ECP</p>\n<p></p>\n<p> </p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># =_=</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br><span class=\"line\"><span class=\"string\">3-------2       </span></span><br><span class=\"line\"><span class=\"string\">|       |</span></span><br><span class=\"line\"><span class=\"string\">|       |</span></span><br><span class=\"line\"><span class=\"string\">|       |</span></span><br><span class=\"line\"><span class=\"string\">0-------1</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">=&gt;</span></span><br><span class=\"line\"><span class=\"string\">3---7---2</span></span><br><span class=\"line\"><span class=\"string\">|   |   |</span></span><br><span class=\"line\"><span class=\"string\">8---4---6</span></span><br><span class=\"line\"><span class=\"string\">|   |   |</span></span><br><span class=\"line\"><span class=\"string\">0---5---1</span></span><br><span class=\"line\"><span class=\"string\"></span></span><br><span class=\"line\"><span class=\"string\">=&gt;</span></span><br><span class=\"line\"><span class=\"string\">...</span></span><br><span class=\"line\"><span class=\"string\">&quot;&quot;&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>O(logn)</p>\n<p>pythonparaview= =</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/QTree.png?imageMogr2/thumbnail/!50p\" alt=\"QTree\"></p>\n"},{"title":"Sobolev space","date":"2017-02-11T06:37:53.000Z","_content":"\n#  Sobolev space\n\n## \n\nwiki\n\n>p  1fkLp\n\nC1(11)\n\n## \n\n$$\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p\n$$\n\n$W^{k,p}$\n\n## $H^k$\n\n\n$$\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}\n$$\n\n\n$$\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}\n$$\n","source":"_posts/Sobolev-space.md","raw":"---\ntitle: Sobolev space\ndate: 2017-02-11 14:37:53\ncategories: [math, unfinished]\ntags: [Sobolev, analyse, math, EDP]\n---\n\n#  Sobolev space\n\n## \n\nwiki\n\n>p  1fkLp\n\nC1(11)\n\n## \n\n$$\n||f||_{k,p} = (\\sum_{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\\\\n=||f^{(i)}||_p +||f||_p\n$$\n\n$W^{k,p}$\n\n## $H^k$\n\n\n$$\nH^k = W^{k,2} \\\\\nH^1(\\Omega) := \\{ v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d \\} \\\\ \\\\\n(.,.)_{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)_{L^2} +(\\nabla u,\\nabla v)_{L^2} \\\\\n\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum_{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}\n$$\n\n\n$$\n||.||_{H^1}: v \\mapsto \\sqrt{||v||_{L^2}^2+||\\nabla v||_{L^2}^2} \\\\\n|.|_{H^1(\\Omega)} := ||\\nabla .||_{L^2(\\Omega)} \\\\\n||.||_{H_0^1} := |.|_{H^1}\n$$\n","slug":"Sobolev-space","published":1,"updated":"2017-02-11T16:48:47.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpe001jgwtl4fjl5y7q","content":"<h1 id=\"-Sobolev-space\"><a href=\"#-Sobolev-space\" class=\"headerlink\" title=\" Sobolev space\"></a> Sobolev space</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>wiki</p>\n<blockquote>\n<p>p  1fkLp</p>\n</blockquote>\n<p>C1(11)</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$$<br>||f||<em>{k,p} = (\\sum</em>{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\<br>=||f^{(i)}||_p +||f||_p<br>$$</p>\n<p>$W^{k,p}$</p>\n<h2 id=\"H-k\"><a href=\"#H-k\" class=\"headerlink\" title=\"$H^k$\"></a>$H^k$</h2><p><br>$$<br>H^k = W^{k,2} \\<br>H^1(\\Omega) := { v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d } \\ \\<br>(.,.)<em>{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)</em>{L^2} +(\\nabla u,\\nabla v)<em>{L^2} \\<br>\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum</em>{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}<br>$$</p>\n<p><br>$$<br>||.||<em>{H^1}: v \\mapsto \\sqrt{||v||</em>{L^2}^2+||\\nabla v||<em>{L^2}^2} \\<br>|.|</em>{H^1(\\Omega)} := ||\\nabla .||<em>{L^2(\\Omega)} \\<br>||.||</em>{H_0^1} := |.|_{H^1}<br>$$</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"-Sobolev-space\"><a href=\"#-Sobolev-space\" class=\"headerlink\" title=\" Sobolev space\"></a> Sobolev space</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>wiki</p>\n<blockquote>\n<p>p  1fkLp</p>\n</blockquote>\n<p>C1(11)</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>$$<br>||f||<em>{k,p} = (\\sum</em>{i=0}^k{||f^{(i)}||_p^p})^{1/p} \\<br>=||f^{(i)}||_p +||f||_p<br>$$</p>\n<p>$W^{k,p}$</p>\n<h2 id=\"H-k\"><a href=\"#H-k\" class=\"headerlink\" title=\"$H^k$\"></a>$H^k$</h2><p><br>$$<br>H^k = W^{k,2} \\<br>H^1(\\Omega) := { v\\in L^2(\\Omega) : \\nabla v \\in (L^2(\\Omega))^d } \\ \\<br>(.,.)<em>{H^1} : (u,v) \\in H^1 \\times H^1 \\mapsto (u,v)</em>{L^2} +(\\nabla u,\\nabla v)<em>{L^2} \\<br>\\qquad \\qquad \\qquad = \\int_\\Omega {uv} + \\sum</em>{i=1}^d{\\int_ \\Omega {\\partial_{x_i}{u} \\partial_{x_i}{v}}}<br>$$</p>\n<p><br>$$<br>||.||<em>{H^1}: v \\mapsto \\sqrt{||v||</em>{L^2}^2+||\\nabla v||<em>{L^2}^2} \\<br>|.|</em>{H^1(\\Omega)} := ||\\nabla .||<em>{L^2(\\Omega)} \\<br>||.||</em>{H_0^1} := |.|_{H^1}<br>$$</p>\n"},{"title":" Entity resolution","date":"2017-12-10T00:00:00.000Z","_content":"\n## 1. Entity resolution\n\n###1.1 Sequence labeling\n\nMLNamed Entity RecognitionSequence labelingnlpsequence labelingRNN-CRF\n\n- Embedding layer\n- Bi-directional RNN (usually LSTM) layer\n- Tanh hidden layer\n- CRF layer\n\nsequence labelingnamed entity recognitionevent recognitionseq labeling\n\n#### 1.1.1 Attention \n\n> [1] RNN-CRF  attention  attention \n>\n> [2] BiLSTM-CRF  attention \n>\n>                        from paperweekly\n\n#### 1.1.2  \n\n\n\n- [Deep Active Learning for Named Entity Recognition](https://openreview.net/forum?id=ry018WZAZ)[7]\n\n  ICLR 2018paperactive learningCNN-CNN-LSTMNERseq labeling25%state-of-the-art\n\n  paperseq labelingdecoderLSTMCRFLSTMCRFactive learningseq labeling\n\n- Semi-supervised sequence tagging with bidirectional language models[4]\n\n  LM embedding RNN-CRF \n\n   NER  RNN-CRF \n\n### 1.2 Relation extraction\n\npipeline\n\npipelineentity\n\n[9]LSTM-RNNword sequencebidirectional sequential LSTM-RNNsTree Structures bidirectional tree- structured LSTM-RNNs\n\n![LSTM-RNNs](https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg)\n\npaperjoint\n\n[7] encoder-decoder  bi-lstm  encoderlstm  decoder BIEM++pipeline F1  0.5\n\nsoftmax\n\n## 2. Others\n\n\n\n1. Ngram2vec[5]\n\n    word2vec  ngram [https://github.com/zhezhaoa/ngram2vec/](http://link.zhihu.com/?target=https%3A//github.com/zhezhaoa/ngram2vec/)\n\n2. [AutoML](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html)\n\n   googlereinforcement learning\n\n3. Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]\n\n   meta learning4mnistconv netpretrained\n\n## Reference\n\n[1] Rei, M., Crichton, G. K., & Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. *arXiv preprint arXiv:1611.04361*.\n\n[2] Mortensen, A. B. D., & Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.\n\n[3] Yang, Z., Salakhutdinov, R., & Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. *arXiv preprint arXiv:1703.06345*.\n\n[4] Peters, M. E., Ammar, W., Bhagavatula, C., & Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. *arXiv preprint arXiv:1705.00108*.\n\n[5] Zhao, Z., Liu, T., Li, S., Li, B., & Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In *Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing* (pp. 244-253).\n\n[6] Sinha, A., Sarkar, M., Mukherjee, A., & Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. *arXiv preprint arXiv:1704.04959*.\n\n[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, & Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.\n\n[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., & Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. *arXiv preprint arXiv:1706.05075*.\n\n[9] Miwa, M., & Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. *arXiv preprint arXiv:1601.00770*.","source":"_posts/[2017.12.10]Entity-resolution.md","raw":"---\ntitle:  Entity resolution\ndate: 2017-12-10 08:00:00\ncategories: [research]\ntags: [entity-resolution, sequence-labeling, relation-extraction, LSTM, RNN]\n---\n\n## 1. Entity resolution\n\n###1.1 Sequence labeling\n\nMLNamed Entity RecognitionSequence labelingnlpsequence labelingRNN-CRF\n\n- Embedding layer\n- Bi-directional RNN (usually LSTM) layer\n- Tanh hidden layer\n- CRF layer\n\nsequence labelingnamed entity recognitionevent recognitionseq labeling\n\n#### 1.1.1 Attention \n\n> [1] RNN-CRF  attention  attention \n>\n> [2] BiLSTM-CRF  attention \n>\n>                        from paperweekly\n\n#### 1.1.2  \n\n\n\n- [Deep Active Learning for Named Entity Recognition](https://openreview.net/forum?id=ry018WZAZ)[7]\n\n  ICLR 2018paperactive learningCNN-CNN-LSTMNERseq labeling25%state-of-the-art\n\n  paperseq labelingdecoderLSTMCRFLSTMCRFactive learningseq labeling\n\n- Semi-supervised sequence tagging with bidirectional language models[4]\n\n  LM embedding RNN-CRF \n\n   NER  RNN-CRF \n\n### 1.2 Relation extraction\n\npipeline\n\npipelineentity\n\n[9]LSTM-RNNword sequencebidirectional sequential LSTM-RNNsTree Structures bidirectional tree- structured LSTM-RNNs\n\n![LSTM-RNNs](https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg)\n\npaperjoint\n\n[7] encoder-decoder  bi-lstm  encoderlstm  decoder BIEM++pipeline F1  0.5\n\nsoftmax\n\n## 2. Others\n\n\n\n1. Ngram2vec[5]\n\n    word2vec  ngram [https://github.com/zhezhaoa/ngram2vec/](http://link.zhihu.com/?target=https%3A//github.com/zhezhaoa/ngram2vec/)\n\n2. [AutoML](https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html)\n\n   googlereinforcement learning\n\n3. Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]\n\n   meta learning4mnistconv netpretrained\n\n## Reference\n\n[1] Rei, M., Crichton, G. K., & Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. *arXiv preprint arXiv:1611.04361*.\n\n[2] Mortensen, A. B. D., & Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.\n\n[3] Yang, Z., Salakhutdinov, R., & Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. *arXiv preprint arXiv:1703.06345*.\n\n[4] Peters, M. E., Ammar, W., Bhagavatula, C., & Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. *arXiv preprint arXiv:1705.00108*.\n\n[5] Zhao, Z., Liu, T., Li, S., Li, B., & Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In *Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing* (pp. 244-253).\n\n[6] Sinha, A., Sarkar, M., Mukherjee, A., & Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. *arXiv preprint arXiv:1704.04959*.\n\n[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, & Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.\n\n[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., & Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. *arXiv preprint arXiv:1706.05075*.\n\n[9] Miwa, M., & Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. *arXiv preprint arXiv:1601.00770*.","slug":"[2017.12.10]Entity-resolution","published":1,"updated":"2018-01-27T11:07:30.140Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpf001ngwtlek9x1j7n","content":"<h2 id=\"1-Entity-resolution\"><a href=\"#1-Entity-resolution\" class=\"headerlink\" title=\"1. Entity resolution\"></a>1. Entity resolution</h2><p>###1.1 Sequence labeling</p>\n<p>MLNamed Entity RecognitionSequence labelingnlpsequence labelingRNN-CRF</p>\n<ul>\n<li>Embedding layer</li>\n<li>Bi-directional RNN (usually LSTM) layer</li>\n<li>Tanh hidden layer</li>\n<li>CRF layer</li>\n</ul>\n<p>sequence labelingnamed entity recognitionevent recognitionseq labeling</p>\n<h4 id=\"1-1-1-Attention\"><a href=\"#1-1-1-Attention\" class=\"headerlink\" title=\"1.1.1 Attention\"></a>1.1.1 Attention</h4><blockquote>\n<p>[1] RNN-CRF  attention  attention </p>\n<p>[2] BiLSTM-CRF  attention </p>\n<p>                       from paperweekly</p>\n</blockquote>\n<h4 id=\"1-1-2-\"><a href=\"#1-1-2-\" class=\"headerlink\" title=\"1.1.2 \"></a>1.1.2 </h4><p></p>\n<ul>\n<li><p><a href=\"https://openreview.net/forum?id=ry018WZAZ\">Deep Active Learning for Named Entity Recognition</a>[7]</p>\n<p>ICLR 2018paperactive learningCNN-CNN-LSTMNERseq labeling25%state-of-the-art</p>\n<p>paperseq labelingdecoderLSTMCRFLSTMCRFactive learningseq labeling</p>\n</li>\n<li><p>Semi-supervised sequence tagging with bidirectional language models[4]</p>\n<p>LM embedding RNN-CRF </p>\n<p> NER  RNN-CRF </p>\n</li>\n</ul>\n<h3 id=\"1-2-Relation-extraction\"><a href=\"#1-2-Relation-extraction\" class=\"headerlink\" title=\"1.2 Relation extraction\"></a>1.2 Relation extraction</h3><p>pipeline</p>\n<p>pipelineentity</p>\n<p>[9]LSTM-RNNword sequencebidirectional sequential LSTM-RNNsTree Structures bidirectional tree- structured LSTM-RNNs</p>\n<p><img src=\"https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg\" alt=\"LSTM-RNNs\"></p>\n<p>paperjoint</p>\n<p>[7] encoder-decoder  bi-lstm  encoderlstm  decoder BIEM++pipeline F1  0.5</p>\n<p>softmax</p>\n<h2 id=\"2-Others\"><a href=\"#2-Others\" class=\"headerlink\" title=\"2. Others\"></a>2. Others</h2><p></p>\n<ol>\n<li><p>Ngram2vec[5]</p>\n<p> word2vec  ngram <a href=\"http://link.zhihu.com/?target=https://github.com/zhezhaoa/ngram2vec/\">https://github.com/zhezhaoa/ngram2vec/</a></p>\n</li>\n<li><p><a href=\"https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html\">AutoML</a></p>\n<p>googlereinforcement learning</p>\n</li>\n<li><p>Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]</p>\n<p>meta learning4mnistconv netpretrained</p>\n</li>\n</ol>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] Rei, M., Crichton, G. K., &amp; Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. <em>arXiv preprint arXiv:1611.04361</em>.</p>\n<p>[2] Mortensen, A. B. D., &amp; Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.</p>\n<p>[3] Yang, Z., Salakhutdinov, R., &amp; Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. <em>arXiv preprint arXiv:1703.06345</em>.</p>\n<p>[4] Peters, M. E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. <em>arXiv preprint arXiv:1705.00108</em>.</p>\n<p>[5] Zhao, Z., Liu, T., Li, S., Li, B., &amp; Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In <em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em> (pp. 244-253).</p>\n<p>[6] Sinha, A., Sarkar, M., Mukherjee, A., &amp; Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. <em>arXiv preprint arXiv:1704.04959</em>.</p>\n<p>[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, &amp; Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.</p>\n<p>[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., &amp; Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. <em>arXiv preprint arXiv:1706.05075</em>.</p>\n<p>[9] Miwa, M., &amp; Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. <em>arXiv preprint arXiv:1601.00770</em>.</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"1-Entity-resolution\"><a href=\"#1-Entity-resolution\" class=\"headerlink\" title=\"1. Entity resolution\"></a>1. Entity resolution</h2><p>###1.1 Sequence labeling</p>\n<p>MLNamed Entity RecognitionSequence labelingnlpsequence labelingRNN-CRF</p>\n<ul>\n<li>Embedding layer</li>\n<li>Bi-directional RNN (usually LSTM) layer</li>\n<li>Tanh hidden layer</li>\n<li>CRF layer</li>\n</ul>\n<p>sequence labelingnamed entity recognitionevent recognitionseq labeling</p>\n<h4 id=\"1-1-1-Attention\"><a href=\"#1-1-1-Attention\" class=\"headerlink\" title=\"1.1.1 Attention\"></a>1.1.1 Attention</h4><blockquote>\n<p>[1] RNN-CRF  attention  attention </p>\n<p>[2] BiLSTM-CRF  attention </p>\n<p>                       from paperweekly</p>\n</blockquote>\n<h4 id=\"1-1-2-\"><a href=\"#1-1-2-\" class=\"headerlink\" title=\"1.1.2 \"></a>1.1.2 </h4><p></p>\n<ul>\n<li><p><a href=\"https://openreview.net/forum?id=ry018WZAZ\">Deep Active Learning for Named Entity Recognition</a>[7]</p>\n<p>ICLR 2018paperactive learningCNN-CNN-LSTMNERseq labeling25%state-of-the-art</p>\n<p>paperseq labelingdecoderLSTMCRFLSTMCRFactive learningseq labeling</p>\n</li>\n<li><p>Semi-supervised sequence tagging with bidirectional language models[4]</p>\n<p>LM embedding RNN-CRF </p>\n<p> NER  RNN-CRF </p>\n</li>\n</ul>\n<h3 id=\"1-2-Relation-extraction\"><a href=\"#1-2-Relation-extraction\" class=\"headerlink\" title=\"1.2 Relation extraction\"></a>1.2 Relation extraction</h3><p>pipeline</p>\n<p>pipelineentity</p>\n<p>[9]LSTM-RNNword sequencebidirectional sequential LSTM-RNNsTree Structures bidirectional tree- structured LSTM-RNNs</p>\n<p><img src=\"https://pic3.zhimg.com/v2-8a44b362fb60fff951dbfaa2bc4469f3_r.jpg\" alt=\"LSTM-RNNs\"></p>\n<p>paperjoint</p>\n<p>[7] encoder-decoder  bi-lstm  encoderlstm  decoder BIEM++pipeline F1  0.5</p>\n<p>softmax</p>\n<h2 id=\"2-Others\"><a href=\"#2-Others\" class=\"headerlink\" title=\"2. Others\"></a>2. Others</h2><p></p>\n<ol>\n<li><p>Ngram2vec[5]</p>\n<p> word2vec  ngram <a href=\"http://link.zhihu.com/?target=https://github.com/zhezhaoa/ngram2vec/\">https://github.com/zhezhaoa/ngram2vec/</a></p>\n</li>\n<li><p><a href=\"https://research.googleblog.com/2017/05/using-machine-learning-to-explore.html\">AutoML</a></p>\n<p>googlereinforcement learning</p>\n</li>\n<li><p>Introspection:Accelerating Neural Network Training By Learning Weight Evolution[6]</p>\n<p>meta learning4mnistconv netpretrained</p>\n</li>\n</ol>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>[1] Rei, M., Crichton, G. K., &amp; Pyysalo, S. (2016). Attending to Characters in Neural Sequence Labeling Models. <em>arXiv preprint arXiv:1611.04361</em>.</p>\n<p>[2] Mortensen, A. B. D., &amp; Carbonell, C. D. J. G. (2016). Phonologically aware neural model for named entity recognition in low resource transfer settings.</p>\n<p>[3] Yang, Z., Salakhutdinov, R., &amp; Cohen, W. W. (2017). Transfer learning for sequence tagging with hierarchical recurrent networks. <em>arXiv preprint arXiv:1703.06345</em>.</p>\n<p>[4] Peters, M. E., Ammar, W., Bhagavatula, C., &amp; Power, R. (2017). Semi-supervised sequence tagging with bidirectional language models. <em>arXiv preprint arXiv:1705.00108</em>.</p>\n<p>[5] Zhao, Z., Liu, T., Li, S., Li, B., &amp; Du, X. (2017). Ngram2vec: Learning Improved Word Representations from Ngram Co-occurrence Statistics. In <em>Proceedings of the 2017 Conference on Empirical Methods in Natural Language Processing</em> (pp. 244-253).</p>\n<p>[6] Sinha, A., Sarkar, M., Mukherjee, A., &amp; Krishnamurthy, B. (2017). Introspection: Accelerating Neural Network Training By Learning Weight Evolution. <em>arXiv preprint arXiv:1704.04959</em>.</p>\n<p>[7] Shen, Yanyao, Yun, Hyokun, Lipton, Zachary C, Kronrod, Yakov, &amp; Anandkumar, Animashree. (2017). Deep active learning for named entity recognition.</p>\n<p>[8] Zheng, S., Wang, F., Bao, H., Hao, Y., Zhou, P., &amp; Xu, B. (2017). Joint Extraction of Entities and Relations Based on a Novel Tagging Scheme. <em>arXiv preprint arXiv:1706.05075</em>.</p>\n<p>[9] Miwa, M., &amp; Bansal, M. (2016). End-to-end relation extraction using lstms on sequences and tree structures. <em>arXiv preprint arXiv:1601.00770</em>.</p>\n"},{"title":" relation extraction ","date":"2018-01-14T00:00:00.000Z","_content":"\n##  relation extraction \n\n****Distant supervision relation extraction [1] dynamic-transition matrix distant supervision  relation extraction [2]negative pattern[3] relation extraction  Multi-instance Multi-label \n\n### 1. Problem of distant supervision\n\nDistant supervision  \\<e1, r, e2\\> \\<subj, r, obj\\> e1  e2  r \n\n\\<DonaldTrump, born-in, New York\\>Donald Trump was born in New YorkDonaldTrump worked in New Yorkborn-in\n\n### 2. Approaches to this problems\n\n-  \n  - dynamic-transition matrix [1]\n-  \n  - [2]\n  - Multi-instance learning[3],  attention  at-least-one-assumption\n\n\n\n#### 2.1 Learning with dynamic-transition matrix [1]\n\n[1]  dynamic-transition matrix Distant supervision dynamic-transition matrix  curriculum learning  relation extraction  state-of-the-art\n\n![overview](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202153.jpg)\n\nTransition matrix T n*nnT $T_{ij}$ p( j| i ) i j \n\n    = \n\npredicted observed  timeRE  entityRE(NYT)  state-of-art\n\n#### 2.2 Reducing Wrong Labels [2] \n\nFreebase      \n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202150.jpg\" width=\"70%\">\n\nNegPat(r)rnegative patternirelationiiNegPat relation DS 1\n\n####2.3 Multi-instance Multi-label Learning [3]\n\n entities  entities  born in is the president of \n\n\n\n Multi-instance Multi-label   relation extraction \n\n### 3. Conclusion \n\n[1] relation extraction \n\n## References\n\n\\*[ | Learning with Noise: Supervised Relation Extraction](https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg)\n\n[1] Luo, Bingfeng, et al. \"Learning with noise: enhance distantly supervised relation extraction with dynamic transition matrix.\" *arXiv preprint arXiv:1705.03995* (2017).\n\n[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. \"Reducing wrong labels in distant supervision for relation extraction.\" *Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1*. Association for Computational Linguistics, 2012.\n\n[3] Surdeanu, Mihai, et al. \"Multi-instance multi-label learning for relation extraction.\" *Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning*. Association for Computational Linguistics, 2012.","source":"_posts/[2018.1.14]Models-for-relation-extraction.md","raw":"---\ntitle:  relation extraction \ndate: 2018-01-14 08:00:00\ncategories: [research]\ntags: [relation-extraction, distant-supervision]\n---\n\n##  relation extraction \n\n****Distant supervision relation extraction [1] dynamic-transition matrix distant supervision  relation extraction [2]negative pattern[3] relation extraction  Multi-instance Multi-label \n\n### 1. Problem of distant supervision\n\nDistant supervision  \\<e1, r, e2\\> \\<subj, r, obj\\> e1  e2  r \n\n\\<DonaldTrump, born-in, New York\\>Donald Trump was born in New YorkDonaldTrump worked in New Yorkborn-in\n\n### 2. Approaches to this problems\n\n-  \n  - dynamic-transition matrix [1]\n-  \n  - [2]\n  - Multi-instance learning[3],  attention  at-least-one-assumption\n\n\n\n#### 2.1 Learning with dynamic-transition matrix [1]\n\n[1]  dynamic-transition matrix Distant supervision dynamic-transition matrix  curriculum learning  relation extraction  state-of-the-art\n\n![overview](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202153.jpg)\n\nTransition matrix T n*nnT $T_{ij}$ p( j| i ) i j \n\n    = \n\npredicted observed  timeRE  entityRE(NYT)  state-of-art\n\n#### 2.2 Reducing Wrong Labels [2] \n\nFreebase      \n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202150.jpg\" width=\"70%\">\n\nNegPat(r)rnegative patternirelationiiNegPat relation DS 1\n\n####2.3 Multi-instance Multi-label Learning [3]\n\n entities  entities  born in is the president of \n\n\n\n Multi-instance Multi-label   relation extraction \n\n### 3. Conclusion \n\n[1] relation extraction \n\n## References\n\n\\*[ | Learning with Noise: Supervised Relation Extraction](https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg)\n\n[1] Luo, Bingfeng, et al. \"Learning with noise: enhance distantly supervised relation extraction with dynamic transition matrix.\" *arXiv preprint arXiv:1705.03995* (2017).\n\n[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. \"Reducing wrong labels in distant supervision for relation extraction.\" *Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1*. Association for Computational Linguistics, 2012.\n\n[3] Surdeanu, Mihai, et al. \"Multi-instance multi-label learning for relation extraction.\" *Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning*. Association for Computational Linguistics, 2012.","slug":"[2018.1.14]Models-for-relation-extraction","published":1,"updated":"2020-11-03T03:26:13.796Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufph001qgwtldfrq166l","content":"<h2 id=\"-relation-extraction-\"><a href=\"#-relation-extraction-\" class=\"headerlink\" title=\" relation extraction \"></a> relation extraction </h2><p><strong></strong>Distant supervision relation extraction [1] dynamic-transition matrix distant supervision  relation extraction [2]negative pattern[3] relation extraction  Multi-instance Multi-label </p>\n<h3 id=\"1-Problem-of-distant-supervision\"><a href=\"#1-Problem-of-distant-supervision\" class=\"headerlink\" title=\"1. Problem of distant supervision\"></a>1. Problem of distant supervision</h3><p>Distant supervision  &lt;e1, r, e2&gt; &lt;subj, r, obj&gt; e1  e2  r </p>\n<p>&lt;DonaldTrump, born-in, New York&gt;Donald Trump was born in New YorkDonaldTrump worked in New Yorkborn-in</p>\n<h3 id=\"2-Approaches-to-this-problems\"><a href=\"#2-Approaches-to-this-problems\" class=\"headerlink\" title=\"2. Approaches to this problems\"></a>2. Approaches to this problems</h3><ul>\n<li> </li>\n<li>dynamic-transition matrix [1]</li>\n<li> </li>\n<li>[2]</li>\n<li>Multi-instance learning[3],  attention  at-least-one-assumption</li>\n</ul>\n<p></p>\n<h4 id=\"2-1-Learning-with-dynamic-transition-matrix-1\"><a href=\"#2-1-Learning-with-dynamic-transition-matrix-1\" class=\"headerlink\" title=\"2.1 Learning with dynamic-transition matrix [1]\"></a>2.1 Learning with dynamic-transition matrix [1]</h4><p>[1]  dynamic-transition matrix Distant supervision dynamic-transition matrix  curriculum learning  relation extraction  state-of-the-art</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202153.jpg\" alt=\"overview\"></p>\n<p>Transition matrix T n*nnT $T_{ij}$ p( j| i ) i j </p>\n<p>    = </p>\n<p>predicted observed  timeRE  entityRE(NYT)  state-of-art</p>\n<h4 id=\"2-2-Reducing-Wrong-Labels-2\"><a href=\"#2-2-Reducing-Wrong-Labels-2\" class=\"headerlink\" title=\"2.2 Reducing Wrong Labels [2]\"></a>2.2 Reducing Wrong Labels [2]</h4><p>Freebase      </p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202150.jpg\" width=\"70%\">\n\n<p>NegPat(r)rnegative patternirelationiiNegPat relation DS 1</p>\n<p>####2.3 Multi-instance Multi-label Learning [3]</p>\n<p> entities  entities  born in is the president of </p>\n<p></p>\n<p> Multi-instance Multi-label   relation extraction </p>\n<h3 id=\"3-Conclusion\"><a href=\"#3-Conclusion\" class=\"headerlink\" title=\"3. Conclusion\"></a>3. Conclusion</h3><p>[1] relation extraction </p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p>*<a href=\"https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg\"> | Learning with Noise: Supervised Relation Extraction</a></p>\n<p>[1] Luo, Bingfeng, et al. Learning with noise: enhance distantly supervised relation extraction with dynamic transition matrix. <em>arXiv preprint arXiv:1705.03995</em> (2017).</p>\n<p>[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. Reducing wrong labels in distant supervision for relation extraction. <em>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1</em>. Association for Computational Linguistics, 2012.</p>\n<p>[3] Surdeanu, Mihai, et al. Multi-instance multi-label learning for relation extraction. <em>Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</em>. Association for Computational Linguistics, 2012.</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"-relation-extraction-\"><a href=\"#-relation-extraction-\" class=\"headerlink\" title=\" relation extraction \"></a> relation extraction </h2><p><strong></strong>Distant supervision relation extraction [1] dynamic-transition matrix distant supervision  relation extraction [2]negative pattern[3] relation extraction  Multi-instance Multi-label </p>\n<h3 id=\"1-Problem-of-distant-supervision\"><a href=\"#1-Problem-of-distant-supervision\" class=\"headerlink\" title=\"1. Problem of distant supervision\"></a>1. Problem of distant supervision</h3><p>Distant supervision  &lt;e1, r, e2&gt; &lt;subj, r, obj&gt; e1  e2  r </p>\n<p>&lt;DonaldTrump, born-in, New York&gt;Donald Trump was born in New YorkDonaldTrump worked in New Yorkborn-in</p>\n<h3 id=\"2-Approaches-to-this-problems\"><a href=\"#2-Approaches-to-this-problems\" class=\"headerlink\" title=\"2. Approaches to this problems\"></a>2. Approaches to this problems</h3><ul>\n<li> </li>\n<li>dynamic-transition matrix [1]</li>\n<li> </li>\n<li>[2]</li>\n<li>Multi-instance learning[3],  attention  at-least-one-assumption</li>\n</ul>\n<p></p>\n<h4 id=\"2-1-Learning-with-dynamic-transition-matrix-1\"><a href=\"#2-1-Learning-with-dynamic-transition-matrix-1\" class=\"headerlink\" title=\"2.1 Learning with dynamic-transition matrix [1]\"></a>2.1 Learning with dynamic-transition matrix [1]</h4><p>[1]  dynamic-transition matrix Distant supervision dynamic-transition matrix  curriculum learning  relation extraction  state-of-the-art</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202153.jpg\" alt=\"overview\"></p>\n<p>Transition matrix T n*nnT $T_{ij}$ p( j| i ) i j </p>\n<p>    = </p>\n<p>predicted observed  timeRE  entityRE(NYT)  state-of-art</p>\n<h4 id=\"2-2-Reducing-Wrong-Labels-2\"><a href=\"#2-2-Reducing-Wrong-Labels-2\" class=\"headerlink\" title=\"2.2 Reducing Wrong Labels [2]\"></a>2.2 Reducing Wrong Labels [2]</h4><p>Freebase      </p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202150.jpg\" width=\"70%\">\n\n<p>NegPat(r)rnegative patternirelationiiNegPat relation DS 1</p>\n<p>####2.3 Multi-instance Multi-label Learning [3]</p>\n<p> entities  entities  born in is the president of </p>\n<p></p>\n<p> Multi-instance Multi-label   relation extraction </p>\n<h3 id=\"3-Conclusion\"><a href=\"#3-Conclusion\" class=\"headerlink\" title=\"3. Conclusion\"></a>3. Conclusion</h3><p>[1] relation extraction </p>\n<h2 id=\"References\"><a href=\"#References\" class=\"headerlink\" title=\"References\"></a>References</h2><p>*<a href=\"https://mp.weixin.qq.com/s/O9JaalDhoX97DMoUBFxmtg\"> | Learning with Noise: Supervised Relation Extraction</a></p>\n<p>[1] Luo, Bingfeng, et al. Learning with noise: enhance distantly supervised relation extraction with dynamic transition matrix. <em>arXiv preprint arXiv:1705.03995</em> (2017).</p>\n<p>[2] Takamatsu, Shingo, Issei Sato, and Hiroshi Nakagawa. Reducing wrong labels in distant supervision for relation extraction. <em>Proceedings of the 50th Annual Meeting of the Association for Computational Linguistics: Long Papers-Volume 1</em>. Association for Computational Linguistics, 2012.</p>\n<p>[3] Surdeanu, Mihai, et al. Multi-instance multi-label learning for relation extraction. <em>Proceedings of the 2012 joint conference on empirical methods in natural language processing and computational natural language learning</em>. Association for Computational Linguistics, 2012.</p>\n"},{"title":"Relation Classification via Attention Model ","date":"2017-12-17T00:00:00.000Z","_content":"\n## Relation Classification via Attention Model\n\n[1]Attentionattentionattention\n\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n### 1. Attention\n\n#### 1.1 \n\nAttentionNLPBahdanau[2]attentionattentionNLP\n\n#### 1.2 Recurrent Models of Visual Attention \n\nRNNattentionAttention\n\n#### 1.3 Attention-based RNN in NLP\n\n[1]EncoderDecoderSeq2seqEncoderDecoder\n\nDecoder\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201155.jpg\" width=\"30%\">\n\n[3]attentionRNN\n\n#### 1.4 Attention-based CNN in NLP\n\n[4]CNNattentioncnn3CNNattention\n\n- ABCNN-1: attentionattentionattention feature mapfeature map\n- ABCNN-2: attentionattention.\n- ABCNN-3: ABCNN-1 + ABCNN-2\n\n### 2. Relation Classification \n\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n#### \t2.1 Classification Objective\n\nL2\n$$\n\\delta_{\\theta}(S,y) = ||\\frac{w^O}{|w^O|} - W_y^L||_{L^2} \\\\\nS:\\text{Sentence}, y:\\text{Output relation}, w^O: \\text{Network output}, W^L:\\text{Relation embedding}\n$$\n\n$$\n\\mathcal{L} = [\\delta_\\theta(S,y) + (1-\\delta_\\theta(S, \\hat{y}^-))] + \\beta||\\theta||^2 \\\\\n\\hat{y}^- : \\text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\\\\n\\hat{y}^- = argmax_{y'\\in \\mathcal{Y},y'\\ne y}(\\delta(S, y'))\n$$\n$\\beta$\n\n#### 2.2 Input Representation \n\ne1,e2\n$$\nS = (w_1,w_2,...,w_n) \\\\\ne_1 := w_p, e_2 := w_t . p,t\\in [1,n], p\\ne t\n$$\nword position embeddingsiEmbedding\n$$\nw_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T\n$$\nkinput representation\n$$\nz_i = [(w_{i - (k-1)/2}^M)^T,...,(w_{i + (k-1)/2}^M)^T]^T\n$$\n\n#### 2.3 Input Attention Mechanism\n\n<img src=\"https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg\" width=\"70%\">\n\nattention$A_{i,i}^j=f(e_j,w_i)$wiej f \n$$\n\\alpha_i^j = \\frac{exp(A_{i,i}^j)}{\\sum_{i'=1}^{n}{exp(A_{i',i}^j)}}\n$$\nj=1,2 :\n\n- \n  $$\n  r_i = z_i \\frac{\\alpha_i^1 + \\alpha_i^2}{2}\n  $$\n\n- \n  $$\n  r_i = [(z_i \\alpha_i^1)^T, (z_i \\alpha_i^2)^T]^T\n  $$\n\n- \n  $$\n  r_i = z_i \\frac{\\alpha_i^1 - \\alpha_i^2}{2}\n  $$\n\n\n\n\n\n\n\n\n\n$R = [r_1, r_2,,r_n]$\n\n#### 2.4 Convolutional Max-Pooling with Secondary Attention\n\nRdc:\n$$\nR^\\star = tanh(W_fR+B_f), \\text{where the siaze of Wf is } d^c \\times k(d^w+2d^p)\n$$\nR*WL\n$$\nG = R^{\\star T}UW^L, \\\\U :\\text{weighting matrix learnt by the network}\n$$\n\nsoftmaxGattention pooling matrix Ap:\n$$\nA_{i,j}^p = \\frac{exp(G_{i,j})}{\\sum_{i'=1}^n{exp(G_{i',j})}}\n$$\nApR*attention\n$$\nw_i^O = max_j(R^\\star A^p)_{i,j}\n$$\n\n### 3. \n\n[1]attentionSem-Eval-2010 Task 8\n\n\n\n- \n- \n- \n\nAttentionpytorch[](https://github.com/lawlietAi/relation-classification-via-attention-model)\n\n## Reference\n\nhttps://zhuanlan.zhihu.com/p/22867750\n\n[1] Wang, L., Cao, Z., Melo, G. D., & Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. *Meeting of the Association for Computational Linguistics* (pp.1298-1307).\n\n[2] Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. *Computer Science*.\n\n[3] Luong, M. T., Pham, H., & Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. *Computer Science*.\n\n[4] Yin, W., Schtze, H., Xiang, B., & Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. *Computer Science*.","source":"_posts/[2017.12.17]Relation-Classification-via-Attention-Model.md","raw":"---\ntitle: Relation Classification via Attention Model \ndate: 2017-12-17 08:00:00\ncategories: [research]\ntags: [relation-classification, attention, relation-extraction]\n---\n\n## Relation Classification via Attention Model\n\n[1]Attentionattentionattention\n\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n### 1. Attention\n\n#### 1.1 \n\nAttentionNLPBahdanau[2]attentionattentionNLP\n\n#### 1.2 Recurrent Models of Visual Attention \n\nRNNattentionAttention\n\n#### 1.3 Attention-based RNN in NLP\n\n[1]EncoderDecoderSeq2seqEncoderDecoder\n\nDecoder\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201155.jpg\" width=\"30%\">\n\n[3]attentionRNN\n\n#### 1.4 Attention-based CNN in NLP\n\n[4]CNNattentioncnn3CNNattention\n\n- ABCNN-1: attentionattentionattention feature mapfeature map\n- ABCNN-2: attentionattention.\n- ABCNN-3: ABCNN-1 + ABCNN-2\n\n### 2. Relation Classification \n\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n#### \t2.1 Classification Objective\n\nL2\n$$\n\\delta_{\\theta}(S,y) = ||\\frac{w^O}{|w^O|} - W_y^L||_{L^2} \\\\\nS:\\text{Sentence}, y:\\text{Output relation}, w^O: \\text{Network output}, W^L:\\text{Relation embedding}\n$$\n\n$$\n\\mathcal{L} = [\\delta_\\theta(S,y) + (1-\\delta_\\theta(S, \\hat{y}^-))] + \\beta||\\theta||^2 \\\\\n\\hat{y}^- : \\text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\\\\n\\hat{y}^- = argmax_{y'\\in \\mathcal{Y},y'\\ne y}(\\delta(S, y'))\n$$\n$\\beta$\n\n#### 2.2 Input Representation \n\ne1,e2\n$$\nS = (w_1,w_2,...,w_n) \\\\\ne_1 := w_p, e_2 := w_t . p,t\\in [1,n], p\\ne t\n$$\nword position embeddingsiEmbedding\n$$\nw_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T\n$$\nkinput representation\n$$\nz_i = [(w_{i - (k-1)/2}^M)^T,...,(w_{i + (k-1)/2}^M)^T]^T\n$$\n\n#### 2.3 Input Attention Mechanism\n\n<img src=\"https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg\" width=\"70%\">\n\nattention$A_{i,i}^j=f(e_j,w_i)$wiej f \n$$\n\\alpha_i^j = \\frac{exp(A_{i,i}^j)}{\\sum_{i'=1}^{n}{exp(A_{i',i}^j)}}\n$$\nj=1,2 :\n\n- \n  $$\n  r_i = z_i \\frac{\\alpha_i^1 + \\alpha_i^2}{2}\n  $$\n\n- \n  $$\n  r_i = [(z_i \\alpha_i^1)^T, (z_i \\alpha_i^2)^T]^T\n  $$\n\n- \n  $$\n  r_i = z_i \\frac{\\alpha_i^1 - \\alpha_i^2}{2}\n  $$\n\n\n\n\n\n\n\n\n\n$R = [r_1, r_2,,r_n]$\n\n#### 2.4 Convolutional Max-Pooling with Secondary Attention\n\nRdc:\n$$\nR^\\star = tanh(W_fR+B_f), \\text{where the siaze of Wf is } d^c \\times k(d^w+2d^p)\n$$\nR*WL\n$$\nG = R^{\\star T}UW^L, \\\\U :\\text{weighting matrix learnt by the network}\n$$\n\nsoftmaxGattention pooling matrix Ap:\n$$\nA_{i,j}^p = \\frac{exp(G_{i,j})}{\\sum_{i'=1}^n{exp(G_{i',j})}}\n$$\nApR*attention\n$$\nw_i^O = max_j(R^\\star A^p)_{i,j}\n$$\n\n### 3. \n\n[1]attentionSem-Eval-2010 Task 8\n\n\n\n- \n- \n- \n\nAttentionpytorch[](https://github.com/lawlietAi/relation-classification-via-attention-model)\n\n## Reference\n\nhttps://zhuanlan.zhihu.com/p/22867750\n\n[1] Wang, L., Cao, Z., Melo, G. D., & Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. *Meeting of the Association for Computational Linguistics* (pp.1298-1307).\n\n[2] Bahdanau, D., Cho, K., & Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. *Computer Science*.\n\n[3] Luong, M. T., Pham, H., & Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. *Computer Science*.\n\n[4] Yin, W., Schtze, H., Xiang, B., & Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. *Computer Science*.","slug":"[2017.12.17]Relation-Classification-via-Attention-Model","published":1,"updated":"2020-11-03T03:26:14.244Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpi001ugwtlfxsu6m4s","content":"<h2 id=\"Relation-Classification-via-Attention-Model\"><a href=\"#Relation-Classification-via-Attention-Model\" class=\"headerlink\" title=\"Relation Classification via Attention Model\"></a>Relation Classification via Attention Model</h2><p>[1]Attentionattentionattention</p>\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n<h3 id=\"1-Attention\"><a href=\"#1-Attention\" class=\"headerlink\" title=\"1. Attention\"></a>1. Attention</h3><h4 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h4><p>AttentionNLPBahdanau[2]attentionattentionNLP</p>\n<h4 id=\"1-2-Recurrent-Models-of-Visual-Attention\"><a href=\"#1-2-Recurrent-Models-of-Visual-Attention\" class=\"headerlink\" title=\"1.2 Recurrent Models of Visual Attention\"></a>1.2 Recurrent Models of Visual Attention</h4><p>RNNattentionAttention</p>\n<h4 id=\"1-3-Attention-based-RNN-in-NLP\"><a href=\"#1-3-Attention-based-RNN-in-NLP\" class=\"headerlink\" title=\"1.3 Attention-based RNN in NLP\"></a>1.3 Attention-based RNN in NLP</h4><p>[1]EncoderDecoderSeq2seqEncoderDecoder</p>\n<p>Decoder</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201155.jpg\" width=\"30%\">\n\n<p>[3]attentionRNN</p>\n<h4 id=\"1-4-Attention-based-CNN-in-NLP\"><a href=\"#1-4-Attention-based-CNN-in-NLP\" class=\"headerlink\" title=\"1.4 Attention-based CNN in NLP\"></a>1.4 Attention-based CNN in NLP</h4><p>[4]CNNattentioncnn3CNNattention</p>\n<ul>\n<li>ABCNN-1: attentionattentionattention feature mapfeature map</li>\n<li>ABCNN-2: attentionattention.</li>\n<li>ABCNN-3: ABCNN-1 + ABCNN-2</li>\n</ul>\n<h3 id=\"2-Relation-Classification\"><a href=\"#2-Relation-Classification\" class=\"headerlink\" title=\"2. Relation Classification\"></a>2. Relation Classification</h3><img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n<h4 id=\"2-1-Classification-Objective\"><a href=\"#2-1-Classification-Objective\" class=\"headerlink\" title=\"2.1 Classification Objective\"></a>2.1 Classification Objective</h4><p>L2<br>$$<br>\\delta_{\\theta}(S,y) = ||\\frac{w^O}{|w^O|} - W_y^L||<em>{L^2} \\<br>S:\\text{Sentence}, y:\\text{Output relation}, w^O: \\text{Network output}, W^L:\\text{Relation embedding}<br>$$<br><br>$$<br>\\mathcal{L} = [\\delta_\\theta(S,y) + (1-\\delta_\\theta(S, \\hat{y}^-))] + \\beta||\\theta||^2 \\<br>\\hat{y}^- : \\text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\<br>\\hat{y}^- = argmax</em>{y\\in \\mathcal{Y},y\\ne y}(\\delta(S, y))<br>$$<br>$\\beta$</p>\n<h4 id=\"2-2-Input-Representation\"><a href=\"#2-2-Input-Representation\" class=\"headerlink\" title=\"2.2 Input Representation\"></a>2.2 Input Representation</h4><p>e1,e2<br>$$<br>S = (w_1,w_2,,w_n) \\<br>e_1 := w_p, e_2 := w_t . p,t\\in [1,n], p\\ne t<br>$$<br>word position embeddingsiEmbedding<br>$$<br>w_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T<br>$$<br>kinput representation<br>$$<br>z_i = [(w_{i - (k-1)/2}^M)^T,,(w_{i + (k-1)/2}^M)^T]^T<br>$$</p>\n<h4 id=\"2-3-Input-Attention-Mechanism\"><a href=\"#2-3-Input-Attention-Mechanism\" class=\"headerlink\" title=\"2.3 Input Attention Mechanism\"></a>2.3 Input Attention Mechanism</h4><img src=\"https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg\" width=\"70%\">\n\n<p>attention$A_{i,i}^j=f(e_j,w_i)$wiej f <br>$$<br>\\alpha_i^j = \\frac{exp(A_{i,i}^j)}{\\sum_{i=1}^{n}{exp(A_{i,i}^j)}}<br>$$<br>j=1,2 :</p>\n<ul>\n<li><p><br>$$<br>r_i = z_i \\frac{\\alpha_i^1 + \\alpha_i^2}{2}<br>$$</p>\n</li>\n<li><p><br>$$<br>r_i = [(z_i \\alpha_i^1)^T, (z_i \\alpha_i^2)^T]^T<br>$$</p>\n</li>\n<li><p><br>$$<br>r_i = z_i \\frac{\\alpha_i^1 - \\alpha_i^2}{2}<br>$$</p>\n</li>\n</ul>\n<p>$R = [r_1, r_2,,r_n]$</p>\n<h4 id=\"2-4-Convolutional-Max-Pooling-with-Secondary-Attention\"><a href=\"#2-4-Convolutional-Max-Pooling-with-Secondary-Attention\" class=\"headerlink\" title=\"2.4 Convolutional Max-Pooling with Secondary Attention\"></a>2.4 Convolutional Max-Pooling with Secondary Attention</h4><p>Rdc:<br>$$<br>R^\\star = tanh(W_fR+B_f), \\text{where the siaze of Wf is } d^c \\times k(d^w+2d^p)<br>$$<br>R*WL<br>$$<br>G = R^{\\star T}UW^L, \\U :\\text{weighting matrix learnt by the network}<br>$$</p>\n<p>softmaxGattention pooling matrix Ap:<br>$$<br>A_{i,j}^p = \\frac{exp(G_{i,j})}{\\sum_{i=1}^n{exp(G_{i,j})}}<br>$$<br>ApR*attention<br>$$<br>w_i^O = max_j(R^\\star A^p)_{i,j}<br>$$</p>\n<h3 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h3><p>[1]attentionSem-Eval-2010 Task 8</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p>Attentionpytorch<a href=\"https://github.com/lawlietAi/relation-classification-via-attention-model\"></a></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://zhuanlan.zhihu.com/p/22867750\">https://zhuanlan.zhihu.com/p/22867750</a></p>\n<p>[1] Wang, L., Cao, Z., Melo, G. D., &amp; Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. <em>Meeting of the Association for Computational Linguistics</em> (pp.1298-1307).</p>\n<p>[2] Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <em>Computer Science</em>.</p>\n<p>[3] Luong, M. T., Pham, H., &amp; Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. <em>Computer Science</em>.</p>\n<p>[4] Yin, W., Schtze, H., Xiang, B., &amp; Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. <em>Computer Science</em>.</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"Relation-Classification-via-Attention-Model\"><a href=\"#Relation-Classification-via-Attention-Model\" class=\"headerlink\" title=\"Relation Classification via Attention Model\"></a>Relation Classification via Attention Model</h2><p>[1]Attentionattentionattention</p>\n<img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n<h3 id=\"1-Attention\"><a href=\"#1-Attention\" class=\"headerlink\" title=\"1. Attention\"></a>1. Attention</h3><h4 id=\"1-1-\"><a href=\"#1-1-\" class=\"headerlink\" title=\"1.1 \"></a>1.1 </h4><p>AttentionNLPBahdanau[2]attentionattentionNLP</p>\n<h4 id=\"1-2-Recurrent-Models-of-Visual-Attention\"><a href=\"#1-2-Recurrent-Models-of-Visual-Attention\" class=\"headerlink\" title=\"1.2 Recurrent Models of Visual Attention\"></a>1.2 Recurrent Models of Visual Attention</h4><p>RNNattentionAttention</p>\n<h4 id=\"1-3-Attention-based-RNN-in-NLP\"><a href=\"#1-3-Attention-based-RNN-in-NLP\" class=\"headerlink\" title=\"1.3 Attention-based RNN in NLP\"></a>1.3 Attention-based RNN in NLP</h4><p>[1]EncoderDecoderSeq2seqEncoderDecoder</p>\n<p>Decoder</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201155.jpg\" width=\"30%\">\n\n<p>[3]attentionRNN</p>\n<h4 id=\"1-4-Attention-based-CNN-in-NLP\"><a href=\"#1-4-Attention-based-CNN-in-NLP\" class=\"headerlink\" title=\"1.4 Attention-based CNN in NLP\"></a>1.4 Attention-based CNN in NLP</h4><p>[4]CNNattentioncnn3CNNattention</p>\n<ul>\n<li>ABCNN-1: attentionattentionattention feature mapfeature map</li>\n<li>ABCNN-2: attentionattention.</li>\n<li>ABCNN-3: ABCNN-1 + ABCNN-2</li>\n</ul>\n<h3 id=\"2-Relation-Classification\"><a href=\"#2-Relation-Classification\" class=\"headerlink\" title=\"2. Relation Classification\"></a>2. Relation Classification</h3><img src=\"https://github.com/lawlietAi/relation-classification-via-attention-model/raw/master/acnn_structure.png\" width=\"50%\">\n\n<h4 id=\"2-1-Classification-Objective\"><a href=\"#2-1-Classification-Objective\" class=\"headerlink\" title=\"2.1 Classification Objective\"></a>2.1 Classification Objective</h4><p>L2<br>$$<br>\\delta_{\\theta}(S,y) = ||\\frac{w^O}{|w^O|} - W_y^L||<em>{L^2} \\<br>S:\\text{Sentence}, y:\\text{Output relation}, w^O: \\text{Network output}, W^L:\\text{Relation embedding}<br>$$<br><br>$$<br>\\mathcal{L} = [\\delta_\\theta(S,y) + (1-\\delta_\\theta(S, \\hat{y}^-))] + \\beta||\\theta||^2 \\<br>\\hat{y}^- : \\text{A selected incorrect relation label chosen as the one with the highest score among all i.e.} \\<br>\\hat{y}^- = argmax</em>{y\\in \\mathcal{Y},y\\ne y}(\\delta(S, y))<br>$$<br>$\\beta$</p>\n<h4 id=\"2-2-Input-Representation\"><a href=\"#2-2-Input-Representation\" class=\"headerlink\" title=\"2.2 Input Representation\"></a>2.2 Input Representation</h4><p>e1,e2<br>$$<br>S = (w_1,w_2,,w_n) \\<br>e_1 := w_p, e_2 := w_t . p,t\\in [1,n], p\\ne t<br>$$<br>word position embeddingsiEmbedding<br>$$<br>w_i^M = [(w_i^d)^T, (w_{i,2}^p)^T,(w_{i,2}^p)^T]^T<br>$$<br>kinput representation<br>$$<br>z_i = [(w_{i - (k-1)/2}^M)^T,,(w_{i + (k-1)/2}^M)^T]^T<br>$$</p>\n<h4 id=\"2-3-Input-Attention-Mechanism\"><a href=\"#2-3-Input-Attention-Mechanism\" class=\"headerlink\" title=\"2.3 Input Attention Mechanism\"></a>2.3 Input Attention Mechanism</h4><img src=\"https://pic3.zhimg.com/50/v2-2399a406ad0960c422702728b6418fa3_hd.jpg\" width=\"70%\">\n\n<p>attention$A_{i,i}^j=f(e_j,w_i)$wiej f <br>$$<br>\\alpha_i^j = \\frac{exp(A_{i,i}^j)}{\\sum_{i=1}^{n}{exp(A_{i,i}^j)}}<br>$$<br>j=1,2 :</p>\n<ul>\n<li><p><br>$$<br>r_i = z_i \\frac{\\alpha_i^1 + \\alpha_i^2}{2}<br>$$</p>\n</li>\n<li><p><br>$$<br>r_i = [(z_i \\alpha_i^1)^T, (z_i \\alpha_i^2)^T]^T<br>$$</p>\n</li>\n<li><p><br>$$<br>r_i = z_i \\frac{\\alpha_i^1 - \\alpha_i^2}{2}<br>$$</p>\n</li>\n</ul>\n<p>$R = [r_1, r_2,,r_n]$</p>\n<h4 id=\"2-4-Convolutional-Max-Pooling-with-Secondary-Attention\"><a href=\"#2-4-Convolutional-Max-Pooling-with-Secondary-Attention\" class=\"headerlink\" title=\"2.4 Convolutional Max-Pooling with Secondary Attention\"></a>2.4 Convolutional Max-Pooling with Secondary Attention</h4><p>Rdc:<br>$$<br>R^\\star = tanh(W_fR+B_f), \\text{where the siaze of Wf is } d^c \\times k(d^w+2d^p)<br>$$<br>R*WL<br>$$<br>G = R^{\\star T}UW^L, \\U :\\text{weighting matrix learnt by the network}<br>$$</p>\n<p>softmaxGattention pooling matrix Ap:<br>$$<br>A_{i,j}^p = \\frac{exp(G_{i,j})}{\\sum_{i=1}^n{exp(G_{i,j})}}<br>$$<br>ApR*attention<br>$$<br>w_i^O = max_j(R^\\star A^p)_{i,j}<br>$$</p>\n<h3 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h3><p>[1]attentionSem-Eval-2010 Task 8</p>\n<p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<p>Attentionpytorch<a href=\"https://github.com/lawlietAi/relation-classification-via-attention-model\"></a></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p><a href=\"https://zhuanlan.zhihu.com/p/22867750\">https://zhuanlan.zhihu.com/p/22867750</a></p>\n<p>[1] Wang, L., Cao, Z., Melo, G. D., &amp; Liu, Z. (2016). Relation Classification via Multi-Level Attention CNNs. <em>Meeting of the Association for Computational Linguistics</em> (pp.1298-1307).</p>\n<p>[2] Bahdanau, D., Cho, K., &amp; Bengio, Y. (2014). Neural machine translation by jointly learning to align and translate. <em>Computer Science</em>.</p>\n<p>[3] Luong, M. T., Pham, H., &amp; Manning, C. D. (2015). Effective approaches to attention-based neural machine translation. <em>Computer Science</em>.</p>\n<p>[4] Yin, W., Schtze, H., Xiang, B., &amp; Zhou, B. (2015). Abcnn: attention-based convolutional neural network for modeling sentence pairs. <em>Computer Science</em>.</p>\n"},{"title":"Event detection and co-reference with minimal supervision ","date":"2018-01-21T00:00:00.000Z","_content":"\n## Event detection and co-reference with minimal supervision [1]\n\n****ACErich EREFreebase\n\n### 1. Introduction\n\n<img src='https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202215.jpg' width='70%'>\n\nMSEPMinimally Supervised Event Pipeline Event examples  Example vectorsMSEP\n\n\n\n- Event detection \n- Co-reference problem. Co-reference problem\n\neevent detection e co-reference problem e1e2\n\n1. 2. semantic role labeling  representationSRLembedding\n\nevent mentionevent ontology co-reference \n\n\n\n### 2. The MSEP System\n\n#### 2.1 Structured Vector Representation \n\n\n\n![basic](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202214.jpg)\n\n**Basic event vector representation**\n\n![basic](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202217.jpg)\n\n**Augmented event vector representation**+ ESA\n\n#### 2.2 Event Mention Detection\n\n Event type representation \n\n\n$$\nS(e_1, e_2) = \\frac{vec(e_1)  vec(e_2)}{||vec(e_1)||||vec(e_2)||} \\\\\n= \\frac{\\sum_a{vec(a_1)  vec(a_2)}}{\\sqrt{\\sum_a{||vec(a_1)||^2}  \\sum_a{||vec(a_2)||^2}}}\n$$\n e1 e2 a  a \n\n#### 2.3 Event co-reference\n\n$S(e_1, e_2)$\n\n$agnet_{sub}, agnet_{obj}$$Set_{conflict}$\n\nk+1\n$$\ne_p = argmax_{e\\in \\{e_1,...,e_k\\} e \\notin Set_{conflit}} {S(e_p, e_{k+1})}\n$$\n$S(e_p, e_{k+1})$\n\n### 3. Vector Representation\n\n embedding \n\n- Explicit Semantic Analysis\n- Brown Cluster\n- Word2Vec\n- Dependency-Based Embedding\n\n### 4. Semantic Role Labeling\n\n Semantic Role Labeling  Semantic Role Labeling\n\n[2]RNN-CRF\n\n- Embedding layer\n- Bi-directional RNN (usually LSTM) layer\n- Tanh hidden layer\n- CRF layer\n\nAttention\n\nLTP Semantic Role Labeling \n\n### 5. Conclusion\n\nevent\n\n\n\n## Bibliography\n\n[1] Peng, H., Song, Y., & Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In *EMNLP* (pp. 392-402).\n\n[2] Zhou, J., & Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In *ACL (1)* (pp. 1127-1137).","source":"_posts/[2018.1.21]Event-detection-and-co-referentce.md","raw":"---\ntitle: Event detection and co-reference with minimal supervision \ndate: 2018-01-21 08:00:00\ncategories: [research]\ntags: [event-detection, co-reference]\n---\n\n## Event detection and co-reference with minimal supervision [1]\n\n****ACErich EREFreebase\n\n### 1. Introduction\n\n<img src='https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202215.jpg' width='70%'>\n\nMSEPMinimally Supervised Event Pipeline Event examples  Example vectorsMSEP\n\n\n\n- Event detection \n- Co-reference problem. Co-reference problem\n\neevent detection e co-reference problem e1e2\n\n1. 2. semantic role labeling  representationSRLembedding\n\nevent mentionevent ontology co-reference \n\n\n\n### 2. The MSEP System\n\n#### 2.1 Structured Vector Representation \n\n\n\n![basic](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202214.jpg)\n\n**Basic event vector representation**\n\n![basic](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202217.jpg)\n\n**Augmented event vector representation**+ ESA\n\n#### 2.2 Event Mention Detection\n\n Event type representation \n\n\n$$\nS(e_1, e_2) = \\frac{vec(e_1)  vec(e_2)}{||vec(e_1)||||vec(e_2)||} \\\\\n= \\frac{\\sum_a{vec(a_1)  vec(a_2)}}{\\sqrt{\\sum_a{||vec(a_1)||^2}  \\sum_a{||vec(a_2)||^2}}}\n$$\n e1 e2 a  a \n\n#### 2.3 Event co-reference\n\n$S(e_1, e_2)$\n\n$agnet_{sub}, agnet_{obj}$$Set_{conflict}$\n\nk+1\n$$\ne_p = argmax_{e\\in \\{e_1,...,e_k\\} e \\notin Set_{conflit}} {S(e_p, e_{k+1})}\n$$\n$S(e_p, e_{k+1})$\n\n### 3. Vector Representation\n\n embedding \n\n- Explicit Semantic Analysis\n- Brown Cluster\n- Word2Vec\n- Dependency-Based Embedding\n\n### 4. Semantic Role Labeling\n\n Semantic Role Labeling  Semantic Role Labeling\n\n[2]RNN-CRF\n\n- Embedding layer\n- Bi-directional RNN (usually LSTM) layer\n- Tanh hidden layer\n- CRF layer\n\nAttention\n\nLTP Semantic Role Labeling \n\n### 5. Conclusion\n\nevent\n\n\n\n## Bibliography\n\n[1] Peng, H., Song, Y., & Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In *EMNLP* (pp. 392-402).\n\n[2] Zhou, J., & Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In *ACL (1)* (pp. 1127-1137).","slug":"[2018.1.21]Event-detection-and-co-referentce","published":1,"updated":"2020-11-03T03:26:13.403Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpm001ygwtl9ur9czfz","content":"<h2 id=\"Event-detection-and-co-reference-with-minimal-supervision-1\"><a href=\"#Event-detection-and-co-reference-with-minimal-supervision-1\" class=\"headerlink\" title=\"Event detection and co-reference with minimal supervision [1]\"></a>Event detection and co-reference with minimal supervision [1]</h2><p><strong></strong>ACErich EREFreebase</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202215.jpg\" width=\"70%\">\n\n<p>MSEPMinimally Supervised Event Pipeline Event examples  Example vectorsMSEP</p>\n<p></p>\n<ul>\n<li>Event detection </li>\n<li>Co-reference problem. Co-reference problem</li>\n</ul>\n<p>eevent detection e co-reference problem e1e2</p>\n<p>1. 2. semantic role labeling  representationSRLembedding</p>\n<p>event mentionevent ontology co-reference </p>\n<h3 id=\"2-The-MSEP-System\"><a href=\"#2-The-MSEP-System\" class=\"headerlink\" title=\"2. The MSEP System\"></a>2. The MSEP System</h3><h4 id=\"2-1-Structured-Vector-Representation\"><a href=\"#2-1-Structured-Vector-Representation\" class=\"headerlink\" title=\"2.1 Structured Vector Representation\"></a>2.1 Structured Vector Representation</h4><p></p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202214.jpg\" alt=\"basic\"></p>\n<p><strong>Basic event vector representation</strong></p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202217.jpg\" alt=\"basic\"></p>\n<p><strong>Augmented event vector representation</strong>+ ESA</p>\n<h4 id=\"2-2-Event-Mention-Detection\"><a href=\"#2-2-Event-Mention-Detection\" class=\"headerlink\" title=\"2.2 Event Mention Detection\"></a>2.2 Event Mention Detection</h4><p> Event type representation </p>\n<p><br>$$<br>S(e_1, e_2) = \\frac{vec(e_1)  vec(e_2)}{||vec(e_1)||||vec(e_2)||} \\<br>= \\frac{\\sum_a{vec(a_1)  vec(a_2)}}{\\sqrt{\\sum_a{||vec(a_1)||^2}  \\sum_a{||vec(a_2)||^2}}}<br>$$<br> e1 e2 a  a </p>\n<h4 id=\"2-3-Event-co-reference\"><a href=\"#2-3-Event-co-reference\" class=\"headerlink\" title=\"2.3 Event co-reference\"></a>2.3 Event co-reference</h4><p>$S(e_1, e_2)$</p>\n<p>$agnet_{sub}, agnet_{obj}$$Set_{conflict}$</p>\n<p>k+1<br>$$<br>e_p = argmax_{e\\in {e_1,,e_k} e \\notin Set_{conflit}} {S(e_p, e_{k+1})}<br>$$<br>$S(e_p, e_{k+1})$</p>\n<h3 id=\"3-Vector-Representation\"><a href=\"#3-Vector-Representation\" class=\"headerlink\" title=\"3. Vector Representation\"></a>3. Vector Representation</h3><p> embedding </p>\n<ul>\n<li>Explicit Semantic Analysis</li>\n<li>Brown Cluster</li>\n<li>Word2Vec</li>\n<li>Dependency-Based Embedding</li>\n</ul>\n<h3 id=\"4-Semantic-Role-Labeling\"><a href=\"#4-Semantic-Role-Labeling\" class=\"headerlink\" title=\"4. Semantic Role Labeling\"></a>4. Semantic Role Labeling</h3><p> Semantic Role Labeling  Semantic Role Labeling</p>\n<p>[2]RNN-CRF</p>\n<ul>\n<li>Embedding layer</li>\n<li>Bi-directional RNN (usually LSTM) layer</li>\n<li>Tanh hidden layer</li>\n<li>CRF layer</li>\n</ul>\n<p>Attention</p>\n<p>LTP Semantic Role Labeling </p>\n<h3 id=\"5-Conclusion\"><a href=\"#5-Conclusion\" class=\"headerlink\" title=\"5. Conclusion\"></a>5. Conclusion</h3><p>event</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[1] Peng, H., Song, Y., &amp; Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In <em>EMNLP</em> (pp. 392-402).</p>\n<p>[2] Zhou, J., &amp; Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In <em>ACL (1)</em> (pp. 1127-1137).</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"Event-detection-and-co-reference-with-minimal-supervision-1\"><a href=\"#Event-detection-and-co-reference-with-minimal-supervision-1\" class=\"headerlink\" title=\"Event detection and co-reference with minimal supervision [1]\"></a>Event detection and co-reference with minimal supervision [1]</h2><p><strong></strong>ACErich EREFreebase</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><img src='https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202215.jpg' width='70%'>\n\n<p>MSEPMinimally Supervised Event Pipeline Event examples  Example vectorsMSEP</p>\n<p></p>\n<ul>\n<li>Event detection </li>\n<li>Co-reference problem. Co-reference problem</li>\n</ul>\n<p>eevent detection e co-reference problem e1e2</p>\n<p>1. 2. semantic role labeling  representationSRLembedding</p>\n<p>event mentionevent ontology co-reference </p>\n<h3 id=\"2-The-MSEP-System\"><a href=\"#2-The-MSEP-System\" class=\"headerlink\" title=\"2. The MSEP System\"></a>2. The MSEP System</h3><h4 id=\"2-1-Structured-Vector-Representation\"><a href=\"#2-1-Structured-Vector-Representation\" class=\"headerlink\" title=\"2.1 Structured Vector Representation\"></a>2.1 Structured Vector Representation</h4><p></p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202214.jpg\" alt=\"basic\"></p>\n<p><strong>Basic event vector representation</strong></p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202217.jpg\" alt=\"basic\"></p>\n<p><strong>Augmented event vector representation</strong>+ ESA</p>\n<h4 id=\"2-2-Event-Mention-Detection\"><a href=\"#2-2-Event-Mention-Detection\" class=\"headerlink\" title=\"2.2 Event Mention Detection\"></a>2.2 Event Mention Detection</h4><p> Event type representation </p>\n<p><br>$$<br>S(e_1, e_2) = \\frac{vec(e_1)  vec(e_2)}{||vec(e_1)||||vec(e_2)||} \\<br>= \\frac{\\sum_a{vec(a_1)  vec(a_2)}}{\\sqrt{\\sum_a{||vec(a_1)||^2}  \\sum_a{||vec(a_2)||^2}}}<br>$$<br> e1 e2 a  a </p>\n<h4 id=\"2-3-Event-co-reference\"><a href=\"#2-3-Event-co-reference\" class=\"headerlink\" title=\"2.3 Event co-reference\"></a>2.3 Event co-reference</h4><p>$S(e_1, e_2)$</p>\n<p>$agnet_{sub}, agnet_{obj}$$Set_{conflict}$</p>\n<p>k+1<br>$$<br>e_p = argmax_{e\\in {e_1,,e_k} e \\notin Set_{conflit}} {S(e_p, e_{k+1})}<br>$$<br>$S(e_p, e_{k+1})$</p>\n<h3 id=\"3-Vector-Representation\"><a href=\"#3-Vector-Representation\" class=\"headerlink\" title=\"3. Vector Representation\"></a>3. Vector Representation</h3><p> embedding </p>\n<ul>\n<li>Explicit Semantic Analysis</li>\n<li>Brown Cluster</li>\n<li>Word2Vec</li>\n<li>Dependency-Based Embedding</li>\n</ul>\n<h3 id=\"4-Semantic-Role-Labeling\"><a href=\"#4-Semantic-Role-Labeling\" class=\"headerlink\" title=\"4. Semantic Role Labeling\"></a>4. Semantic Role Labeling</h3><p> Semantic Role Labeling  Semantic Role Labeling</p>\n<p>[2]RNN-CRF</p>\n<ul>\n<li>Embedding layer</li>\n<li>Bi-directional RNN (usually LSTM) layer</li>\n<li>Tanh hidden layer</li>\n<li>CRF layer</li>\n</ul>\n<p>Attention</p>\n<p>LTP Semantic Role Labeling </p>\n<h3 id=\"5-Conclusion\"><a href=\"#5-Conclusion\" class=\"headerlink\" title=\"5. Conclusion\"></a>5. Conclusion</h3><p>event</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[1] Peng, H., Song, Y., &amp; Roth, D. (2016). Event Detection and Co-reference with Minimal Supervision. In <em>EMNLP</em> (pp. 392-402).</p>\n<p>[2] Zhou, J., &amp; Xu, W. (2015). End-to-end learning of semantic role labeling using recurrent neural networks. In <em>ACL (1)</em> (pp. 1127-1137).</p>\n"},{"title":"A convolution BiLSTM neural network model for chinese event extraction ","date":"2018-01-29T00:00:00.000Z","_content":"\n## A convolution BiLSTM neural network model for chinese event extraction\n\n****NLP \\[1\\]LSTMCNNLSTM\n\n### 1. Introduction\n\nAutomatic Content ExtractionACE\n\n- \n- \n\n********\n\nS1Intel****\n\nIntel\n\n state-of-the-art [2-4] ********\n\nS2****1994\n\nS3****\n\nS2\n\nS3\n\n[2, 3]NLP\n\nChen et al. [5] LSTMLSTM POSNER\n\n### 2. Trigger Labeling \n\n#### 2.1 Language Specific Issues\n\n\n\n- \n- \n\n BIOBIOLSTM\n\n![trigger-labeling](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202231.jpg)\n\n awtctCNNb  734 bP\n\n#### 2.2 Word-Based Method\n\n**LSTM Network**  nlpLSTMLSTM\n\n**CNN**  nlp\n\nn{w1, w2, ... , wn}wtwt  map   cwtwt\n\n73\n\n**Output Layer**  BiLSTMCNNtcwt \\[ht; cwt\\]softmaxwt\n\n\n#### 2.3 Character-Based Method\n\nCharacter-embeddinginput layer\n\n![character](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202234.jpg)\n\n### 3. Argument Labeling\n\n\n\n#### 3.1 Input Layer\n\npipelineword embeddings embeddingBiLSTMCNN\n\n- \n- NONE\n- \n- NONE ACENLP**1. embed2. \n  BiLSTMCNN\n\n#### 3.2 Output Layer\n\n ACE  S4\n\nS7*******Bob******Joe*****\n\nCNNBiLSTM\n\nBiLSTMhN\n\nCNN softmax\n\n### 4. Conclusion\n\n[1]LSTMACE 2005BiLSTM+CRF[1]\n\n## Bibliography\n\n\\[1\\] Zeng, Y., Yang, H., Feng, Y., Wang, Z., & Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In *Natural Language Understanding and Intelligent Applications* (pp. 275-287). Springer, Cham.\n\n\\[2\\] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529544. Citeseer (2012)\n\n\\[3\\] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)\n\n[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 7382 (2013)\n\n[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)","source":"_posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction.md","raw":"---\ntitle: A convolution BiLSTM neural network model for chinese event extraction \ndate: 2018-01-29 08:00:00\ncategories: [research]\ntags: [convolution, BiLSTM, event-extraction]\n---\n\n## A convolution BiLSTM neural network model for chinese event extraction\n\n****NLP \\[1\\]LSTMCNNLSTM\n\n### 1. Introduction\n\nAutomatic Content ExtractionACE\n\n- \n- \n\n********\n\nS1Intel****\n\nIntel\n\n state-of-the-art [2-4] ********\n\nS2****1994\n\nS3****\n\nS2\n\nS3\n\n[2, 3]NLP\n\nChen et al. [5] LSTMLSTM POSNER\n\n### 2. Trigger Labeling \n\n#### 2.1 Language Specific Issues\n\n\n\n- \n- \n\n BIOBIOLSTM\n\n![trigger-labeling](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202231.jpg)\n\n awtctCNNb  734 bP\n\n#### 2.2 Word-Based Method\n\n**LSTM Network**  nlpLSTMLSTM\n\n**CNN**  nlp\n\nn{w1, w2, ... , wn}wtwt  map   cwtwt\n\n73\n\n**Output Layer**  BiLSTMCNNtcwt \\[ht; cwt\\]softmaxwt\n\n\n#### 2.3 Character-Based Method\n\nCharacter-embeddinginput layer\n\n![character](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202234.jpg)\n\n### 3. Argument Labeling\n\n\n\n#### 3.1 Input Layer\n\npipelineword embeddings embeddingBiLSTMCNN\n\n- \n- NONE\n- \n- NONE ACENLP**1. embed2. \n  BiLSTMCNN\n\n#### 3.2 Output Layer\n\n ACE  S4\n\nS7*******Bob******Joe*****\n\nCNNBiLSTM\n\nBiLSTMhN\n\nCNN softmax\n\n### 4. Conclusion\n\n[1]LSTMACE 2005BiLSTM+CRF[1]\n\n## Bibliography\n\n\\[1\\] Zeng, Y., Yang, H., Feng, Y., Wang, Z., & Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In *Natural Language Understanding and Intelligent Applications* (pp. 275-287). Springer, Cham.\n\n\\[2\\] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529544. Citeseer (2012)\n\n\\[3\\] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)\n\n[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 7382 (2013)\n\n[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)","slug":"[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction","published":1,"updated":"2020-11-03T03:26:12.997Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpn0021gwtl3zwebh66","content":"<h2 id=\"A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction\"><a href=\"#A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction\" class=\"headerlink\" title=\"A convolution BiLSTM neural network model for chinese event extraction\"></a>A convolution BiLSTM neural network model for chinese event extraction</h2><p><strong></strong>NLP [1]LSTMCNNLSTM</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>Automatic Content ExtractionACE</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p><strong></strong><strong></strong></p>\n<p>S1Intel<strong></strong></p>\n<p>Intel</p>\n<p> state-of-the-art [2-4] <strong></strong><strong></strong></p>\n<p>S2<strong></strong>1994</p>\n<p>S3<strong></strong></p>\n<p>S2</p>\n<p>S3</p>\n<p>[2, 3]NLP</p>\n<p>Chen et al. [5] LSTMLSTM POSNER</p>\n<h3 id=\"2-Trigger-Labeling\"><a href=\"#2-Trigger-Labeling\" class=\"headerlink\" title=\"2. Trigger Labeling\"></a>2. Trigger Labeling</h3><h4 id=\"2-1-Language-Specific-Issues\"><a href=\"#2-1-Language-Specific-Issues\" class=\"headerlink\" title=\"2.1 Language Specific Issues\"></a>2.1 Language Specific Issues</h4><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p> BIOBIOLSTM</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202231.jpg\" alt=\"trigger-labeling\"></p>\n<p> awtctCNNb  734 bP</p>\n<h4 id=\"2-2-Word-Based-Method\"><a href=\"#2-2-Word-Based-Method\" class=\"headerlink\" title=\"2.2 Word-Based Method\"></a>2.2 Word-Based Method</h4><p><strong>LSTM Network</strong>  nlpLSTMLSTM</p>\n<p><strong>CNN</strong>  nlp</p>\n<p>n{w1, w2,  , wn}wtwt  map   cwtwt</p>\n<p>73</p>\n<p><strong>Output Layer</strong>  BiLSTMCNNtcwt [ht; cwt]softmaxwt<br></p>\n<h4 id=\"2-3-Character-Based-Method\"><a href=\"#2-3-Character-Based-Method\" class=\"headerlink\" title=\"2.3 Character-Based Method\"></a>2.3 Character-Based Method</h4><p>Character-embeddinginput layer</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202234.jpg\" alt=\"character\"></p>\n<h3 id=\"3-Argument-Labeling\"><a href=\"#3-Argument-Labeling\" class=\"headerlink\" title=\"3. Argument Labeling\"></a>3. Argument Labeling</h3><p></p>\n<h4 id=\"3-1-Input-Layer\"><a href=\"#3-1-Input-Layer\" class=\"headerlink\" title=\"3.1 Input Layer\"></a>3.1 Input Layer</h4><p>pipelineword embeddings embeddingBiLSTMCNN</p>\n<ul>\n<li></li>\n<li>NONE</li>\n<li></li>\n<li>NONE ACENLP<em></em>1. embed2. <br>BiLSTMCNN</li>\n</ul>\n<h4 id=\"3-2-Output-Layer\"><a href=\"#3-2-Output-Layer\" class=\"headerlink\" title=\"3.2 Output Layer\"></a>3.2 Output Layer</h4><p> ACE  S4</p>\n<p>S7<strong></strong><em></em><em>Bob</em><strong></strong><em>Joe</em><strong></strong></p>\n<p>CNNBiLSTM</p>\n<p>BiLSTMhN</p>\n<p>CNN softmax</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>[1]LSTMACE 2005BiLSTM+CRF[1]</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[1] Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.</p>\n<p>[2] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529544. Citeseer (2012)</p>\n<p>[3] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)</p>\n<p>[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 7382 (2013)</p>\n<p>[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction\"><a href=\"#A-convolution-BiLSTM-neural-network-model-for-chinese-event-extraction\" class=\"headerlink\" title=\"A convolution BiLSTM neural network model for chinese event extraction\"></a>A convolution BiLSTM neural network model for chinese event extraction</h2><p><strong></strong>NLP [1]LSTMCNNLSTM</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>Automatic Content ExtractionACE</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p><strong></strong><strong></strong></p>\n<p>S1Intel<strong></strong></p>\n<p>Intel</p>\n<p> state-of-the-art [2-4] <strong></strong><strong></strong></p>\n<p>S2<strong></strong>1994</p>\n<p>S3<strong></strong></p>\n<p>S2</p>\n<p>S3</p>\n<p>[2, 3]NLP</p>\n<p>Chen et al. [5] LSTMLSTM POSNER</p>\n<h3 id=\"2-Trigger-Labeling\"><a href=\"#2-Trigger-Labeling\" class=\"headerlink\" title=\"2. Trigger Labeling\"></a>2. Trigger Labeling</h3><h4 id=\"2-1-Language-Specific-Issues\"><a href=\"#2-1-Language-Specific-Issues\" class=\"headerlink\" title=\"2.1 Language Specific Issues\"></a>2.1 Language Specific Issues</h4><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p> BIOBIOLSTM</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202231.jpg\" alt=\"trigger-labeling\"></p>\n<p> awtctCNNb  734 bP</p>\n<h4 id=\"2-2-Word-Based-Method\"><a href=\"#2-2-Word-Based-Method\" class=\"headerlink\" title=\"2.2 Word-Based Method\"></a>2.2 Word-Based Method</h4><p><strong>LSTM Network</strong>  nlpLSTMLSTM</p>\n<p><strong>CNN</strong>  nlp</p>\n<p>n{w1, w2,  , wn}wtwt  map   cwtwt</p>\n<p>73</p>\n<p><strong>Output Layer</strong>  BiLSTMCNNtcwt [ht; cwt]softmaxwt<br></p>\n<h4 id=\"2-3-Character-Based-Method\"><a href=\"#2-3-Character-Based-Method\" class=\"headerlink\" title=\"2.3 Character-Based Method\"></a>2.3 Character-Based Method</h4><p>Character-embeddinginput layer</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202234.jpg\" alt=\"character\"></p>\n<h3 id=\"3-Argument-Labeling\"><a href=\"#3-Argument-Labeling\" class=\"headerlink\" title=\"3. Argument Labeling\"></a>3. Argument Labeling</h3><p></p>\n<h4 id=\"3-1-Input-Layer\"><a href=\"#3-1-Input-Layer\" class=\"headerlink\" title=\"3.1 Input Layer\"></a>3.1 Input Layer</h4><p>pipelineword embeddings embeddingBiLSTMCNN</p>\n<ul>\n<li></li>\n<li>NONE</li>\n<li></li>\n<li>NONE ACENLP<em></em>1. embed2. <br>BiLSTMCNN</li>\n</ul>\n<h4 id=\"3-2-Output-Layer\"><a href=\"#3-2-Output-Layer\" class=\"headerlink\" title=\"3.2 Output Layer\"></a>3.2 Output Layer</h4><p> ACE  S4</p>\n<p>S7<strong></strong><em></em><em>Bob</em><strong></strong><em>Joe</em><strong></strong></p>\n<p>CNNBiLSTM</p>\n<p>BiLSTMhN</p>\n<p>CNN softmax</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>[1]LSTMACE 2005BiLSTM+CRF[1]</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[1] Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.</p>\n<p>[2] Chen, C., Ng, V.: Joint modeling for Chinese event extraction with rich linguistic features. In: COLING, pp. 529544. Citeseer (2012)</p>\n<p>[3] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)</p>\n<p>[4] Li, Q., Ji, H., Huang, L.: Joint event extraction via structured prediction with global features. In: ACL (1), pp. 7382 (2013)</p>\n<p>[5] Chen, Y., Xu, L., Liu, K., Zeng, D., Zhao, J.: Event extraction via dynamic multipooling convolutional neural networks. In: Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing, vol. 1, pp. 167176 (2015)</p>\n"},{"title":"Overcoming Limited Supervision in Relation Extraction ","date":"2018-01-04T00:00:00.000Z","_content":"\nOvercoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach[1]distributional approachpattern-based approach\n\n![illustration](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201441.jpg)\n\n### 1. Introduction\n\n#### 1.1 Weakly Supervised Learning\n\nseed\n\n\n\n1. \n2. \n3. \n\n#### 1.2 Co-training strategy\n\nco-training[2]\n\nco-training\n\n#### 1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)\n\nREPEL\n\n### 2. Problem definition\n\n\n\n $(e_h, e_t)$$(e_h, e_t, r)$\n\nDRseed$ \\{(e_h^{r(k)}, e_t^{r(k)}, r)\\} _{k=1}^{N_r} $$ \\{(e_h^{r(i)}, e_t^{r(i)}, r)\\} _{i=1}^M $$ r \\in R $$ \\{(e_h^{r(i)}, e_t^{r(i)})\\} _{i=1}^{M_r} $\n\n### 3. REPEL Framework\n\n\n\n\n\n\n$$\nmax_{P,D}O = max_{P,D}\\{O_p + O_d + \\lambda O_i\\}\n$$\nPDOpOdOi\n\n\n\n#### 3.1 Pattern Module\n\nrK\n\npath-based patternmeta pattern\n\n$\\pi$\n$$\nR(\\pi)=\\frac{|G(\\pi)\\cap S_{pair}|}{|G(\\pi)|}\n$$\n$G(\\pi)$$\\pi$$S_{pair}$seedR$\\pi$seedseed\n$$\nO_p = \\sum_{\\pi \\in P}R(\\pi)\n$$\n\n\n- seed\n- RK\n\n#### 3.2 Distributional Module\n\n\n\new\n$$\nP(w|e) =\\frac{exp(x_e*c_w)}{Z}\n$$\n$x_e$ $c_w$word embeddingZ\n$$\nO_{text} = \\sum_{w,e}n_{w,e}log(P(w|e))\n$$\n$n_{w,e}$\n\n\n$$\nL_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2\n$$\n$(x_{e_h} - x_{e_t})$$y_r$r$L_D$1\n$$\nO_{seed} = \\sum_{f\\in S_{pair}} \\sum_{f'\\in(e'_h,e'_t)} {min\\{1, L_D(f|r) - L_D(f'|r)\\}}\n$$\n$(e'_h,e'_t)$$L_D(f'|r)$\n\nOd\n$$\nO_d = O_{text} + \\eta O_{seed}\n$$\n$\\eta$\n\n#### 3.3 Modeling the Module Interaction\n\n$$\nO_i = E_{f\\in G(P)}[L_D(f|r)]\n$$\n\nE\n\nOiPOiG(P)LD\n\n### 4. The Joint Optimization Problem\n\n![algo](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201444.jpg)\n\n\n\nseed$S_{pair}$$G(P)$Eqn.11\n$$\nmax_D \\{ O_d + \\lambda O_i \\} = max_D \\{ O_d + \\lambda E_{f \\in G(P)}[L_D(f|r)] \\}\n$$\n$S_{pair}$Eqn.12\n$$\nmax_P \\{ O_p + \\lambda O_i \\} = max_P \\{ \\sum_{\\pi \\in P}(R(\\pi) + \\lambda E_{f \\in G(\\pi)}[L_D(f|r)]) \\}\n$$\n\n\n### 5. Conclusion\n\n\n\n## Reference\n\n\\*https://zhuanlan.zhihu.com/p/32364723\n\n[1] Qu, M., Ren, X., Zhang, Y., & Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. *arXiv preprint arXiv:1711.03226*.\n\n[2] Blum, Avrim, and Tom Mitchell. \"Combining labeled and unlabeled data with co-training.\" *Proceedings of the eleventh annual conference on Computational learning theory*. ACM, 1998.\n\n","source":"_posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction.md","raw":"---\ntitle: Overcoming Limited Supervision in Relation Extraction \ndate: 2018-01-04 08:00:00\ncategories: [research]\ntags: [relation-extraction, limited-supervision, weak-supervision]\n---\n\nOvercoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach[1]distributional approachpattern-based approach\n\n![illustration](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201441.jpg)\n\n### 1. Introduction\n\n#### 1.1 Weakly Supervised Learning\n\nseed\n\n\n\n1. \n2. \n3. \n\n#### 1.2 Co-training strategy\n\nco-training[2]\n\nco-training\n\n#### 1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)\n\nREPEL\n\n### 2. Problem definition\n\n\n\n $(e_h, e_t)$$(e_h, e_t, r)$\n\nDRseed$ \\{(e_h^{r(k)}, e_t^{r(k)}, r)\\} _{k=1}^{N_r} $$ \\{(e_h^{r(i)}, e_t^{r(i)}, r)\\} _{i=1}^M $$ r \\in R $$ \\{(e_h^{r(i)}, e_t^{r(i)})\\} _{i=1}^{M_r} $\n\n### 3. REPEL Framework\n\n\n\n\n\n\n$$\nmax_{P,D}O = max_{P,D}\\{O_p + O_d + \\lambda O_i\\}\n$$\nPDOpOdOi\n\n\n\n#### 3.1 Pattern Module\n\nrK\n\npath-based patternmeta pattern\n\n$\\pi$\n$$\nR(\\pi)=\\frac{|G(\\pi)\\cap S_{pair}|}{|G(\\pi)|}\n$$\n$G(\\pi)$$\\pi$$S_{pair}$seedR$\\pi$seedseed\n$$\nO_p = \\sum_{\\pi \\in P}R(\\pi)\n$$\n\n\n- seed\n- RK\n\n#### 3.2 Distributional Module\n\n\n\new\n$$\nP(w|e) =\\frac{exp(x_e*c_w)}{Z}\n$$\n$x_e$ $c_w$word embeddingZ\n$$\nO_{text} = \\sum_{w,e}n_{w,e}log(P(w|e))\n$$\n$n_{w,e}$\n\n\n$$\nL_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2\n$$\n$(x_{e_h} - x_{e_t})$$y_r$r$L_D$1\n$$\nO_{seed} = \\sum_{f\\in S_{pair}} \\sum_{f'\\in(e'_h,e'_t)} {min\\{1, L_D(f|r) - L_D(f'|r)\\}}\n$$\n$(e'_h,e'_t)$$L_D(f'|r)$\n\nOd\n$$\nO_d = O_{text} + \\eta O_{seed}\n$$\n$\\eta$\n\n#### 3.3 Modeling the Module Interaction\n\n$$\nO_i = E_{f\\in G(P)}[L_D(f|r)]\n$$\n\nE\n\nOiPOiG(P)LD\n\n### 4. The Joint Optimization Problem\n\n![algo](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201444.jpg)\n\n\n\nseed$S_{pair}$$G(P)$Eqn.11\n$$\nmax_D \\{ O_d + \\lambda O_i \\} = max_D \\{ O_d + \\lambda E_{f \\in G(P)}[L_D(f|r)] \\}\n$$\n$S_{pair}$Eqn.12\n$$\nmax_P \\{ O_p + \\lambda O_i \\} = max_P \\{ \\sum_{\\pi \\in P}(R(\\pi) + \\lambda E_{f \\in G(\\pi)}[L_D(f|r)]) \\}\n$$\n\n\n### 5. Conclusion\n\n\n\n## Reference\n\n\\*https://zhuanlan.zhihu.com/p/32364723\n\n[1] Qu, M., Ren, X., Zhang, Y., & Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. *arXiv preprint arXiv:1711.03226*.\n\n[2] Blum, Avrim, and Tom Mitchell. \"Combining labeled and unlabeled data with co-training.\" *Proceedings of the eleventh annual conference on Computational learning theory*. ACM, 1998.\n\n","slug":"[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction","published":1,"updated":"2020-11-03T03:26:12.569Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpo0024gwtlezik90yy","content":"<p>Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach[1]distributional approachpattern-based approach</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201441.jpg\" alt=\"illustration\"></p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><h4 id=\"1-1-Weakly-Supervised-Learning\"><a href=\"#1-1-Weakly-Supervised-Learning\" class=\"headerlink\" title=\"1.1 Weakly Supervised Learning\"></a>1.1 Weakly Supervised Learning</h4><p>seed</p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<h4 id=\"1-2-Co-training-strategy\"><a href=\"#1-2-Co-training-strategy\" class=\"headerlink\" title=\"1.2 Co-training strategy\"></a>1.2 Co-training strategy</h4><p>co-training[2]</p>\n<p>co-training</p>\n<h4 id=\"1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding\"><a href=\"#1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding\" class=\"headerlink\" title=\"1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)\"></a>1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)</h4><p>REPEL</p>\n<h3 id=\"2-Problem-definition\"><a href=\"#2-Problem-definition\" class=\"headerlink\" title=\"2. Problem definition\"></a>2. Problem definition</h3><p></p>\n<p> $(e_h, e_t)$$(e_h, e_t, r)$</p>\n<p>DRseed$ {(e_h^{r(k)}, e_t^{r(k)}, r)} _{k=1}^{N_r} $$ {(e_h^{r(i)}, e_t^{r(i)}, r)} _{i=1}^M $$ r \\in R $$ {(e_h^{r(i)}, e_t^{r(i)})} _{i=1}^{M_r} $</p>\n<h3 id=\"3-REPEL-Framework\"><a href=\"#3-REPEL-Framework\" class=\"headerlink\" title=\"3. REPEL Framework\"></a>3. REPEL Framework</h3><p></p>\n<p></p>\n<p><br>$$<br>max_{P,D}O = max_{P,D}{O_p + O_d + \\lambda O_i}<br>$$<br>PDOpOdOi</p>\n<p></p>\n<h4 id=\"3-1-Pattern-Module\"><a href=\"#3-1-Pattern-Module\" class=\"headerlink\" title=\"3.1 Pattern Module\"></a>3.1 Pattern Module</h4><p>rK</p>\n<p>path-based patternmeta pattern</p>\n<p>$\\pi$<br>$$<br>R(\\pi)=\\frac{|G(\\pi)\\cap S_{pair}|}{|G(\\pi)|}<br>$$<br>$G(\\pi)$$\\pi$$S_{pair}$seedR$\\pi$seedseed<br>$$<br>O_p = \\sum_{\\pi \\in P}R(\\pi)<br>$$<br></p>\n<ul>\n<li>seed</li>\n<li>RK</li>\n</ul>\n<h4 id=\"3-2-Distributional-Module\"><a href=\"#3-2-Distributional-Module\" class=\"headerlink\" title=\"3.2 Distributional Module\"></a>3.2 Distributional Module</h4><p></p>\n<p>ew<br>$$<br>P(w|e) =\\frac{exp(x_e*c_w)}{Z}<br>$$<br>$x_e$ $c_w$word embeddingZ<br>$$<br>O_{text} = \\sum_{w,e}n_{w,e}log(P(w|e))<br>$$<br>$n_{w,e}$</p>\n<p><br>$$<br>L_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2<br>$$<br>$(x_{e_h} - x_{e_t})$$y_r$r$L_D$1<br>$$<br>O_{seed} = \\sum_{f\\in S_{pair}} \\sum_{f\\in(e_h,e_t)} {min{1, L_D(f|r) - L_D(f|r)}}<br>$$<br>$(e_h,e_t)$$L_D(f|r)$</p>\n<p>Od<br>$$<br>O_d = O_{text} + \\eta O_{seed}<br>$$<br>$\\eta$</p>\n<h4 id=\"3-3-Modeling-the-Module-Interaction\"><a href=\"#3-3-Modeling-the-Module-Interaction\" class=\"headerlink\" title=\"3.3 Modeling the Module Interaction\"></a>3.3 Modeling the Module Interaction</h4><p>$$<br>O_i = E_{f\\in G(P)}[L_D(f|r)]<br>$$</p>\n<p>E</p>\n<p>OiPOiG(P)LD</p>\n<h3 id=\"4-The-Joint-Optimization-Problem\"><a href=\"#4-The-Joint-Optimization-Problem\" class=\"headerlink\" title=\"4. The Joint Optimization Problem\"></a>4. The Joint Optimization Problem</h3><p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201444.jpg\" alt=\"algo\"></p>\n<p></p>\n<p>seed$S_{pair}$$G(P)$Eqn.11<br>$$<br>max_D { O_d + \\lambda O_i } = max_D { O_d + \\lambda E_{f \\in G(P)}[L_D(f|r)] }<br>$$<br>$S_{pair}$Eqn.12<br>$$<br>max_P { O_p + \\lambda O_i } = max_P { \\sum_{\\pi \\in P}(R(\\pi) + \\lambda E_{f \\in G(\\pi)}[L_D(f|r)]) }<br>$$<br></p>\n<h3 id=\"5-Conclusion\"><a href=\"#5-Conclusion\" class=\"headerlink\" title=\"5. Conclusion\"></a>5. Conclusion</h3><p></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>*<a href=\"https://zhuanlan.zhihu.com/p/32364723\">https://zhuanlan.zhihu.com/p/32364723</a></p>\n<p>[1] Qu, M., Ren, X., Zhang, Y., &amp; Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. <em>arXiv preprint arXiv:1711.03226</em>.</p>\n<p>[2] Blum, Avrim, and Tom Mitchell. Combining labeled and unlabeled data with co-training. <em>Proceedings of the eleventh annual conference on Computational learning theory</em>. ACM, 1998.</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach[1]distributional approachpattern-based approach</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201441.jpg\" alt=\"illustration\"></p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><h4 id=\"1-1-Weakly-Supervised-Learning\"><a href=\"#1-1-Weakly-Supervised-Learning\" class=\"headerlink\" title=\"1.1 Weakly Supervised Learning\"></a>1.1 Weakly Supervised Learning</h4><p>seed</p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<h4 id=\"1-2-Co-training-strategy\"><a href=\"#1-2-Co-training-strategy\" class=\"headerlink\" title=\"1.2 Co-training strategy\"></a>1.2 Co-training strategy</h4><p>co-training[2]</p>\n<p>co-training</p>\n<h4 id=\"1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding\"><a href=\"#1-3-REPEL-Relation-Extraction-with-pattern-enhanced-Embedding\" class=\"headerlink\" title=\"1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)\"></a>1.3 REPEL (Relation Extraction with pattern-enhanced Embedding)</h4><p>REPEL</p>\n<h3 id=\"2-Problem-definition\"><a href=\"#2-Problem-definition\" class=\"headerlink\" title=\"2. Problem definition\"></a>2. Problem definition</h3><p></p>\n<p> $(e_h, e_t)$$(e_h, e_t, r)$</p>\n<p>DRseed$ {(e_h^{r(k)}, e_t^{r(k)}, r)} _{k=1}^{N_r} $$ {(e_h^{r(i)}, e_t^{r(i)}, r)} _{i=1}^M $$ r \\in R $$ {(e_h^{r(i)}, e_t^{r(i)})} _{i=1}^{M_r} $</p>\n<h3 id=\"3-REPEL-Framework\"><a href=\"#3-REPEL-Framework\" class=\"headerlink\" title=\"3. REPEL Framework\"></a>3. REPEL Framework</h3><p></p>\n<p></p>\n<p><br>$$<br>max_{P,D}O = max_{P,D}{O_p + O_d + \\lambda O_i}<br>$$<br>PDOpOdOi</p>\n<p></p>\n<h4 id=\"3-1-Pattern-Module\"><a href=\"#3-1-Pattern-Module\" class=\"headerlink\" title=\"3.1 Pattern Module\"></a>3.1 Pattern Module</h4><p>rK</p>\n<p>path-based patternmeta pattern</p>\n<p>$\\pi$<br>$$<br>R(\\pi)=\\frac{|G(\\pi)\\cap S_{pair}|}{|G(\\pi)|}<br>$$<br>$G(\\pi)$$\\pi$$S_{pair}$seedR$\\pi$seedseed<br>$$<br>O_p = \\sum_{\\pi \\in P}R(\\pi)<br>$$<br></p>\n<ul>\n<li>seed</li>\n<li>RK</li>\n</ul>\n<h4 id=\"3-2-Distributional-Module\"><a href=\"#3-2-Distributional-Module\" class=\"headerlink\" title=\"3.2 Distributional Module\"></a>3.2 Distributional Module</h4><p></p>\n<p>ew<br>$$<br>P(w|e) =\\frac{exp(x_e*c_w)}{Z}<br>$$<br>$x_e$ $c_w$word embeddingZ<br>$$<br>O_{text} = \\sum_{w,e}n_{w,e}log(P(w|e))<br>$$<br>$n_{w,e}$</p>\n<p><br>$$<br>L_D(f|r)=1-||x_{e_h} + y_r- x_{e_t} ||^2_2<br>$$<br>$(x_{e_h} - x_{e_t})$$y_r$r$L_D$1<br>$$<br>O_{seed} = \\sum_{f\\in S_{pair}} \\sum_{f\\in(e_h,e_t)} {min{1, L_D(f|r) - L_D(f|r)}}<br>$$<br>$(e_h,e_t)$$L_D(f|r)$</p>\n<p>Od<br>$$<br>O_d = O_{text} + \\eta O_{seed}<br>$$<br>$\\eta$</p>\n<h4 id=\"3-3-Modeling-the-Module-Interaction\"><a href=\"#3-3-Modeling-the-Module-Interaction\" class=\"headerlink\" title=\"3.3 Modeling the Module Interaction\"></a>3.3 Modeling the Module Interaction</h4><p>$$<br>O_i = E_{f\\in G(P)}[L_D(f|r)]<br>$$</p>\n<p>E</p>\n<p>OiPOiG(P)LD</p>\n<h3 id=\"4-The-Joint-Optimization-Problem\"><a href=\"#4-The-Joint-Optimization-Problem\" class=\"headerlink\" title=\"4. The Joint Optimization Problem\"></a>4. The Joint Optimization Problem</h3><p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-201444.jpg\" alt=\"algo\"></p>\n<p></p>\n<p>seed$S_{pair}$$G(P)$Eqn.11<br>$$<br>max_D { O_d + \\lambda O_i } = max_D { O_d + \\lambda E_{f \\in G(P)}[L_D(f|r)] }<br>$$<br>$S_{pair}$Eqn.12<br>$$<br>max_P { O_p + \\lambda O_i } = max_P { \\sum_{\\pi \\in P}(R(\\pi) + \\lambda E_{f \\in G(\\pi)}[L_D(f|r)]) }<br>$$<br></p>\n<h3 id=\"5-Conclusion\"><a href=\"#5-Conclusion\" class=\"headerlink\" title=\"5. Conclusion\"></a>5. Conclusion</h3><p></p>\n<h2 id=\"Reference\"><a href=\"#Reference\" class=\"headerlink\" title=\"Reference\"></a>Reference</h2><p>*<a href=\"https://zhuanlan.zhihu.com/p/32364723\">https://zhuanlan.zhihu.com/p/32364723</a></p>\n<p>[1] Qu, M., Ren, X., Zhang, Y., &amp; Han, J. (2017). Overcoming Limited Supervision in Relation Extraction: A Pattern-enhanced Distributional Representation Approach. <em>arXiv preprint arXiv:1711.03226</em>.</p>\n<p>[2] Blum, Avrim, and Tom Mitchell. Combining labeled and unlabeled data with co-training. <em>Proceedings of the eleventh annual conference on Computational learning theory</em>. ACM, 1998.</p>\n"},{"title":"Open-World Knowledge Graph Completion ","date":"2018-02-26T00:00:00.000Z","_content":"\n## Open-World Knowledge Graph Completion\n\n****\\[1\\]Closed-World KGC KG KG Open-World KGC  KGConMaskattention\n\n### 1. Introduction\n\nKG $(h,r,t)$ h: head entity, t: tail entity, r: relationKG DBPediaConceptNet KGWikipediaDBPedia4605\n\nKnowledge Graph Completion (KGC)\n\n#### Closed-World KGC\n\nKG $G=(E,R,T)$  $E,R,T$ Closed-World KGC $ T' = \\{ \\langle h,r,t \\rangle|h \\in E, r \\in R, t \\in E, \\langle h,r,t \\rangle \\notin T \\}$  $G$.\n\nClosed-World KGC  $G$  $G$ \n\nClosed-World KGCTranE $h+r=t$  Embedding \n\nKGKG\n\n#### Open-World KGC\n\nKG $G=(E,R,T)$  $E,R,T$ Open-World KGC  $G$ $T' =\\{<h,r,t>|h\\in E^i,r\\in R, t\\in E^i,<h,r,t>\\notin T\\}$  $E^i$ G\n\nClosed-Worldembedding\n\nentity description\n\n1. Closed-world KGCembedding ()Open-World KGCword embeddingentity embeddingword embeddingentities\n2. Open-World KGC\n\n### 2. Closed-World KGC \n\n Closed-World KGC (RL)TransE \\[2\\]. \n$$\nh+r = t\n$$\nhhead entityttail entityr\n\nTransEloss function\n$$\n\\mathcal{L(T)} = \\sum_{<h,r,t>\\in T} [\\gamma + E(\\langle h,r,t \\rangle) - E(\\langle h',r',t' \\rangle)]_+\n$$\n $T$ $E(\\langle h,r,t \\rangle) = ||h+r-t||_{L_n}$energy function$\\langle h,r,t \\rangle$G$h',\\langle r',t' \\rangle$ $T$ $\\langle h,r,t \\rangle$\n\nTransEClosed-World KGC\n\n### 3. ConMask for Open-World KGC\n\n\n\n**** $\\langle \\text{Ameen Sayani, residence, ?}\\rangle$KGAmeen Sayani\n\n****\"... **Ameen Sayani** was introduced to All India Radio, **Bombay**, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years ...\" \n\n****Bombay (or Mumbai)\n\nAmeen SayaniAmeen SayaniAll India RadioBombayAmeen SayaniBombayBombayMumbai\n\n\n\n1. \n2. \n3. \n\nConMask\n\n1. **Relationship-dependent content masking** -- \n2. **Target fusion** -- embedding\n3. **Target entity resolution** -- KG2embedding\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202310.jpg\" width=\"60%\">\n\nConMaskConMaskConMaskFCNword-embeddingembeddingKG\n\n#### 3.1 Relationship-dependent content masking \n\nConMaskcontent-maskingattentionRNN\\[3\\]attention\n\n\n$$\n\\tau(\\phi(e), \\psi(r)) = W_{\\phi(e)} \\circ f_w(W_{\\phi(e)}, W_{\\psi(r)})\n$$\n $e$ $r$ , $\\phi$ description function$\\psi$ name mapping function $ W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding $W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding$\\circ$ row-wise product$f_w$ \n\n$f_w$ Maximal Word-Relationship Weights(MWRW)cos:\n$$\nf_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max_j(\\frac{\\sum_m^k{W_{\\phi(e)[i,m]} W_{\\psi(r)[j,m]}}}{\\sqrt{\\sum_m^k{W^2_{\\phi(e)[i,m]}}}\\sqrt{\\sum_m^k{W^2_{\\psi(e)[j,m]}}}})\n$$\nspousemarriedmarriedspouseMWRWindicator wordbarack obamamarried\n\nword $k_m$  Maximal Context-Relationship Weights (MCRW)\n$$\nf_w^{MCRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max(f_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i-k_m:i]})\n$$\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202313.jpg\">\n\n#### 3.2 Target Fusion\n\nembedding$\\xi$Conetent Masking $\\tau$ \n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202312.jpg\">\n\n**Semantic Averaging**\n\nembeddingTarget fusiontarget fusion\n\nembedding$\\eta(W) = \\frac{1}{k_l}\\sum_i^{k_i}W_i$\n\n#### 3.3 Loss function\n\n list-wise ranking loss function (Shi and Weninger 2017) partial list-wise ranking loss function$E^+$head entitytail entity$E^-$ \n$$\n\\mathcal{L}(h, r, t) =  \\begin{cases}\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h_+,r,t,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c > 0.5; \\\\\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h,r,t_+,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c \\le 0.5; .\n\\end{cases}\n$$\n$p_c$ $[0,1]$0.5tail entity0.5head entityhead entitytail entity50%$S$,  softmax normalized output of ConMask\n$$\nS(h,r,t,E^+) = \\begin{cases}\n\\sum_{e \\in E^\\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} & \\text{if } p_c > 0.5 \\\\\n\\sum_{e \\in E^\\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} & \\text{if } p_c \\le 0.5 \\\\\n\\end{cases}\n$$\n\n### 4. Results\n\nConMaskClosed-WorldConMaskTransETransR\n\nConMask\n\n## Bibliographies\n\nhttps://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178\n\nhttps://github.com/bxshi/ConMask\n\n\\[1\\] Shi, Baoxu, and Tim Weninger. \"Open-World Knowledge Graph Completion.\" *arXiv preprint arXiv:1711.03438* (2017).\n\n\\[2\\] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In *Advances in neural information processing systems* (pp. 2787-2795).\n\n\\[3\\] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., & Bengio, Y. (2015). Attention-based models for speech recognition. In *Advances in neural information processing systems* (pp. 577-585).","source":"_posts/[2018.2.26]Open-World-Knowledge-Graph-Completion.md","raw":"---\ntitle: Open-World Knowledge Graph Completion \ndate: 2018-02-26 08:00:00\ncategories: [research]\ntags: [KGC, CNN, knowledge-graph]\n---\n\n## Open-World Knowledge Graph Completion\n\n****\\[1\\]Closed-World KGC KG KG Open-World KGC  KGConMaskattention\n\n### 1. Introduction\n\nKG $(h,r,t)$ h: head entity, t: tail entity, r: relationKG DBPediaConceptNet KGWikipediaDBPedia4605\n\nKnowledge Graph Completion (KGC)\n\n#### Closed-World KGC\n\nKG $G=(E,R,T)$  $E,R,T$ Closed-World KGC $ T' = \\{ \\langle h,r,t \\rangle|h \\in E, r \\in R, t \\in E, \\langle h,r,t \\rangle \\notin T \\}$  $G$.\n\nClosed-World KGC  $G$  $G$ \n\nClosed-World KGCTranE $h+r=t$  Embedding \n\nKGKG\n\n#### Open-World KGC\n\nKG $G=(E,R,T)$  $E,R,T$ Open-World KGC  $G$ $T' =\\{<h,r,t>|h\\in E^i,r\\in R, t\\in E^i,<h,r,t>\\notin T\\}$  $E^i$ G\n\nClosed-Worldembedding\n\nentity description\n\n1. Closed-world KGCembedding ()Open-World KGCword embeddingentity embeddingword embeddingentities\n2. Open-World KGC\n\n### 2. Closed-World KGC \n\n Closed-World KGC (RL)TransE \\[2\\]. \n$$\nh+r = t\n$$\nhhead entityttail entityr\n\nTransEloss function\n$$\n\\mathcal{L(T)} = \\sum_{<h,r,t>\\in T} [\\gamma + E(\\langle h,r,t \\rangle) - E(\\langle h',r',t' \\rangle)]_+\n$$\n $T$ $E(\\langle h,r,t \\rangle) = ||h+r-t||_{L_n}$energy function$\\langle h,r,t \\rangle$G$h',\\langle r',t' \\rangle$ $T$ $\\langle h,r,t \\rangle$\n\nTransEClosed-World KGC\n\n### 3. ConMask for Open-World KGC\n\n\n\n**** $\\langle \\text{Ameen Sayani, residence, ?}\\rangle$KGAmeen Sayani\n\n****\"... **Ameen Sayani** was introduced to All India Radio, **Bombay**, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years ...\" \n\n****Bombay (or Mumbai)\n\nAmeen SayaniAmeen SayaniAll India RadioBombayAmeen SayaniBombayBombayMumbai\n\n\n\n1. \n2. \n3. \n\nConMask\n\n1. **Relationship-dependent content masking** -- \n2. **Target fusion** -- embedding\n3. **Target entity resolution** -- KG2embedding\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202310.jpg\" width=\"60%\">\n\nConMaskConMaskConMaskFCNword-embeddingembeddingKG\n\n#### 3.1 Relationship-dependent content masking \n\nConMaskcontent-maskingattentionRNN\\[3\\]attention\n\n\n$$\n\\tau(\\phi(e), \\psi(r)) = W_{\\phi(e)} \\circ f_w(W_{\\phi(e)}, W_{\\psi(r)})\n$$\n $e$ $r$ , $\\phi$ description function$\\psi$ name mapping function $ W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding $W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding$\\circ$ row-wise product$f_w$ \n\n$f_w$ Maximal Word-Relationship Weights(MWRW)cos:\n$$\nf_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max_j(\\frac{\\sum_m^k{W_{\\phi(e)[i,m]} W_{\\psi(r)[j,m]}}}{\\sqrt{\\sum_m^k{W^2_{\\phi(e)[i,m]}}}\\sqrt{\\sum_m^k{W^2_{\\psi(e)[j,m]}}}})\n$$\nspousemarriedmarriedspouseMWRWindicator wordbarack obamamarried\n\nword $k_m$  Maximal Context-Relationship Weights (MCRW)\n$$\nf_w^{MCRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i]} =  max(f_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})_{[i-k_m:i]})\n$$\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202313.jpg\">\n\n#### 3.2 Target Fusion\n\nembedding$\\xi$Conetent Masking $\\tau$ \n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202312.jpg\">\n\n**Semantic Averaging**\n\nembeddingTarget fusiontarget fusion\n\nembedding$\\eta(W) = \\frac{1}{k_l}\\sum_i^{k_i}W_i$\n\n#### 3.3 Loss function\n\n list-wise ranking loss function (Shi and Weninger 2017) partial list-wise ranking loss function$E^+$head entitytail entity$E^-$ \n$$\n\\mathcal{L}(h, r, t) =  \\begin{cases}\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h_+,r,t,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c > 0.5; \\\\\n\\sum_{h_+\\in E^+}{-\\frac{log(S(h,r,t_+,E^+\\cup E^-))}{|E^+|}}, & \\text{if }p_c \\le 0.5; .\n\\end{cases}\n$$\n$p_c$ $[0,1]$0.5tail entity0.5head entityhead entitytail entity50%$S$,  softmax normalized output of ConMask\n$$\nS(h,r,t,E^+) = \\begin{cases}\n\\sum_{e \\in E^\\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} & \\text{if } p_c > 0.5 \\\\\n\\sum_{e \\in E^\\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} & \\text{if } p_c \\le 0.5 \\\\\n\\end{cases}\n$$\n\n### 4. Results\n\nConMaskClosed-WorldConMaskTransETransR\n\nConMask\n\n## Bibliographies\n\nhttps://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178\n\nhttps://github.com/bxshi/ConMask\n\n\\[1\\] Shi, Baoxu, and Tim Weninger. \"Open-World Knowledge Graph Completion.\" *arXiv preprint arXiv:1711.03438* (2017).\n\n\\[2\\] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In *Advances in neural information processing systems* (pp. 2787-2795).\n\n\\[3\\] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., & Bengio, Y. (2015). Attention-based models for speech recognition. In *Advances in neural information processing systems* (pp. 577-585).","slug":"[2018.2.26]Open-World-Knowledge-Graph-Completion","published":1,"updated":"2020-11-03T03:26:12.121Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpp0027gwtl4fief2tn","content":"<h2 id=\"Open-World-Knowledge-Graph-Completion\"><a href=\"#Open-World-Knowledge-Graph-Completion\" class=\"headerlink\" title=\"Open-World Knowledge Graph Completion\"></a>Open-World Knowledge Graph Completion</h2><p><strong></strong>[1]Closed-World KGC KG KG Open-World KGC  KGConMaskattention</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>KG $(h,r,t)$ h: head entity, t: tail entity, r: relationKG DBPediaConceptNet KGWikipediaDBPedia4605</p>\n<p>Knowledge Graph Completion (KGC)</p>\n<h4 id=\"Closed-World-KGC\"><a href=\"#Closed-World-KGC\" class=\"headerlink\" title=\"Closed-World KGC\"></a>Closed-World KGC</h4><p>KG $G=(E,R,T)$  $E,R,T$ Closed-World KGC $ T = { \\langle h,r,t \\rangle|h \\in E, r \\in R, t \\in E, \\langle h,r,t \\rangle \\notin T }$  $G$.</p>\n<p>Closed-World KGC  $G$  $G$ </p>\n<p>Closed-World KGCTranE $h+r=t$  Embedding </p>\n<p>KGKG</p>\n<h4 id=\"Open-World-KGC\"><a href=\"#Open-World-KGC\" class=\"headerlink\" title=\"Open-World KGC\"></a>Open-World KGC</h4><p>KG $G=(E,R,T)$  $E,R,T$ Open-World KGC  $G$ $T ={&lt;h,r,t&gt;|h\\in E^i,r\\in R, t\\in E^i,&lt;h,r,t&gt;\\notin T}$  $E^i$ G</p>\n<p>Closed-Worldembedding</p>\n<p>entity description</p>\n<ol>\n<li>Closed-world KGCembedding ()Open-World KGCword embeddingentity embeddingword embeddingentities</li>\n<li>Open-World KGC</li>\n</ol>\n<h3 id=\"2-Closed-World-KGC\"><a href=\"#2-Closed-World-KGC\" class=\"headerlink\" title=\"2. Closed-World KGC\"></a>2. Closed-World KGC</h3><p> Closed-World KGC (RL)TransE [2]. <br>$$<br>h+r = t<br>$$<br>hhead entityttail entityr</p>\n<p>TransEloss function<br>$$<br>\\mathcal{L(T)} = \\sum_{&lt;h,r,t&gt;\\in T} [\\gamma + E(\\langle h,r,t \\rangle) - E(\\langle h,r,t \\rangle)]<em>+<br>$$<br> $T$ $E(\\langle h,r,t \\rangle) = ||h+r-t||</em>{L_n}$energy function$\\langle h,r,t \\rangle$G$h,\\langle r,t \\rangle$ $T$ $\\langle h,r,t \\rangle$</p>\n<p>TransEClosed-World KGC</p>\n<h3 id=\"3-ConMask-for-Open-World-KGC\"><a href=\"#3-ConMask-for-Open-World-KGC\" class=\"headerlink\" title=\"3. ConMask for Open-World KGC\"></a>3. ConMask for Open-World KGC</h3><p></p>\n<p><strong></strong> $\\langle \\text{Ameen Sayani, residence, ?}\\rangle$KGAmeen Sayani</p>\n<p><strong></strong> <strong>Ameen Sayani</strong> was introduced to All India Radio, <strong>Bombay</strong>, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years  </p>\n<p><strong></strong>Bombay (or Mumbai)</p>\n<p>Ameen SayaniAmeen SayaniAll India RadioBombayAmeen SayaniBombayBombayMumbai</p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<p>ConMask</p>\n<ol>\n<li><strong>Relationship-dependent content masking</strong>  </li>\n<li><strong>Target fusion</strong>  embedding</li>\n<li><strong>Target entity resolution</strong>  KG2embedding</li>\n</ol>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202310.jpg\" width=\"60%\">\n\n<p>ConMaskConMaskConMaskFCNword-embeddingembeddingKG</p>\n<h4 id=\"3-1-Relationship-dependent-content-masking\"><a href=\"#3-1-Relationship-dependent-content-masking\" class=\"headerlink\" title=\"3.1 Relationship-dependent content masking\"></a>3.1 Relationship-dependent content masking</h4><p>ConMaskcontent-maskingattentionRNN[3]attention</p>\n<p><br>$$<br>\\tau(\\phi(e), \\psi(r)) = W_{\\phi(e)} \\circ f_w(W_{\\phi(e)}, W_{\\psi(r)})<br>$$<br> $e$ $r$ , $\\phi$ description function$\\psi$ name mapping function $ W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding $W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding$\\circ$ row-wise product$f_w$ </p>\n<p>$f_w$ Maximal Word-Relationship Weights(MWRW)cos:<br>$$<br>f_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})<em>{[i]} =  max_j(\\frac{\\sum_m^k{W</em>{\\phi(e)[i,m]} W_{\\psi(r)[j,m]}}}{\\sqrt{\\sum_m^k{W^2_{\\phi(e)[i,m]}}}\\sqrt{\\sum_m^k{W^2_{\\psi(e)[j,m]}}}})<br>$$<br>spousemarriedmarriedspouseMWRWindicator wordbarack obamamarried</p>\n<p>word $k_m$  Maximal Context-Relationship Weights (MCRW)<br>$$<br>f_w^{MCRW}(W_{\\phi(e)}, W_{\\psi(r)})<em>{[i]} =  max(f_w^{MWRW}(W</em>{\\phi(e)}, W_{\\psi(r)})_{[i-k_m:i]})<br>$$<br><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202313.jpg\"></p>\n<h4 id=\"3-2-Target-Fusion\"><a href=\"#3-2-Target-Fusion\" class=\"headerlink\" title=\"3.2 Target Fusion\"></a>3.2 Target Fusion</h4><p>embedding$\\xi$Conetent Masking $\\tau$ </p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202312.jpg\">\n\n<p><strong>Semantic Averaging</strong></p>\n<p>embeddingTarget fusiontarget fusion</p>\n<p>embedding$\\eta(W) = \\frac{1}{k_l}\\sum_i^{k_i}W_i$</p>\n<h4 id=\"3-3-Loss-function\"><a href=\"#3-3-Loss-function\" class=\"headerlink\" title=\"3.3 Loss function\"></a>3.3 Loss function</h4><p> list-wise ranking loss function (Shi and Weninger 2017) partial list-wise ranking loss function$E^+$head entitytail entity$E^-$ <br>$$<br>\\mathcal{L}(h, r, t) =  \\begin{cases}<br>\\sum_{h_+\\in E^+}{-\\frac{log(S(h_+,r,t,E^+\\cup E^-))}{|E^+|}}, &amp; \\text{if }p_c &gt; 0.5; \\<br>\\sum_{h_+\\in E^+}{-\\frac{log(S(h,r,t_+,E^+\\cup E^-))}{|E^+|}}, &amp; \\text{if }p_c \\le 0.5; .<br>\\end{cases}<br>$$<br>$p_c$ $[0,1]$0.5tail entity0.5head entityhead entitytail entity50%$S$,  softmax normalized output of ConMask<br>$$<br>S(h,r,t,E^+) = \\begin{cases}<br>\\sum_{e \\in E^\\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} &amp; \\text{if } p_c &gt; 0.5 \\<br>\\sum_{e \\in E^\\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} &amp; \\text{if } p_c \\le 0.5 \\<br>\\end{cases}<br>$$</p>\n<h3 id=\"4-Results\"><a href=\"#4-Results\" class=\"headerlink\" title=\"4. Results\"></a>4. Results</h3><p>ConMaskClosed-WorldConMaskTransETransR</p>\n<p>ConMask</p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p><a href=\"https://zhuanlan.zhihu.com/p/33026043%EF%BC%8Chttp://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178\">https://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178</a></p>\n<p><a href=\"https://github.com/bxshi/ConMask\">https://github.com/bxshi/ConMask</a></p>\n<p>[1] Shi, Baoxu, and Tim Weninger. Open-World Knowledge Graph Completion. <em>arXiv preprint arXiv:1711.03438</em> (2017).</p>\n<p>[2] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).</p>\n<p>[3] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., &amp; Bengio, Y. (2015). Attention-based models for speech recognition. In <em>Advances in neural information processing systems</em> (pp. 577-585).</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"Open-World-Knowledge-Graph-Completion\"><a href=\"#Open-World-Knowledge-Graph-Completion\" class=\"headerlink\" title=\"Open-World Knowledge Graph Completion\"></a>Open-World Knowledge Graph Completion</h2><p><strong></strong>[1]Closed-World KGC KG KG Open-World KGC  KGConMaskattention</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>KG $(h,r,t)$ h: head entity, t: tail entity, r: relationKG DBPediaConceptNet KGWikipediaDBPedia4605</p>\n<p>Knowledge Graph Completion (KGC)</p>\n<h4 id=\"Closed-World-KGC\"><a href=\"#Closed-World-KGC\" class=\"headerlink\" title=\"Closed-World KGC\"></a>Closed-World KGC</h4><p>KG $G=(E,R,T)$  $E,R,T$ Closed-World KGC $ T = { \\langle h,r,t \\rangle|h \\in E, r \\in R, t \\in E, \\langle h,r,t \\rangle \\notin T }$  $G$.</p>\n<p>Closed-World KGC  $G$  $G$ </p>\n<p>Closed-World KGCTranE $h+r=t$  Embedding </p>\n<p>KGKG</p>\n<h4 id=\"Open-World-KGC\"><a href=\"#Open-World-KGC\" class=\"headerlink\" title=\"Open-World KGC\"></a>Open-World KGC</h4><p>KG $G=(E,R,T)$  $E,R,T$ Open-World KGC  $G$ $T ={&lt;h,r,t&gt;|h\\in E^i,r\\in R, t\\in E^i,&lt;h,r,t&gt;\\notin T}$  $E^i$ G</p>\n<p>Closed-Worldembedding</p>\n<p>entity description</p>\n<ol>\n<li>Closed-world KGCembedding ()Open-World KGCword embeddingentity embeddingword embeddingentities</li>\n<li>Open-World KGC</li>\n</ol>\n<h3 id=\"2-Closed-World-KGC\"><a href=\"#2-Closed-World-KGC\" class=\"headerlink\" title=\"2. Closed-World KGC\"></a>2. Closed-World KGC</h3><p> Closed-World KGC (RL)TransE [2]. <br>$$<br>h+r = t<br>$$<br>hhead entityttail entityr</p>\n<p>TransEloss function<br>$$<br>\\mathcal{L(T)} = \\sum_{&lt;h,r,t&gt;\\in T} [\\gamma + E(\\langle h,r,t \\rangle) - E(\\langle h,r,t \\rangle)]<em>+<br>$$<br> $T$ $E(\\langle h,r,t \\rangle) = ||h+r-t||</em>{L_n}$energy function$\\langle h,r,t \\rangle$G$h,\\langle r,t \\rangle$ $T$ $\\langle h,r,t \\rangle$</p>\n<p>TransEClosed-World KGC</p>\n<h3 id=\"3-ConMask-for-Open-World-KGC\"><a href=\"#3-ConMask-for-Open-World-KGC\" class=\"headerlink\" title=\"3. ConMask for Open-World KGC\"></a>3. ConMask for Open-World KGC</h3><p></p>\n<p><strong></strong> $\\langle \\text{Ameen Sayani, residence, ?}\\rangle$KGAmeen Sayani</p>\n<p><strong></strong> <strong>Ameen Sayani</strong> was introduced to All India Radio, <strong>Bombay</strong>, by his brother Hamid Sayani. Ameen participated in English programmes there for ten years  </p>\n<p><strong></strong>Bombay (or Mumbai)</p>\n<p>Ameen SayaniAmeen SayaniAll India RadioBombayAmeen SayaniBombayBombayMumbai</p>\n<p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n<p>ConMask</p>\n<ol>\n<li><strong>Relationship-dependent content masking</strong>  </li>\n<li><strong>Target fusion</strong>  embedding</li>\n<li><strong>Target entity resolution</strong>  KG2embedding</li>\n</ol>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202310.jpg\" width=\"60%\">\n\n<p>ConMaskConMaskConMaskFCNword-embeddingembeddingKG</p>\n<h4 id=\"3-1-Relationship-dependent-content-masking\"><a href=\"#3-1-Relationship-dependent-content-masking\" class=\"headerlink\" title=\"3.1 Relationship-dependent content masking\"></a>3.1 Relationship-dependent content masking</h4><p>ConMaskcontent-maskingattentionRNN[3]attention</p>\n<p><br>$$<br>\\tau(\\phi(e), \\psi(r)) = W_{\\phi(e)} \\circ f_w(W_{\\phi(e)}, W_{\\psi(r)})<br>$$<br> $e$ $r$ , $\\phi$ description function$\\psi$ name mapping function $ W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding $W_{\\phi{(e)}} \\in \\mathbb{R}^{|\\phi(r)|\\times k} $ kword-embedding$\\circ$ row-wise product$f_w$ </p>\n<p>$f_w$ Maximal Word-Relationship Weights(MWRW)cos:<br>$$<br>f_w^{MWRW}(W_{\\phi(e)}, W_{\\psi(r)})<em>{[i]} =  max_j(\\frac{\\sum_m^k{W</em>{\\phi(e)[i,m]} W_{\\psi(r)[j,m]}}}{\\sqrt{\\sum_m^k{W^2_{\\phi(e)[i,m]}}}\\sqrt{\\sum_m^k{W^2_{\\psi(e)[j,m]}}}})<br>$$<br>spousemarriedmarriedspouseMWRWindicator wordbarack obamamarried</p>\n<p>word $k_m$  Maximal Context-Relationship Weights (MCRW)<br>$$<br>f_w^{MCRW}(W_{\\phi(e)}, W_{\\psi(r)})<em>{[i]} =  max(f_w^{MWRW}(W</em>{\\phi(e)}, W_{\\psi(r)})_{[i-k_m:i]})<br>$$<br><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202313.jpg\"></p>\n<h4 id=\"3-2-Target-Fusion\"><a href=\"#3-2-Target-Fusion\" class=\"headerlink\" title=\"3.2 Target Fusion\"></a>3.2 Target Fusion</h4><p>embedding$\\xi$Conetent Masking $\\tau$ </p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202312.jpg\">\n\n<p><strong>Semantic Averaging</strong></p>\n<p>embeddingTarget fusiontarget fusion</p>\n<p>embedding$\\eta(W) = \\frac{1}{k_l}\\sum_i^{k_i}W_i$</p>\n<h4 id=\"3-3-Loss-function\"><a href=\"#3-3-Loss-function\" class=\"headerlink\" title=\"3.3 Loss function\"></a>3.3 Loss function</h4><p> list-wise ranking loss function (Shi and Weninger 2017) partial list-wise ranking loss function$E^+$head entitytail entity$E^-$ <br>$$<br>\\mathcal{L}(h, r, t) =  \\begin{cases}<br>\\sum_{h_+\\in E^+}{-\\frac{log(S(h_+,r,t,E^+\\cup E^-))}{|E^+|}}, &amp; \\text{if }p_c &gt; 0.5; \\<br>\\sum_{h_+\\in E^+}{-\\frac{log(S(h,r,t_+,E^+\\cup E^-))}{|E^+|}}, &amp; \\text{if }p_c \\le 0.5; .<br>\\end{cases}<br>$$<br>$p_c$ $[0,1]$0.5tail entity0.5head entityhead entitytail entity50%$S$,  softmax normalized output of ConMask<br>$$<br>S(h,r,t,E^+) = \\begin{cases}<br>\\sum_{e \\in E^\\pm}^{exp(ConMask(h,r,t))}{exp(ConMask(e,r,t))} &amp; \\text{if } p_c &gt; 0.5 \\<br>\\sum_{e \\in E^\\pm}^{exp(ConMask(e,r,t))}{exp(ConMask(h,r,t))} &amp; \\text{if } p_c \\le 0.5 \\<br>\\end{cases}<br>$$</p>\n<h3 id=\"4-Results\"><a href=\"#4-Results\" class=\"headerlink\" title=\"4. Results\"></a>4. Results</h3><p>ConMaskClosed-WorldConMaskTransETransR</p>\n<p>ConMask</p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p><a href=\"https://zhuanlan.zhihu.com/p/33026043%EF%BC%8Chttp://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178\">https://zhuanlan.zhihu.com/p/33026043http://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/79224178</a></p>\n<p><a href=\"https://github.com/bxshi/ConMask\">https://github.com/bxshi/ConMask</a></p>\n<p>[1] Shi, Baoxu, and Tim Weninger. Open-World Knowledge Graph Completion. <em>arXiv preprint arXiv:1711.03438</em> (2017).</p>\n<p>[2] Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).</p>\n<p>[3] Chorowski, J. K., Bahdanau, D., Serdyuk, D., Cho, K., &amp; Bengio, Y. (2015). Attention-based models for speech recognition. In <em>Advances in neural information processing systems</em> (pp. 577-585).</p>\n"},{"title":"Nested LSTMs ","date":"2018-02-05T00:00:00.000Z","_content":"\n## Nested LSTMs\n\n**** Nested LSTMs LSTMLSTMRNNNested LSTMLSTMNLSTMLSTMLSTMNLSTM$c_t^{outer} = f_t \\odot c_{t-1} + i_t \\odot g_t$ $(f_t \\odot c_{t-1}, i_t \\odot g_t)$ LSTMNLSTM $c_t^{outer} = h_t^{inner}$Nested LSTM  LSTM NLSTM  LSTMNested LSTM  LSTM\n\n### 1. Introduction\n\nnlp\n\n#### single-layer LSTM\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202251.jpg\" width=\"90%\">\n\nRNNHochreiter1991Bengio1994RNNHochreiterSchmidhuber1997LSTMLSTM\n\n#### Stacked LSTMs\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202254.jpg\" width=\"60%\">\n\n LSTM  LSTM LSTM\n\nLSTM   \n\n#### Nested LSTMs\n\n NLSTM LSTM  LSTM NLSTM Stacked LSTM Stacked LSTM Nested LSTM NLSTM \n\n### 2. Model of Nested LSTMs\n\nLSTM Nested LSTM gate\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202253.jpg\" width=\"80%\">\n\n#### The architecture\n\n LSTM \n$$\ni_t = \\sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\\\\nf_t = \\sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\\\\nc_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\\\\no_t = \\sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\\\\nh_t = o_t \\odot \\sigma_h(c_t)\n$$\nNested LSTM  $c_t = m_t(f_t\\odot c_{t1}, i_t \\odot g_t)$  LSTM  $c_t$  m  t inner memory $c_t$  $m_{t+1}$ LSTM  Nested LSTM Nested LSTM \n\nNLSTM \n$$\n\\tilde{h}_{t-1} = f_t \\odot c_{t-1} \\\\\n\\tilde{x}_t = i_t \\odot \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c)\n$$\n$c_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) =  \\tilde{h}_{t-1} + \\tilde{x}_t $ LSTM\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202250.jpg\">\n\n*LSTMStacked LSTM  Nested LSTM hcd*\n$$\n\\widetilde{i}_t = \\widetilde{\\sigma}_i (\\widetilde{x}_t \\widetilde{W}_{xi} + \\widetilde{h}_{t-1} \\widetilde{W}_{hi} + \\widetilde{b}_i) \\\\\n\\widetilde{f}_t = \\widetilde{\\sigma}_t (\\widetilde{x}_t \\widetilde{W}_{xf} + \\widetilde{h}_{t-1} \\widetilde{W}_{hf} + \\widetilde{b}_i) \\\\\n\\widetilde{c}_t = \\widetilde{f}_t \\odot \\widetilde{c}_{c-1} + \\widetilde{\\sigma}_c (\\widetilde{x}_t \\widetilde{W}_{xc} + \\widetilde{h}_{t-1} \\widetilde{W}_{hc} + \\widetilde{b}_c) \\\\\n\\widetilde{o_t} = \\widetilde{\\sigma}_o (\\widetilde{x}_t \\widetilde{W}_{xo} + \\widetilde{h}_{t-1} \\widetilde{W}_{ho} + \\widetilde{b}_o) \\\\\n\\widetilde{h}_t = \\widetilde{o}_t \\odot \\widetilde{\\sigma}_h(\\widetilde{c}_t)\n$$\n LSTM  $ c_t = \\tilde{h}_{t} $ \n\n### 3. Experiments\n\n[1]\n\n### 4. Conclusion\n\nNested LSTMNLSTMLSTM NLSTM\n\n[1]Nested LSTM Stacked LSTMsingle-layer LSTMStacked LSTM LSTM \n\n[NLSTMTensorflow](https://github.com/hannw/nlstm)\n\n[NLSTMKeras](https://github.com/titu1994/Nested-LSTM)\n\n\n\n## Bibliographies\n\nhttp://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&type=title\n\n[1] Moniz, Joel Ruben Antony, and David Krueger. \"Nested LSTMs.\" *Asian Conference on Machine Learning*. 2017.\n\n[2] Hochreiter, Sepp, and Jrgen Schmidhuber. \"Long short-term memory.\" *Neural computation* 9.8 (1997): 1735-1780.\n\n","source":"_posts/[2018.2.5]Nested-LSTMs.md","raw":"---\ntitle: Nested LSTMs \ndate: 2018-02-05 08:00:00\ncategories: [research]\ntags: [LSTM, RNN]\n---\n\n## Nested LSTMs\n\n**** Nested LSTMs LSTMLSTMRNNNested LSTMLSTMNLSTMLSTMLSTMNLSTM$c_t^{outer} = f_t \\odot c_{t-1} + i_t \\odot g_t$ $(f_t \\odot c_{t-1}, i_t \\odot g_t)$ LSTMNLSTM $c_t^{outer} = h_t^{inner}$Nested LSTM  LSTM NLSTM  LSTMNested LSTM  LSTM\n\n### 1. Introduction\n\nnlp\n\n#### single-layer LSTM\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202251.jpg\" width=\"90%\">\n\nRNNHochreiter1991Bengio1994RNNHochreiterSchmidhuber1997LSTMLSTM\n\n#### Stacked LSTMs\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202254.jpg\" width=\"60%\">\n\n LSTM  LSTM LSTM\n\nLSTM   \n\n#### Nested LSTMs\n\n NLSTM LSTM  LSTM NLSTM Stacked LSTM Stacked LSTM Nested LSTM NLSTM \n\n### 2. Model of Nested LSTMs\n\nLSTM Nested LSTM gate\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202253.jpg\" width=\"80%\">\n\n#### The architecture\n\n LSTM \n$$\ni_t = \\sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\\\\nf_t = \\sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\\\\nc_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\\\\no_t = \\sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\\\\nh_t = o_t \\odot \\sigma_h(c_t)\n$$\nNested LSTM  $c_t = m_t(f_t\\odot c_{t1}, i_t \\odot g_t)$  LSTM  $c_t$  m  t inner memory $c_t$  $m_{t+1}$ LSTM  Nested LSTM Nested LSTM \n\nNLSTM \n$$\n\\tilde{h}_{t-1} = f_t \\odot c_{t-1} \\\\\n\\tilde{x}_t = i_t \\odot \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c)\n$$\n$c_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) =  \\tilde{h}_{t-1} + \\tilde{x}_t $ LSTM\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202250.jpg\">\n\n*LSTMStacked LSTM  Nested LSTM hcd*\n$$\n\\widetilde{i}_t = \\widetilde{\\sigma}_i (\\widetilde{x}_t \\widetilde{W}_{xi} + \\widetilde{h}_{t-1} \\widetilde{W}_{hi} + \\widetilde{b}_i) \\\\\n\\widetilde{f}_t = \\widetilde{\\sigma}_t (\\widetilde{x}_t \\widetilde{W}_{xf} + \\widetilde{h}_{t-1} \\widetilde{W}_{hf} + \\widetilde{b}_i) \\\\\n\\widetilde{c}_t = \\widetilde{f}_t \\odot \\widetilde{c}_{c-1} + \\widetilde{\\sigma}_c (\\widetilde{x}_t \\widetilde{W}_{xc} + \\widetilde{h}_{t-1} \\widetilde{W}_{hc} + \\widetilde{b}_c) \\\\\n\\widetilde{o_t} = \\widetilde{\\sigma}_o (\\widetilde{x}_t \\widetilde{W}_{xo} + \\widetilde{h}_{t-1} \\widetilde{W}_{ho} + \\widetilde{b}_o) \\\\\n\\widetilde{h}_t = \\widetilde{o}_t \\odot \\widetilde{\\sigma}_h(\\widetilde{c}_t)\n$$\n LSTM  $ c_t = \\tilde{h}_{t} $ \n\n### 3. Experiments\n\n[1]\n\n### 4. Conclusion\n\nNested LSTMNLSTMLSTM NLSTM\n\n[1]Nested LSTM Stacked LSTMsingle-layer LSTMStacked LSTM LSTM \n\n[NLSTMTensorflow](https://github.com/hannw/nlstm)\n\n[NLSTMKeras](https://github.com/titu1994/Nested-LSTM)\n\n\n\n## Bibliographies\n\nhttp://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&type=title\n\n[1] Moniz, Joel Ruben Antony, and David Krueger. \"Nested LSTMs.\" *Asian Conference on Machine Learning*. 2017.\n\n[2] Hochreiter, Sepp, and Jrgen Schmidhuber. \"Long short-term memory.\" *Neural computation* 9.8 (1997): 1735-1780.\n\n","slug":"[2018.2.5]Nested-LSTMs","published":1,"updated":"2020-11-03T03:26:11.654Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpq0029gwtlb95sfef3","content":"<h2 id=\"Nested-LSTMs\"><a href=\"#Nested-LSTMs\" class=\"headerlink\" title=\"Nested LSTMs\"></a>Nested LSTMs</h2><p><strong></strong> Nested LSTMs LSTMLSTMRNNNested LSTMLSTMNLSTMLSTMLSTMNLSTM$c_t^{outer} = f_t \\odot c_{t-1} + i_t \\odot g_t$ $(f_t \\odot c_{t-1}, i_t \\odot g_t)$ LSTMNLSTM $c_t^{outer} = h_t^{inner}$Nested LSTM  LSTM NLSTM  LSTMNested LSTM  LSTM</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>nlp</p>\n<h4 id=\"single-layer-LSTM\"><a href=\"#single-layer-LSTM\" class=\"headerlink\" title=\"single-layer LSTM\"></a>single-layer LSTM</h4><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202251.jpg\" width=\"90%\">\n\n<p>RNNHochreiter1991Bengio1994RNNHochreiterSchmidhuber1997LSTMLSTM</p>\n<h4 id=\"Stacked-LSTMs\"><a href=\"#Stacked-LSTMs\" class=\"headerlink\" title=\"Stacked LSTMs\"></a>Stacked LSTMs</h4><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202254.jpg\" width=\"60%\">\n\n<p> LSTM  LSTM LSTM</p>\n<p>LSTM   </p>\n<h4 id=\"Nested-LSTMs-1\"><a href=\"#Nested-LSTMs-1\" class=\"headerlink\" title=\"Nested LSTMs\"></a>Nested LSTMs</h4><p> NLSTM LSTM  LSTM NLSTM Stacked LSTM Stacked LSTM Nested LSTM NLSTM </p>\n<h3 id=\"2-Model-of-Nested-LSTMs\"><a href=\"#2-Model-of-Nested-LSTMs\" class=\"headerlink\" title=\"2. Model of Nested LSTMs\"></a>2. Model of Nested LSTMs</h3><p>LSTM Nested LSTM gate</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202253.jpg\" width=\"80%\">\n\n<h4 id=\"The-architecture\"><a href=\"#The-architecture\" class=\"headerlink\" title=\"The architecture\"></a>The architecture</h4><p> LSTM <br>$$<br>i_t = \\sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\<br>f_t = \\sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\<br>c_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\<br>o_t = \\sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\<br>h_t = o_t \\odot \\sigma_h(c_t)<br>$$<br>Nested LSTM  $c_t = m_t(f_t\\odot c_{t1}, i_t \\odot g_t)$  LSTM  $c_t$  m  t inner memory $c_t$  $m_{t+1}$ LSTM  Nested LSTM Nested LSTM </p>\n<p>NLSTM <br>$$<br>\\tilde{h}<em>{t-1} = f_t \\odot c</em>{t-1} \\<br>\\tilde{x}<em>t = i_t \\odot \\sigma_c (x_t W</em>{xc} + h_{t-1} W_{hc} + b_c)<br>$$<br>$c_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) =  \\tilde{h}_{t-1} + \\tilde{x}_t $ LSTM</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202250.jpg\">\n\n<p><em>LSTMStacked LSTM  Nested LSTM hcd</em><br>$$<br>\\widetilde{i}<em>t = \\widetilde{\\sigma}<em>i (\\widetilde{x}<em>t \\widetilde{W}</em>{xi} + \\widetilde{h}</em>{t-1} \\widetilde{W}</em>{hi} + \\widetilde{b}_i) \\<br>\\widetilde{f}<em>t = \\widetilde{\\sigma}<em>t (\\widetilde{x}<em>t \\widetilde{W}</em>{xf} + \\widetilde{h}</em>{t-1} \\widetilde{W}</em>{hf} + \\widetilde{b}_i) \\<br>\\widetilde{c}<em>t = \\widetilde{f}<em>t \\odot \\widetilde{c}</em>{c-1} + \\widetilde{\\sigma}<em>c (\\widetilde{x}<em>t \\widetilde{W}</em>{xc} + \\widetilde{h}</em>{t-1} \\widetilde{W}</em>{hc} + \\widetilde{b}<em>c) \\<br>\\widetilde{o_t} = \\widetilde{\\sigma}<em>o (\\widetilde{x}<em>t \\widetilde{W}</em>{xo} + \\widetilde{h}</em>{t-1} \\widetilde{W}</em>{ho} + \\widetilde{b}_o) \\<br>\\widetilde{h}_t = \\widetilde{o}_t \\odot \\widetilde{\\sigma}_h(\\widetilde{c}<em>t)<br>$$<br> LSTM  $ c_t = \\tilde{h}</em>{t} $ </p>\n<h3 id=\"3-Experiments\"><a href=\"#3-Experiments\" class=\"headerlink\" title=\"3. Experiments\"></a>3. Experiments</h3><p>[1]</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>Nested LSTMNLSTMLSTM NLSTM</p>\n<p>[1]Nested LSTM Stacked LSTMsingle-layer LSTMStacked LSTM LSTM </p>\n<p><a href=\"https://github.com/hannw/nlstm\">NLSTMTensorflow</a></p>\n<p><a href=\"https://github.com/titu1994/Nested-LSTM\">NLSTMKeras</a></p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p><a href=\"http://www.sohu.com/a/220745456_390227%EF%BC%8Chttp://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title\">http://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title</a></p>\n<p>[1] Moniz, Joel Ruben Antony, and David Krueger. Nested LSTMs. <em>Asian Conference on Machine Learning</em>. 2017.</p>\n<p>[2] Hochreiter, Sepp, and Jrgen Schmidhuber. Long short-term memory. <em>Neural computation</em> 9.8 (1997): 1735-1780.</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"Nested-LSTMs\"><a href=\"#Nested-LSTMs\" class=\"headerlink\" title=\"Nested LSTMs\"></a>Nested LSTMs</h2><p><strong></strong> Nested LSTMs LSTMLSTMRNNNested LSTMLSTMNLSTMLSTMLSTMNLSTM$c_t^{outer} = f_t \\odot c_{t-1} + i_t \\odot g_t$ $(f_t \\odot c_{t-1}, i_t \\odot g_t)$ LSTMNLSTM $c_t^{outer} = h_t^{inner}$Nested LSTM  LSTM NLSTM  LSTMNested LSTM  LSTM</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>nlp</p>\n<h4 id=\"single-layer-LSTM\"><a href=\"#single-layer-LSTM\" class=\"headerlink\" title=\"single-layer LSTM\"></a>single-layer LSTM</h4><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202251.jpg\" width=\"90%\">\n\n<p>RNNHochreiter1991Bengio1994RNNHochreiterSchmidhuber1997LSTMLSTM</p>\n<h4 id=\"Stacked-LSTMs\"><a href=\"#Stacked-LSTMs\" class=\"headerlink\" title=\"Stacked LSTMs\"></a>Stacked LSTMs</h4><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202254.jpg\" width=\"60%\">\n\n<p> LSTM  LSTM LSTM</p>\n<p>LSTM   </p>\n<h4 id=\"Nested-LSTMs-1\"><a href=\"#Nested-LSTMs-1\" class=\"headerlink\" title=\"Nested LSTMs\"></a>Nested LSTMs</h4><p> NLSTM LSTM  LSTM NLSTM Stacked LSTM Stacked LSTM Nested LSTM NLSTM </p>\n<h3 id=\"2-Model-of-Nested-LSTMs\"><a href=\"#2-Model-of-Nested-LSTMs\" class=\"headerlink\" title=\"2. Model of Nested LSTMs\"></a>2. Model of Nested LSTMs</h3><p>LSTM Nested LSTM gate</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202253.jpg\" width=\"80%\">\n\n<h4 id=\"The-architecture\"><a href=\"#The-architecture\" class=\"headerlink\" title=\"The architecture\"></a>The architecture</h4><p> LSTM <br>$$<br>i_t = \\sigma_i (x_t W_{xi} + h_{t-1} W_{hi} + b_i) \\<br>f_t = \\sigma_t (x_t W_{xf} + h_{t-1} W_{hf} + b_i) \\<br>c_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) \\<br>o_t = \\sigma_o (x_t W_{xo} + h_{t-1} W_{ho} + b_o) \\<br>h_t = o_t \\odot \\sigma_h(c_t)<br>$$<br>Nested LSTM  $c_t = m_t(f_t\\odot c_{t1}, i_t \\odot g_t)$  LSTM  $c_t$  m  t inner memory $c_t$  $m_{t+1}$ LSTM  Nested LSTM Nested LSTM </p>\n<p>NLSTM <br>$$<br>\\tilde{h}<em>{t-1} = f_t \\odot c</em>{t-1} \\<br>\\tilde{x}<em>t = i_t \\odot \\sigma_c (x_t W</em>{xc} + h_{t-1} W_{hc} + b_c)<br>$$<br>$c_t = f_t \\odot c_{c-1} + \\sigma_c (x_t W_{xc} + h_{t-1} W_{hc} + b_c) =  \\tilde{h}_{t-1} + \\tilde{x}_t $ LSTM</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202250.jpg\">\n\n<p><em>LSTMStacked LSTM  Nested LSTM hcd</em><br>$$<br>\\widetilde{i}<em>t = \\widetilde{\\sigma}<em>i (\\widetilde{x}<em>t \\widetilde{W}</em>{xi} + \\widetilde{h}</em>{t-1} \\widetilde{W}</em>{hi} + \\widetilde{b}_i) \\<br>\\widetilde{f}<em>t = \\widetilde{\\sigma}<em>t (\\widetilde{x}<em>t \\widetilde{W}</em>{xf} + \\widetilde{h}</em>{t-1} \\widetilde{W}</em>{hf} + \\widetilde{b}_i) \\<br>\\widetilde{c}<em>t = \\widetilde{f}<em>t \\odot \\widetilde{c}</em>{c-1} + \\widetilde{\\sigma}<em>c (\\widetilde{x}<em>t \\widetilde{W}</em>{xc} + \\widetilde{h}</em>{t-1} \\widetilde{W}</em>{hc} + \\widetilde{b}<em>c) \\<br>\\widetilde{o_t} = \\widetilde{\\sigma}<em>o (\\widetilde{x}<em>t \\widetilde{W}</em>{xo} + \\widetilde{h}</em>{t-1} \\widetilde{W}</em>{ho} + \\widetilde{b}_o) \\<br>\\widetilde{h}_t = \\widetilde{o}_t \\odot \\widetilde{\\sigma}_h(\\widetilde{c}<em>t)<br>$$<br> LSTM  $ c_t = \\tilde{h}</em>{t} $ </p>\n<h3 id=\"3-Experiments\"><a href=\"#3-Experiments\" class=\"headerlink\" title=\"3. Experiments\"></a>3. Experiments</h3><p>[1]</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>Nested LSTMNLSTMLSTM NLSTM</p>\n<p>[1]Nested LSTM Stacked LSTMsingle-layer LSTMStacked LSTM LSTM </p>\n<p><a href=\"https://github.com/hannw/nlstm\">NLSTMTensorflow</a></p>\n<p><a href=\"https://github.com/titu1994/Nested-LSTM\">NLSTMKeras</a></p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p><a href=\"http://www.sohu.com/a/220745456_390227%EF%BC%8Chttp://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title\">http://www.sohu.com/a/220745456_390227http://posts.careerengine.us/p/5a768ab3381fe136215b3de5?from=latest-posts-panel&amp;type=title</a></p>\n<p>[1] Moniz, Joel Ruben Antony, and David Krueger. Nested LSTMs. <em>Asian Conference on Machine Learning</em>. 2017.</p>\n<p>[2] Hochreiter, Sepp, and Jrgen Schmidhuber. Long short-term memory. <em>Neural computation</em> 9.8 (1997): 1735-1780.</p>\n"},{"title":"Several models for knowledge graph representing and completing ","date":"2018-03-10T00:00:00.000Z","_content":"\n# 2018.3.10\n\n## Several models for knowledge graph representing and completing\n\n****ConMaskknowledge graph completion\n\n### 1. Series of Trans\n\n#### 1.1 TransE \n\nTransE [^1] (RL). \n$$\nh+r = t\n$$\nhhead entityttail entityr\n\nTransEloss function\n$$\n\\mathcal{L(T)} = \\sum_{<h,r,t>\\in T} [\\gamma + E(<h,r,t>) - E(<h',r',t'>)]_+\n$$\n $T$ $E(<h,r,t>) = ||h+r-t||_{L_n}$energy function$<h,r,t>$G$<h',r',t'>$ $T$ $<h,r,t>$$\\gamma$ \n\n h+r-t  0 h+r-t  TransE  hinge loss function  SGD(Stochastic Gradient Descent) \n\nTransE\n\n#### 1.2 TransH\n\n TransE TransH [^2]  h+r-l=0\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202332.jpg\">\n\nhead tail\n\n\n\n#### 1.3 TransR/CTrans \n\nTransETransHembeddingTransR[^3]**r**mapping$M_r$\n$$\nh_{\\perp} + r \\simeq t_{\\perp} \\quad \\text{where } h_{\\perp} = M_{r}\\cdot h, t_{\\perp} = M_{r} \\cdot t\n$$\nTransE\n\n#### 1.4 TransD\n\nTransD[^4]TransR/CTransTransR\n\n- rmapping$M_{r}$r\n- mappingentityrelationmapping\n- Knowledge graphrelationknowledge graph\n\nentityrelationTransDentityrelationentityrelationmappingentity-relation pairmapping\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202326.jpg\">\n\nTransD\n\n#### 1.5 TransA\n\nentityrelation\n\nTransA[^5] \n\nTransA\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202330.jpg\">\n\n\n\n### 2. ProjE\n\nProjE[^6]Open-World Knowledge Graph CompletionAAAI2017AAAI2018KGC state-of-the-artProjE\n\n#### 2.1 Model Architecture\n\n\\<h, r, ?\\>hr ? entityhrentity\n\ntransmappingentityrelationmapping\n$$\ne \\oplus r = D_e e + D_r r + b_c\n$$\n$D_e$$D_r$\n\nembedding\n$$\nh(e, r) = g(W^c f(e \\oplus r) + b_r )\n$$\nfg(activation function)$W^c$entityhentity\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202328.jpg\">\n\nProjE$e \\oplus r$$h(e,r)$\n\n#### 2.2 Loss function\n\npointwise loss function\n$$\n\\mathcal{L}(e, r, y) = - \\sum_{i\\in\\{i|y_i=1\\} } {log(h(e,r)_i)} - \\sum_{m} {\\mathbb{E}_{j \\sim P_y} log(h(e,r)_j)}\n$$\n$y$10mpointwise ProjE  f  g  sigmoid  tanh \n\n https://github.com/bxshi/ProjE\n\n## Bibliographies\n\n\n\nhttp://www.infosec-wiki.com/?p=175755\n\nhttps://www.jiqizhixin.com/articles/2017-11-03-5\n\n[^1]: Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In *Advances in neural information processing systems* (pp. 2787-2795).\n[^2]: Wang, Z., Zhang, J., Feng, J., & Chen, Z. (2014, July). Knowledge Graph Embedding by Translating on Hyperplanes. In *AAAI* (Vol. 14, pp. 1112-1119).\n\n[^3]: Lin, Y., Liu, Z., Sun, M., Liu, Y., & Zhu, X. (2015, January). Learning entity and relation embeddings for knowledge graph completion. In *AAAI* (Vol. 15, pp. 2181-2187).\n[^4]: Ji, G., He, S., Xu, L., Liu, K., & Zhao, J. (2015). Knowledge graph embedding via dynamic mapping matrix. In *Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)* (Vol. 1, pp. 687-696).\n[^5]: Xiao, H., Huang, M., Hao, Y., & Zhu, X. (2015). TransA: An adaptive approach for knowledge graph embedding. *arXiv preprint arXiv:1509.05490*.\n[^6]: Shi, B., & Weninger, T. (2017, February). ProjE: Embedding Projection for Knowledge Graph Completion. In *AAAI* (Vol. 17, pp. 1236-1242).","source":"_posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing.md","raw":"---\ntitle: Several models for knowledge graph representing and completing \ndate: 2018-03-10 08:00:00\ncategories: [research]\ntags: [KGC, knowledge-graph]\n---\n\n# 2018.3.10\n\n## Several models for knowledge graph representing and completing\n\n****ConMaskknowledge graph completion\n\n### 1. Series of Trans\n\n#### 1.1 TransE \n\nTransE [^1] (RL). \n$$\nh+r = t\n$$\nhhead entityttail entityr\n\nTransEloss function\n$$\n\\mathcal{L(T)} = \\sum_{<h,r,t>\\in T} [\\gamma + E(<h,r,t>) - E(<h',r',t'>)]_+\n$$\n $T$ $E(<h,r,t>) = ||h+r-t||_{L_n}$energy function$<h,r,t>$G$<h',r',t'>$ $T$ $<h,r,t>$$\\gamma$ \n\n h+r-t  0 h+r-t  TransE  hinge loss function  SGD(Stochastic Gradient Descent) \n\nTransE\n\n#### 1.2 TransH\n\n TransE TransH [^2]  h+r-l=0\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202332.jpg\">\n\nhead tail\n\n\n\n#### 1.3 TransR/CTrans \n\nTransETransHembeddingTransR[^3]**r**mapping$M_r$\n$$\nh_{\\perp} + r \\simeq t_{\\perp} \\quad \\text{where } h_{\\perp} = M_{r}\\cdot h, t_{\\perp} = M_{r} \\cdot t\n$$\nTransE\n\n#### 1.4 TransD\n\nTransD[^4]TransR/CTransTransR\n\n- rmapping$M_{r}$r\n- mappingentityrelationmapping\n- Knowledge graphrelationknowledge graph\n\nentityrelationTransDentityrelationentityrelationmappingentity-relation pairmapping\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202326.jpg\">\n\nTransD\n\n#### 1.5 TransA\n\nentityrelation\n\nTransA[^5] \n\nTransA\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202330.jpg\">\n\n\n\n### 2. ProjE\n\nProjE[^6]Open-World Knowledge Graph CompletionAAAI2017AAAI2018KGC state-of-the-artProjE\n\n#### 2.1 Model Architecture\n\n\\<h, r, ?\\>hr ? entityhrentity\n\ntransmappingentityrelationmapping\n$$\ne \\oplus r = D_e e + D_r r + b_c\n$$\n$D_e$$D_r$\n\nembedding\n$$\nh(e, r) = g(W^c f(e \\oplus r) + b_r )\n$$\nfg(activation function)$W^c$entityhentity\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202328.jpg\">\n\nProjE$e \\oplus r$$h(e,r)$\n\n#### 2.2 Loss function\n\npointwise loss function\n$$\n\\mathcal{L}(e, r, y) = - \\sum_{i\\in\\{i|y_i=1\\} } {log(h(e,r)_i)} - \\sum_{m} {\\mathbb{E}_{j \\sim P_y} log(h(e,r)_j)}\n$$\n$y$10mpointwise ProjE  f  g  sigmoid  tanh \n\n https://github.com/bxshi/ProjE\n\n## Bibliographies\n\n\n\nhttp://www.infosec-wiki.com/?p=175755\n\nhttps://www.jiqizhixin.com/articles/2017-11-03-5\n\n[^1]: Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., & Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In *Advances in neural information processing systems* (pp. 2787-2795).\n[^2]: Wang, Z., Zhang, J., Feng, J., & Chen, Z. (2014, July). Knowledge Graph Embedding by Translating on Hyperplanes. In *AAAI* (Vol. 14, pp. 1112-1119).\n\n[^3]: Lin, Y., Liu, Z., Sun, M., Liu, Y., & Zhu, X. (2015, January). Learning entity and relation embeddings for knowledge graph completion. In *AAAI* (Vol. 15, pp. 2181-2187).\n[^4]: Ji, G., He, S., Xu, L., Liu, K., & Zhao, J. (2015). Knowledge graph embedding via dynamic mapping matrix. In *Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)* (Vol. 1, pp. 687-696).\n[^5]: Xiao, H., Huang, M., Hao, Y., & Zhu, X. (2015). TransA: An adaptive approach for knowledge graph embedding. *arXiv preprint arXiv:1509.05490*.\n[^6]: Shi, B., & Weninger, T. (2017, February). ProjE: Embedding Projection for Knowledge Graph Completion. In *AAAI* (Vol. 17, pp. 1236-1242).","slug":"[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing","published":1,"updated":"2020-11-03T03:26:11.105Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpr002dgwtl3nxy0i7w","content":"<h1 id=\"2018-3-10\"><a href=\"#2018-3-10\" class=\"headerlink\" title=\"2018.3.10\"></a>2018.3.10</h1><h2 id=\"Several-models-for-knowledge-graph-representing-and-completing\"><a href=\"#Several-models-for-knowledge-graph-representing-and-completing\" class=\"headerlink\" title=\"Several models for knowledge graph representing and completing\"></a>Several models for knowledge graph representing and completing</h2><p><strong></strong>ConMaskknowledge graph completion</p>\n<h3 id=\"1-Series-of-Trans\"><a href=\"#1-Series-of-Trans\" class=\"headerlink\" title=\"1. Series of Trans\"></a>1. Series of Trans</h3><h4 id=\"1-1-TransE\"><a href=\"#1-1-TransE\" class=\"headerlink\" title=\"1.1 TransE\"></a>1.1 TransE</h4><p>TransE [^1] (RL). <br>$$<br>h+r = t<br>$$<br>hhead entityttail entityr</p>\n<p>TransEloss function<br>$$<br>\\mathcal{L(T)} = \\sum_{&lt;h,r,t&gt;\\in T} [\\gamma + E(&lt;h,r,t&gt;) - E(&lt;h,r,t&gt;)]<em>+<br>$$<br> $T$ $E(&lt;h,r,t&gt;) = ||h+r-t||</em>{L_n}$energy function$&lt;h,r,t&gt;$G$&lt;h,r,t&gt;$ $T$ $&lt;h,r,t&gt;$$\\gamma$ </p>\n<p> h+r-t  0 h+r-t  TransE  hinge loss function  SGD(Stochastic Gradient Descent) </p>\n<p>TransE</p>\n<h4 id=\"1-2-TransH\"><a href=\"#1-2-TransH\" class=\"headerlink\" title=\"1.2 TransH\"></a>1.2 TransH</h4><p> TransE TransH [^2]  h+r-l=0</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202332.jpg\">\n\n<p>head tail</p>\n<h4 id=\"1-3-TransR-CTrans\"><a href=\"#1-3-TransR-CTrans\" class=\"headerlink\" title=\"1.3 TransR/CTrans\"></a>1.3 TransR/CTrans</h4><p>TransETransHembeddingTransR[^3]<strong>r</strong>mapping$M_r$<br>$$<br>h_{\\perp} + r \\simeq t_{\\perp} \\quad \\text{where } h_{\\perp} = M_{r}\\cdot h, t_{\\perp} = M_{r} \\cdot t<br>$$<br>TransE</p>\n<h4 id=\"1-4-TransD\"><a href=\"#1-4-TransD\" class=\"headerlink\" title=\"1.4 TransD\"></a>1.4 TransD</h4><p>TransD[^4]TransR/CTransTransR</p>\n<ul>\n<li>rmapping$M_{r}$r</li>\n<li>mappingentityrelationmapping</li>\n<li>Knowledge graphrelationknowledge graph</li>\n</ul>\n<p>entityrelationTransDentityrelationentityrelationmappingentity-relation pairmapping</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202326.jpg\">\n\n<p>TransD</p>\n<h4 id=\"1-5-TransA\"><a href=\"#1-5-TransA\" class=\"headerlink\" title=\"1.5 TransA\"></a>1.5 TransA</h4><p>entityrelation</p>\n<p>TransA[^5] </p>\n<p>TransA</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202330.jpg\">\n\n\n\n<h3 id=\"2-ProjE\"><a href=\"#2-ProjE\" class=\"headerlink\" title=\"2. ProjE\"></a>2. ProjE</h3><p>ProjE[^6]Open-World Knowledge Graph CompletionAAAI2017AAAI2018KGC state-of-the-artProjE</p>\n<h4 id=\"2-1-Model-Architecture\"><a href=\"#2-1-Model-Architecture\" class=\"headerlink\" title=\"2.1 Model Architecture\"></a>2.1 Model Architecture</h4><p>&lt;h, r, ?&gt;hr ? entityhrentity</p>\n<p>transmappingentityrelationmapping<br>$$<br>e \\oplus r = D_e e + D_r r + b_c<br>$$<br>$D_e$$D_r$</p>\n<p>embedding<br>$$<br>h(e, r) = g(W^c f(e \\oplus r) + b_r )<br>$$<br>fg(activation function)$W^c$entityhentity</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202328.jpg\">\n\n<p>ProjE$e \\oplus r$$h(e,r)$</p>\n<h4 id=\"2-2-Loss-function\"><a href=\"#2-2-Loss-function\" class=\"headerlink\" title=\"2.2 Loss function\"></a>2.2 Loss function</h4><p>pointwise loss function<br>$$<br>\\mathcal{L}(e, r, y) = - \\sum_{i\\in{i|y_i=1} } {log(h(e,r)<em>i)} - \\sum</em>{m} {\\mathbb{E}_{j \\sim P_y} log(h(e,r)_j)}<br>$$<br>$y$10mpointwise ProjE  f  g  sigmoid  tanh </p>\n<p> <a href=\"https://github.com/bxshi/ProjE\">https://github.com/bxshi/ProjE</a></p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p></p>\n<p><a href=\"http://www.infosec-wiki.com/?p=175755\">http://www.infosec-wiki.com/?p=175755</a></p>\n<p><a href=\"https://www.jiqizhixin.com/articles/2017-11-03-5\">https://www.jiqizhixin.com/articles/2017-11-03-5</a></p>\n<p>[^1]: Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).<br>[^2]: Wang, Z., Zhang, J., Feng, J., &amp; Chen, Z. (2014, July). Knowledge Graph Embedding by Translating on Hyperplanes. In <em>AAAI</em> (Vol. 14, pp. 1112-1119).</p>\n<p>[^3]: Lin, Y., Liu, Z., Sun, M., Liu, Y., &amp; Zhu, X. (2015, January). Learning entity and relation embeddings for knowledge graph completion. In <em>AAAI</em> (Vol. 15, pp. 2181-2187).<br>[^4]: Ji, G., He, S., Xu, L., Liu, K., &amp; Zhao, J. (2015). Knowledge graph embedding via dynamic mapping matrix. In <em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em> (Vol. 1, pp. 687-696).<br>[^5]: Xiao, H., Huang, M., Hao, Y., &amp; Zhu, X. (2015). TransA: An adaptive approach for knowledge graph embedding. <em>arXiv preprint arXiv:1509.05490</em>.<br>[^6]: Shi, B., &amp; Weninger, T. (2017, February). ProjE: Embedding Projection for Knowledge Graph Completion. In <em>AAAI</em> (Vol. 17, pp. 1236-1242).</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"2018-3-10\"><a href=\"#2018-3-10\" class=\"headerlink\" title=\"2018.3.10\"></a>2018.3.10</h1><h2 id=\"Several-models-for-knowledge-graph-representing-and-completing\"><a href=\"#Several-models-for-knowledge-graph-representing-and-completing\" class=\"headerlink\" title=\"Several models for knowledge graph representing and completing\"></a>Several models for knowledge graph representing and completing</h2><p><strong></strong>ConMaskknowledge graph completion</p>\n<h3 id=\"1-Series-of-Trans\"><a href=\"#1-Series-of-Trans\" class=\"headerlink\" title=\"1. Series of Trans\"></a>1. Series of Trans</h3><h4 id=\"1-1-TransE\"><a href=\"#1-1-TransE\" class=\"headerlink\" title=\"1.1 TransE\"></a>1.1 TransE</h4><p>TransE [^1] (RL). <br>$$<br>h+r = t<br>$$<br>hhead entityttail entityr</p>\n<p>TransEloss function<br>$$<br>\\mathcal{L(T)} = \\sum_{&lt;h,r,t&gt;\\in T} [\\gamma + E(&lt;h,r,t&gt;) - E(&lt;h,r,t&gt;)]<em>+<br>$$<br> $T$ $E(&lt;h,r,t&gt;) = ||h+r-t||</em>{L_n}$energy function$&lt;h,r,t&gt;$G$&lt;h,r,t&gt;$ $T$ $&lt;h,r,t&gt;$$\\gamma$ </p>\n<p> h+r-t  0 h+r-t  TransE  hinge loss function  SGD(Stochastic Gradient Descent) </p>\n<p>TransE</p>\n<h4 id=\"1-2-TransH\"><a href=\"#1-2-TransH\" class=\"headerlink\" title=\"1.2 TransH\"></a>1.2 TransH</h4><p> TransE TransH [^2]  h+r-l=0</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202332.jpg\">\n\n<p>head tail</p>\n<h4 id=\"1-3-TransR-CTrans\"><a href=\"#1-3-TransR-CTrans\" class=\"headerlink\" title=\"1.3 TransR/CTrans\"></a>1.3 TransR/CTrans</h4><p>TransETransHembeddingTransR[^3]<strong>r</strong>mapping$M_r$<br>$$<br>h_{\\perp} + r \\simeq t_{\\perp} \\quad \\text{where } h_{\\perp} = M_{r}\\cdot h, t_{\\perp} = M_{r} \\cdot t<br>$$<br>TransE</p>\n<h4 id=\"1-4-TransD\"><a href=\"#1-4-TransD\" class=\"headerlink\" title=\"1.4 TransD\"></a>1.4 TransD</h4><p>TransD[^4]TransR/CTransTransR</p>\n<ul>\n<li>rmapping$M_{r}$r</li>\n<li>mappingentityrelationmapping</li>\n<li>Knowledge graphrelationknowledge graph</li>\n</ul>\n<p>entityrelationTransDentityrelationentityrelationmappingentity-relation pairmapping</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202326.jpg\">\n\n<p>TransD</p>\n<h4 id=\"1-5-TransA\"><a href=\"#1-5-TransA\" class=\"headerlink\" title=\"1.5 TransA\"></a>1.5 TransA</h4><p>entityrelation</p>\n<p>TransA[^5] </p>\n<p>TransA</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202330.jpg\">\n\n\n\n<h3 id=\"2-ProjE\"><a href=\"#2-ProjE\" class=\"headerlink\" title=\"2. ProjE\"></a>2. ProjE</h3><p>ProjE[^6]Open-World Knowledge Graph CompletionAAAI2017AAAI2018KGC state-of-the-artProjE</p>\n<h4 id=\"2-1-Model-Architecture\"><a href=\"#2-1-Model-Architecture\" class=\"headerlink\" title=\"2.1 Model Architecture\"></a>2.1 Model Architecture</h4><p>&lt;h, r, ?&gt;hr ? entityhrentity</p>\n<p>transmappingentityrelationmapping<br>$$<br>e \\oplus r = D_e e + D_r r + b_c<br>$$<br>$D_e$$D_r$</p>\n<p>embedding<br>$$<br>h(e, r) = g(W^c f(e \\oplus r) + b_r )<br>$$<br>fg(activation function)$W^c$entityhentity</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-12-202328.jpg\">\n\n<p>ProjE$e \\oplus r$$h(e,r)$</p>\n<h4 id=\"2-2-Loss-function\"><a href=\"#2-2-Loss-function\" class=\"headerlink\" title=\"2.2 Loss function\"></a>2.2 Loss function</h4><p>pointwise loss function<br>$$<br>\\mathcal{L}(e, r, y) = - \\sum_{i\\in{i|y_i=1} } {log(h(e,r)<em>i)} - \\sum</em>{m} {\\mathbb{E}_{j \\sim P_y} log(h(e,r)_j)}<br>$$<br>$y$10mpointwise ProjE  f  g  sigmoid  tanh </p>\n<p> <a href=\"https://github.com/bxshi/ProjE\">https://github.com/bxshi/ProjE</a></p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p></p>\n<p><a href=\"http://www.infosec-wiki.com/?p=175755\">http://www.infosec-wiki.com/?p=175755</a></p>\n<p><a href=\"https://www.jiqizhixin.com/articles/2017-11-03-5\">https://www.jiqizhixin.com/articles/2017-11-03-5</a></p>\n<p>[^1]: Bordes, A., Usunier, N., Garcia-Duran, A., Weston, J., &amp; Yakhnenko, O. (2013). Translating embeddings for modeling multi-relational data. In <em>Advances in neural information processing systems</em> (pp. 2787-2795).<br>[^2]: Wang, Z., Zhang, J., Feng, J., &amp; Chen, Z. (2014, July). Knowledge Graph Embedding by Translating on Hyperplanes. In <em>AAAI</em> (Vol. 14, pp. 1112-1119).</p>\n<p>[^3]: Lin, Y., Liu, Z., Sun, M., Liu, Y., &amp; Zhu, X. (2015, January). Learning entity and relation embeddings for knowledge graph completion. In <em>AAAI</em> (Vol. 15, pp. 2181-2187).<br>[^4]: Ji, G., He, S., Xu, L., Liu, K., &amp; Zhao, J. (2015). Knowledge graph embedding via dynamic mapping matrix. In <em>Proceedings of the 53rd Annual Meeting of the Association for Computational Linguistics and the 7th International Joint Conference on Natural Language Processing (Volume 1: Long Papers)</em> (Vol. 1, pp. 687-696).<br>[^5]: Xiao, H., Huang, M., Hao, Y., &amp; Zhu, X. (2015). TransA: An adaptive approach for knowledge graph embedding. <em>arXiv preprint arXiv:1509.05490</em>.<br>[^6]: Shi, B., &amp; Weninger, T. (2017, February). ProjE: Embedding Projection for Knowledge Graph Completion. In <em>AAAI</em> (Vol. 17, pp. 1236-1242).</p>\n"},{"title":"Event detection ","date":"2018-03-20T00:00:00.000Z","_content":"\n## Event detection \n\n**** ace trigger word  attributes event detection  trigger word detection3paper\n\n### 1. Dual CNN\n\n[^1]CNN\n\npipline\n\n![WX20180320-221054@2x](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-221054%402x.png)\n\n1. Text Processing: \n2. Word Vector Initialisation:  pre-trained word embedding \n3. Concept Extraction: 2.\n4. Concept Vector Initialisation: \n5. Dual-CNN Training:  Dual-CNN \n\n#### Dual-CNN\n\nCNNchannelentity related embeddingchannelCNN\n\n![WX20180320-224531@2x](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224531%402x.png)\n\nembedding $D = $ 'Obama attends vigil for Boston Marathon bombing victims.' $T_w = $ \\['obama', 'attends', 'vigil', 'for', 'boston', 'marathon', 'bombing', 'victims'\\]$T_s = $ ['obama', 'politician', 'none', 'none', 'none', 'boston', 'location', 'none', 'none', 'none'] entity-type $T_w$$T_s$ channelsentitytypeembedding\n\nCNN\n\n### 2. convolution BiLSTM\n\n[^2]2018.1.29\n\n![WX20180320-224725@2x](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224725%402x.png)\n\nbiLSTMCNNbiLSTMOutput layerSoftmaxCNNsequence labeling\n\n### 3. BiLSTM + CNN\n\n[^3][^2]BiLSTMCNN\n\n![WX20180320-225956@2x](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-225956%402x.png)\n\n### 4. Conclusion\n\nCNNRNNbiLSTMCNN\n\nword embedding entity embeddingentity typeembedding\n\n## Bibliographies\n\n[^1]: Burel, G., Saif, H., Fernandez, M., & Alani, H. (2017). On semantics and deep learning for event detection in crisis situations.\n\n[^2]: Zeng, Y., Yang, H., Feng, Y., Wang, Z., & Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In *Natural Language Understanding and Intelligent Applications* (pp. 275-287). Springer, Cham.\n[^3]: Feng, X., Huang, L., Tang, D., Ji, H., Qin, B., & Liu, T. (2016). A language-independent neural network for event detection. In *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)* (Vol. 2, pp. 66-71).","source":"_posts/[2018.3.20]Event-detection.md","raw":"---\ntitle: Event detection \ndate: 2018-03-20 08:00:00\ncategories: [research]\ntags: [event-detection, neural-network]\n---\n\n## Event detection \n\n**** ace trigger word  attributes event detection  trigger word detection3paper\n\n### 1. Dual CNN\n\n[^1]CNN\n\npipline\n\n![WX20180320-221054@2x](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-221054%402x.png)\n\n1. Text Processing: \n2. Word Vector Initialisation:  pre-trained word embedding \n3. Concept Extraction: 2.\n4. Concept Vector Initialisation: \n5. Dual-CNN Training:  Dual-CNN \n\n#### Dual-CNN\n\nCNNchannelentity related embeddingchannelCNN\n\n![WX20180320-224531@2x](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224531%402x.png)\n\nembedding $D = $ 'Obama attends vigil for Boston Marathon bombing victims.' $T_w = $ \\['obama', 'attends', 'vigil', 'for', 'boston', 'marathon', 'bombing', 'victims'\\]$T_s = $ ['obama', 'politician', 'none', 'none', 'none', 'boston', 'location', 'none', 'none', 'none'] entity-type $T_w$$T_s$ channelsentitytypeembedding\n\nCNN\n\n### 2. convolution BiLSTM\n\n[^2]2018.1.29\n\n![WX20180320-224725@2x](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224725%402x.png)\n\nbiLSTMCNNbiLSTMOutput layerSoftmaxCNNsequence labeling\n\n### 3. BiLSTM + CNN\n\n[^3][^2]BiLSTMCNN\n\n![WX20180320-225956@2x](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-225956%402x.png)\n\n### 4. Conclusion\n\nCNNRNNbiLSTMCNN\n\nword embedding entity embeddingentity typeembedding\n\n## Bibliographies\n\n[^1]: Burel, G., Saif, H., Fernandez, M., & Alani, H. (2017). On semantics and deep learning for event detection in crisis situations.\n\n[^2]: Zeng, Y., Yang, H., Feng, Y., Wang, Z., & Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In *Natural Language Understanding and Intelligent Applications* (pp. 275-287). Springer, Cham.\n[^3]: Feng, X., Huang, L., Tang, D., Ji, H., Qin, B., & Liu, T. (2016). A language-independent neural network for event detection. In *Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)* (Vol. 2, pp. 66-71).","slug":"[2018.3.20]Event-detection","published":1,"updated":"2020-11-03T03:26:07.533Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufps002fgwtl1uppb39d","content":"<h2 id=\"Event-detection-\"><a href=\"#Event-detection-\" class=\"headerlink\" title=\"Event detection \"></a>Event detection </h2><p><strong></strong> ace trigger word  attributes event detection  trigger word detection3paper</p>\n<h3 id=\"1-Dual-CNN\"><a href=\"#1-Dual-CNN\" class=\"headerlink\" title=\"1. Dual CNN\"></a>1. Dual CNN</h3><p>[^1]CNN</p>\n<p>pipline</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-221054%402x.png\" alt=\"WX20180320-221054@2x\"></p>\n<ol>\n<li>Text Processing: </li>\n<li>Word Vector Initialisation:  pre-trained word embedding </li>\n<li>Concept Extraction: 2.</li>\n<li>Concept Vector Initialisation: </li>\n<li>Dual-CNN Training:  Dual-CNN </li>\n</ol>\n<h4 id=\"Dual-CNN\"><a href=\"#Dual-CNN\" class=\"headerlink\" title=\"Dual-CNN\"></a>Dual-CNN</h4><p>CNNchannelentity related embeddingchannelCNN</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224531%402x.png\" alt=\"WX20180320-224531@2x\"></p>\n<p>embedding $D = $ Obama attends vigil for Boston Marathon bombing victims. $T_w = $ [obama, attends, vigil, for, boston, marathon, bombing, victims]$T_s = $ [obama, politician, none, none, none, boston, location, none, none, none] entity-type $T_w$$T_s$ channelsentitytypeembedding</p>\n<p>CNN</p>\n<h3 id=\"2-convolution-BiLSTM\"><a href=\"#2-convolution-BiLSTM\" class=\"headerlink\" title=\"2. convolution BiLSTM\"></a>2. convolution BiLSTM</h3><p>[^2]2018.1.29</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224725%402x.png\" alt=\"WX20180320-224725@2x\"></p>\n<p>biLSTMCNNbiLSTMOutput layerSoftmaxCNNsequence labeling</p>\n<h3 id=\"3-BiLSTM-CNN\"><a href=\"#3-BiLSTM-CNN\" class=\"headerlink\" title=\"3. BiLSTM + CNN\"></a>3. BiLSTM + CNN</h3><p>[^3][^2]BiLSTMCNN</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-225956%402x.png\" alt=\"WX20180320-225956@2x\"></p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>CNNRNNbiLSTMCNN</p>\n<p>word embedding entity embeddingentity typeembedding</p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p>[^1]: Burel, G., Saif, H., Fernandez, M., &amp; Alani, H. (2017). On semantics and deep learning for event detection in crisis situations.</p>\n<p>[^2]: Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.<br>[^3]: Feng, X., Huang, L., Tang, D., Ji, H., Qin, B., &amp; Liu, T. (2016). A language-independent neural network for event detection. In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em> (Vol. 2, pp. 66-71).</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"Event-detection-\"><a href=\"#Event-detection-\" class=\"headerlink\" title=\"Event detection \"></a>Event detection </h2><p><strong></strong> ace trigger word  attributes event detection  trigger word detection3paper</p>\n<h3 id=\"1-Dual-CNN\"><a href=\"#1-Dual-CNN\" class=\"headerlink\" title=\"1. Dual CNN\"></a>1. Dual CNN</h3><p>[^1]CNN</p>\n<p>pipline</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-221054%402x.png\" alt=\"WX20180320-221054@2x\"></p>\n<ol>\n<li>Text Processing: </li>\n<li>Word Vector Initialisation:  pre-trained word embedding </li>\n<li>Concept Extraction: 2.</li>\n<li>Concept Vector Initialisation: </li>\n<li>Dual-CNN Training:  Dual-CNN </li>\n</ol>\n<h4 id=\"Dual-CNN\"><a href=\"#Dual-CNN\" class=\"headerlink\" title=\"Dual-CNN\"></a>Dual-CNN</h4><p>CNNchannelentity related embeddingchannelCNN</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224531%402x.png\" alt=\"WX20180320-224531@2x\"></p>\n<p>embedding $D = $ Obama attends vigil for Boston Marathon bombing victims. $T_w = $ [obama, attends, vigil, for, boston, marathon, bombing, victims]$T_s = $ [obama, politician, none, none, none, boston, location, none, none, none] entity-type $T_w$$T_s$ channelsentitytypeembedding</p>\n<p>CNN</p>\n<h3 id=\"2-convolution-BiLSTM\"><a href=\"#2-convolution-BiLSTM\" class=\"headerlink\" title=\"2. convolution BiLSTM\"></a>2. convolution BiLSTM</h3><p>[^2]2018.1.29</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-224725%402x.png\" alt=\"WX20180320-224725@2x\"></p>\n<p>biLSTMCNNbiLSTMOutput layerSoftmaxCNNsequence labeling</p>\n<h3 id=\"3-BiLSTM-CNN\"><a href=\"#3-BiLSTM-CNN\" class=\"headerlink\" title=\"3. BiLSTM + CNN\"></a>3. BiLSTM + CNN</h3><p>[^3][^2]BiLSTMCNN</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-03-20-WX20180320-225956%402x.png\" alt=\"WX20180320-225956@2x\"></p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>CNNRNNbiLSTMCNN</p>\n<p>word embedding entity embeddingentity typeembedding</p>\n<h2 id=\"Bibliographies\"><a href=\"#Bibliographies\" class=\"headerlink\" title=\"Bibliographies\"></a>Bibliographies</h2><p>[^1]: Burel, G., Saif, H., Fernandez, M., &amp; Alani, H. (2017). On semantics and deep learning for event detection in crisis situations.</p>\n<p>[^2]: Zeng, Y., Yang, H., Feng, Y., Wang, Z., &amp; Zhao, D. (2016). A convolution BiLSTM neural network model for Chinese event extraction. In <em>Natural Language Understanding and Intelligent Applications</em> (pp. 275-287). Springer, Cham.<br>[^3]: Feng, X., Huang, L., Tang, D., Ji, H., Qin, B., &amp; Liu, T. (2016). A language-independent neural network for event detection. In <em>Proceedings of the 54th Annual Meeting of the Association for Computational Linguistics (Volume 2: Short Papers)</em> (Vol. 2, pp. 66-71).</p>\n"},{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","date":"2018-04-14T00:00:00.000Z","_content":"\n## Reinforcement Learning for Relation Classification from Noisy Data \n\n****(distant supervision)[^1]\n\n## 1. Introduction\n\nnlp\n\n\n\nbag-levelbag\n\n![X20180414-152317@2](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-152317%402x.png)\n\n1. 2. bag\n\n1. 2. \n\n## 2. Methodology\n\n bagQA\n \n\n### Problem definition\n\n\n\n(sentence, relation label)$X = \\{(x_1,r_1),(x_2,r_2),,(x_n,r_n)\\}$$x_i$$(e_{1i},e_{2i})$$r_i$\n\n$x_i$$(h_i,t_i)$$x_i$$r_i$$p_{\\Phi}(r_i | x_i,h_i,t_i)$\n\n### Overview\n\n![X20180414-165503@2](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-165503%402x.png)\n\n### Instance Selector\n\nInstance Selectorpolicy$X=\\{x_1, ,x_n\\}$Nbag $B = \\{B^1, B^2, , B^N\\}$$B^k$$r^k$\n\n- **State**1) CNN; 2) ; 3) embedding\n\n- **Action**action $a_i \\in \\{0,1\\}$ i$a_i$policy function\n  $$\n  \\pi_{\\Theta}(s_i,a_i) = a_i \\sigma(W * F(s_i) + b) + (1 - a_i)(1 - \\sigma(W * F(s_i)+b))\n  $$\n\n- **Reward**reward functionbag $B = \\{x_1,... ,x_{| B |}\\}$action $s_{| B | +1}$ rewardCNN\n\n### Relation Classifier\n\nCNN\n\n\n\n1. word embedding\n2. position embedding\n\n## 3. Analysis\n\nNew York Times300baselineCNNCNN+Max(bag)CNN+ATTCNN+RLbag\n\nnlpnlp\n\n\n\n## Bibliography\n\nc++https://github.com/JuneFeng/RelationClassification-RL\n\n[^1]: Feng, J., Huang, M., Zhao, L., Yang, Y., & Zhu, X. (2018). Reinforcement Learning for Relation Classification from Noisy Data.","source":"_posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data.md","raw":"---\ntitle: Reinforcement Learning for Relation Classification from Noisy Data \ndate: 2018-04-14 08:00:00\ncategories: [research]\ntags: [relation-classification, relation-extraction, reinforcement-learning]\n---\n\n## Reinforcement Learning for Relation Classification from Noisy Data \n\n****(distant supervision)[^1]\n\n## 1. Introduction\n\nnlp\n\n\n\nbag-levelbag\n\n![X20180414-152317@2](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-152317%402x.png)\n\n1. 2. bag\n\n1. 2. \n\n## 2. Methodology\n\n bagQA\n \n\n### Problem definition\n\n\n\n(sentence, relation label)$X = \\{(x_1,r_1),(x_2,r_2),,(x_n,r_n)\\}$$x_i$$(e_{1i},e_{2i})$$r_i$\n\n$x_i$$(h_i,t_i)$$x_i$$r_i$$p_{\\Phi}(r_i | x_i,h_i,t_i)$\n\n### Overview\n\n![X20180414-165503@2](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-165503%402x.png)\n\n### Instance Selector\n\nInstance Selectorpolicy$X=\\{x_1, ,x_n\\}$Nbag $B = \\{B^1, B^2, , B^N\\}$$B^k$$r^k$\n\n- **State**1) CNN; 2) ; 3) embedding\n\n- **Action**action $a_i \\in \\{0,1\\}$ i$a_i$policy function\n  $$\n  \\pi_{\\Theta}(s_i,a_i) = a_i \\sigma(W * F(s_i) + b) + (1 - a_i)(1 - \\sigma(W * F(s_i)+b))\n  $$\n\n- **Reward**reward functionbag $B = \\{x_1,... ,x_{| B |}\\}$action $s_{| B | +1}$ rewardCNN\n\n### Relation Classifier\n\nCNN\n\n\n\n1. word embedding\n2. position embedding\n\n## 3. Analysis\n\nNew York Times300baselineCNNCNN+Max(bag)CNN+ATTCNN+RLbag\n\nnlpnlp\n\n\n\n## Bibliography\n\nc++https://github.com/JuneFeng/RelationClassification-RL\n\n[^1]: Feng, J., Huang, M., Zhao, L., Yang, Y., & Zhu, X. (2018). Reinforcement Learning for Relation Classification from Noisy Data.","slug":"[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data","published":1,"updated":"2020-11-03T03:26:07.006Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpt002jgwtl6mih547q","content":"<h2 id=\"Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data-\"><a href=\"#Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data-\" class=\"headerlink\" title=\"Reinforcement Learning for Relation Classification from Noisy Data \"></a>Reinforcement Learning for Relation Classification from Noisy Data </h2><p><strong></strong>(distant supervision)[^1]</p>\n<h2 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h2><p>nlp</p>\n<p></p>\n<p>bag-levelbag</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-152317%402x.png\" alt=\"X20180414-152317@2\"></p>\n<p>1. 2. bag</p>\n<p>1. 2. </p>\n<h2 id=\"2-Methodology\"><a href=\"#2-Methodology\" class=\"headerlink\" title=\"2. Methodology\"></a>2. Methodology</h2><p> bagQA<br> </p>\n<h3 id=\"Problem-definition\"><a href=\"#Problem-definition\" class=\"headerlink\" title=\"Problem definition\"></a>Problem definition</h3><p></p>\n<p>(sentence, relation label)$X = {(x_1,r_1),(x_2,r_2),,(x_n,r_n)}$$x_i$$(e_{1i},e_{2i})$$r_i$</p>\n<p>$x_i$$(h_i,t_i)$$x_i$$r_i$$p_{\\Phi}(r_i | x_i,h_i,t_i)$</p>\n<h3 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h3><p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-165503%402x.png\" alt=\"X20180414-165503@2\"></p>\n<h3 id=\"Instance-Selector\"><a href=\"#Instance-Selector\" class=\"headerlink\" title=\"Instance Selector\"></a>Instance Selector</h3><p>Instance Selectorpolicy$X={x_1, ,x_n}$Nbag $B = {B^1, B^2, , B^N}$$B^k$$r^k$</p>\n<ul>\n<li><p><strong>State</strong>1) CNN; 2) ; 3) embedding</p>\n</li>\n<li><p><strong>Action</strong>action $a_i \\in {0,1}$ i$a_i$policy function<br>$$<br>\\pi_{\\Theta}(s_i,a_i) = a_i \\sigma(W * F(s_i) + b) + (1 - a_i)(1 - \\sigma(W * F(s_i)+b))<br>$$</p>\n</li>\n<li><p><strong>Reward</strong>reward functionbag $B = {x_1, ,x_{| B |}}$action $s_{| B | +1}$ rewardCNN</p>\n</li>\n</ul>\n<h3 id=\"Relation-Classifier\"><a href=\"#Relation-Classifier\" class=\"headerlink\" title=\"Relation Classifier\"></a>Relation Classifier</h3><p>CNN</p>\n<p></p>\n<ol>\n<li>word embedding</li>\n<li>position embedding</li>\n</ol>\n<h2 id=\"3-Analysis\"><a href=\"#3-Analysis\" class=\"headerlink\" title=\"3. Analysis\"></a>3. Analysis</h2><p>New York Times300baselineCNNCNN+Max(bag)CNN+ATTCNN+RLbag</p>\n<p>nlpnlp</p>\n<p></p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>c++<a href=\"https://github.com/JuneFeng/RelationClassification-RL\">https://github.com/JuneFeng/RelationClassification-RL</a></p>\n<p>[^1]: Feng, J., Huang, M., Zhao, L., Yang, Y., &amp; Zhu, X. (2018). Reinforcement Learning for Relation Classification from Noisy Data.</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data-\"><a href=\"#Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data-\" class=\"headerlink\" title=\"Reinforcement Learning for Relation Classification from Noisy Data \"></a>Reinforcement Learning for Relation Classification from Noisy Data </h2><p><strong></strong>(distant supervision)[^1]</p>\n<h2 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h2><p>nlp</p>\n<p></p>\n<p>bag-levelbag</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-152317%402x.png\" alt=\"X20180414-152317@2\"></p>\n<p>1. 2. bag</p>\n<p>1. 2. </p>\n<h2 id=\"2-Methodology\"><a href=\"#2-Methodology\" class=\"headerlink\" title=\"2. Methodology\"></a>2. Methodology</h2><p> bagQA<br> </p>\n<h3 id=\"Problem-definition\"><a href=\"#Problem-definition\" class=\"headerlink\" title=\"Problem definition\"></a>Problem definition</h3><p></p>\n<p>(sentence, relation label)$X = {(x_1,r_1),(x_2,r_2),,(x_n,r_n)}$$x_i$$(e_{1i},e_{2i})$$r_i$</p>\n<p>$x_i$$(h_i,t_i)$$x_i$$r_i$$p_{\\Phi}(r_i | x_i,h_i,t_i)$</p>\n<h3 id=\"Overview\"><a href=\"#Overview\" class=\"headerlink\" title=\"Overview\"></a>Overview</h3><p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-14-WX20180414-165503%402x.png\" alt=\"X20180414-165503@2\"></p>\n<h3 id=\"Instance-Selector\"><a href=\"#Instance-Selector\" class=\"headerlink\" title=\"Instance Selector\"></a>Instance Selector</h3><p>Instance Selectorpolicy$X={x_1, ,x_n}$Nbag $B = {B^1, B^2, , B^N}$$B^k$$r^k$</p>\n<ul>\n<li><p><strong>State</strong>1) CNN; 2) ; 3) embedding</p>\n</li>\n<li><p><strong>Action</strong>action $a_i \\in {0,1}$ i$a_i$policy function<br>$$<br>\\pi_{\\Theta}(s_i,a_i) = a_i \\sigma(W * F(s_i) + b) + (1 - a_i)(1 - \\sigma(W * F(s_i)+b))<br>$$</p>\n</li>\n<li><p><strong>Reward</strong>reward functionbag $B = {x_1, ,x_{| B |}}$action $s_{| B | +1}$ rewardCNN</p>\n</li>\n</ul>\n<h3 id=\"Relation-Classifier\"><a href=\"#Relation-Classifier\" class=\"headerlink\" title=\"Relation Classifier\"></a>Relation Classifier</h3><p>CNN</p>\n<p></p>\n<ol>\n<li>word embedding</li>\n<li>position embedding</li>\n</ol>\n<h2 id=\"3-Analysis\"><a href=\"#3-Analysis\" class=\"headerlink\" title=\"3. Analysis\"></a>3. Analysis</h2><p>New York Times300baselineCNNCNN+Max(bag)CNN+ATTCNN+RLbag</p>\n<p>nlpnlp</p>\n<p></p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>c++<a href=\"https://github.com/JuneFeng/RelationClassification-RL\">https://github.com/JuneFeng/RelationClassification-RL</a></p>\n<p>[^1]: Feng, J., Huang, M., Zhao, L., Yang, Y., &amp; Zhu, X. (2018). Reinforcement Learning for Relation Classification from Noisy Data.</p>\n"},{"title":"A Neural Model for Joint Event Detection and Summarization ","date":"2018-04-04T00:00:00.000Z","_content":"\n## A Neural Model for Joint Event Detection and Summarization \n\n****Twitterfirst storiesevent clusterpipelineevent clusterWang, Z.[^2]\n\n[^1]joint modeleventNeural stacking modelpipelineneural joint modelpipeline\n\n### 1. Introduction\n\nDDos\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-225501%402x.png\" width=\"60%\">\n\n\n\n****locality sensitive hashingTFIDF\n\n****event detection \n\n****   \n\npipeline   joint model\n\nneural stackingpipeline\n\n### 2. Model\n\n\n\n- ****DDOS\n- ****\n- ****n\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-232216%402x.png\" width=\"60%\">\n\nHembeddingHdHcPs\n\npipelineneural stackingtweetsLSTM\n\n#### 2.1 Shared Tweet Representation\n\nLSTM $X =(w_1,w_2,,w_n)$$n$$w_i$i $w_i$word embedding$w_i$$x_i$word embeddingDskip-gramembedding\nLSTM$(h_1,h_2,,h_n)$ t$x_t$$h_{t-1}$$h_t = LSTM(x_th_{t-1})$LSTM$h_t$ LSTM $H = h_n$X\n\n#### 2.2 Joint Model \n\n##### Event mention detection\n\nH\n$$\nH_d = \\sigma(W_d^h H + b_d^h)\n$$\n$H_d$softmax\n$$\nP_d = softmax(W_dH_d + B_d)\n$$\n$W_d^h, b_d^b, W_d$$P_d$ 2$P_d(0)$X$P_d(1)$\n\n##### Event clustering\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-234532%402x.png\" width=\"60%\">\n\n$\\mu - 3\\cdot \\sigma$\n$X_i$$X_j$$H_i$$H_j$$P_c$:\n$$\nH_c = \\sigma(W_c^h(H_i \\oplus H_j)+ b_c^h) \\\\\nP_c = softmax(W_cH_c + B_c)\n$$\n $W_c^hb_b^c,W_c,b_c$\n\n$X_i$$X_j$$H_d$Siamese\n$$\nH_c = \\sigma(W_c^h(H_i \\oplus H_j \\oplus H_{d_i} \\oplus H_{d_j})+ b_c^h)\n$$\n\n##### Event summarization\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180405-000354%402x.png\" width=\"60%\">\n\n$P_s$ X$P_s$$H \\oplus \\bar{H_c^h}$ $\\bar{H_c^h}$X$H_c^h$ $H_c^h$ $H_c^h$\n$$\nP_s = softmax(W_sH_s + B_s)\n$$\nwhere\n$$\nH_s = \\sigma(W_s^h(H\\oplus \\bar{H_c^h})+ b_s^h)\n$$\n$W_s^h, b_s^b, Ws$\n\n#### 2.3 Training\n\ncross-entropy loss Adagradword embedding0.2dropout$H_d, H_c,H_s$32Skip-gramword embedding Word embedding128\n\n### 3. Experiment\n\npaper\n\n### 4. Conclusion\n\n[^1]joint model joint modelpipelinebaseline\n\n## Bibliography\n\nhttps://github.com/wangzq870305/joint_event_detection\n\n[^1]: Wang, Z., & Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In *Proceedings of the 26th International Joint Conference on Artificial Intelligence* (pp. 4158-4164). AAAI Press.\n[^2]: Wang, Z., Shou, L., Chen, K., Chen, G., & Mehrotra, S. (2015). On summarization and timeline generation for evolutionary tweet streams. *IEEE Transactions on Knowledge and Data Engineering*, *27*(5), 1301-1315.","source":"_posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization.md","raw":"---\ntitle: A Neural Model for Joint Event Detection and Summarization \ndate: 2018-04-04 08:00:00\ncategories: [research]\ntags: [event-detection, summarization]\n---\n\n## A Neural Model for Joint Event Detection and Summarization \n\n****Twitterfirst storiesevent clusterpipelineevent clusterWang, Z.[^2]\n\n[^1]joint modeleventNeural stacking modelpipelineneural joint modelpipeline\n\n### 1. Introduction\n\nDDos\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-225501%402x.png\" width=\"60%\">\n\n\n\n****locality sensitive hashingTFIDF\n\n****event detection \n\n****   \n\npipeline   joint model\n\nneural stackingpipeline\n\n### 2. Model\n\n\n\n- ****DDOS\n- ****\n- ****n\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-232216%402x.png\" width=\"60%\">\n\nHembeddingHdHcPs\n\npipelineneural stackingtweetsLSTM\n\n#### 2.1 Shared Tweet Representation\n\nLSTM $X =(w_1,w_2,,w_n)$$n$$w_i$i $w_i$word embedding$w_i$$x_i$word embeddingDskip-gramembedding\nLSTM$(h_1,h_2,,h_n)$ t$x_t$$h_{t-1}$$h_t = LSTM(x_th_{t-1})$LSTM$h_t$ LSTM $H = h_n$X\n\n#### 2.2 Joint Model \n\n##### Event mention detection\n\nH\n$$\nH_d = \\sigma(W_d^h H + b_d^h)\n$$\n$H_d$softmax\n$$\nP_d = softmax(W_dH_d + B_d)\n$$\n$W_d^h, b_d^b, W_d$$P_d$ 2$P_d(0)$X$P_d(1)$\n\n##### Event clustering\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-234532%402x.png\" width=\"60%\">\n\n$\\mu - 3\\cdot \\sigma$\n$X_i$$X_j$$H_i$$H_j$$P_c$:\n$$\nH_c = \\sigma(W_c^h(H_i \\oplus H_j)+ b_c^h) \\\\\nP_c = softmax(W_cH_c + B_c)\n$$\n $W_c^hb_b^c,W_c,b_c$\n\n$X_i$$X_j$$H_d$Siamese\n$$\nH_c = \\sigma(W_c^h(H_i \\oplus H_j \\oplus H_{d_i} \\oplus H_{d_j})+ b_c^h)\n$$\n\n##### Event summarization\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180405-000354%402x.png\" width=\"60%\">\n\n$P_s$ X$P_s$$H \\oplus \\bar{H_c^h}$ $\\bar{H_c^h}$X$H_c^h$ $H_c^h$ $H_c^h$\n$$\nP_s = softmax(W_sH_s + B_s)\n$$\nwhere\n$$\nH_s = \\sigma(W_s^h(H\\oplus \\bar{H_c^h})+ b_s^h)\n$$\n$W_s^h, b_s^b, Ws$\n\n#### 2.3 Training\n\ncross-entropy loss Adagradword embedding0.2dropout$H_d, H_c,H_s$32Skip-gramword embedding Word embedding128\n\n### 3. Experiment\n\npaper\n\n### 4. Conclusion\n\n[^1]joint model joint modelpipelinebaseline\n\n## Bibliography\n\nhttps://github.com/wangzq870305/joint_event_detection\n\n[^1]: Wang, Z., & Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In *Proceedings of the 26th International Joint Conference on Artificial Intelligence* (pp. 4158-4164). AAAI Press.\n[^2]: Wang, Z., Shou, L., Chen, K., Chen, G., & Mehrotra, S. (2015). On summarization and timeline generation for evolutionary tweet streams. *IEEE Transactions on Knowledge and Data Engineering*, *27*(5), 1301-1315.","slug":"[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization","published":1,"updated":"2020-11-03T03:26:06.064Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpu002mgwtl1ggb971o","content":"<h2 id=\"A-Neural-Model-for-Joint-Event-Detection-and-Summarization-\"><a href=\"#A-Neural-Model-for-Joint-Event-Detection-and-Summarization-\" class=\"headerlink\" title=\"A Neural Model for Joint Event Detection and Summarization \"></a>A Neural Model for Joint Event Detection and Summarization </h2><p><strong></strong>Twitterfirst storiesevent clusterpipelineevent clusterWang, Z.[^2]</p>\n<p>[^1]joint modeleventNeural stacking modelpipelineneural joint modelpipeline</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>DDos</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-225501%402x.png\" width=\"60%\">\n\n<p></p>\n<p><strong></strong>locality sensitive hashingTFIDF</p>\n<p><strong></strong>event detection </p>\n<p><strong></strong>   </p>\n<p>pipeline   joint model</p>\n<p>neural stackingpipeline</p>\n<h3 id=\"2-Model\"><a href=\"#2-Model\" class=\"headerlink\" title=\"2. Model\"></a>2. Model</h3><p></p>\n<ul>\n<li><strong></strong>DDOS</li>\n<li><strong></strong></li>\n<li><strong></strong>n</li>\n</ul>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-232216%402x.png\" width=\"60%\">\n\n<p>HembeddingHdHcPs</p>\n<p>pipelineneural stackingtweetsLSTM</p>\n<h4 id=\"2-1-Shared-Tweet-Representation\"><a href=\"#2-1-Shared-Tweet-Representation\" class=\"headerlink\" title=\"2.1 Shared Tweet Representation\"></a>2.1 Shared Tweet Representation</h4><p>LSTM $X =(w_1,w_2,,w_n)$$n$$w_i$i $w_i$word embedding$w_i$$x_i$word embeddingDskip-gramembedding<br>LSTM$(h_1,h_2,,h_n)$ t$x_t$$h_{t-1}$$h_t = LSTM(x_th_{t-1})$LSTM$h_t$ LSTM $H = h_n$X</p>\n<h4 id=\"2-2-Joint-Model\"><a href=\"#2-2-Joint-Model\" class=\"headerlink\" title=\"2.2 Joint Model\"></a>2.2 Joint Model</h4><h5 id=\"Event-mention-detection\"><a href=\"#Event-mention-detection\" class=\"headerlink\" title=\"Event mention detection\"></a>Event mention detection</h5><p>H<br>$$<br>H_d = \\sigma(W_d^h H + b_d^h)<br>$$<br>$H_d$softmax<br>$$<br>P_d = softmax(W_dH_d + B_d)<br>$$<br>$W_d^h, b_d^b, W_d$$P_d$ 2$P_d(0)$X$P_d(1)$</p>\n<h5 id=\"Event-clustering\"><a href=\"#Event-clustering\" class=\"headerlink\" title=\"Event clustering\"></a>Event clustering</h5><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-234532%402x.png\" width=\"60%\">\n\n<p>$\\mu - 3\\cdot \\sigma$<br>$X_i$$X_j$$H_i$$H_j$$P_c$:<br>$$<br>H_c = \\sigma(W_c^h(H_i \\oplus H_j)+ b_c^h) \\<br>P_c = softmax(W_cH_c + B_c)<br>$$<br> $W_c^hb_b^c,W_c,b_c$</p>\n<p>$X_i$$X_j$$H_d$Siamese<br>$$<br>H_c = \\sigma(W_c^h(H_i \\oplus H_j \\oplus H_{d_i} \\oplus H_{d_j})+ b_c^h)<br>$$</p>\n<h5 id=\"Event-summarization\"><a href=\"#Event-summarization\" class=\"headerlink\" title=\"Event summarization\"></a>Event summarization</h5><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180405-000354%402x.png\" width=\"60%\">\n\n<p>$P_s$ X$P_s$$H \\oplus \\bar{H_c^h}$ $\\bar{H_c^h}$X$H_c^h$ $H_c^h$ $H_c^h$<br>$$<br>P_s = softmax(W_sH_s + B_s)<br>$$<br>where<br>$$<br>H_s = \\sigma(W_s^h(H\\oplus \\bar{H_c^h})+ b_s^h)<br>$$<br>$W_s^h, b_s^b, Ws$</p>\n<h4 id=\"2-3-Training\"><a href=\"#2-3-Training\" class=\"headerlink\" title=\"2.3 Training\"></a>2.3 Training</h4><p>cross-entropy loss Adagradword embedding0.2dropout$H_d, H_c,H_s$32Skip-gramword embedding Word embedding128</p>\n<h3 id=\"3-Experiment\"><a href=\"#3-Experiment\" class=\"headerlink\" title=\"3. Experiment\"></a>3. Experiment</h3><p>paper</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>[^1]joint model joint modelpipelinebaseline</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p><a href=\"https://github.com/wangzq870305/joint_event_detection\">https://github.com/wangzq870305/joint_event_detection</a></p>\n<p>[^1]: Wang, Z., &amp; Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In <em>Proceedings of the 26th International Joint Conference on Artificial Intelligence</em> (pp. 4158-4164). AAAI Press.<br>[^2]: Wang, Z., Shou, L., Chen, K., Chen, G., &amp; Mehrotra, S. (2015). On summarization and timeline generation for evolutionary tweet streams. <em>IEEE Transactions on Knowledge and Data Engineering</em>, <em>27</em>(5), 1301-1315.</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"A-Neural-Model-for-Joint-Event-Detection-and-Summarization-\"><a href=\"#A-Neural-Model-for-Joint-Event-Detection-and-Summarization-\" class=\"headerlink\" title=\"A Neural Model for Joint Event Detection and Summarization \"></a>A Neural Model for Joint Event Detection and Summarization </h2><p><strong></strong>Twitterfirst storiesevent clusterpipelineevent clusterWang, Z.[^2]</p>\n<p>[^1]joint modeleventNeural stacking modelpipelineneural joint modelpipeline</p>\n<h3 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h3><p>DDos</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-225501%402x.png\" width=\"60%\">\n\n<p></p>\n<p><strong></strong>locality sensitive hashingTFIDF</p>\n<p><strong></strong>event detection </p>\n<p><strong></strong>   </p>\n<p>pipeline   joint model</p>\n<p>neural stackingpipeline</p>\n<h3 id=\"2-Model\"><a href=\"#2-Model\" class=\"headerlink\" title=\"2. Model\"></a>2. Model</h3><p></p>\n<ul>\n<li><strong></strong>DDOS</li>\n<li><strong></strong></li>\n<li><strong></strong>n</li>\n</ul>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-232216%402x.png\" width=\"60%\">\n\n<p>HembeddingHdHcPs</p>\n<p>pipelineneural stackingtweetsLSTM</p>\n<h4 id=\"2-1-Shared-Tweet-Representation\"><a href=\"#2-1-Shared-Tweet-Representation\" class=\"headerlink\" title=\"2.1 Shared Tweet Representation\"></a>2.1 Shared Tweet Representation</h4><p>LSTM $X =(w_1,w_2,,w_n)$$n$$w_i$i $w_i$word embedding$w_i$$x_i$word embeddingDskip-gramembedding<br>LSTM$(h_1,h_2,,h_n)$ t$x_t$$h_{t-1}$$h_t = LSTM(x_th_{t-1})$LSTM$h_t$ LSTM $H = h_n$X</p>\n<h4 id=\"2-2-Joint-Model\"><a href=\"#2-2-Joint-Model\" class=\"headerlink\" title=\"2.2 Joint Model\"></a>2.2 Joint Model</h4><h5 id=\"Event-mention-detection\"><a href=\"#Event-mention-detection\" class=\"headerlink\" title=\"Event mention detection\"></a>Event mention detection</h5><p>H<br>$$<br>H_d = \\sigma(W_d^h H + b_d^h)<br>$$<br>$H_d$softmax<br>$$<br>P_d = softmax(W_dH_d + B_d)<br>$$<br>$W_d^h, b_d^b, W_d$$P_d$ 2$P_d(0)$X$P_d(1)$</p>\n<h5 id=\"Event-clustering\"><a href=\"#Event-clustering\" class=\"headerlink\" title=\"Event clustering\"></a>Event clustering</h5><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180404-234532%402x.png\" width=\"60%\">\n\n<p>$\\mu - 3\\cdot \\sigma$<br>$X_i$$X_j$$H_i$$H_j$$P_c$:<br>$$<br>H_c = \\sigma(W_c^h(H_i \\oplus H_j)+ b_c^h) \\<br>P_c = softmax(W_cH_c + B_c)<br>$$<br> $W_c^hb_b^c,W_c,b_c$</p>\n<p>$X_i$$X_j$$H_d$Siamese<br>$$<br>H_c = \\sigma(W_c^h(H_i \\oplus H_j \\oplus H_{d_i} \\oplus H_{d_j})+ b_c^h)<br>$$</p>\n<h5 id=\"Event-summarization\"><a href=\"#Event-summarization\" class=\"headerlink\" title=\"Event summarization\"></a>Event summarization</h5><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-04-04-WX20180405-000354%402x.png\" width=\"60%\">\n\n<p>$P_s$ X$P_s$$H \\oplus \\bar{H_c^h}$ $\\bar{H_c^h}$X$H_c^h$ $H_c^h$ $H_c^h$<br>$$<br>P_s = softmax(W_sH_s + B_s)<br>$$<br>where<br>$$<br>H_s = \\sigma(W_s^h(H\\oplus \\bar{H_c^h})+ b_s^h)<br>$$<br>$W_s^h, b_s^b, Ws$</p>\n<h4 id=\"2-3-Training\"><a href=\"#2-3-Training\" class=\"headerlink\" title=\"2.3 Training\"></a>2.3 Training</h4><p>cross-entropy loss Adagradword embedding0.2dropout$H_d, H_c,H_s$32Skip-gramword embedding Word embedding128</p>\n<h3 id=\"3-Experiment\"><a href=\"#3-Experiment\" class=\"headerlink\" title=\"3. Experiment\"></a>3. Experiment</h3><p>paper</p>\n<h3 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h3><p>[^1]joint model joint modelpipelinebaseline</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p><a href=\"https://github.com/wangzq870305/joint_event_detection\">https://github.com/wangzq870305/joint_event_detection</a></p>\n<p>[^1]: Wang, Z., &amp; Zhang, Y. (2017, August). A neural model for joint event detection and summarization. In <em>Proceedings of the 26th International Joint Conference on Artificial Intelligence</em> (pp. 4158-4164). AAAI Press.<br>[^2]: Wang, Z., Shou, L., Chen, K., Chen, G., &amp; Mehrotra, S. (2015). On summarization and timeline generation for evolutionary tweet streams. <em>IEEE Transactions on Knowledge and Data Engineering</em>, <em>27</em>(5), 1301-1315.</p>\n"},{"title":"Learning beyond datasets - Knowledge Graph Augmented Neural Networks for Natural language Processing ","date":"2018-05-10T00:00:00.000Z","_content":"\n## Knowledge Graph Augmented Neural Networks for Natural language Processing \n\n****[^1]KGNLPattentionattentionNLP\n\n## 1. Introduction\n\ntransfer learning\n\n![X20180503-190446@2](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-03-WX20180503-190446%402x.png)\n\n$\\mathcal{X}$$\\mathcal{Y}$$\\mathcal{X}$$\\mathcal{X_w}$$\\mathcal{X'}$\n\nfact(subject entity, relation, object entity)(h,r,t)\n\nworld knowledge $\\langle \\text{},\\text{},\\text{} \\rangle$$\\langle \\text{},\\text{},\\text{} \\rangle$ground-truth\n\n\n\n## 2. Knowledge graph representations\n\nembeddingstructure-based embeddingsemantically-enriched embedding\n\n#### structure-based embedding\n\nTransE$h + r = t$. [](https://blog.lorrin.info/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/)\n\n#### semantically-enriched embedding\n\nembeddingKG/ NTNSocher et al [2011] Zhong et al [2015]SSP Xiao et al[2017] DKRL Xie et al [2016]KGTransE word2vecCNN\n\nDKRLTransE$t = h + r$fact\n\n## 3. The proposed model\n\n$\\Theta$$x$$y$\n$$\n\\max_{\\Theta}{P(y|x, \\Theta)}\n$$\n\n\n$$\n\\Theta = \\arg\\max_{\\Theta} {\\log{P(y|x, \\Theta)}}\n$$\nworld knowledge$x_w$$x$world knowledge$x_w = F(x, \\Theta^{(2)})$ \n$$\n\\max_{\\Theta}{P(y|x, x_w, \\Theta^{(1)})}\n$$\n$\\Theta = \\{\\Theta^{(1)}, \\Theta^{(2)}\\}$\n$$\n\\Theta = \\arg\\max_{\\Theta} {\\log{P(y|x,F(x, \\Theta^{(2)}), \\Theta^{(1)})}}\n$$\nFxsoftmaxLSTM Greff et al. [2015]PFsoft attention\n\nA. B. \n\n#### A. \n\nKGDKRL $e_i \\in \\mathbb{R}^m$i$r_j\\in \\mathbb R^m$KGj $x =(x_1,x_2,,x_T)$LSTM Greff et al. [2015]\n$$\nh_t = f(x_t, h_{t-1})\n$$\n\n$$\no = \\frac{1}{T}\\sum_{t=1}^{T}{h_t}\n$$\n$h_t \\in \\mathbb{R}^n$LSTMfT \n$$\nC = ReLU(o^T W)\n$$\n$W\\in \\mathbb R^n \\times m$($C_E$)($C_R$)\n\nKG \n$$\n\\alpha_{e_i} = \\frac{\\exp{C_E^T{e_i}}}{\\sum_{j=0}^{|E|} \\exp{C_E^T{e_j}}}\n$$\n\n$$\n\\alpha_{r_i} = \\frac{\\exp{C_R^T{r_i}}}{\\sum_{j=0}^{|R|} \\exp{C_R^T{r_j}}}\n$$\n![mage-20180511000712](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110007120.png)\n\n2/KGDKRLTransE($h + r = t$)(subject entity)$t = e + r$ $\\mathcal F = [ere + r]$$F \\in \\mathbb R^{3m}$ LSTMx(C) $\\mathbb y$\n$$\n\\mathcal F' = ReLU(\\mathcal F^T V) \\\\\n\\mathbb y = softmax([\\mathcal F' : C]^T U)\n$$\n$V\\mathbb R^{3m \\times u}$$U\\in \\mathbb R^{2u\\times u}$ $\\mathbb y$$\\mathbb y$\n\n#### A+. KG\n\n![mage-20180511003414](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110034147.png)\n\n/attentionKGKGKGKGKGKGKGNews2059SNLI663KGattention/\n\n#### B. \n\nattention/ /attention\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110044225.png\" width=\"60%\">\n\n/k-means/$l$CNNclusterk-means/$\\{e^T_1,e^T_2,,e^T_q\\}$$e_i \\in\\mathbb R^m$$ q =\\frac{| E |}{l}$cluster$\\mathcal E$CNN2D$\\mathcal E\\in\\mathbb R^{m\\times q}$ 2-D$e_i$$\\mathcal E$4yk\n$$\n\\mathcal E'(i,j) = W^T[e_{i,j}, e_{i+1,j},...,e_{i+k-1, j}]^T\n$$\n$\\mathcal E'(i,j)$$\\mathcal E'$(i, j)$W\\in \\mathbb R^k$poolingykn$\\mathcal E_i\\in \\mathbb R^m$icluster$E$$R$attentionattention\n\n## 4. Conclusion\n\nKGworld knowledgeembeddingNLP\n\n\n\n## Bibliography\n\n https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742\n\n[^1]: Annervaz, K. M., Somnath Basu Roy Chowdhury, and Ambedkar Dukkipati. 'Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing.' arXiv preprint arXiv:1802.05930 (2018).","source":"_posts/[2018.5.10]Knowledge-Graph-Augmented-Neural-Networks-for-NLP.md","raw":"---\ntitle: Learning beyond datasets - Knowledge Graph Augmented Neural Networks for Natural language Processing \ndate: 2018-05-10 08:00:00\ncategories: [research]\ntags: [neural-network, NLP, knowledge-graph]\n---\n\n## Knowledge Graph Augmented Neural Networks for Natural language Processing \n\n****[^1]KGNLPattentionattentionNLP\n\n## 1. Introduction\n\ntransfer learning\n\n![X20180503-190446@2](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-03-WX20180503-190446%402x.png)\n\n$\\mathcal{X}$$\\mathcal{Y}$$\\mathcal{X}$$\\mathcal{X_w}$$\\mathcal{X'}$\n\nfact(subject entity, relation, object entity)(h,r,t)\n\nworld knowledge $\\langle \\text{},\\text{},\\text{} \\rangle$$\\langle \\text{},\\text{},\\text{} \\rangle$ground-truth\n\n\n\n## 2. Knowledge graph representations\n\nembeddingstructure-based embeddingsemantically-enriched embedding\n\n#### structure-based embedding\n\nTransE$h + r = t$. [](https://blog.lorrin.info/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/)\n\n#### semantically-enriched embedding\n\nembeddingKG/ NTNSocher et al [2011] Zhong et al [2015]SSP Xiao et al[2017] DKRL Xie et al [2016]KGTransE word2vecCNN\n\nDKRLTransE$t = h + r$fact\n\n## 3. The proposed model\n\n$\\Theta$$x$$y$\n$$\n\\max_{\\Theta}{P(y|x, \\Theta)}\n$$\n\n\n$$\n\\Theta = \\arg\\max_{\\Theta} {\\log{P(y|x, \\Theta)}}\n$$\nworld knowledge$x_w$$x$world knowledge$x_w = F(x, \\Theta^{(2)})$ \n$$\n\\max_{\\Theta}{P(y|x, x_w, \\Theta^{(1)})}\n$$\n$\\Theta = \\{\\Theta^{(1)}, \\Theta^{(2)}\\}$\n$$\n\\Theta = \\arg\\max_{\\Theta} {\\log{P(y|x,F(x, \\Theta^{(2)}), \\Theta^{(1)})}}\n$$\nFxsoftmaxLSTM Greff et al. [2015]PFsoft attention\n\nA. B. \n\n#### A. \n\nKGDKRL $e_i \\in \\mathbb{R}^m$i$r_j\\in \\mathbb R^m$KGj $x =(x_1,x_2,,x_T)$LSTM Greff et al. [2015]\n$$\nh_t = f(x_t, h_{t-1})\n$$\n\n$$\no = \\frac{1}{T}\\sum_{t=1}^{T}{h_t}\n$$\n$h_t \\in \\mathbb{R}^n$LSTMfT \n$$\nC = ReLU(o^T W)\n$$\n$W\\in \\mathbb R^n \\times m$($C_E$)($C_R$)\n\nKG \n$$\n\\alpha_{e_i} = \\frac{\\exp{C_E^T{e_i}}}{\\sum_{j=0}^{|E|} \\exp{C_E^T{e_j}}}\n$$\n\n$$\n\\alpha_{r_i} = \\frac{\\exp{C_R^T{r_i}}}{\\sum_{j=0}^{|R|} \\exp{C_R^T{r_j}}}\n$$\n![mage-20180511000712](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110007120.png)\n\n2/KGDKRLTransE($h + r = t$)(subject entity)$t = e + r$ $\\mathcal F = [ere + r]$$F \\in \\mathbb R^{3m}$ LSTMx(C) $\\mathbb y$\n$$\n\\mathcal F' = ReLU(\\mathcal F^T V) \\\\\n\\mathbb y = softmax([\\mathcal F' : C]^T U)\n$$\n$V\\mathbb R^{3m \\times u}$$U\\in \\mathbb R^{2u\\times u}$ $\\mathbb y$$\\mathbb y$\n\n#### A+. KG\n\n![mage-20180511003414](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110034147.png)\n\n/attentionKGKGKGKGKGKGKGNews2059SNLI663KGattention/\n\n#### B. \n\nattention/ /attention\n\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110044225.png\" width=\"60%\">\n\n/k-means/$l$CNNclusterk-means/$\\{e^T_1,e^T_2,,e^T_q\\}$$e_i \\in\\mathbb R^m$$ q =\\frac{| E |}{l}$cluster$\\mathcal E$CNN2D$\\mathcal E\\in\\mathbb R^{m\\times q}$ 2-D$e_i$$\\mathcal E$4yk\n$$\n\\mathcal E'(i,j) = W^T[e_{i,j}, e_{i+1,j},...,e_{i+k-1, j}]^T\n$$\n$\\mathcal E'(i,j)$$\\mathcal E'$(i, j)$W\\in \\mathbb R^k$poolingykn$\\mathcal E_i\\in \\mathbb R^m$icluster$E$$R$attentionattention\n\n## 4. Conclusion\n\nKGworld knowledgeembeddingNLP\n\n\n\n## Bibliography\n\n https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742\n\n[^1]: Annervaz, K. M., Somnath Basu Roy Chowdhury, and Ambedkar Dukkipati. 'Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing.' arXiv preprint arXiv:1802.05930 (2018).","slug":"[2018.5.10]Knowledge-Graph-Augmented-Neural-Networks-for-NLP","published":1,"updated":"2020-11-03T03:26:05.090Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpv002qgwtl5hcyhnfp","content":"<h2 id=\"Knowledge-Graph-Augmented-Neural-Networks-for-Natural-language-Processing-\"><a href=\"#Knowledge-Graph-Augmented-Neural-Networks-for-Natural-language-Processing-\" class=\"headerlink\" title=\"Knowledge Graph Augmented Neural Networks for Natural language Processing \"></a>Knowledge Graph Augmented Neural Networks for Natural language Processing </h2><p><strong></strong>[^1]KGNLPattentionattentionNLP</p>\n<h2 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h2><p>transfer learning</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-03-WX20180503-190446%402x.png\" alt=\"X20180503-190446@2\"></p>\n<p>$\\mathcal{X}$$\\mathcal{Y}$$\\mathcal{X}$$\\mathcal{X_w}$$\\mathcal{X}$</p>\n<p>fact(subject entity, relation, object entity)(h,r,t)</p>\n<p>world knowledge $\\langle \\text{},\\text{},\\text{} \\rangle$$\\langle \\text{},\\text{},\\text{} \\rangle$ground-truth</p>\n<p></p>\n<h2 id=\"2-Knowledge-graph-representations\"><a href=\"#2-Knowledge-graph-representations\" class=\"headerlink\" title=\"2. Knowledge graph representations\"></a>2. Knowledge graph representations</h2><p>embeddingstructure-based embeddingsemantically-enriched embedding</p>\n<h4 id=\"structure-based-embedding\"><a href=\"#structure-based-embedding\" class=\"headerlink\" title=\"structure-based embedding\"></a>structure-based embedding</h4><p>TransE$h + r = t$. <a href=\"https://blog.lorrin.info/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/\"></a></p>\n<h4 id=\"semantically-enriched-embedding\"><a href=\"#semantically-enriched-embedding\" class=\"headerlink\" title=\"semantically-enriched embedding\"></a>semantically-enriched embedding</h4><p>embeddingKG/ NTNSocher et al [2011] Zhong et al [2015]SSP Xiao et al[2017] DKRL Xie et al [2016]KGTransE word2vecCNN</p>\n<p>DKRLTransE$t = h + r$fact</p>\n<h2 id=\"3-The-proposed-model\"><a href=\"#3-The-proposed-model\" class=\"headerlink\" title=\"3. The proposed model\"></a>3. The proposed model</h2><p>$\\Theta$$x$$y$<br>$$<br>\\max_{\\Theta}{P(y|x, \\Theta)}<br>$$</p>\n<p><br>$$<br>\\Theta = \\arg\\max_{\\Theta} {\\log{P(y|x, \\Theta)}}<br>$$<br>world knowledge$x_w$$x$world knowledge$x_w = F(x, \\Theta^{(2)})$ <br>$$<br>\\max_{\\Theta}{P(y|x, x_w, \\Theta^{(1)})}<br>$$<br>$\\Theta = {\\Theta^{(1)}, \\Theta^{(2)}}$<br>$$<br>\\Theta = \\arg\\max_{\\Theta} {\\log{P(y|x,F(x, \\Theta^{(2)}), \\Theta^{(1)})}}<br>$$<br>FxsoftmaxLSTM Greff et al. [2015]PFsoft attention</p>\n<p>A. B. </p>\n<h4 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A. \"></a>A. </h4><p>KGDKRL $e_i \\in \\mathbb{R}^m$i$r_j\\in \\mathbb R^m$KGj $x =(x_1,x_2,,x_T)$LSTM Greff et al. [2015]<br>$$<br>h_t = f(x_t, h_{t-1})<br>$$<br><br>$$<br>o = \\frac{1}{T}\\sum_{t=1}^{T}{h_t}<br>$$<br>$h_t \\in \\mathbb{R}^n$LSTMfT <br>$$<br>C = ReLU(o^T W)<br>$$<br>$W\\in \\mathbb R^n \\times m$($C_E$)($C_R$)</p>\n<p>KG <br>$$<br>\\alpha_{e_i} = \\frac{\\exp{C_E^T{e_i}}}{\\sum_{j=0}^{|E|} \\exp{C_E^T{e_j}}}<br>$$<br><br>$$<br>\\alpha_{r_i} = \\frac{\\exp{C_R^T{r_i}}}{\\sum_{j=0}^{|R|} \\exp{C_R^T{r_j}}}<br>$$<br><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110007120.png\" alt=\"mage-20180511000712\"></p>\n<p>2/KGDKRLTransE($h + r = t$)(subject entity)$t = e + r$ $\\mathcal F = [ere + r]$$F \\in \\mathbb R^{3m}$ LSTMx(C) $\\mathbb y$<br>$$<br>\\mathcal F = ReLU(\\mathcal F^T V) \\<br>\\mathbb y = softmax([\\mathcal F : C]^T U)<br>$$<br>$V\\mathbb R^{3m \\times u}$$U\\in \\mathbb R^{2u\\times u}$ $\\mathbb y$$\\mathbb y$</p>\n<h4 id=\"A-KG\"><a href=\"#A-KG\" class=\"headerlink\" title=\"A+. KG\"></a>A+. KG</h4><p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110034147.png\" alt=\"mage-20180511003414\"></p>\n<p>/attentionKGKGKGKGKGKGKGNews2059SNLI663KGattention/</p>\n<h4 id=\"B-\"><a href=\"#B-\" class=\"headerlink\" title=\"B. \"></a>B. </h4><p>attention/ /attention</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110044225.png\" width=\"60%\">\n\n<p>/k-means/$l$CNNclusterk-means/${e^T_1,e^T_2,,e^T_q}$$e_i \\in\\mathbb R^m$$ q =\\frac{| E |}{l}$cluster$\\mathcal E$CNN2D$\\mathcal E\\in\\mathbb R^{m\\times q}$ 2-D$e_i$$\\mathcal E$4yk<br>$$<br>\\mathcal E(i,j) = W^T[e_{i,j}, e_{i+1,j},,e_{i+k-1, j}]^T<br>$$<br>$\\mathcal E(i,j)$$\\mathcal E$(i, j)$W\\in \\mathbb R^k$poolingykn$\\mathcal E_i\\in \\mathbb R^m$icluster$E$$R$attentionattention</p>\n<h2 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h2><p>KGworld knowledgeembeddingNLP</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p> <a href=\"https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742\">https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742</a></p>\n<p>[^1]: Annervaz, K. M., Somnath Basu Roy Chowdhury, and Ambedkar Dukkipati. Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing. arXiv preprint arXiv:1802.05930 (2018).</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"Knowledge-Graph-Augmented-Neural-Networks-for-Natural-language-Processing-\"><a href=\"#Knowledge-Graph-Augmented-Neural-Networks-for-Natural-language-Processing-\" class=\"headerlink\" title=\"Knowledge Graph Augmented Neural Networks for Natural language Processing \"></a>Knowledge Graph Augmented Neural Networks for Natural language Processing </h2><p><strong></strong>[^1]KGNLPattentionattentionNLP</p>\n<h2 id=\"1-Introduction\"><a href=\"#1-Introduction\" class=\"headerlink\" title=\"1. Introduction\"></a>1. Introduction</h2><p>transfer learning</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-03-WX20180503-190446%402x.png\" alt=\"X20180503-190446@2\"></p>\n<p>$\\mathcal{X}$$\\mathcal{Y}$$\\mathcal{X}$$\\mathcal{X_w}$$\\mathcal{X}$</p>\n<p>fact(subject entity, relation, object entity)(h,r,t)</p>\n<p>world knowledge $\\langle \\text{},\\text{},\\text{} \\rangle$$\\langle \\text{},\\text{},\\text{} \\rangle$ground-truth</p>\n<p></p>\n<h2 id=\"2-Knowledge-graph-representations\"><a href=\"#2-Knowledge-graph-representations\" class=\"headerlink\" title=\"2. Knowledge graph representations\"></a>2. Knowledge graph representations</h2><p>embeddingstructure-based embeddingsemantically-enriched embedding</p>\n<h4 id=\"structure-based-embedding\"><a href=\"#structure-based-embedding\" class=\"headerlink\" title=\"structure-based embedding\"></a>structure-based embedding</h4><p>TransE$h + r = t$. <a href=\"https://blog.lorrin.info/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/\"></a></p>\n<h4 id=\"semantically-enriched-embedding\"><a href=\"#semantically-enriched-embedding\" class=\"headerlink\" title=\"semantically-enriched embedding\"></a>semantically-enriched embedding</h4><p>embeddingKG/ NTNSocher et al [2011] Zhong et al [2015]SSP Xiao et al[2017] DKRL Xie et al [2016]KGTransE word2vecCNN</p>\n<p>DKRLTransE$t = h + r$fact</p>\n<h2 id=\"3-The-proposed-model\"><a href=\"#3-The-proposed-model\" class=\"headerlink\" title=\"3. The proposed model\"></a>3. The proposed model</h2><p>$\\Theta$$x$$y$<br>$$<br>\\max_{\\Theta}{P(y|x, \\Theta)}<br>$$</p>\n<p><br>$$<br>\\Theta = \\arg\\max_{\\Theta} {\\log{P(y|x, \\Theta)}}<br>$$<br>world knowledge$x_w$$x$world knowledge$x_w = F(x, \\Theta^{(2)})$ <br>$$<br>\\max_{\\Theta}{P(y|x, x_w, \\Theta^{(1)})}<br>$$<br>$\\Theta = {\\Theta^{(1)}, \\Theta^{(2)}}$<br>$$<br>\\Theta = \\arg\\max_{\\Theta} {\\log{P(y|x,F(x, \\Theta^{(2)}), \\Theta^{(1)})}}<br>$$<br>FxsoftmaxLSTM Greff et al. [2015]PFsoft attention</p>\n<p>A. B. </p>\n<h4 id=\"A-\"><a href=\"#A-\" class=\"headerlink\" title=\"A. \"></a>A. </h4><p>KGDKRL $e_i \\in \\mathbb{R}^m$i$r_j\\in \\mathbb R^m$KGj $x =(x_1,x_2,,x_T)$LSTM Greff et al. [2015]<br>$$<br>h_t = f(x_t, h_{t-1})<br>$$<br><br>$$<br>o = \\frac{1}{T}\\sum_{t=1}^{T}{h_t}<br>$$<br>$h_t \\in \\mathbb{R}^n$LSTMfT <br>$$<br>C = ReLU(o^T W)<br>$$<br>$W\\in \\mathbb R^n \\times m$($C_E$)($C_R$)</p>\n<p>KG <br>$$<br>\\alpha_{e_i} = \\frac{\\exp{C_E^T{e_i}}}{\\sum_{j=0}^{|E|} \\exp{C_E^T{e_j}}}<br>$$<br><br>$$<br>\\alpha_{r_i} = \\frac{\\exp{C_R^T{r_i}}}{\\sum_{j=0}^{|R|} \\exp{C_R^T{r_j}}}<br>$$<br><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110007120.png\" alt=\"mage-20180511000712\"></p>\n<p>2/KGDKRLTransE($h + r = t$)(subject entity)$t = e + r$ $\\mathcal F = [ere + r]$$F \\in \\mathbb R^{3m}$ LSTMx(C) $\\mathbb y$<br>$$<br>\\mathcal F = ReLU(\\mathcal F^T V) \\<br>\\mathbb y = softmax([\\mathcal F : C]^T U)<br>$$<br>$V\\mathbb R^{3m \\times u}$$U\\in \\mathbb R^{2u\\times u}$ $\\mathbb y$$\\mathbb y$</p>\n<h4 id=\"A-KG\"><a href=\"#A-KG\" class=\"headerlink\" title=\"A+. KG\"></a>A+. KG</h4><p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110034147.png\" alt=\"mage-20180511003414\"></p>\n<p>/attentionKGKGKGKGKGKGKGNews2059SNLI663KGattention/</p>\n<h4 id=\"B-\"><a href=\"#B-\" class=\"headerlink\" title=\"B. \"></a>B. </h4><p>attention/ /attention</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-10-image-201805110044225.png\" width=\"60%\">\n\n<p>/k-means/$l$CNNclusterk-means/${e^T_1,e^T_2,,e^T_q}$$e_i \\in\\mathbb R^m$$ q =\\frac{| E |}{l}$cluster$\\mathcal E$CNN2D$\\mathcal E\\in\\mathbb R^{m\\times q}$ 2-D$e_i$$\\mathcal E$4yk<br>$$<br>\\mathcal E(i,j) = W^T[e_{i,j}, e_{i+1,j},,e_{i+k-1, j}]^T<br>$$<br>$\\mathcal E(i,j)$$\\mathcal E$(i, j)$W\\in \\mathbb R^k$poolingykn$\\mathcal E_i\\in \\mathbb R^m$icluster$E$$R$attentionattention</p>\n<h2 id=\"4-Conclusion\"><a href=\"#4-Conclusion\" class=\"headerlink\" title=\"4. Conclusion\"></a>4. Conclusion</h2><p>KGworld knowledgeembeddingNLP</p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p> <a href=\"https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742\">https://blog.csdn.net/TgqDT3gGaMdkHasLZv/article/details/80118742</a></p>\n<p>[^1]: Annervaz, K. M., Somnath Basu Roy Chowdhury, and Ambedkar Dukkipati. Learning beyond datasets: Knowledge Graph Augmented Neural Networks for Natural language Processing. arXiv preprint arXiv:1802.05930 (2018).</p>\n"},{"title":"RegEx with NN","date":"2018-08-22T05:58:00.000Z","_content":"\norz\n\n# Marrying Up Regexs with Neural Networks\n\n## \n\n-  \n\n  - \n\n  - \n\n-  \n  -   \n  - \n\ncases\n\nBingfeng et al. 2018[^1]\n\n## Problem def. and the baselines \n\nintent detectionslot fillingclassificationseq2seqbaselinesLiu, Bing, and Ian Lane. 2016[^2]attention-based rnn\n\n![image-20180916143407395](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-063410.png)\n\n## Approaches\n\ninput levelnetwork leveloutput level\n\n### Input level\n\n- For intent detection, \n\n  two possible approach:\n\n  - Append the embedding to all words (deprecated <= )\n  - Append the embedding to the input of softmax layer( in Fig(a) )\n\n- For slot filling, \n\n  Embed and average the REtags into a vector fi for each word and append it to the corresponding word embedding wi ( in Fig(b) )\n\n![image-20180916144059096](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064101.png)\n\n### Network level\n\n- For intent detection, \n\n  For each intent label k, use different attention ak , which is used to generate the sentence embedding sk   ( in Fig(a) )\n\n  Note that a RE can also indicate that a sentence does not express intent k (negative REs), it is also necessary to set another group of attention. \n\n\n$$\n  s_{k} = \\sum_i {\\alpha_{ki} h_i}, \\quad \\alpha_{ki} = \\frac{\\exp(h_i^T W_{a} c_k)}{\\sum_i {\\exp(h_i^T W_{a} c_k)}}\n$$\n\n- For slot filling, \n\n  The mechanism introduced for intent detection is unsuitable for slot filling.\n\n  A simple version of the two-side attention, where all the slot labels share the same set of positive and negative attention. ( in Fig(b) )\n\n  $$\n  s_{pi} = \\sum_j {\\alpha_{pij} h_j}, \\quad \\alpha_{pij} = \\frac{\\exp(h_j^T W_{sp} h_i)}{\\sum_j {\\exp(h_j^T W_{sp} h_i)}}\n  $$\n\n\n\n\n![image-20180916144733081](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064735.png)\n\n### Output level\n\nLet $z_k$ be a 0-1 indicator of whether there is at least one matched RE that leads to target label $k$ (intent or slot label), the final logits of label k for a sentence (or a spefic word for slot filling) is:\n$$\nlogit_k = logit_k' + w_k z_k\n$$\nwhere $logit_k$ is the logit produced by the original NN, and $w_k$ is a trainable weight indicating the overall confidence for REs that lead to target label $k$.\n\n## Experimental Results \n\n![image-20180916145004296](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065006.png) \n\n![image-20180916145033498](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065035.png)\n\n## Bibliography\n\n[^1]: Luo, Bingfeng, et al. Marrying up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding.arXiv preprint arXiv:1805.05588(2018). \n[^2]: Liu, Bing, and Ian Lane. Attention-based recurrent neural network models for joint intent detection and slot filling. arXiv preprint arXiv:1609.01454 (2016). \n\n\n","source":"_posts/[2018.8.22]RegEx-with-NN.md","raw":"---\ntitle: RegEx with NN\ncategories:\n  - research\ntags:\n  - neural-network\n  - regular-expression\ndate: 2018-08-22 13:58:00\n---\n\norz\n\n# Marrying Up Regexs with Neural Networks\n\n## \n\n-  \n\n  - \n\n  - \n\n-  \n  -   \n  - \n\ncases\n\nBingfeng et al. 2018[^1]\n\n## Problem def. and the baselines \n\nintent detectionslot fillingclassificationseq2seqbaselinesLiu, Bing, and Ian Lane. 2016[^2]attention-based rnn\n\n![image-20180916143407395](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-063410.png)\n\n## Approaches\n\ninput levelnetwork leveloutput level\n\n### Input level\n\n- For intent detection, \n\n  two possible approach:\n\n  - Append the embedding to all words (deprecated <= )\n  - Append the embedding to the input of softmax layer( in Fig(a) )\n\n- For slot filling, \n\n  Embed and average the REtags into a vector fi for each word and append it to the corresponding word embedding wi ( in Fig(b) )\n\n![image-20180916144059096](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064101.png)\n\n### Network level\n\n- For intent detection, \n\n  For each intent label k, use different attention ak , which is used to generate the sentence embedding sk   ( in Fig(a) )\n\n  Note that a RE can also indicate that a sentence does not express intent k (negative REs), it is also necessary to set another group of attention. \n\n\n$$\n  s_{k} = \\sum_i {\\alpha_{ki} h_i}, \\quad \\alpha_{ki} = \\frac{\\exp(h_i^T W_{a} c_k)}{\\sum_i {\\exp(h_i^T W_{a} c_k)}}\n$$\n\n- For slot filling, \n\n  The mechanism introduced for intent detection is unsuitable for slot filling.\n\n  A simple version of the two-side attention, where all the slot labels share the same set of positive and negative attention. ( in Fig(b) )\n\n  $$\n  s_{pi} = \\sum_j {\\alpha_{pij} h_j}, \\quad \\alpha_{pij} = \\frac{\\exp(h_j^T W_{sp} h_i)}{\\sum_j {\\exp(h_j^T W_{sp} h_i)}}\n  $$\n\n\n\n\n![image-20180916144733081](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064735.png)\n\n### Output level\n\nLet $z_k$ be a 0-1 indicator of whether there is at least one matched RE that leads to target label $k$ (intent or slot label), the final logits of label k for a sentence (or a spefic word for slot filling) is:\n$$\nlogit_k = logit_k' + w_k z_k\n$$\nwhere $logit_k$ is the logit produced by the original NN, and $w_k$ is a trainable weight indicating the overall confidence for REs that lead to target label $k$.\n\n## Experimental Results \n\n![image-20180916145004296](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065006.png) \n\n![image-20180916145033498](https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065035.png)\n\n## Bibliography\n\n[^1]: Luo, Bingfeng, et al. Marrying up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding.arXiv preprint arXiv:1805.05588(2018). \n[^2]: Liu, Bing, and Ian Lane. Attention-based recurrent neural network models for joint intent detection and slot filling. arXiv preprint arXiv:1609.01454 (2016). \n\n\n","slug":"[2018.8.22]RegEx-with-NN","published":1,"updated":"2020-11-03T03:26:04.399Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpw002ugwtl2aagaeeh","content":"<p>orz</p>\n<h1 id=\"Marrying-Up-Regexs-with-Neural-Networks\"><a href=\"#Marrying-Up-Regexs-with-Neural-Networks\" class=\"headerlink\" title=\"Marrying Up Regexs with Neural Networks\"></a>Marrying Up Regexs with Neural Networks</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p> </p>\n<ul>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p> </p>\n<ul>\n<li>  </li>\n<li></li>\n</ul>\n</li>\n</ul>\n<p>cases</p>\n<p>Bingfeng et al. 2018[^1]</p>\n<h2 id=\"Problem-def-and-the-baselines\"><a href=\"#Problem-def-and-the-baselines\" class=\"headerlink\" title=\"Problem def. and the baselines\"></a>Problem def. and the baselines</h2><p>intent detectionslot fillingclassificationseq2seqbaselinesLiu, Bing, and Ian Lane. 2016[^2]attention-based rnn</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-063410.png\" alt=\"image-20180916143407395\"></p>\n<h2 id=\"Approaches\"><a href=\"#Approaches\" class=\"headerlink\" title=\"Approaches\"></a>Approaches</h2><p>input levelnetwork leveloutput level</p>\n<h3 id=\"Input-level\"><a href=\"#Input-level\" class=\"headerlink\" title=\"Input level\"></a>Input level</h3><ul>\n<li><p>For intent detection, </p>\n<p>two possible approach:</p>\n<ul>\n<li>Append the embedding to all words (deprecated &lt;= )</li>\n<li>Append the embedding to the input of softmax layer( in Fig(a) )</li>\n</ul>\n</li>\n<li><p>For slot filling, </p>\n<p>Embed and average the REtags into a vector fi for each word and append it to the corresponding word embedding wi ( in Fig(b) )</p>\n</li>\n</ul>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064101.png\" alt=\"image-20180916144059096\"></p>\n<h3 id=\"Network-level\"><a href=\"#Network-level\" class=\"headerlink\" title=\"Network level\"></a>Network level</h3><ul>\n<li><p>For intent detection, </p>\n<p>For each intent label k, use different attention ak , which is used to generate the sentence embedding sk   ( in Fig(a) )</p>\n<p>Note that a RE can also indicate that a sentence does not express intent k (negative REs), it is also necessary to set another group of attention. </p>\n</li>\n</ul>\n<p>$$<br>  s_{k} = \\sum_i {\\alpha_{ki} h_i}, \\quad \\alpha_{ki} = \\frac{\\exp(h_i^T W_{a} c_k)}{\\sum_i {\\exp(h_i^T W_{a} c_k)}}<br>$$</p>\n<ul>\n<li><p>For slot filling, </p>\n<p>The mechanism introduced for intent detection is unsuitable for slot filling.</p>\n<p>A simple version of the two-side attention, where all the slot labels share the same set of positive and negative attention. ( in Fig(b) )</p>\n<p>$$<br>s_{pi} = \\sum_j {\\alpha_{pij} h_j}, \\quad \\alpha_{pij} = \\frac{\\exp(h_j^T W_{sp} h_i)}{\\sum_j {\\exp(h_j^T W_{sp} h_i)}}<br>$$</p>\n</li>\n</ul>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064735.png\" alt=\"image-20180916144733081\"></p>\n<h3 id=\"Output-level\"><a href=\"#Output-level\" class=\"headerlink\" title=\"Output level\"></a>Output level</h3><p>Let $z_k$ be a 0-1 indicator of whether there is at least one matched RE that leads to target label $k$ (intent or slot label), the final logits of label k for a sentence (or a spefic word for slot filling) is:<br>$$<br>logit_k = logit_k + w_k z_k<br>$$<br>where $logit_k$ is the logit produced by the original NN, and $w_k$ is a trainable weight indicating the overall confidence for REs that lead to target label $k$.</p>\n<h2 id=\"Experimental-Results\"><a href=\"#Experimental-Results\" class=\"headerlink\" title=\"Experimental Results\"></a>Experimental Results</h2><p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065006.png\" alt=\"image-20180916145004296\"> </p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065035.png\" alt=\"image-20180916145033498\"></p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[^1]: Luo, Bingfeng, et al. Marrying up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding.&nbsp;arXiv preprint arXiv:1805.05588&nbsp;(2018).<br>[^2]: Liu, Bing, and Ian Lane. Attention-based recurrent neural network models for joint intent detection and slot filling. arXiv preprint arXiv:1609.01454 (2016). </p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>orz</p>\n<h1 id=\"Marrying-Up-Regexs-with-Neural-Networks\"><a href=\"#Marrying-Up-Regexs-with-Neural-Networks\" class=\"headerlink\" title=\"Marrying Up Regexs with Neural Networks\"></a>Marrying Up Regexs with Neural Networks</h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ul>\n<li><p> </p>\n<ul>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p> </p>\n<ul>\n<li>  </li>\n<li></li>\n</ul>\n</li>\n</ul>\n<p>cases</p>\n<p>Bingfeng et al. 2018[^1]</p>\n<h2 id=\"Problem-def-and-the-baselines\"><a href=\"#Problem-def-and-the-baselines\" class=\"headerlink\" title=\"Problem def. and the baselines\"></a>Problem def. and the baselines</h2><p>intent detectionslot fillingclassificationseq2seqbaselinesLiu, Bing, and Ian Lane. 2016[^2]attention-based rnn</p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-063410.png\" alt=\"image-20180916143407395\"></p>\n<h2 id=\"Approaches\"><a href=\"#Approaches\" class=\"headerlink\" title=\"Approaches\"></a>Approaches</h2><p>input levelnetwork leveloutput level</p>\n<h3 id=\"Input-level\"><a href=\"#Input-level\" class=\"headerlink\" title=\"Input level\"></a>Input level</h3><ul>\n<li><p>For intent detection, </p>\n<p>two possible approach:</p>\n<ul>\n<li>Append the embedding to all words (deprecated &lt;= )</li>\n<li>Append the embedding to the input of softmax layer( in Fig(a) )</li>\n</ul>\n</li>\n<li><p>For slot filling, </p>\n<p>Embed and average the REtags into a vector fi for each word and append it to the corresponding word embedding wi ( in Fig(b) )</p>\n</li>\n</ul>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064101.png\" alt=\"image-20180916144059096\"></p>\n<h3 id=\"Network-level\"><a href=\"#Network-level\" class=\"headerlink\" title=\"Network level\"></a>Network level</h3><ul>\n<li><p>For intent detection, </p>\n<p>For each intent label k, use different attention ak , which is used to generate the sentence embedding sk   ( in Fig(a) )</p>\n<p>Note that a RE can also indicate that a sentence does not express intent k (negative REs), it is also necessary to set another group of attention. </p>\n</li>\n</ul>\n<p>$$<br>  s_{k} = \\sum_i {\\alpha_{ki} h_i}, \\quad \\alpha_{ki} = \\frac{\\exp(h_i^T W_{a} c_k)}{\\sum_i {\\exp(h_i^T W_{a} c_k)}}<br>$$</p>\n<ul>\n<li><p>For slot filling, </p>\n<p>The mechanism introduced for intent detection is unsuitable for slot filling.</p>\n<p>A simple version of the two-side attention, where all the slot labels share the same set of positive and negative attention. ( in Fig(b) )</p>\n<p>$$<br>s_{pi} = \\sum_j {\\alpha_{pij} h_j}, \\quad \\alpha_{pij} = \\frac{\\exp(h_j^T W_{sp} h_i)}{\\sum_j {\\exp(h_j^T W_{sp} h_i)}}<br>$$</p>\n</li>\n</ul>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-064735.png\" alt=\"image-20180916144733081\"></p>\n<h3 id=\"Output-level\"><a href=\"#Output-level\" class=\"headerlink\" title=\"Output level\"></a>Output level</h3><p>Let $z_k$ be a 0-1 indicator of whether there is at least one matched RE that leads to target label $k$ (intent or slot label), the final logits of label k for a sentence (or a spefic word for slot filling) is:<br>$$<br>logit_k = logit_k + w_k z_k<br>$$<br>where $logit_k$ is the logit produced by the original NN, and $w_k$ is a trainable weight indicating the overall confidence for REs that lead to target label $k$.</p>\n<h2 id=\"Experimental-Results\"><a href=\"#Experimental-Results\" class=\"headerlink\" title=\"Experimental Results\"></a>Experimental Results</h2><p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065006.png\" alt=\"image-20180916145004296\"> </p>\n<p><img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-09-16-065035.png\" alt=\"image-20180916145033498\"></p>\n<h2 id=\"Bibliography\"><a href=\"#Bibliography\" class=\"headerlink\" title=\"Bibliography\"></a>Bibliography</h2><p>[^1]: Luo, Bingfeng, et al. Marrying up Regular Expressions with Neural Networks: A Case Study for Spoken Language Understanding.arXiv preprint arXiv:1805.05588(2018).<br>[^2]: Liu, Bing, and Ian Lane. Attention-based recurrent neural network models for joint intent detection and slot filling. arXiv preprint arXiv:1609.01454 (2016). </p>\n"},{"title":"nlp short reviews - week 1","date":"2018-09-18T03:24:29.000Z","_content":"\n## 9.21\n\n### Robust Spoken Language Understanding via Paraphrasing. (arXiv:1809.06444v1 [cs.CL])\n\n***Abstract:*** Learning intents and slot labels from user utterances is a fundamental step in all spoken language understanding (SLU) and dialog systems. State-of-the-art neural network based methods, after deployment, often suffer from performance degradation on encountering paraphrased utterances, and out-of-vocabulary words, rarely observed in their training set. We address this challenging problem by introducing a novel paraphrasing based SLU model which can be integrated with any existing SLU model in order to improve their overall performance. We propose two new paraphrase generators using RNN and sequence-to-sequence based neural networks, which are suitable for our application. Our experiments on existing benchmark and in house datasets demonstrate the robustness of our models to rare and complex paraphrased utterances, even under adversarial test distributions.\n\n***Comment:***  SLUstate-of-the-artstate-of-the-artSLUOlabel??word\n\n## 9.20\n\n### User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks. (arXiv:1809.06559v1 [cs.CL])\n\n***Abstract:*** Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. It has two main tasks: intent detection and slot filling. Although state-of-the-art approaches showed good results, they require large annotated training data and long training time. In this paper, we aim to alleviate these drawbacks for semantic frame parsing by utilizing the ubiquitous user information. We design a novel coarse-to-fine deep neural network model to incorporate prior knowledge of user information intermediately to better and quickly train a semantic frame parser. Due to the lack of benchmark dataset with real user information, we synthesize the simplest type of user information (location and time) on ATIS benchmark data. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.\n\n***Comment:***  intent classificationslot fillingstate-of-the-artattention-based-biLSTM\n\n### Learning Universal Sentence Representations with Mean-Max Attention Autoencoder. (arXiv:1809.06590v1 [cs.CL])\n\n***Abstract:*** In order to learn universal sentence representations, previous methods focus on complex recurrent neural networks or supervised learning. In this paper, we propose a mean-max attention autoencoder (mean-max AAE) within the encoder-decoder framework. Our autoencoder rely entirely on the MultiHead self-attention mechanism to reconstruct the input sequence. In the encoding we propose a mean-max strategy that applies both mean and max pooling operations over the hidden vectors to capture diverse information of the input. To enable the information to steer the reconstruction process dynamically, the decoder performs attention over the mean-max representation. By training our model on a large collection of unlabelled data, we obtain high-quality representations of sentences. Experimental results on a broad range of 10 transfer tasks demonstrate that our model outperforms the state-of-the-art unsupervised single methods, including the classical skip-thoughts and the advanced skip-thoughts+LN model. Furthermore, compared with the traditional recurrent neural network, our mean-max AAE greatly reduce the training time.\n\n***Comment:***  mean-max AAEself-attentionmean-max poolingencoderdecoderstate-of-the-art\n\n### Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation. (arXiv:1809.06748v1 [cs.CL])\n\n***Abstract:*** In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task: semantic interpretation of noun--noun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that transfer learning via parameter initialization and multi-task learning via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its F1 scores on the less frequent, but more difficult relations.\n\n***Comment:*** interpretationtransfer learningmulti-task learningnoun-noun compoundrelation extraction\n\n## 9.18\n\n### Learning to Accept New Classes without Training. (arXiv:1809.06004v1 \\[cs.CL\\])]\n\n***Abstract:*** Classic supervised learning makes the closed-world assumption, meaning that classes seen in testing must have been seen in training. However, in the dynamic world, new or unseen class examples may appear constantly. A model working in such an environment must be able to reject unseen classes (not seen or used in training). If enough data is collected for the unseen classes, the system should incrementally learn to accept/classify them. This learning paradigm is called open-world learning (OWL). Existing OWL methods all need some form of re-training to accept or include the new classes in the overall model. In this paper, we propose a meta-learning approach to the problem. Its key novelty is that it only needs to train a meta-classifier, which can then continually accept new classes when they have enough labeled data for the meta-classifier to use, and also detect/reject future unseen classes. No re-training of the meta-classifier or a new overall classifier covering all old and new classes is needed. In testing, the method only uses the examples of the seen classes (including the newly added classes) on-the-fly for classification and rejection. Experimental results demonstrate the effectiveness of the new approach.\n\n***Comment:*** meta-classifierknnmeta-classifier\n\n### Events Beyond ACE: Curated Training for Events. (arXiv:1809.05576v1 \\[cs.CL\\])\n\n***Abstract:*** We explore a human-driven approach to annotation, curated training (CT), in which annotation is framed as teaching the system by using interactive search to identify informative snippets of text to annotate, unlike traditional approaches which either annotate preselected text or use active learning. A trained annotator performed 80 hours of CT for the thirty event types of the NIST TAC KBP Event Argument Extraction evaluation. Combining this annotation with ACE results in a 6% reduction in error and the learning curve of CT plateaus more slowly than for full-document annotation. 3 NLP researchers performed CT for one event type and showed much sharper learning curves with all three exceeding ACE performance in less than ninety minutes, suggesting that CT can provide further benefits when the annotator deeply understands the system.\n\n***Comment:*** mark\n\n### Extending Neural Generative Conversational Model using External Knowledge Sources. (arXiv:1809.05524v1 [cs.CL])\n\n***Abstract:*** The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.\n\n***Comment:*** paper\n","source":"_posts/[2018.9]nlp-short-reviews-week-1.md","raw":"---\ntitle: nlp short reviews - week 1\ndate: 2018-09-18 11:24:29\ncategories: [research]\ntags: [review, nlp]\n---\n\n## 9.21\n\n### Robust Spoken Language Understanding via Paraphrasing. (arXiv:1809.06444v1 [cs.CL])\n\n***Abstract:*** Learning intents and slot labels from user utterances is a fundamental step in all spoken language understanding (SLU) and dialog systems. State-of-the-art neural network based methods, after deployment, often suffer from performance degradation on encountering paraphrased utterances, and out-of-vocabulary words, rarely observed in their training set. We address this challenging problem by introducing a novel paraphrasing based SLU model which can be integrated with any existing SLU model in order to improve their overall performance. We propose two new paraphrase generators using RNN and sequence-to-sequence based neural networks, which are suitable for our application. Our experiments on existing benchmark and in house datasets demonstrate the robustness of our models to rare and complex paraphrased utterances, even under adversarial test distributions.\n\n***Comment:***  SLUstate-of-the-artstate-of-the-artSLUOlabel??word\n\n## 9.20\n\n### User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks. (arXiv:1809.06559v1 [cs.CL])\n\n***Abstract:*** Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. It has two main tasks: intent detection and slot filling. Although state-of-the-art approaches showed good results, they require large annotated training data and long training time. In this paper, we aim to alleviate these drawbacks for semantic frame parsing by utilizing the ubiquitous user information. We design a novel coarse-to-fine deep neural network model to incorporate prior knowledge of user information intermediately to better and quickly train a semantic frame parser. Due to the lack of benchmark dataset with real user information, we synthesize the simplest type of user information (location and time) on ATIS benchmark data. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.\n\n***Comment:***  intent classificationslot fillingstate-of-the-artattention-based-biLSTM\n\n### Learning Universal Sentence Representations with Mean-Max Attention Autoencoder. (arXiv:1809.06590v1 [cs.CL])\n\n***Abstract:*** In order to learn universal sentence representations, previous methods focus on complex recurrent neural networks or supervised learning. In this paper, we propose a mean-max attention autoencoder (mean-max AAE) within the encoder-decoder framework. Our autoencoder rely entirely on the MultiHead self-attention mechanism to reconstruct the input sequence. In the encoding we propose a mean-max strategy that applies both mean and max pooling operations over the hidden vectors to capture diverse information of the input. To enable the information to steer the reconstruction process dynamically, the decoder performs attention over the mean-max representation. By training our model on a large collection of unlabelled data, we obtain high-quality representations of sentences. Experimental results on a broad range of 10 transfer tasks demonstrate that our model outperforms the state-of-the-art unsupervised single methods, including the classical skip-thoughts and the advanced skip-thoughts+LN model. Furthermore, compared with the traditional recurrent neural network, our mean-max AAE greatly reduce the training time.\n\n***Comment:***  mean-max AAEself-attentionmean-max poolingencoderdecoderstate-of-the-art\n\n### Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation. (arXiv:1809.06748v1 [cs.CL])\n\n***Abstract:*** In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task: semantic interpretation of noun--noun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that transfer learning via parameter initialization and multi-task learning via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its F1 scores on the less frequent, but more difficult relations.\n\n***Comment:*** interpretationtransfer learningmulti-task learningnoun-noun compoundrelation extraction\n\n## 9.18\n\n### Learning to Accept New Classes without Training. (arXiv:1809.06004v1 \\[cs.CL\\])]\n\n***Abstract:*** Classic supervised learning makes the closed-world assumption, meaning that classes seen in testing must have been seen in training. However, in the dynamic world, new or unseen class examples may appear constantly. A model working in such an environment must be able to reject unseen classes (not seen or used in training). If enough data is collected for the unseen classes, the system should incrementally learn to accept/classify them. This learning paradigm is called open-world learning (OWL). Existing OWL methods all need some form of re-training to accept or include the new classes in the overall model. In this paper, we propose a meta-learning approach to the problem. Its key novelty is that it only needs to train a meta-classifier, which can then continually accept new classes when they have enough labeled data for the meta-classifier to use, and also detect/reject future unseen classes. No re-training of the meta-classifier or a new overall classifier covering all old and new classes is needed. In testing, the method only uses the examples of the seen classes (including the newly added classes) on-the-fly for classification and rejection. Experimental results demonstrate the effectiveness of the new approach.\n\n***Comment:*** meta-classifierknnmeta-classifier\n\n### Events Beyond ACE: Curated Training for Events. (arXiv:1809.05576v1 \\[cs.CL\\])\n\n***Abstract:*** We explore a human-driven approach to annotation, curated training (CT), in which annotation is framed as teaching the system by using interactive search to identify informative snippets of text to annotate, unlike traditional approaches which either annotate preselected text or use active learning. A trained annotator performed 80 hours of CT for the thirty event types of the NIST TAC KBP Event Argument Extraction evaluation. Combining this annotation with ACE results in a 6% reduction in error and the learning curve of CT plateaus more slowly than for full-document annotation. 3 NLP researchers performed CT for one event type and showed much sharper learning curves with all three exceeding ACE performance in less than ninety minutes, suggesting that CT can provide further benefits when the annotator deeply understands the system.\n\n***Comment:*** mark\n\n### Extending Neural Generative Conversational Model using External Knowledge Sources. (arXiv:1809.05524v1 [cs.CL])\n\n***Abstract:*** The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.\n\n***Comment:*** paper\n","slug":"[2018.9]nlp-short-reviews-week-1","published":1,"updated":"2018-10-06T02:10:34.775Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpx002ygwtlfb0shkrr","content":"<h2 id=\"9-21\"><a href=\"#9-21\" class=\"headerlink\" title=\"9.21\"></a>9.21</h2><h3 id=\"Robust-Spoken-Language-Understanding-via-Paraphrasing-arXiv-1809-06444v1-cs-CL\"><a href=\"#Robust-Spoken-Language-Understanding-via-Paraphrasing-arXiv-1809-06444v1-cs-CL\" class=\"headerlink\" title=\"Robust Spoken Language Understanding via Paraphrasing. (arXiv:1809.06444v1 [cs.CL])\"></a>Robust Spoken Language Understanding via Paraphrasing. (arXiv:1809.06444v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> Learning intents and slot labels from user utterances is a fundamental step in all spoken language understanding (SLU) and dialog systems. State-of-the-art neural network based methods, after deployment, often suffer from performance degradation on encountering paraphrased utterances, and out-of-vocabulary words, rarely observed in their training set. We address this challenging problem by introducing a novel paraphrasing based SLU model which can be integrated with any existing SLU model in order to improve their overall performance. We propose two new paraphrase generators using RNN and sequence-to-sequence based neural networks, which are suitable for our application. Our experiments on existing benchmark and in house datasets demonstrate the robustness of our models to rare and complex paraphrased utterances, even under adversarial test distributions.</p>\n<p><em><strong>Comment:</strong></em>  SLUstate-of-the-artstate-of-the-artSLUOlabel??word</p>\n<h2 id=\"9-20\"><a href=\"#9-20\" class=\"headerlink\" title=\"9.20\"></a>9.20</h2><h3 id=\"User-Information-Augmented-Semantic-Frame-Parsing-using-Coarse-to-Fine-Neural-Networks-arXiv-1809-06559v1-cs-CL\"><a href=\"#User-Information-Augmented-Semantic-Frame-Parsing-using-Coarse-to-Fine-Neural-Networks-arXiv-1809-06559v1-cs-CL\" class=\"headerlink\" title=\"User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks. (arXiv:1809.06559v1 [cs.CL])\"></a>User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks. (arXiv:1809.06559v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. It has two main tasks: intent detection and slot filling. Although state-of-the-art approaches showed good results, they require large annotated training data and long training time. In this paper, we aim to alleviate these drawbacks for semantic frame parsing by utilizing the ubiquitous user information. We design a novel coarse-to-fine deep neural network model to incorporate prior knowledge of user information intermediately to better and quickly train a semantic frame parser. Due to the lack of benchmark dataset with real user information, we synthesize the simplest type of user information (location and time) on ATIS benchmark data. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.</p>\n<p><em><strong>Comment:</strong></em>  intent classificationslot fillingstate-of-the-artattention-based-biLSTM</p>\n<h3 id=\"Learning-Universal-Sentence-Representations-with-Mean-Max-Attention-Autoencoder-arXiv-1809-06590v1-cs-CL\"><a href=\"#Learning-Universal-Sentence-Representations-with-Mean-Max-Attention-Autoencoder-arXiv-1809-06590v1-cs-CL\" class=\"headerlink\" title=\"Learning Universal Sentence Representations with Mean-Max Attention Autoencoder. (arXiv:1809.06590v1 [cs.CL])\"></a>Learning Universal Sentence Representations with Mean-Max Attention Autoencoder. (arXiv:1809.06590v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> In order to learn universal sentence representations, previous methods focus on complex recurrent neural networks or supervised learning. In this paper, we propose a mean-max attention autoencoder (mean-max AAE) within the encoder-decoder framework. Our autoencoder rely entirely on the MultiHead self-attention mechanism to reconstruct the input sequence. In the encoding we propose a mean-max strategy that applies both mean and max pooling operations over the hidden vectors to capture diverse information of the input. To enable the information to steer the reconstruction process dynamically, the decoder performs attention over the mean-max representation. By training our model on a large collection of unlabelled data, we obtain high-quality representations of sentences. Experimental results on a broad range of 10 transfer tasks demonstrate that our model outperforms the state-of-the-art unsupervised single methods, including the classical skip-thoughts and the advanced skip-thoughts+LN model. Furthermore, compared with the traditional recurrent neural network, our mean-max AAE greatly reduce the training time.</p>\n<p><em><strong>Comment:</strong></em>  mean-max AAEself-attentionmean-max poolingencoderdecoderstate-of-the-art</p>\n<h3 id=\"Transfer-and-Multi-Task-Learning-for-Noun-Noun-Compound-Interpretation-arXiv-1809-06748v1-cs-CL\"><a href=\"#Transfer-and-Multi-Task-Learning-for-Noun-Noun-Compound-Interpretation-arXiv-1809-06748v1-cs-CL\" class=\"headerlink\" title=\"Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation. (arXiv:1809.06748v1 [cs.CL])\"></a>Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation. (arXiv:1809.06748v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task: semantic interpretation of nounnoun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that transfer learning via parameter initialization and multi-task learning via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its F1 scores on the less frequent, but more difficult relations.</p>\n<p><em><strong>Comment:</strong></em> interpretationtransfer learningmulti-task learningnoun-noun compoundrelation extraction</p>\n<h2 id=\"9-18\"><a href=\"#9-18\" class=\"headerlink\" title=\"9.18\"></a>9.18</h2><h3 id=\"Learning-to-Accept-New-Classes-without-Training-arXiv-1809-06004v1-cs-CL\"><a href=\"#Learning-to-Accept-New-Classes-without-Training-arXiv-1809-06004v1-cs-CL\" class=\"headerlink\" title=\"Learning to Accept New Classes without Training. (arXiv:1809.06004v1 [cs.CL])]\"></a>Learning to Accept New Classes without Training. (arXiv:1809.06004v1 [cs.CL])]</h3><p><em><strong>Abstract:</strong></em> Classic supervised learning makes the closed-world assumption, meaning that classes seen in testing must have been seen in training. However, in the dynamic world, new or unseen class examples may appear constantly. A model working in such an environment must be able to reject unseen classes (not seen or used in training). If enough data is collected for the unseen classes, the system should incrementally learn to accept/classify them. This learning paradigm is called open-world learning (OWL). Existing OWL methods all need some form of re-training to accept or include the new classes in the overall model. In this paper, we propose a meta-learning approach to the problem. Its key novelty is that it only needs to train a meta-classifier, which can then continually accept new classes when they have enough labeled data for the meta-classifier to use, and also detect/reject future unseen classes. No re-training of the meta-classifier or a new overall classifier covering all old and new classes is needed. In testing, the method only uses the examples of the seen classes (including the newly added classes) on-the-fly for classification and rejection. Experimental results demonstrate the effectiveness of the new approach.</p>\n<p><em><strong>Comment:</strong></em> meta-classifierknnmeta-classifier</p>\n<h3 id=\"Events-Beyond-ACE-Curated-Training-for-Events-arXiv-1809-05576v1-cs-CL\"><a href=\"#Events-Beyond-ACE-Curated-Training-for-Events-arXiv-1809-05576v1-cs-CL\" class=\"headerlink\" title=\"Events Beyond ACE: Curated Training for Events. (arXiv:1809.05576v1 [cs.CL])\"></a>Events Beyond ACE: Curated Training for Events. (arXiv:1809.05576v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> We explore a human-driven approach to annotation, curated training (CT), in which annotation is framed as teaching the system by using interactive search to identify informative snippets of text to annotate, unlike traditional approaches which either annotate preselected text or use active learning. A trained annotator performed 80 hours of CT for the thirty event types of the NIST TAC KBP Event Argument Extraction evaluation. Combining this annotation with ACE results in a 6% reduction in error and the learning curve of CT plateaus more slowly than for full-document annotation. 3 NLP researchers performed CT for one event type and showed much sharper learning curves with all three exceeding ACE performance in less than ninety minutes, suggesting that CT can provide further benefits when the annotator deeply understands the system.</p>\n<p><em><strong>Comment:</strong></em> mark</p>\n<h3 id=\"Extending-Neural-Generative-Conversational-Model-using-External-Knowledge-Sources-arXiv-1809-05524v1-cs-CL\"><a href=\"#Extending-Neural-Generative-Conversational-Model-using-External-Knowledge-Sources-arXiv-1809-05524v1-cs-CL\" class=\"headerlink\" title=\"Extending Neural Generative Conversational Model using External Knowledge Sources. (arXiv:1809.05524v1 [cs.CL])\"></a>Extending Neural Generative Conversational Model using External Knowledge Sources. (arXiv:1809.05524v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.</p>\n<p><em><strong>Comment:</strong></em> paper</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h2 id=\"9-21\"><a href=\"#9-21\" class=\"headerlink\" title=\"9.21\"></a>9.21</h2><h3 id=\"Robust-Spoken-Language-Understanding-via-Paraphrasing-arXiv-1809-06444v1-cs-CL\"><a href=\"#Robust-Spoken-Language-Understanding-via-Paraphrasing-arXiv-1809-06444v1-cs-CL\" class=\"headerlink\" title=\"Robust Spoken Language Understanding via Paraphrasing. (arXiv:1809.06444v1 [cs.CL])\"></a>Robust Spoken Language Understanding via Paraphrasing. (arXiv:1809.06444v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> Learning intents and slot labels from user utterances is a fundamental step in all spoken language understanding (SLU) and dialog systems. State-of-the-art neural network based methods, after deployment, often suffer from performance degradation on encountering paraphrased utterances, and out-of-vocabulary words, rarely observed in their training set. We address this challenging problem by introducing a novel paraphrasing based SLU model which can be integrated with any existing SLU model in order to improve their overall performance. We propose two new paraphrase generators using RNN and sequence-to-sequence based neural networks, which are suitable for our application. Our experiments on existing benchmark and in house datasets demonstrate the robustness of our models to rare and complex paraphrased utterances, even under adversarial test distributions.</p>\n<p><em><strong>Comment:</strong></em>  SLUstate-of-the-artstate-of-the-artSLUOlabel??word</p>\n<h2 id=\"9-20\"><a href=\"#9-20\" class=\"headerlink\" title=\"9.20\"></a>9.20</h2><h3 id=\"User-Information-Augmented-Semantic-Frame-Parsing-using-Coarse-to-Fine-Neural-Networks-arXiv-1809-06559v1-cs-CL\"><a href=\"#User-Information-Augmented-Semantic-Frame-Parsing-using-Coarse-to-Fine-Neural-Networks-arXiv-1809-06559v1-cs-CL\" class=\"headerlink\" title=\"User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks. (arXiv:1809.06559v1 [cs.CL])\"></a>User Information Augmented Semantic Frame Parsing using Coarse-to-Fine Neural Networks. (arXiv:1809.06559v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> Semantic frame parsing is a crucial component in spoken language understanding (SLU) to build spoken dialog systems. It has two main tasks: intent detection and slot filling. Although state-of-the-art approaches showed good results, they require large annotated training data and long training time. In this paper, we aim to alleviate these drawbacks for semantic frame parsing by utilizing the ubiquitous user information. We design a novel coarse-to-fine deep neural network model to incorporate prior knowledge of user information intermediately to better and quickly train a semantic frame parser. Due to the lack of benchmark dataset with real user information, we synthesize the simplest type of user information (location and time) on ATIS benchmark data. The results show that our approach leverages such simple user information to outperform state-of-the-art approaches by 0.25% for intent detection and 0.31% for slot filling using standard training data. When using smaller training data, the performance improvement on intent detection and slot filling reaches up to 1.35% and 1.20% respectively. We also show that our approach can achieve similar performance as state-of-the-art approaches by using less than 80% annotated training data. Moreover, the training time to achieve the similar performance is also reduced by over 60%.</p>\n<p><em><strong>Comment:</strong></em>  intent classificationslot fillingstate-of-the-artattention-based-biLSTM</p>\n<h3 id=\"Learning-Universal-Sentence-Representations-with-Mean-Max-Attention-Autoencoder-arXiv-1809-06590v1-cs-CL\"><a href=\"#Learning-Universal-Sentence-Representations-with-Mean-Max-Attention-Autoencoder-arXiv-1809-06590v1-cs-CL\" class=\"headerlink\" title=\"Learning Universal Sentence Representations with Mean-Max Attention Autoencoder. (arXiv:1809.06590v1 [cs.CL])\"></a>Learning Universal Sentence Representations with Mean-Max Attention Autoencoder. (arXiv:1809.06590v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> In order to learn universal sentence representations, previous methods focus on complex recurrent neural networks or supervised learning. In this paper, we propose a mean-max attention autoencoder (mean-max AAE) within the encoder-decoder framework. Our autoencoder rely entirely on the MultiHead self-attention mechanism to reconstruct the input sequence. In the encoding we propose a mean-max strategy that applies both mean and max pooling operations over the hidden vectors to capture diverse information of the input. To enable the information to steer the reconstruction process dynamically, the decoder performs attention over the mean-max representation. By training our model on a large collection of unlabelled data, we obtain high-quality representations of sentences. Experimental results on a broad range of 10 transfer tasks demonstrate that our model outperforms the state-of-the-art unsupervised single methods, including the classical skip-thoughts and the advanced skip-thoughts+LN model. Furthermore, compared with the traditional recurrent neural network, our mean-max AAE greatly reduce the training time.</p>\n<p><em><strong>Comment:</strong></em>  mean-max AAEself-attentionmean-max poolingencoderdecoderstate-of-the-art</p>\n<h3 id=\"Transfer-and-Multi-Task-Learning-for-Noun-Noun-Compound-Interpretation-arXiv-1809-06748v1-cs-CL\"><a href=\"#Transfer-and-Multi-Task-Learning-for-Noun-Noun-Compound-Interpretation-arXiv-1809-06748v1-cs-CL\" class=\"headerlink\" title=\"Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation. (arXiv:1809.06748v1 [cs.CL])\"></a>Transfer and Multi-Task Learning for Noun-Noun Compound Interpretation. (arXiv:1809.06748v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> In this paper, we empirically evaluate the utility of transfer and multi-task learning on a challenging semantic classification task: semantic interpretation of nounnoun compounds. Through a comprehensive series of experiments and in-depth error analysis, we show that transfer learning via parameter initialization and multi-task learning via parameter sharing can help a neural classification model generalize over a highly skewed distribution of relations. Further, we demonstrate how dual annotation with two distinct sets of relations over the same set of compounds can be exploited to improve the overall accuracy of a neural classifier and its F1 scores on the less frequent, but more difficult relations.</p>\n<p><em><strong>Comment:</strong></em> interpretationtransfer learningmulti-task learningnoun-noun compoundrelation extraction</p>\n<h2 id=\"9-18\"><a href=\"#9-18\" class=\"headerlink\" title=\"9.18\"></a>9.18</h2><h3 id=\"Learning-to-Accept-New-Classes-without-Training-arXiv-1809-06004v1-cs-CL\"><a href=\"#Learning-to-Accept-New-Classes-without-Training-arXiv-1809-06004v1-cs-CL\" class=\"headerlink\" title=\"Learning to Accept New Classes without Training. (arXiv:1809.06004v1 [cs.CL])]\"></a>Learning to Accept New Classes without Training. (arXiv:1809.06004v1 [cs.CL])]</h3><p><em><strong>Abstract:</strong></em> Classic supervised learning makes the closed-world assumption, meaning that classes seen in testing must have been seen in training. However, in the dynamic world, new or unseen class examples may appear constantly. A model working in such an environment must be able to reject unseen classes (not seen or used in training). If enough data is collected for the unseen classes, the system should incrementally learn to accept/classify them. This learning paradigm is called open-world learning (OWL). Existing OWL methods all need some form of re-training to accept or include the new classes in the overall model. In this paper, we propose a meta-learning approach to the problem. Its key novelty is that it only needs to train a meta-classifier, which can then continually accept new classes when they have enough labeled data for the meta-classifier to use, and also detect/reject future unseen classes. No re-training of the meta-classifier or a new overall classifier covering all old and new classes is needed. In testing, the method only uses the examples of the seen classes (including the newly added classes) on-the-fly for classification and rejection. Experimental results demonstrate the effectiveness of the new approach.</p>\n<p><em><strong>Comment:</strong></em> meta-classifierknnmeta-classifier</p>\n<h3 id=\"Events-Beyond-ACE-Curated-Training-for-Events-arXiv-1809-05576v1-cs-CL\"><a href=\"#Events-Beyond-ACE-Curated-Training-for-Events-arXiv-1809-05576v1-cs-CL\" class=\"headerlink\" title=\"Events Beyond ACE: Curated Training for Events. (arXiv:1809.05576v1 [cs.CL])\"></a>Events Beyond ACE: Curated Training for Events. (arXiv:1809.05576v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> We explore a human-driven approach to annotation, curated training (CT), in which annotation is framed as teaching the system by using interactive search to identify informative snippets of text to annotate, unlike traditional approaches which either annotate preselected text or use active learning. A trained annotator performed 80 hours of CT for the thirty event types of the NIST TAC KBP Event Argument Extraction evaluation. Combining this annotation with ACE results in a 6% reduction in error and the learning curve of CT plateaus more slowly than for full-document annotation. 3 NLP researchers performed CT for one event type and showed much sharper learning curves with all three exceeding ACE performance in less than ninety minutes, suggesting that CT can provide further benefits when the annotator deeply understands the system.</p>\n<p><em><strong>Comment:</strong></em> mark</p>\n<h3 id=\"Extending-Neural-Generative-Conversational-Model-using-External-Knowledge-Sources-arXiv-1809-05524v1-cs-CL\"><a href=\"#Extending-Neural-Generative-Conversational-Model-using-External-Knowledge-Sources-arXiv-1809-05524v1-cs-CL\" class=\"headerlink\" title=\"Extending Neural Generative Conversational Model using External Knowledge Sources. (arXiv:1809.05524v1 [cs.CL])\"></a>Extending Neural Generative Conversational Model using External Knowledge Sources. (arXiv:1809.05524v1 [cs.CL])</h3><p><em><strong>Abstract:</strong></em> The use of connectionist approaches in conversational agents has been progressing rapidly due to the availability of large corpora. However current generative dialogue models often lack coherence and are content poor. This work proposes an architecture to incorporate unstructured knowledge sources to enhance the next utterance prediction in chit-chat type of generative dialogue models. We focus on Sequence-to-Sequence (Seq2Seq) conversational agents trained with the Reddit News dataset, and consider incorporating external knowledge from Wikipedia summaries as well as from the NELL knowledge base. Our experiments show faster training time and improved perplexity when leveraging external knowledge.</p>\n<p><em><strong>Comment:</strong></em> paper</p>\n"},{"title":"Jue Wang","date":"2021-06-01T08:00:00.000Z","top":100,"_content":"\nHello, I am a PhD student in [Data Intelligence Lab](http://59.111.103.237:8081/) of Zhejiang University, advised by [Prof. Lidan Shou](https://person.zju.edu.cn/en/should).\n\nI work on Natural Language Processing and Data Mining. More specifically, my research interests lie in Information Extraction (e.g., Named Entity Recognition and Relation Extraction), NLP in low-resource scenarios (e.g., Weak/Semi-Supervised Learning), and Efficient Algorithms for NLP (e.g., Knowledge Distillation and Network Pruning). If you want to get in touch, please [send me an email](mailto:zjuwangjue@gmail.com). \n\nMy [resume](resume-Jue.Wang.pdf). \n\n## Updates\n\n- Jun 2021: I graduated from [CentraleSuplec](https://www.centralesupelec.fr/) with diplme d'Ingnieur (master degree), cheers!\n- Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.\n- Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.\n- Apr 2020: As the first author, I had one long paper accepted to ACL 2020.\n- Feb 2020: I had a remote internship at [StatNLP](https://statnlp-research.github.io/) under the guidance of [Prof. Wei Lu](https://istd.sutd.edu.sg/people/faculty/lu-wei).\n- Aug 2019: I was enrolled in ByteCamp hosted by [ByteDance](https://bytedance.com/en), where I mainly deal with Multimodal Classification.\n- July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.\n- Jun 2018 to Dec 2018: I did an internship in [Rokid](https://www.rokid.com/), where I mainly deal with Spoken Language Understanding.\n- Jun 2017 to Aug 2018: I did an research internship in [Data Intelligence Lab](http://59.111.103.237:8081/).\n\n## Education\n\n- **Zhejiang University**, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)\n- **Universite Paris Saclay (CentraleSupelec)**, Master (Engineer) in General Engineering, Sep 2016 - May 2021\n- **Zhejiang University**, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018\n\n## Contact\n\nCollege of Computer Science and Technology, Zhejiang University\n\n38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027\n\nEmail: zjuwangjue@gmail.com\n\n\n\n([](/about-zh))\n\n---\n\n[Blog](https://blog.lorrin.info)([RSS](https://blog.lorrin.info/atom.xml)), [Github](https://github.com/LorrinWWW), [](https://www.zhihu.com/people/wang-jue-9/activities), ","source":"_posts/about.md","raw":"---\ntitle: \"Jue Wang\"\ndate: 2021-6-1 16:00:00\ntop: 100\n---\n\nHello, I am a PhD student in [Data Intelligence Lab](http://59.111.103.237:8081/) of Zhejiang University, advised by [Prof. Lidan Shou](https://person.zju.edu.cn/en/should).\n\nI work on Natural Language Processing and Data Mining. More specifically, my research interests lie in Information Extraction (e.g., Named Entity Recognition and Relation Extraction), NLP in low-resource scenarios (e.g., Weak/Semi-Supervised Learning), and Efficient Algorithms for NLP (e.g., Knowledge Distillation and Network Pruning). If you want to get in touch, please [send me an email](mailto:zjuwangjue@gmail.com). \n\nMy [resume](resume-Jue.Wang.pdf). \n\n## Updates\n\n- Jun 2021: I graduated from [CentraleSuplec](https://www.centralesupelec.fr/) with diplme d'Ingnieur (master degree), cheers!\n- Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.\n- Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.\n- Apr 2020: As the first author, I had one long paper accepted to ACL 2020.\n- Feb 2020: I had a remote internship at [StatNLP](https://statnlp-research.github.io/) under the guidance of [Prof. Wei Lu](https://istd.sutd.edu.sg/people/faculty/lu-wei).\n- Aug 2019: I was enrolled in ByteCamp hosted by [ByteDance](https://bytedance.com/en), where I mainly deal with Multimodal Classification.\n- July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.\n- Jun 2018 to Dec 2018: I did an internship in [Rokid](https://www.rokid.com/), where I mainly deal with Spoken Language Understanding.\n- Jun 2017 to Aug 2018: I did an research internship in [Data Intelligence Lab](http://59.111.103.237:8081/).\n\n## Education\n\n- **Zhejiang University**, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)\n- **Universite Paris Saclay (CentraleSupelec)**, Master (Engineer) in General Engineering, Sep 2016 - May 2021\n- **Zhejiang University**, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018\n\n## Contact\n\nCollege of Computer Science and Technology, Zhejiang University\n\n38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027\n\nEmail: zjuwangjue@gmail.com\n\n\n\n([](/about-zh))\n\n---\n\n[Blog](https://blog.lorrin.info)([RSS](https://blog.lorrin.info/atom.xml)), [Github](https://github.com/LorrinWWW), [](https://www.zhihu.com/people/wang-jue-9/activities), ","slug":"about","published":1,"updated":"2021-11-18T09:18:19.227Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpy0031gwtlfssibi1s","content":"<p>Hello, I am a PhD student in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a> of Zhejiang University, advised by <a href=\"https://person.zju.edu.cn/en/should\">Prof. Lidan Shou</a>.</p>\n<p>I work on Natural Language Processing and Data Mining. More specifically, my research interests lie in Information Extraction (e.g., Named Entity Recognition and Relation Extraction), NLP in low-resource scenarios (e.g., Weak/Semi-Supervised Learning), and Efficient Algorithms for NLP (e.g., Knowledge Distillation and Network Pruning). If you want to get in touch, please <a href=\"mailto:zjuwangjue@gmail.com\">send me an email</a>. </p>\n<p>My <a href=\"resume-Jue.Wang.pdf\">resume</a>. </p>\n<h2 id=\"Updates\"><a href=\"#Updates\" class=\"headerlink\" title=\"Updates\"></a>Updates</h2><ul>\n<li>Jun 2021: I graduated from <a href=\"https://www.centralesupelec.fr/\">CentraleSuplec</a> with diplme dIngnieur (master degree), cheers!</li>\n<li>Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.</li>\n<li>Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.</li>\n<li>Apr 2020: As the first author, I had one long paper accepted to ACL 2020.</li>\n<li>Feb 2020: I had a remote internship at <a href=\"https://statnlp-research.github.io/\">StatNLP</a> under the guidance of <a href=\"https://istd.sutd.edu.sg/people/faculty/lu-wei\">Prof. Wei Lu</a>.</li>\n<li>Aug 2019: I was enrolled in ByteCamp hosted by <a href=\"https://bytedance.com/en\">ByteDance</a>, where I mainly deal with Multimodal Classification.</li>\n<li>July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.</li>\n<li>Jun 2018 to Dec 2018: I did an internship in <a href=\"https://www.rokid.com/\">Rokid</a>, where I mainly deal with Spoken Language Understanding.</li>\n<li>Jun 2017 to Aug 2018: I did an research internship in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a>.</li>\n</ul>\n<h2 id=\"Education\"><a href=\"#Education\" class=\"headerlink\" title=\"Education\"></a>Education</h2><ul>\n<li><strong>Zhejiang University</strong>, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)</li>\n<li><strong>Universite Paris Saclay (CentraleSupelec)</strong>, Master (Engineer) in General Engineering, Sep 2016 - May 2021</li>\n<li><strong>Zhejiang University</strong>, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018</li>\n</ul>\n<h2 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h2><p>College of Computer Science and Technology, Zhejiang University</p>\n<p>38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027</p>\n<p>Email: <a href=\"mailto:zjuwangjue@gmail.com\">zjuwangjue@gmail.com</a></p>\n<p>(<a href=\"/about-zh\"></a>)</p>\n<hr>\n<p><a href=\"https://blog.lorrin.info/\">Blog</a>(<a href=\"https://blog.lorrin.info/atom.xml\">RSS</a>), <a href=\"https://github.com/LorrinWWW\">Github</a>, <a href=\"https://www.zhihu.com/people/wang-jue-9/activities\"></a>, </p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>Hello, I am a PhD student in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a> of Zhejiang University, advised by <a href=\"https://person.zju.edu.cn/en/should\">Prof. Lidan Shou</a>.</p>\n<p>I work on Natural Language Processing and Data Mining. More specifically, my research interests lie in Information Extraction (e.g., Named Entity Recognition and Relation Extraction), NLP in low-resource scenarios (e.g., Weak/Semi-Supervised Learning), and Efficient Algorithms for NLP (e.g., Knowledge Distillation and Network Pruning). If you want to get in touch, please <a href=\"mailto:zjuwangjue@gmail.com\">send me an email</a>. </p>\n<p>My <a href=\"resume-Jue.Wang.pdf\">resume</a>. </p>\n<h2 id=\"Updates\"><a href=\"#Updates\" class=\"headerlink\" title=\"Updates\"></a>Updates</h2><ul>\n<li>Jun 2021: I graduated from <a href=\"https://www.centralesupelec.fr/\">CentraleSuplec</a> with diplme dIngnieur (master degree), cheers!</li>\n<li>Dec 2020: As the first author, I had one long paper accepted to AAAI 2021.</li>\n<li>Sep 2020: As the first author, I had one long paper accepted to EMNLP 2020.</li>\n<li>Apr 2020: As the first author, I had one long paper accepted to ACL 2020.</li>\n<li>Feb 2020: I had a remote internship at <a href=\"https://statnlp-research.github.io/\">StatNLP</a> under the guidance of <a href=\"https://istd.sutd.edu.sg/people/faculty/lu-wei\">Prof. Wei Lu</a>.</li>\n<li>Aug 2019: I was enrolled in ByteCamp hosted by <a href=\"https://bytedance.com/en\">ByteDance</a>, where I mainly deal with Multimodal Classification.</li>\n<li>July 2019: We got one demo paper accepted to SIGIR 2019. I attended the conference as the assistant presenter.</li>\n<li>Jun 2018 to Dec 2018: I did an internship in <a href=\"https://www.rokid.com/\">Rokid</a>, where I mainly deal with Spoken Language Understanding.</li>\n<li>Jun 2017 to Aug 2018: I did an research internship in <a href=\"http://59.111.103.237:8081/\">Data Intelligence Lab</a>.</li>\n</ul>\n<h2 id=\"Education\"><a href=\"#Education\" class=\"headerlink\" title=\"Education\"></a>Education</h2><ul>\n<li><strong>Zhejiang University</strong>, PhD student in Computer Science (Current), Sep 2018 - Jun 2023 (Expected)</li>\n<li><strong>Universite Paris Saclay (CentraleSupelec)</strong>, Master (Engineer) in General Engineering, Sep 2016 - May 2021</li>\n<li><strong>Zhejiang University</strong>, Bachelor in Electrical Engineering, Sep 2014 - Jun 2018</li>\n</ul>\n<h2 id=\"Contact\"><a href=\"#Contact\" class=\"headerlink\" title=\"Contact\"></a>Contact</h2><p>College of Computer Science and Technology, Zhejiang University</p>\n<p>38 Zheda Rd, Xihu Qu, Hangzhou, Zhejiang, 310027</p>\n<p>Email: <a href=\"mailto:&#122;&#x6a;&#x75;&#x77;&#x61;&#x6e;&#103;&#106;&#x75;&#x65;&#64;&#103;&#x6d;&#97;&#105;&#108;&#x2e;&#x63;&#x6f;&#109;\">&#122;&#x6a;&#x75;&#x77;&#x61;&#x6e;&#103;&#106;&#x75;&#x65;&#64;&#103;&#x6d;&#97;&#105;&#108;&#x2e;&#x63;&#x6f;&#109;</a></p>\n<p>(<a href=\"/about-zh\"></a>)</p>\n<hr>\n<p><a href=\"https://blog.lorrin.info/\">Blog</a>(<a href=\"https://blog.lorrin.info/atom.xml\">RSS</a>), <a href=\"https://github.com/LorrinWWW\">Github</a>, <a href=\"https://www.zhihu.com/people/wang-jue-9/activities\"></a>, </p>\n"},{"title":" complexity","date":"2016-11-27T02:52:05.000Z","_content":"\n#  - Calcul the complexity\n\n\n\nThere, we only discuss the time complexity.\n\n##  - Normal\n\n1. Single operation - O(1)\n\n2. Loop\n\n   ```Python\n   def fun(n):\n   \tfor i in range(n):\n      \t\tpass\n   ```\n\n   ```python\n   def fun(n):\n   \twhile i < n :\n       \ti += 1\n   ```\n\n    O(n)\n\n   ```python\n   def fun(n):\n       while i < n :\n           i *= 2\n   ```\n\n    O(logn)\n\n   Etc.\n\n   ##  - Recursion\n   1.  \n\n       \n\n       ex:\n\n       T(n) = 2*T(n/2) + O(n)\n\n        T(n) = kn^2\n\n       \n\n       \n\n   2.  \n\n          \n\n          ex:\n\n          T(n) = T(n-1) + O(1)\n\n          T(1) = O(1)\n\n          T(n) = T(n-1) + O(1) = T(n-1) + 2 * O(1) =  = n*O(1) = O(n)\n\n   3.  \n\n          \n\n          T(n) = aT(n/b) +f(n)\n\n          \n\n   4.  \n\n          ","source":"_posts/complexity.md","raw":"---\ntitle:  complexity\ndate: 2016-11-27 10:52:05\ncategories: programming\ntags: [algo, programming, complexity]\n---\n\n#  - Calcul the complexity\n\n\n\nThere, we only discuss the time complexity.\n\n##  - Normal\n\n1. Single operation - O(1)\n\n2. Loop\n\n   ```Python\n   def fun(n):\n   \tfor i in range(n):\n      \t\tpass\n   ```\n\n   ```python\n   def fun(n):\n   \twhile i < n :\n       \ti += 1\n   ```\n\n    O(n)\n\n   ```python\n   def fun(n):\n       while i < n :\n           i *= 2\n   ```\n\n    O(logn)\n\n   Etc.\n\n   ##  - Recursion\n   1.  \n\n       \n\n       ex:\n\n       T(n) = 2*T(n/2) + O(n)\n\n        T(n) = kn^2\n\n       \n\n       \n\n   2.  \n\n          \n\n          ex:\n\n          T(n) = T(n-1) + O(1)\n\n          T(1) = O(1)\n\n          T(n) = T(n-1) + O(1) = T(n-1) + 2 * O(1) =  = n*O(1) = O(n)\n\n   3.  \n\n          \n\n          T(n) = aT(n/b) +f(n)\n\n          \n\n   4.  \n\n          ","slug":"complexity","published":1,"updated":"2016-11-30T10:43:08.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufpz0034gwtl8swk33xy","content":"<h1 id=\"-Calcul-the-complexity\"><a href=\"#-Calcul-the-complexity\" class=\"headerlink\" title=\" - Calcul the complexity\"></a> - Calcul the complexity</h1><p></p>\n<p>There, we only discuss the time complexity.</p>\n<h2 id=\"-Normal\"><a href=\"#-Normal\" class=\"headerlink\" title=\" - Normal\"></a> - Normal</h2><ol>\n<li><p>Single operation - O(1)</p>\n</li>\n<li><p>Loop</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span>(<span class=\"params\">n</span>):</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">   \t\t<span class=\"keyword\">pass</span></span><br></pre></td></tr></tbody></table></figure>\n\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span>(<span class=\"params\">n</span>):</span></span><br><span class=\"line\">\t<span class=\"keyword\">while</span> i &lt; n :</span><br><span class=\"line\">    \ti += <span class=\"number\">1</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p> O(n)</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span>(<span class=\"params\">n</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> i &lt; n :</span><br><span class=\"line\">        i *= <span class=\"number\">2</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p> O(logn)</p>\n<p>Etc.</p>\n<h2 id=\"-Recursion\"><a href=\"#-Recursion\" class=\"headerlink\" title=\" - Recursion\"></a> - Recursion</h2><ol>\n<li><p></p>\n<p> </p>\n<p> ex:</p>\n<p> T(n) = 2*T(n/2) + O(n)</p>\n<p>  T(n) = kn^2</p>\n<p> </p>\n<p> </p>\n</li>\n<li><p></p>\n<pre><code>\n\nex:\n\nT(n) = T(n-1) + O(1)\n\nT(1) = O(1)\n\nT(n) = T(n-1) + O(1) = T(n-1) + 2 * O(1) =  = n*O(1) = O(n)\n</code></pre>\n</li>\n<li><p></p>\n<pre><code>\n\nT(n) = aT(n/b) +f(n)\n\n\n</code></pre>\n</li>\n<li><p></p>\n<pre><code>\n</code></pre>\n</li>\n</ol>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"-Calcul-the-complexity\"><a href=\"#-Calcul-the-complexity\" class=\"headerlink\" title=\" - Calcul the complexity\"></a> - Calcul the complexity</h1><p></p>\n<p>There, we only discuss the time complexity.</p>\n<h2 id=\"-Normal\"><a href=\"#-Normal\" class=\"headerlink\" title=\" - Normal\"></a> - Normal</h2><ol>\n<li><p>Single operation - O(1)</p>\n</li>\n<li><p>Loop</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span>(<span class=\"params\">n</span>):</span></span><br><span class=\"line\">\t<span class=\"keyword\">for</span> i <span class=\"keyword\">in</span> <span class=\"built_in\">range</span>(n):</span><br><span class=\"line\">   \t\t<span class=\"keyword\">pass</span></span><br></pre></td></tr></table></figure>\n\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span>(<span class=\"params\">n</span>):</span></span><br><span class=\"line\">\t<span class=\"keyword\">while</span> i &lt; n :</span><br><span class=\"line\">    \ti += <span class=\"number\">1</span></span><br></pre></td></tr></table></figure>\n\n<p> O(n)</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">fun</span>(<span class=\"params\">n</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">while</span> i &lt; n :</span><br><span class=\"line\">        i *= <span class=\"number\">2</span></span><br></pre></td></tr></table></figure>\n\n<p> O(logn)</p>\n<p>Etc.</p>\n<h2 id=\"-Recursion\"><a href=\"#-Recursion\" class=\"headerlink\" title=\" - Recursion\"></a> - Recursion</h2><ol>\n<li><p></p>\n<p> </p>\n<p> ex:</p>\n<p> T(n) = 2*T(n/2) + O(n)</p>\n<p>  T(n) = kn^2</p>\n<p> </p>\n<p> </p>\n</li>\n<li><p></p>\n<pre><code>\n\nex:\n\nT(n) = T(n-1) + O(1)\n\nT(1) = O(1)\n\nT(n) = T(n-1) + O(1) = T(n-1) + 2 * O(1) =  = n*O(1) = O(n)\n</code></pre>\n</li>\n<li><p></p>\n<pre><code>\n\nT(n) = aT(n/b) +f(n)\n\n\n</code></pre>\n</li>\n<li><p></p>\n<pre><code>\n</code></pre>\n</li>\n</ol>\n</li>\n</ol>\n"},{"title":" compression","date":"2016-11-27T06:22:11.000Z","_content":"\n1. Run length encoding\n\n   ex:\n\n   0101  0,101  \"3 pixels are color '0'\"\n\n   1101  1,101  \"6 pixels are color '1'\"\n\n   You can also define other signification like:\n\n   1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.\n\n2. Huffman\n\n   Defined in wiki\n\n   Normally we supppose higher number with \"1\".\n\n   ex:\n\n                           (1)\n\n                      0/       \\1\n\n               a(0.45)     (0.55)\n\n                                0/     \\1\n\n                        b(0.25)    c(0.30)\n\n3. Lempel-Ziv\n\n   Encode:\n\n   - Origin: ababcbab...\n   - Init: a:0, b:1, c:2\n   - Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6...\n   - Result: 01324...\n\n   Decode: pass\n\n   ","source":"_posts/compression.md","raw":"---\ntitle:  compression\ndate: 2016-11-27 14:22:11\ncategories: programming\ntags: [algo, compression, programming]\n---\n\n1. Run length encoding\n\n   ex:\n\n   0101  0,101  \"3 pixels are color '0'\"\n\n   1101  1,101  \"6 pixels are color '1'\"\n\n   You can also define other signification like:\n\n   1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.\n\n2. Huffman\n\n   Defined in wiki\n\n   Normally we supppose higher number with \"1\".\n\n   ex:\n\n                           (1)\n\n                      0/       \\1\n\n               a(0.45)     (0.55)\n\n                                0/     \\1\n\n                        b(0.25)    c(0.30)\n\n3. Lempel-Ziv\n\n   Encode:\n\n   - Origin: ababcbab...\n   - Init: a:0, b:1, c:2\n   - Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6...\n   - Result: 01324...\n\n   Decode: pass\n\n   ","slug":"compression","published":1,"updated":"2016-11-30T10:46:12.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufq10038gwtle9ta0x74","content":"<ol>\n<li><p>Run length encoding</p>\n<p>ex:</p>\n<p>0101  0,101  3 pixels are color 0</p>\n<p>1101  1,101  6 pixels are color 1</p>\n<p>You can also define other signification like:</p>\n<p>1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.</p>\n</li>\n<li><p>Huffman</p>\n<p>Defined in wiki</p>\n<p>Normally we supppose higher number with 1.</p>\n<p>ex:</p>\n<p>                        (1)</p>\n<p>                   0/       \\1</p>\n<p>            a(0.45)     (0.55)</p>\n<p>                             0/     \\1</p>\n<p>                     b(0.25)    c(0.30)</p>\n</li>\n<li><p>Lempel-Ziv</p>\n<p>Encode:</p>\n<ul>\n<li>Origin: ababcbab</li>\n<li>Init: a:0, b:1, c:2</li>\n<li>Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6</li>\n<li>Result: 01324</li>\n</ul>\n<p>Decode: pass</p>\n<p></p>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<ol>\n<li><p>Run length encoding</p>\n<p>ex:</p>\n<p>0101  0,101  3 pixels are color 0</p>\n<p>1101  1,101  6 pixels are color 1</p>\n<p>You can also define other signification like:</p>\n<p>1 |1111|1111|1111|1111|0111|0111|0111|0111| with the first 1 meaning encoding in rank, while 0 meaning encoding in row.</p>\n</li>\n<li><p>Huffman</p>\n<p>Defined in wiki</p>\n<p>Normally we supppose higher number with 1.</p>\n<p>ex:</p>\n<p>                        (1)</p>\n<p>                   0/       \\1</p>\n<p>            a(0.45)     (0.55)</p>\n<p>                             0/     \\1</p>\n<p>                     b(0.25)    c(0.30)</p>\n</li>\n<li><p>Lempel-Ziv</p>\n<p>Encode:</p>\n<ul>\n<li>Origin: ababcbab</li>\n<li>Init: a:0, b:1, c:2</li>\n<li>Extensions du dico: ab: 3, ba: 4, abc: 5, cb: 6</li>\n<li>Result: 01324</li>\n</ul>\n<p>Decode: pass</p>\n<p></p>\n</li>\n</ol>\n"},{"title":"-","date":"2016-12-26T06:56:57.000Z","_content":"\n# \n\n\n\n1. \n\n   \n\n2. \n\n   \n\n      \t\n\n:\n\n1. ()()\n2.  \n3. () \n4. \n5.  \n\n# \n\n1. \n\n   - \n\n     \n\n2. \n\n   \n   $$\n   I(s_1,,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}\n   $$\n   A\n   $$\n   E(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,,s_m) }\n   $$\n   E(A)Sj\n   $$\n   I(s_{1j},,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}\n   $$\n   A:\n   $$\n   Gain(A) =I(s_1,,s_m)- E(A)\n   $$\n   Gain(A)A\n\n   Gain\n\n3. \n\n   1. \n\n      \n\n   2. \n\n      \n\n      (MDL)\n\n      \n\n4. \n\n   \"if...else...\"\n\n5. \n\n#  \n\n\n\n\n\n\n\n1. \n\n   XH\n   $$\n   P(H|X) = \\frac{P(X|H)P(H)}{P(X)}\n   $$\n\n2. \n\n   \n\n   1. nX={x1,,xn}n(A1,,An)\n\n   2. m(C1,,Cm)XCi\n      $$\n      P(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)\n      $$\n      \n      $$\n      P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}\n      $$\n\n   3. P(X|Ci)P(Ci)P(Ci)P(X|Ci)\n\n   4. P(X|Ci)\n      $$\n      P(X|C_i) = \\prod{P(x_k|C_i)}\n      $$\n      P(xk|Ci)\n\n      - Ak\n        $$\n        P(x_k|Ci)=\\frac{s_{ik}}{s_i}\n        $$\n        sikCiAkvksiCi\n\n      - Ak\n        $$\n        P(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}\n        $$\n        $g(x_k,\\mu_{C_i},\\sigma_{C_i})$Ak\n\n   5. XX\n\n3. \n\n   \n\n   \n\n   - \n\n     \n\n     \n\n     \n\n   - (CPT)\n\n     ZCPTP(Z|parent(Z))\n\n     LunCancerFamilyHistorySmoker\n\n|             | FH, S | FH, ~S | ~FH, S | ~FH, ~S |\n| ----------- | ----- | ------ | ------ | ------- |\n| LungCancer  | 0.8   | 0.5    | 0.7    | 0.1     |\n| ~LungCancer | 0.2   | 0.5    | 0.3    | 0.9     |\n\n\n\n$$\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}\n$$\n\n4. \n\n   \n\n   1. \n      $$\n      \\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}\n      $$\n      \n      SXdp\n\n      YiUip\n\n   2. \n      $$\n      w_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}\n      $$\n      l\n\n   3. \n\n      wijk011.\n\n# \n\n1. \n\n   ()()\n\n   \n\n   \n\n   \n\n   \n\n   \n\n2. \n\n   \n\n   - \n   - ()\n   - \n   - \n\n   01.\n\n   A={a0,a1,a2}I0, I1, I20A=a0I11.\n\n   \n\n3. \n\n   \n\n   \n\n   ()\n\n   ```python\n   # sumxf(x)\n   def sum(f(x), x):\n       pass\n\n   # \n   init();\n\n   while !conditions:           # \n       for X in samples:\n           for each layer:      # \n               O[j] = 1 / (1 + exp( - I[j]))\n               I[j] = sum(w[i][j]O[i], i) + theta[j]\n           for each unit of output layer as j:    # j\n               Err[j] = O[j] * (1 - O[j]) * (T[j] - O[j])\n           for each unit of hidden layer as j:    # j\n               Err[j] = O[j] * (1 - O[j]) * sum(Err[k] * w[i][j][k], k)\n           for each w[i][j] in the network:       # networkwij\n               delta_w[i][j] = (l) * Err[j] * O[i]     # (l)01\n               w[i][j] += delta_w[i][j]\n           for each theta[j] in the network:      # networkthetaij\n               delta_theta[j] = (l) * Err[j]\n               v[i] = theta[j] + delta_theta[j]\n           \n   ```\n\n   \n\n# \n\n\n\n# \n\n\n\n1. k-\n\n   \n\n2. \n\n3. \n\n4. \n\n5. \n\n# \n\n1. \n\n   \n\n2. \n\n   \n   $$\n   Y = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3\n   $$\n   \n   $$\n   X_1 = X;X_2 = X^2 ; X_3 = X^3\n   $$\n   \n\n3. \n\n   \n\n# \n\nkbaggingboosting()()","source":"_posts/datamining-class-pred.md","raw":"---\ntitle: -\ndate: 2016-12-26 14:56:57\ncategories: [programming]\ntags: [datamining, programming, classification, prediction]\n---\n\n# \n\n\n\n1. \n\n   \n\n2. \n\n   \n\n      \t\n\n:\n\n1. ()()\n2.  \n3. () \n4. \n5.  \n\n# \n\n1. \n\n   - \n\n     \n\n2. \n\n   \n   $$\n   I(s_1,,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}\n   $$\n   A\n   $$\n   E(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}+...+s_{mj}}{s}I(s_1,,s_m) }\n   $$\n   E(A)Sj\n   $$\n   I(s_{1j},,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}\n   $$\n   A:\n   $$\n   Gain(A) =I(s_1,,s_m)- E(A)\n   $$\n   Gain(A)A\n\n   Gain\n\n3. \n\n   1. \n\n      \n\n   2. \n\n      \n\n      (MDL)\n\n      \n\n4. \n\n   \"if...else...\"\n\n5. \n\n#  \n\n\n\n\n\n\n\n1. \n\n   XH\n   $$\n   P(H|X) = \\frac{P(X|H)P(H)}{P(X)}\n   $$\n\n2. \n\n   \n\n   1. nX={x1,,xn}n(A1,,An)\n\n   2. m(C1,,Cm)XCi\n      $$\n      P(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)\n      $$\n      \n      $$\n      P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}\n      $$\n\n   3. P(X|Ci)P(Ci)P(Ci)P(X|Ci)\n\n   4. P(X|Ci)\n      $$\n      P(X|C_i) = \\prod{P(x_k|C_i)}\n      $$\n      P(xk|Ci)\n\n      - Ak\n        $$\n        P(x_k|Ci)=\\frac{s_{ik}}{s_i}\n        $$\n        sikCiAkvksiCi\n\n      - Ak\n        $$\n        P(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}\n        $$\n        $g(x_k,\\mu_{C_i},\\sigma_{C_i})$Ak\n\n   5. XX\n\n3. \n\n   \n\n   \n\n   - \n\n     \n\n     \n\n     \n\n   - (CPT)\n\n     ZCPTP(Z|parent(Z))\n\n     LunCancerFamilyHistorySmoker\n\n|             | FH, S | FH, ~S | ~FH, S | ~FH, ~S |\n| ----------- | ----- | ------ | ------ | ------- |\n| LungCancer  | 0.8   | 0.5    | 0.7    | 0.1     |\n| ~LungCancer | 0.2   | 0.5    | 0.3    | 0.9     |\n\n\n\n$$\nP(z_1,...,z_n) = \\prod{P(z_i|parent(z_i))}\n$$\n\n4. \n\n   \n\n   1. \n      $$\n      \\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}\n      $$\n      \n      SXdp\n\n      YiUip\n\n   2. \n      $$\n      w_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}\n      $$\n      l\n\n   3. \n\n      wijk011.\n\n# \n\n1. \n\n   ()()\n\n   \n\n   \n\n   \n\n   \n\n   \n\n2. \n\n   \n\n   - \n   - ()\n   - \n   - \n\n   01.\n\n   A={a0,a1,a2}I0, I1, I20A=a0I11.\n\n   \n\n3. \n\n   \n\n   \n\n   ()\n\n   ```python\n   # sumxf(x)\n   def sum(f(x), x):\n       pass\n\n   # \n   init();\n\n   while !conditions:           # \n       for X in samples:\n           for each layer:      # \n               O[j] = 1 / (1 + exp( - I[j]))\n               I[j] = sum(w[i][j]O[i], i) + theta[j]\n           for each unit of output layer as j:    # j\n               Err[j] = O[j] * (1 - O[j]) * (T[j] - O[j])\n           for each unit of hidden layer as j:    # j\n               Err[j] = O[j] * (1 - O[j]) * sum(Err[k] * w[i][j][k], k)\n           for each w[i][j] in the network:       # networkwij\n               delta_w[i][j] = (l) * Err[j] * O[i]     # (l)01\n               w[i][j] += delta_w[i][j]\n           for each theta[j] in the network:      # networkthetaij\n               delta_theta[j] = (l) * Err[j]\n               v[i] = theta[j] + delta_theta[j]\n           \n   ```\n\n   \n\n# \n\n\n\n# \n\n\n\n1. k-\n\n   \n\n2. \n\n3. \n\n4. \n\n5. \n\n# \n\n1. \n\n   \n\n2. \n\n   \n   $$\n   Y = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3\n   $$\n   \n   $$\n   X_1 = X;X_2 = X^2 ; X_3 = X^3\n   $$\n   \n\n3. \n\n   \n\n# \n\nkbaggingboosting()()","slug":"datamining-class-pred","published":1,"updated":"2016-12-26T15:52:42.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufq1003bgwtlfgnpfpxn","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p>       </p>\n</li>\n</ol>\n<p>:</p>\n<ol>\n<li>()()</li>\n<li> </li>\n<li>() </li>\n<li></li>\n<li> </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<ul>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<p><br>$$<br>I(s_1,,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}<br>$$<br>A<br>$$<br>E(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}++s_{mj}}{s}I(s_1,,s_m) }<br>$$<br>E(A)Sj<br>$$<br>I(s_{1j},,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}<br>$$<br>A:<br>$$<br>Gain(A) =I(s_1,,s_m)- E(A)<br>$$<br>Gain(A)A</p>\n<p>Gain</p>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p>(MDL)</p>\n<p></p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<p>ifelse</p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<p></p>\n<ol>\n<li><p></p>\n<p>XH<br>$$<br>P(H|X) = \\frac{P(X|H)P(H)}{P(X)}<br>$$</p>\n</li>\n<li><p></p>\n<p></p>\n<ol>\n<li><p>nX={x1,,xn}n(A1,,An)</p>\n</li>\n<li><p>m(C1,,Cm)XCi<br>$$<br>P(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)<br>$$<br><br>$$<br>P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}<br>$$</p>\n</li>\n<li><p>P(X|Ci)P(Ci)P(Ci)P(X|Ci)</p>\n</li>\n<li><p>P(X|Ci)<br>$$<br>P(X|C_i) = \\prod{P(x_k|C_i)}<br>$$<br>P(xk|Ci)</p>\n<ul>\n<li><p>Ak<br>$$<br>P(x_k|Ci)=\\frac{s_{ik}}{s_i}<br>$$<br>sikCiAkvksiCi</p>\n</li>\n<li><p>Ak<br>$$<br>P(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}<br>$$<br>$g(x_k,\\mu_{C_i},\\sigma_{C_i})$Ak</p>\n</li>\n</ul>\n</li>\n<li><p>XX</p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n<ul>\n<li><p></p>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p>(CPT)</p>\n<p>ZCPTP(Z|parent(Z))</p>\n<p>LunCancerFamilyHistorySmoker</p>\n</li>\n</ul>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>FH, S</th>\n<th>FH, ~S</th>\n<th>~FH, S</th>\n<th>~FH, ~S</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>LungCancer</td>\n<td>0.8</td>\n<td>0.5</td>\n<td>0.7</td>\n<td>0.1</td>\n</tr>\n<tr>\n<td>~LungCancer</td>\n<td>0.2</td>\n<td>0.5</td>\n<td>0.3</td>\n<td>0.9</td>\n</tr>\n</tbody></table>\n<p><br>$$<br>P(z_1,,z_n) = \\prod{P(z_i|parent(z_i))}<br>$$</p>\n<ol start=\"4\">\n<li><p></p>\n<p></p>\n<ol>\n<li><p><br>$$<br>\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}<br>$$<br><br>SXdp</p>\n<p>YiUip</p>\n</li>\n<li><p><br>$$<br>w_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}<br>$$<br>l</p>\n</li>\n<li><p></p>\n<p>wijk011.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>()()</p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li></li>\n<li>()</li>\n<li></li>\n<li></li>\n</ul>\n<p>01.</p>\n<p>A={a0,a1,a2}I0, I1, I20A=a0I11.</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n<p>()</p>\n<figure class=\"highlight python\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># sumxf(x)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sum</span>(<span class=\"params\">f(<span class=\"params\">x</span>), x</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">init();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> !conditions:           <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> samples:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each layer:      <span class=\"comment\"># </span></span><br><span class=\"line\">            O[j] = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + exp( - I[j]))</span><br><span class=\"line\">            I[j] = <span class=\"built_in\">sum</span>(w[i][j]O[i], i) + theta[j]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each unit of output layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># j</span></span><br><span class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * (T[j] - O[j])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each unit of hidden layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># j</span></span><br><span class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * <span class=\"built_in\">sum</span>(Err[k] * w[i][j][k], k)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each w[i][j] <span class=\"keyword\">in</span> the network:       <span class=\"comment\"># networkwij</span></span><br><span class=\"line\">            delta_w[i][j] = (l) * Err[j] * O[i]     <span class=\"comment\"># (l)01</span></span><br><span class=\"line\">            w[i][j] += delta_w[i][j]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each theta[j] <span class=\"keyword\">in</span> the network:      <span class=\"comment\"># networkthetaij</span></span><br><span class=\"line\">            delta_theta[j] = (l) * Err[j]</span><br><span class=\"line\">            v[i] = theta[j] + delta_theta[j]</span><br><span class=\"line\">        </span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li><p>k-</p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p><br>$$<br>Y = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3<br>$$<br><br>$$<br>X_1 = X;X_2 = X^2 ; X_3 = X^3<br>$$<br></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>kbaggingboosting()()</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p>       </p>\n</li>\n</ol>\n<p>:</p>\n<ol>\n<li>()()</li>\n<li> </li>\n<li>() </li>\n<li></li>\n<li> </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<ul>\n<li><p></p>\n<p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<p><br>$$<br>I(s_1,,s_m) = - \\sum_{i=1}^{m}{p_i \\log (p_i)}<br>$$<br>A<br>$$<br>E(A) = \\sum_{j=1}^{v}{\\frac{s_{1j}+s_{2j}++s_{mj}}{s}I(s_1,,s_m) }<br>$$<br>E(A)Sj<br>$$<br>I(s_{1j},,s_{mj}) = - \\sum_{i=1}^{m}{p_{ij} \\log (p_{ij})}<br>$$<br>A:<br>$$<br>Gain(A) =I(s_1,,s_m)- E(A)<br>$$<br>Gain(A)A</p>\n<p>Gain</p>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p>(MDL)</p>\n<p></p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<p>ifelse</p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<p></p>\n<p></p>\n<ol>\n<li><p></p>\n<p>XH<br>$$<br>P(H|X) = \\frac{P(X|H)P(H)}{P(X)}<br>$$</p>\n</li>\n<li><p></p>\n<p></p>\n<ol>\n<li><p>nX={x1,,xn}n(A1,,An)</p>\n</li>\n<li><p>m(C1,,Cm)XCi<br>$$<br>P(C_i|X) = \\max(P(C_j|X)|1\\le j\\le m)<br>$$<br><br>$$<br>P(C_i|X) = \\frac{P(X|C_i)P(C_i)}{P(X)}<br>$$</p>\n</li>\n<li><p>P(X|Ci)P(Ci)P(Ci)P(X|Ci)</p>\n</li>\n<li><p>P(X|Ci)<br>$$<br>P(X|C_i) = \\prod{P(x_k|C_i)}<br>$$<br>P(xk|Ci)</p>\n<ul>\n<li><p>Ak<br>$$<br>P(x_k|Ci)=\\frac{s_{ik}}{s_i}<br>$$<br>sikCiAkvksiCi</p>\n</li>\n<li><p>Ak<br>$$<br>P(x_k|Ci)=g(x_k,\\mu_{C_i},\\sigma_{C_i}) = \\frac{1}{\\sqrt{2\\pi}\\sigma_{C_i}}e^{-\\frac{(x-\\mu_{C_i})^2}{2\\sigma^2_{C_i}}}<br>$$<br>$g(x_k,\\mu_{C_i},\\sigma_{C_i})$Ak</p>\n</li>\n</ul>\n</li>\n<li><p>XX</p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n<ul>\n<li><p></p>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p>(CPT)</p>\n<p>ZCPTP(Z|parent(Z))</p>\n<p>LunCancerFamilyHistorySmoker</p>\n</li>\n</ul>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th></th>\n<th>FH, S</th>\n<th>FH, ~S</th>\n<th>~FH, S</th>\n<th>~FH, ~S</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>LungCancer</td>\n<td>0.8</td>\n<td>0.5</td>\n<td>0.7</td>\n<td>0.1</td>\n</tr>\n<tr>\n<td>~LungCancer</td>\n<td>0.2</td>\n<td>0.5</td>\n<td>0.3</td>\n<td>0.9</td>\n</tr>\n</tbody></table>\n<p><br>$$<br>P(z_1,,z_n) = \\prod{P(z_i|parent(z_i))}<br>$$</p>\n<ol start=\"4\">\n<li><p></p>\n<p></p>\n<ol>\n<li><p><br>$$<br>\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}} = \\sum_{d=1}^{s}{\\frac{P(Y_i=y_{ij}, U_i=u_{ik} |X_d)}{w_{ijk}}}<br>$$<br><br>SXdp</p>\n<p>YiUip</p>\n</li>\n<li><p><br>$$<br>w_{ijk} \\leftarrow w_{ijk} + (l)\\frac{\\partial\\ln{P_w(S)}}{\\partial w_{ijk}}<br>$$<br>l</p>\n</li>\n<li><p></p>\n<p>wijk011.</p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>()()</p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li></li>\n<li>()</li>\n<li></li>\n<li></li>\n</ul>\n<p>01.</p>\n<p>A={a0,a1,a2}I0, I1, I20A=a0I11.</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n<p></p>\n<p>()</p>\n<figure class=\"highlight python\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br><span class=\"line\">15</span><br><span class=\"line\">16</span><br><span class=\"line\">17</span><br><span class=\"line\">18</span><br><span class=\"line\">19</span><br><span class=\"line\">20</span><br><span class=\"line\">21</span><br><span class=\"line\">22</span><br><span class=\"line\">23</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"comment\"># sumxf(x)</span></span><br><span class=\"line\"><span class=\"function\"><span class=\"keyword\">def</span> <span class=\"title\">sum</span>(<span class=\"params\">f(<span class=\"params\">x</span>), x</span>):</span></span><br><span class=\"line\">    <span class=\"keyword\">pass</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"comment\"># </span></span><br><span class=\"line\">init();</span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"keyword\">while</span> !conditions:           <span class=\"comment\"># </span></span><br><span class=\"line\">    <span class=\"keyword\">for</span> X <span class=\"keyword\">in</span> samples:</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each layer:      <span class=\"comment\"># </span></span><br><span class=\"line\">            O[j] = <span class=\"number\">1</span> / (<span class=\"number\">1</span> + exp( - I[j]))</span><br><span class=\"line\">            I[j] = <span class=\"built_in\">sum</span>(w[i][j]O[i], i) + theta[j]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each unit of output layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># j</span></span><br><span class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * (T[j] - O[j])</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each unit of hidden layer <span class=\"keyword\">as</span> j:    <span class=\"comment\"># j</span></span><br><span class=\"line\">            Err[j] = O[j] * (<span class=\"number\">1</span> - O[j]) * <span class=\"built_in\">sum</span>(Err[k] * w[i][j][k], k)</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each w[i][j] <span class=\"keyword\">in</span> the network:       <span class=\"comment\"># networkwij</span></span><br><span class=\"line\">            delta_w[i][j] = (l) * Err[j] * O[i]     <span class=\"comment\"># (l)01</span></span><br><span class=\"line\">            w[i][j] += delta_w[i][j]</span><br><span class=\"line\">        <span class=\"keyword\">for</span> each theta[j] <span class=\"keyword\">in</span> the network:      <span class=\"comment\"># networkthetaij</span></span><br><span class=\"line\">            delta_theta[j] = (l) * Err[j]</span><br><span class=\"line\">            v[i] = theta[j] + delta_theta[j]</span><br><span class=\"line\">        </span><br></pre></td></tr></table></figure>\n\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<ol>\n<li><p>k-</p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p><br>$$<br>Y = \\alpha + \\beta_1 X+\\beta_2 X^2+\\beta_3 X^3<br>$$<br><br>$$<br>X_1 = X;X_2 = X^2 ; X_3 = X^3<br>$$<br></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p>kbaggingboosting()()</p>\n"},{"title":"-","date":"2016-12-06T14:05:57.000Z","_content":"\n\n\n \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  ()\n\n  - \n  - \n  - \n  - \n\n# \n\n1. \n   - \n   - \n   - \n   - \n   - \n   - \n     - \n     - \n\n   \n\n2. \n\n   - Bin  \n   - \n   - \n   -   \n\n\n# \n\n1. \n\n   \n\n   - \"custom_id\", \"cum_num\" \n\n   - \n\n     \n     $$\n     r_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}\n     $$\n\n   - \n\n2. \n\n   1. bin\n\n   2. \n\n   3. \n\n   4. (1020100)4\n\n      -   \n\n      - \n        $$\n        v' = \\frac{v - \\bar{v}}{\\sigma}\n        $$\n\n      - \n        $$\n        v' = \\frac{v}{10^j}\n        $$\n\n   5. \n\n# \n\n \n\n1. \n\n   \n\n   \n\n2. \n\n3. \n\n   - \n   - \n\n4. \n\n   - \n   - \n   - \n   - \n\n5. \n\n   - bin\n   - \n   - \n   - \n   - \n\n# \n\n ","source":"_posts/datamining-pretreatment.md","raw":"---\ntitle: -\ndate: 2016-12-06 22:05:57\ncategories: programming\ntags: [datamining, programming]\n---\n\n\n\n \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  \n\n- \n\n  ()\n\n  - \n  - \n  - \n  - \n\n# \n\n1. \n   - \n   - \n   - \n   - \n   - \n   - \n     - \n     - \n\n   \n\n2. \n\n   - Bin  \n   - \n   - \n   -   \n\n\n# \n\n1. \n\n   \n\n   - \"custom_id\", \"cum_num\" \n\n   - \n\n     \n     $$\n     r_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}\n     $$\n\n   - \n\n2. \n\n   1. bin\n\n   2. \n\n   3. \n\n   4. (1020100)4\n\n      -   \n\n      - \n        $$\n        v' = \\frac{v - \\bar{v}}{\\sigma}\n        $$\n\n      - \n        $$\n        v' = \\frac{v}{10^j}\n        $$\n\n   5. \n\n# \n\n \n\n1. \n\n   \n\n   \n\n2. \n\n3. \n\n   - \n   - \n\n4. \n\n   - \n   - \n   - \n   - \n\n5. \n\n   - bin\n   - \n   - \n   - \n   - \n\n# \n\n ","slug":"datamining-pretreatment","published":1,"updated":"2016-12-08T20:29:26.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufq3003ggwtl84r119e1","content":"<p></p>\n<p> </p>\n<ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>()</p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ul>\n<p></p>\n</li>\n<li><p></p>\n<ul>\n<li>Bin  </li>\n<li></li>\n<li></li>\n<li>  </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p></p>\n<ul>\n<li><p>custom_id, cum_num </p>\n</li>\n<li><p></p>\n<p><br>$$<br>r_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}<br>$$</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ol>\n<li><p>bin</p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>(1020100)4</p>\n<ul>\n<li><p>  </p>\n</li>\n<li><p><br>$$<br>v = \\frac{v - \\bar{v}}{\\sigma}<br>$$</p>\n</li>\n<li><p><br>$$<br>v = \\frac{v}{10^j}<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n<ol>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>bin</li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p></p>\n<p> </p>\n<ul>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>()</p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ul>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n<li><ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ul>\n<p></p>\n</li>\n<li><p></p>\n<ul>\n<li>Bin  </li>\n<li></li>\n<li></li>\n<li>  </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p></p>\n<ul>\n<li><p>custom_id, cum_num </p>\n</li>\n<li><p></p>\n<p><br>$$<br>r_{A,B} = \\frac{\\sum{A-\\bar{A}}}{(n-1)\\sigma_A \\sigma_B}<br>$$</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ol>\n<li><p>bin</p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>(1020100)4</p>\n<ul>\n<li><p>  </p>\n</li>\n<li><p><br>$$<br>v = \\frac{v - \\bar{v}}{\\sigma}<br>$$</p>\n</li>\n<li><p><br>$$<br>v = \\frac{v}{10^j}<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n</li>\n</ol>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n<ol>\n<li><p></p>\n<p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>bin</li>\n<li></li>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n</li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p> </p>\n"},{"title":"-","date":"2016-12-08T13:31:50.000Z","_content":"\n# \n\n1.    \n\n      ()\n\n      :() \n\n      roll up: \n\n      drill down: \n\n2.    \n\n      \n\n      ()()()\n\n      \n\n      1. \n\n         \n\n      2. \n\n         :()  \n\n      \n\n      1. \n\n         \n\n      2. \n\n      \n\n3.    \n\n      \n\n      1. \n\n      2. AOI\n\n         \n\n      3. \n\n         \n\n      4. \n\n      5. AOI\n\n          \n\n4.    \n\n      1. \n         1. \n\n         2. \n\n            ()\n\n         3. \n         4. \n         5. \n\n      2. t_weight - \n\n      3. d_weight - \n\n5.    \n\n      1. \n\n         1. \n         2. \n         3. \n\n      2. \n\n         ()\n\n         Q1,Q2,Q3\n\n         M\n\n         MinimumMaximum\n\n         - IQR = Q3 - Q1\n         - Minimum, Q3, M, Q1, Maximum\n\n         n-1.","source":"_posts/datamining-qualitative-induction.md","raw":"---\ntitle: -\ndate: 2016-12-08 21:31:50\ncategories: [programming]\ntags: [datamining, qualitative-induction, programming]\n---\n\n# \n\n1.    \n\n      ()\n\n      :() \n\n      roll up: \n\n      drill down: \n\n2.    \n\n      \n\n      ()()()\n\n      \n\n      1. \n\n         \n\n      2. \n\n         :()  \n\n      \n\n      1. \n\n         \n\n      2. \n\n      \n\n3.    \n\n      \n\n      1. \n\n      2. AOI\n\n         \n\n      3. \n\n         \n\n      4. \n\n      5. AOI\n\n          \n\n4.    \n\n      1. \n         1. \n\n         2. \n\n            ()\n\n         3. \n         4. \n         5. \n\n      2. t_weight - \n\n      3. d_weight - \n\n5.    \n\n      1. \n\n         1. \n         2. \n         3. \n\n      2. \n\n         ()\n\n         Q1,Q2,Q3\n\n         M\n\n         MinimumMaximum\n\n         - IQR = Q3 - Q1\n         - Minimum, Q3, M, Q1, Maximum\n\n         n-1.","slug":"datamining-qualitative-induction","published":1,"updated":"2016-12-23T06:55:11.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufq3003igwtl5rl03yxp","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>   ()</p>\n<p>   :() </p>\n<p>   roll up: </p>\n<p>   drill down: </p>\n</li>\n<li><p></p>\n<p>   </p>\n<p>   ()()()</p>\n<p>   </p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>:()  </p>\n</li>\n</ol>\n<p>   </p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<p>   </p>\n</li>\n<li><p></p>\n<p>   </p>\n<ol>\n<li><p></p>\n</li>\n<li><p>AOI</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>AOI</p>\n<p> </p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<ol>\n<li><p></p>\n</li>\n<li><p></p>\n<p>()</p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n</li>\n<li><p>t_weight - </p>\n</li>\n<li><p>d_weight - </p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p></p>\n<p>()</p>\n<p>Q1,Q2,Q3</p>\n<p>M</p>\n<p>MinimumMaximum</p>\n<ul>\n<li>IQR = Q3 - Q1</li>\n<li>Minimum, Q3, M, Q1, Maximum</li>\n</ul>\n<p>n-1.</p>\n</li>\n</ol>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<p>   ()</p>\n<p>   :() </p>\n<p>   roll up: </p>\n<p>   drill down: </p>\n</li>\n<li><p></p>\n<p>   </p>\n<p>   ()()()</p>\n<p>   </p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>:()  </p>\n</li>\n</ol>\n<p>   </p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<p>   </p>\n</li>\n<li><p></p>\n<p>   </p>\n<ol>\n<li><p></p>\n</li>\n<li><p>AOI</p>\n<p></p>\n</li>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n</li>\n<li><p>AOI</p>\n<p> </p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<ol>\n<li><p></p>\n</li>\n<li><p></p>\n<p>()</p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n</li>\n<li><p>t_weight - </p>\n</li>\n<li><p>d_weight - </p>\n</li>\n</ol>\n</li>\n<li><p></p>\n<ol>\n<li><p></p>\n<ol>\n<li></li>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p></p>\n<p>()</p>\n<p>Q1,Q2,Q3</p>\n<p>M</p>\n<p>MinimumMaximum</p>\n<ul>\n<li>IQR = Q3 - Q1</li>\n<li>Minimum, Q3, M, Q1, Maximum</li>\n</ul>\n<p>n-1.</p>\n</li>\n</ol>\n</li>\n</ol>\n"},{"title":" graph","date":"2016-11-27T06:42:24.000Z","_content":"\n# The symbols\n\nIn graph thery, a graph G = (V, E) is a collection of points.\n\nV, called vertices and lines connecting some subset of them\n\nE, called edges, is contained by V  V\n\nUnion-Find\n\n# Others\n\nwiki\n\n[](https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA)\n\n\n\n>- [](https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95)(D.A)\n>- [](https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95)(K.A)\n>- [](https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95)(P.A)\n>- [](https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F)(TSA)\n>- [](https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84)(CPA)\n>- [](https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)([BFS](https://zh.wikipedia.org/wiki/BFS)'s A)\n>- [](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)([DFS](https://zh.wikipedia.org/wiki/DFS)'s A)\n\n","source":"_posts/graph.md","raw":"---\ntitle:  graph\ndate: 2016-11-27 14:42:24\ncategories: [programming]\ntags: [graph, algo, programming]\n---\n\n# The symbols\n\nIn graph thery, a graph G = (V, E) is a collection of points.\n\nV, called vertices and lines connecting some subset of them\n\nE, called edges, is contained by V  V\n\nUnion-Find\n\n# Others\n\nwiki\n\n[](https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA)\n\n\n\n>- [](https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95)(D.A)\n>- [](https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95)(K.A)\n>- [](https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95)(P.A)\n>- [](https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F)(TSA)\n>- [](https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84)(CPA)\n>- [](https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)([BFS](https://zh.wikipedia.org/wiki/BFS)'s A)\n>- [](https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2)([DFS](https://zh.wikipedia.org/wiki/DFS)'s A)\n\n","slug":"graph","published":1,"updated":"2017-02-11T12:08:30.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufq7003mgwtldit7eklh","content":"<h1 id=\"The-symbols\"><a href=\"#The-symbols\" class=\"headerlink\" title=\"The symbols\"></a>The symbols</h1><p>In graph thery, a graph G = (V, E) is a collection of points.</p>\n<p>V, called vertices and lines connecting some subset of them</p>\n<p>E, called edges, is contained by V  V</p>\n<p>Union-Find</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><p>wiki</p>\n<p><a href=\"https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA\"></a></p>\n<p></p>\n<blockquote>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95\"></a>(D.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95\"></a>(K.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95\"></a>(P.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F\"></a>(TSA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84\"></a>(CPA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\"></a>(<a href=\"https://zh.wikipedia.org/wiki/BFS\">BFS</a>s A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\"></a>(<a href=\"https://zh.wikipedia.org/wiki/DFS\">DFS</a>s A)</li>\n</ul>\n</blockquote>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"The-symbols\"><a href=\"#The-symbols\" class=\"headerlink\" title=\"The symbols\"></a>The symbols</h1><p>In graph thery, a graph G = (V, E) is a collection of points.</p>\n<p>V, called vertices and lines connecting some subset of them</p>\n<p>E, called edges, is contained by V  V</p>\n<p>Union-Find</p>\n<h1 id=\"Others\"><a href=\"#Others\" class=\"headerlink\" title=\"Others\"></a>Others</h1><p>wiki</p>\n<p><a href=\"https://zh.wikipedia.org/wiki/%E5%9B%BE%E8%AE%BA\"></a></p>\n<p></p>\n<blockquote>\n<ul>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%88%B4%E5%85%8B%E6%96%AF%E7%89%B9%E6%8B%89%E7%AE%97%E6%B3%95\"></a>(D.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%8B%E9%B2%81%E6%96%AF%E5%85%8B%E5%B0%94%E6%BC%94%E7%AE%97%E6%B3%95\"></a>(K.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%99%AE%E9%87%8C%E5%A7%86%E7%AE%97%E6%B3%95\"></a>(P.A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%8B%93%E6%89%91%E6%8E%92%E5%BA%8F\"></a>(TSA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%85%B3%E9%94%AE%E8%B7%AF%E5%BE%84\"></a>(CPA)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E5%B9%BF%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\"></a>(<a href=\"https://zh.wikipedia.org/wiki/BFS\">BFS</a>s A)</li>\n<li><a href=\"https://zh.wikipedia.org/wiki/%E6%B7%B1%E5%BA%A6%E4%BC%98%E5%85%88%E6%90%9C%E7%B4%A2\"></a>(<a href=\"https://zh.wikipedia.org/wiki/DFS\">DFS</a>s A)</li>\n</ul>\n</blockquote>\n"},{"title":"hexo hexo with latex","date":"2016-11-30T14:19:02.000Z","_content":"\nhexohexomarkdownlatexmarkdownMarkdown\n\nGoogle[HexoMathJax](http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/)[hexo-renderer-kramed](https://github.com/sun11/hexo-renderer-kramed)fork hexo-renderer-marked MathJax\n\n\n\n\n\n```\n$ npm uninstall hexo-renderer-marked --save\n$ npm install hexo-renderer-kramed --save\n```\n\n\n\n","source":"_posts/hexo-with-latex.md","raw":"---\ntitle: hexo hexo with latex\ndate: 2016-11-30 22:19:02\ncategories: other\ntags: [hexo, latex, mathjax, marked]\n---\n\nhexohexomarkdownlatexmarkdownMarkdown\n\nGoogle[HexoMathJax](http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/)[hexo-renderer-kramed](https://github.com/sun11/hexo-renderer-kramed)fork hexo-renderer-marked MathJax\n\n\n\n\n\n```\n$ npm uninstall hexo-renderer-marked --save\n$ npm install hexo-renderer-kramed --save\n```\n\n\n\n","slug":"hexo-with-latex","published":1,"updated":"2016-11-30T21:45:34.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufq8003pgwtldso8fm3u","content":"<p>hexohexomarkdownlatexmarkdownMarkdown</p>\n<p>Google<a href=\"http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/\">HexoMathJax</a><a href=\"https://github.com/sun11/hexo-renderer-kramed\">hexo-renderer-kramed</a>fork hexo-renderer-marked MathJax</p>\n<p></p>\n<p></p>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm uninstall hexo-renderer-marked --save</span><br><span class=\"line\">$ npm install hexo-renderer-kramed --save</span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n<p></p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>hexohexomarkdownlatexmarkdownMarkdown</p>\n<p>Google<a href=\"http://2wildkids.com/2016/10/06/%E5%A6%82%E4%BD%95%E5%A4%84%E7%90%86Hexo%E5%92%8CMathJax%E7%9A%84%E5%85%BC%E5%AE%B9%E9%97%AE%E9%A2%98/\">HexoMathJax</a><a href=\"https://github.com/sun11/hexo-renderer-kramed\">hexo-renderer-kramed</a>fork hexo-renderer-marked MathJax</p>\n<p></p>\n<p></p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">$ npm uninstall hexo-renderer-marked --save</span><br><span class=\"line\">$ npm install hexo-renderer-kramed --save</span><br></pre></td></tr></table></figure>\n\n<p></p>\n<p></p>\n"},{"title":"intro-about-KG","date":"2018-07-01T12:59:58.000Z","_content":"\n# \n\n\n\n## \n\nknowledge graphGooglekey-value\n\nentityrelationh-r-t\n\nTODO\n\n## \n\n\n\n### \n\n\n\n### \n\nnernlp  \n\n- Name Entity Recognition\n- Relation Extraction    \n- Entity Resolution    \n- Coreference Resolution\n\n## \n\nTODO\n\nRDF\n\n## ","source":"_posts/intro-about-KG.md","raw":"---\ntitle: intro-about-KG\ndate: 2018-07-01 20:59:58\ncategories: [research]\ntags: [knowledge-graph, knowledge-reasoning, deep-learning, machine-learning]\n---\n\n# \n\n\n\n## \n\nknowledge graphGooglekey-value\n\nentityrelationh-r-t\n\nTODO\n\n## \n\n\n\n### \n\n\n\n### \n\nnernlp  \n\n- Name Entity Recognition\n- Relation Extraction    \n- Entity Resolution    \n- Coreference Resolution\n\n## \n\nTODO\n\nRDF\n\n## ","slug":"intro-about-KG","published":1,"updated":"2018-07-01T13:27:45.722Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqa003ugwtldlh2fq72","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>knowledge graphGooglekey-value</p>\n<p>entityrelationh-r-t</p>\n<p>TODO</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>nernlp  </p>\n<ul>\n<li>Name Entity Recognition</li>\n<li>Relation Extraction    </li>\n<li>Entity Resolution    </li>\n<li>Coreference Resolution</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>TODO</p>\n<p>RDF</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>knowledge graphGooglekey-value</p>\n<p>entityrelationh-r-t</p>\n<p>TODO</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>nernlp  </p>\n<ul>\n<li>Name Entity Recognition</li>\n<li>Relation Extraction    </li>\n<li>Entity Resolution    </li>\n<li>Coreference Resolution</li>\n</ul>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p>TODO</p>\n<p>RDF</p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2>"},{"title":"learning OS and building LorriOS","date":"2016-12-28T07:00:08.000Z","_content":"\ntoy OS?()toy os\n\nDayN\n\n----\n\nOS\n\n[](https://github.com/codeurJue/lorriOS)\n\n# Day1:\n\n30\n\nwinos xlinuxos xharibote.binmyos.img\n\n```shell\n# makefile\nmkdir -p /tmp/floppy\nmount -o loop myos.img /tmp/floppy -o fat=12 # mac\nsleep 1\ncp haribote.bin /tmp/floppy\nsleep 1\numount /tmp/floppy\n```\n\nOs x mountubuntuwin\n\n\\*Docker\n\n# Day2:\n\nORANGE'S\n\nxv6MITunixOS\n\nmacweb30winlinuxlinux= =\n\n# Day3:\n\nORANGEmacfreedos\n\n\n\n3216\n\n- GDT\n\n   GDT(Global Descriptor Table)GDTLGDTGDTR\n\n- Selector\n\n   GDTR\n\n- LDT\n\n   LDT(Local Descriptor Table)GDTGDTTIGDTGDTLDT\n\n\n\n1. GDTLDT\n2. \n3. GDT\n4. LDT\n5. \n\n\n\n\n\n# Day4:\n\n### \n\nIA324\n\n- LEVEL 0: \n- LEVEL 1, 2: \n- LEVEL 3: \n\nCPL(current privilege level)DPL(descriptor privilege level)RPL(requested privilege level)\n\nCPLcsss01CPLCPL\n\nDPL\n\nRPL01\n\nCPLRPLDPL\n\n### \n\njmpcall\n\n\n\n- \n- TSS\n- TSS\n\n\n\n-  Call gate\n-  Interrupt gate\n-  Trap gate\n-  Task gate\n\n# Day5:\n\n### \n\nint 15h \n\n\n\n32os\n\nPagingDemopushpoppushret\n\n\n\n### \n\nIDTIDT\n\n- \n- \n- \n\n# Day6:\n\n= =\n\n\n\n\n\n**GDTTSS**\n\n1. GDTLDTGDTGDT\n2. \n3. GDTTSSGDTTSS\n\n**GDTTSS**\n\n1. \n\n   \n\n2. \n\n   process.hglobal.c\n\n   \n\n   GDTLDTprotect.c\n\n3. GDTTSS\n\n   TSSprotect.h\n\n   GDTTSSprotect.c\n\n   TSStrkernel.asm\n\n****\n\n\n\n=> GDTTSSLDTTSS\n\n=> \n\n=>  ring0 -> ring1\n\n### \n\norangeminixtask_table\n\n1.  (proto.h)\n2. task_table (global.c)\n3. (++) (process.h)\n4. ","source":"_posts/learning-OS-and-building-LorriOS.md","raw":"---\ntitle: learning OS and building LorriOS\ndate: 2016-12-28 15:00:08\ncategories: [programming, unfinished]\ntags: [OS, kernel]\n---\n\ntoy OS?()toy os\n\nDayN\n\n----\n\nOS\n\n[](https://github.com/codeurJue/lorriOS)\n\n# Day1:\n\n30\n\nwinos xlinuxos xharibote.binmyos.img\n\n```shell\n# makefile\nmkdir -p /tmp/floppy\nmount -o loop myos.img /tmp/floppy -o fat=12 # mac\nsleep 1\ncp haribote.bin /tmp/floppy\nsleep 1\numount /tmp/floppy\n```\n\nOs x mountubuntuwin\n\n\\*Docker\n\n# Day2:\n\nORANGE'S\n\nxv6MITunixOS\n\nmacweb30winlinuxlinux= =\n\n# Day3:\n\nORANGEmacfreedos\n\n\n\n3216\n\n- GDT\n\n   GDT(Global Descriptor Table)GDTLGDTGDTR\n\n- Selector\n\n   GDTR\n\n- LDT\n\n   LDT(Local Descriptor Table)GDTGDTTIGDTGDTLDT\n\n\n\n1. GDTLDT\n2. \n3. GDT\n4. LDT\n5. \n\n\n\n\n\n# Day4:\n\n### \n\nIA324\n\n- LEVEL 0: \n- LEVEL 1, 2: \n- LEVEL 3: \n\nCPL(current privilege level)DPL(descriptor privilege level)RPL(requested privilege level)\n\nCPLcsss01CPLCPL\n\nDPL\n\nRPL01\n\nCPLRPLDPL\n\n### \n\njmpcall\n\n\n\n- \n- TSS\n- TSS\n\n\n\n-  Call gate\n-  Interrupt gate\n-  Trap gate\n-  Task gate\n\n# Day5:\n\n### \n\nint 15h \n\n\n\n32os\n\nPagingDemopushpoppushret\n\n\n\n### \n\nIDTIDT\n\n- \n- \n- \n\n# Day6:\n\n= =\n\n\n\n\n\n**GDTTSS**\n\n1. GDTLDTGDTGDT\n2. \n3. GDTTSSGDTTSS\n\n**GDTTSS**\n\n1. \n\n   \n\n2. \n\n   process.hglobal.c\n\n   \n\n   GDTLDTprotect.c\n\n3. GDTTSS\n\n   TSSprotect.h\n\n   GDTTSSprotect.c\n\n   TSStrkernel.asm\n\n****\n\n\n\n=> GDTTSSLDTTSS\n\n=> \n\n=>  ring0 -> ring1\n\n### \n\norangeminixtask_table\n\n1.  (proto.h)\n2. task_table (global.c)\n3. (++) (process.h)\n4. ","slug":"learning-OS-and-building-LorriOS","published":1,"updated":"2017-04-17T15:12:41.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqa003wgwtl8s2d3e71","content":"<p>toy OS?()toy os</p>\n<p>DayN</p>\n<hr>\n<p>OS</p>\n<p><a href=\"https://github.com/codeurJue/lorriOS\"></a></p>\n<h1 id=\"Day1\"><a href=\"#Day1\" class=\"headerlink\" title=\"Day1:\"></a>Day1:</h1><p>30</p>\n<p>winos xlinuxos xharibote.binmyos.img</p>\n<figure class=\"highlight shell\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> makefile</span></span><br><span class=\"line\">mkdir -p /tmp/floppy</span><br><span class=\"line\">mount -o loop myos.img /tmp/floppy -o fat=12 # mac</span><br><span class=\"line\">sleep 1</span><br><span class=\"line\">cp haribote.bin /tmp/floppy</span><br><span class=\"line\">sleep 1</span><br><span class=\"line\">umount /tmp/floppy</span><br></pre></td></tr></tbody></table></figure>\n\n<p>Os x mountubuntuwin</p>\n<p>*Docker</p>\n<h1 id=\"Day2\"><a href=\"#Day2\" class=\"headerlink\" title=\"Day2:\"></a>Day2:</h1><p>ORANGES</p>\n<p>xv6MITunixOS</p>\n<p>macweb30winlinuxlinux= =</p>\n<h1 id=\"Day3\"><a href=\"#Day3\" class=\"headerlink\" title=\"Day3:\"></a>Day3:</h1><p>ORANGEmacfreedos</p>\n<p></p>\n<p>3216</p>\n<ul>\n<li><p>GDT</p>\n<p> GDT(Global Descriptor Table)GDTLGDTGDTR</p>\n</li>\n<li><p>Selector</p>\n<p> GDTR</p>\n</li>\n<li><p>LDT</p>\n<p> LDT(Local Descriptor Table)GDTGDTTIGDTGDTLDT</p>\n</li>\n</ul>\n<p></p>\n<ol>\n<li>GDTLDT</li>\n<li></li>\n<li>GDT</li>\n<li>LDT</li>\n<li></li>\n</ol>\n<p></p>\n<p></p>\n<h1 id=\"Day4\"><a href=\"#Day4\" class=\"headerlink\" title=\"Day4:\"></a>Day4:</h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IA324</p>\n<ul>\n<li>LEVEL 0: </li>\n<li>LEVEL 1, 2: </li>\n<li>LEVEL 3: </li>\n</ul>\n<p>CPL(current privilege level)DPL(descriptor privilege level)RPL(requested privilege level)</p>\n<p>CPLcsss01CPLCPL</p>\n<p>DPL</p>\n<p>RPL01</p>\n<p>CPLRPLDPL</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>jmpcall</p>\n<p></p>\n<ul>\n<li></li>\n<li>TSS</li>\n<li>TSS</li>\n</ul>\n<p></p>\n<ul>\n<li> Call gate</li>\n<li> Interrupt gate</li>\n<li> Trap gate</li>\n<li> Task gate</li>\n</ul>\n<h1 id=\"Day5\"><a href=\"#Day5\" class=\"headerlink\" title=\"Day5:\"></a>Day5:</h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>int 15h </p>\n<p></p>\n<p>32os</p>\n<p>PagingDemopushpoppushret</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IDTIDT</p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h1 id=\"Day6\"><a href=\"#Day6\" class=\"headerlink\" title=\"Day6:\"></a>Day6:</h1><p>= =</p>\n<p></p>\n<p></p>\n<p><strong>GDTTSS</strong></p>\n<ol>\n<li>GDTLDTGDTGDT</li>\n<li></li>\n<li>GDTTSSGDTTSS</li>\n</ol>\n<p><strong>GDTTSS</strong></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>process.hglobal.c</p>\n<p></p>\n<p>GDTLDTprotect.c</p>\n</li>\n<li><p>GDTTSS</p>\n<p>TSSprotect.h</p>\n<p>GDTTSSprotect.c</p>\n<p>TSStrkernel.asm</p>\n</li>\n</ol>\n<p><strong></strong></p>\n<p></p>\n<p>=&gt; GDTTSSLDTTSS</p>\n<p>=&gt; </p>\n<p>=&gt;  ring0 -&gt; ring1</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>orangeminixtask_table</p>\n<ol>\n<li> (proto.h)</li>\n<li>task_table (global.c)</li>\n<li>(++) (process.h)</li>\n<li></li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>toy OS?()toy os</p>\n<p>DayN</p>\n<hr>\n<p>OS</p>\n<p><a href=\"https://github.com/codeurJue/lorriOS\"></a></p>\n<h1 id=\"Day1\"><a href=\"#Day1\" class=\"headerlink\" title=\"Day1:\"></a>Day1:</h1><p>30</p>\n<p>winos xlinuxos xharibote.binmyos.img</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">#</span><span class=\"bash\"> makefile</span></span><br><span class=\"line\">mkdir -p /tmp/floppy</span><br><span class=\"line\">mount -o loop myos.img /tmp/floppy -o fat=12 # mac</span><br><span class=\"line\">sleep 1</span><br><span class=\"line\">cp haribote.bin /tmp/floppy</span><br><span class=\"line\">sleep 1</span><br><span class=\"line\">umount /tmp/floppy</span><br></pre></td></tr></table></figure>\n\n<p>Os x mountubuntuwin</p>\n<p>*Docker</p>\n<h1 id=\"Day2\"><a href=\"#Day2\" class=\"headerlink\" title=\"Day2:\"></a>Day2:</h1><p>ORANGES</p>\n<p>xv6MITunixOS</p>\n<p>macweb30winlinuxlinux= =</p>\n<h1 id=\"Day3\"><a href=\"#Day3\" class=\"headerlink\" title=\"Day3:\"></a>Day3:</h1><p>ORANGEmacfreedos</p>\n<p></p>\n<p>3216</p>\n<ul>\n<li><p>GDT</p>\n<p> GDT(Global Descriptor Table)GDTLGDTGDTR</p>\n</li>\n<li><p>Selector</p>\n<p> GDTR</p>\n</li>\n<li><p>LDT</p>\n<p> LDT(Local Descriptor Table)GDTGDTTIGDTGDTLDT</p>\n</li>\n</ul>\n<p></p>\n<ol>\n<li>GDTLDT</li>\n<li></li>\n<li>GDT</li>\n<li>LDT</li>\n<li></li>\n</ol>\n<p></p>\n<p></p>\n<h1 id=\"Day4\"><a href=\"#Day4\" class=\"headerlink\" title=\"Day4:\"></a>Day4:</h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IA324</p>\n<ul>\n<li>LEVEL 0: </li>\n<li>LEVEL 1, 2: </li>\n<li>LEVEL 3: </li>\n</ul>\n<p>CPL(current privilege level)DPL(descriptor privilege level)RPL(requested privilege level)</p>\n<p>CPLcsss01CPLCPL</p>\n<p>DPL</p>\n<p>RPL01</p>\n<p>CPLRPLDPL</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>jmpcall</p>\n<p></p>\n<ul>\n<li></li>\n<li>TSS</li>\n<li>TSS</li>\n</ul>\n<p></p>\n<ul>\n<li> Call gate</li>\n<li> Interrupt gate</li>\n<li> Trap gate</li>\n<li> Task gate</li>\n</ul>\n<h1 id=\"Day5\"><a href=\"#Day5\" class=\"headerlink\" title=\"Day5:\"></a>Day5:</h1><h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>int 15h </p>\n<p></p>\n<p>32os</p>\n<p>PagingDemopushpoppushret</p>\n<p></p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>IDTIDT</p>\n<ul>\n<li></li>\n<li></li>\n<li></li>\n</ul>\n<h1 id=\"Day6\"><a href=\"#Day6\" class=\"headerlink\" title=\"Day6:\"></a>Day6:</h1><p>= =</p>\n<p></p>\n<p></p>\n<p><strong>GDTTSS</strong></p>\n<ol>\n<li>GDTLDTGDTGDT</li>\n<li></li>\n<li>GDTTSSGDTTSS</li>\n</ol>\n<p><strong>GDTTSS</strong></p>\n<ol>\n<li><p></p>\n<p></p>\n</li>\n<li><p></p>\n<p>process.hglobal.c</p>\n<p></p>\n<p>GDTLDTprotect.c</p>\n</li>\n<li><p>GDTTSS</p>\n<p>TSSprotect.h</p>\n<p>GDTTSSprotect.c</p>\n<p>TSStrkernel.asm</p>\n</li>\n</ol>\n<p><strong></strong></p>\n<p></p>\n<p>=&gt; GDTTSSLDTTSS</p>\n<p>=&gt; </p>\n<p>=&gt;  ring0 -&gt; ring1</p>\n<h3 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h3><p>orangeminixtask_table</p>\n<ol>\n<li> (proto.h)</li>\n<li>task_table (global.c)</li>\n<li>(++) (process.h)</li>\n<li></li>\n</ol>\n"},{"title":"machine learning","date":"2016-12-12T14:04:47.000Z","_content":"\n# \n\n\n\n# \n\n[](http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&utm_medium=relatedPosts)","source":"_posts/machine-learning.md","raw":"---\ntitle: machine learning\ndate: 2016-12-12 22:04:47\ncategories: [programming, unfinished]\ntags: [machine-learning]\n---\n\n# \n\n\n\n# \n\n[](http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&utm_medium=relatedPosts)","slug":"machine-learning","published":1,"updated":"2016-12-12T21:07:40.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqc0040gwtlcxv3hxw6","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><a href=\"http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&amp;utm_medium=relatedPosts\"></a></p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p></p>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><p><a href=\"http://blog.jobbole.com/108395/?utm_source=blog.jobbole.com&utm_medium=relatedPosts\"></a></p>\n"},{"title":"","date":"2016-12-10T09:48:37.000Z","_content":"\nThis is the note of learning \"Management of the firm\", with the book of GESTION (ecole centrale paris).\n\n# The firm and the management\n\n## the firm\n\n1. the definition of the firm\n\n   - The company is an economic entity or a place of creation of value\n   - It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.\n   - It uses (destroys) resources (mobilized from partners)\n   - it generates positive or negative externalities on its environment\n2. the different types of resources used by the company\n\n   - The work, provided by employees who sell their working time\n   - Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:\n     1. Tangible resources ()\n     2. Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands\n     3. the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment\n3. the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)\n\n   - Design or R&D\n   - Manufacturing or production\n   - Marketing / sales\n   - Finance\n\n\n4. the importance of the company's relations with its partners in the framework of contracts and with its stakeholders more generally.\n\n   - The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the company's share capital\n   - With the sectoral communities (suppliers, distributors ...), economic (financiers, prescribers, ...) and social (legislation, populations);\n\n\n## The management\n\n1. the definitions of management\n\n   - Manages a planning / organization function and a control function (animation and evaluation) of the activity.\n   - POCCC: prevoir, organiser, commander, coordonner, controle\n\n2. the difference between the operational mode and the strategic management mode\n\n   - manage operationally :\n\n     to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.\n\n   - manage strategically:\n\n     to make sure that you do the right things (doing the right thing)\n\n     That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the company's balance sheet (stock).\n\n# Marketing\n\n**Things important:**\n\n- PESTEL:\n  - Policy, especially government stability and regulations.\n  - Economic, in particular state of the economic situation and economic situation\n  - Sociocultural, particularly demography and changing lifestyles.\n  - Technological, in particular public and private R&D expenditure.\n  - Ecological, in particular legislation on the protection of the environment\n  - Legal, in particular the law of competition and the law of labor.\n\n- SWOT model: \n  - Strengths - Internal\n  - Weaknesses - Internal\n  - Opportunities - External\n  - Threats - External\n\n- Marketing mix ()\n\n  4P => 4C: \n\n  - Product => Consumer wants and needs\n  - Price => Cost\n  - Promotion => communication\n  - Place (distribution) => Convenience\n\n1. the definition of marketing\n\n   - Aggregate of methods to adapt its offer to changing demand\n     - Assess and anticipate relevant changes \n     - Understand customers' needs and desires\n     - Act on supply and its perception\n   - But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.\n\n\n2. The difference between marketing and sales\n\n   - The marketing aims to facilitate and accompany the act of sale,\n\n   - The marketing Collects / Synthesizes Customer and Market Information\n\n   - The marketing helps to define offers (products / services) adapted to the customers\n\n   - The sales representative is in charge of the act of sale and the relationship with customers\n\n     Marketing provides elements for sales support.\n\n3. The distinction between strategic and operational marketing\n\n   - Strategic marketing is devoted to the conception of the offer: \n\n     It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.\n\n   - Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.\n\n4. Market segmentation\n\n   The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups\n\n# Strategy\n\n**things important:**\n\n- Tools and Analysis Methods\n\n| Level              | Internal Analysis                        | External Analysis                        |\n| ------------------ | ---------------------------------------- | ---------------------------------------- |\n| Corporate strategy | <p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p> | PESTEL                                   |\n| Business strategy  | <p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p> | <p>Porters 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p> |\n\n- **Porters 5 forces mode**\n\n  - Suppliers                ->     induxtry competitors\n  - Potential entrants ->\n  - Buyers                     ->\n  - Substitutes             ->\n\n- Strategic group map\n\n  Something like that below:\n\n  ^(high)\n\n  |            O\n\n  |                                                   O\n\n  |(low)>(high)\n\n- Product life circle (PLC)\n\n  1. market development\n  2. growth\n  3. maturity\n  4. decline\n\n- Key success factors\n\n  The factors we must have to compete in a market.\n\n  The rule of the game common to all players\n\n  The necessary conditions to compete in a market.\n\n  1. Segnentation \n  2. DAS ()\n  3. Stracgical activities areas\n\n- **Value chain analysis**\n\n| Support activities     |\n| ---------------------- |\n| Firm infrastructure    |\n| HR                     |\n| Technology Development |\n| Procurement            |\n\n  **Primary activities:**\n\n| Inbound logistics | Outbound logistics | Operations | Marketing | Service | Design |\n| ----------------- | ------------------ | ---------- | --------- | ------- | ------ |\n|                 |                  |          |         |       |      |\n\n- BCG matrix\n\n  market growth\n\n  ^(high)\n\n  |                       **Star**                                    **?**\n\n  |\n\n  |                        **Cow**                                   **Dog**()\n\n  |                                                \n\n  |(low)(high)>(low) market share\n\n1. Definition of strategy\n\n   A firms theory about how to excel in the game it is playing\n\n   A firms theory about how to create a unique position in the markets and industries within which it is operating\n\n2. Competitive advantage: doing different things\n\n3. Resource-based view (internal analysis)\n\n   - Human \n   - Physical \n   - Financial \n   - Organizational \n\n# Development of the firm\n\nGrowth orientations:\n\n1. Integration  \n2. Diversification  \n3. International strategies  \n\nModes of growth:\n\n1. Internal = organic growth\n   - Based on own funds\n   - Slower\n2. External\n   - Rapid market share, or competency gain\n   - Accelerator to grow internationally\n\n# Organizational structure\n\n1. Simple structure\n\n   Owner/Director -> Employees\n\n   - Taylorism\n   - Fayol\n\n2. Complex structure\n\n   - Functional\n\n     Ex: Finance, R&D, Communication, IT\n\n     - Advantages:\n\n        Specialization\n\n        Accumulation of experience\n\n     - Disadvantages:\n\n        Coordination and collaboration\n\n   - Divisional\n\n     \n\n     - Advantages\n\n        Coordination between functions\n\n        Responsibility of results better defined\n\n     - Disadvantages\n\n        Problem of reinventing the wheel\n\n        Internal competition\n\n   - Staff and line\n\n     staff\n\n     - Advantages:\n\n        Specialized expertise\n\n     - Disadvantages:\n\n        Conflict between staff and line\n\n   - Matrix \n\n     \n\n     - Advantages\n\n        Specialization and coordination are facilitated\n\n     - Disadvantages\n\n        Each employee has two bosses  \n\n        Decision making\n","source":"_posts/management-of-the-firm.md","raw":"---\ntitle: \ndate: 2016-12-10 17:48:37\ncategories: other\ntags: [management, firm]\n---\n\nThis is the note of learning \"Management of the firm\", with the book of GESTION (ecole centrale paris).\n\n# The firm and the management\n\n## the firm\n\n1. the definition of the firm\n\n   - The company is an economic entity or a place of creation of value\n   - It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.\n   - It uses (destroys) resources (mobilized from partners)\n   - it generates positive or negative externalities on its environment\n2. the different types of resources used by the company\n\n   - The work, provided by employees who sell their working time\n   - Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:\n     1. Tangible resources ()\n     2. Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands\n     3. the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment\n3. the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)\n\n   - Design or R&D\n   - Manufacturing or production\n   - Marketing / sales\n   - Finance\n\n\n4. the importance of the company's relations with its partners in the framework of contracts and with its stakeholders more generally.\n\n   - The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the company's share capital\n   - With the sectoral communities (suppliers, distributors ...), economic (financiers, prescribers, ...) and social (legislation, populations);\n\n\n## The management\n\n1. the definitions of management\n\n   - Manages a planning / organization function and a control function (animation and evaluation) of the activity.\n   - POCCC: prevoir, organiser, commander, coordonner, controle\n\n2. the difference between the operational mode and the strategic management mode\n\n   - manage operationally :\n\n     to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.\n\n   - manage strategically:\n\n     to make sure that you do the right things (doing the right thing)\n\n     That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the company's balance sheet (stock).\n\n# Marketing\n\n**Things important:**\n\n- PESTEL:\n  - Policy, especially government stability and regulations.\n  - Economic, in particular state of the economic situation and economic situation\n  - Sociocultural, particularly demography and changing lifestyles.\n  - Technological, in particular public and private R&D expenditure.\n  - Ecological, in particular legislation on the protection of the environment\n  - Legal, in particular the law of competition and the law of labor.\n\n- SWOT model: \n  - Strengths - Internal\n  - Weaknesses - Internal\n  - Opportunities - External\n  - Threats - External\n\n- Marketing mix ()\n\n  4P => 4C: \n\n  - Product => Consumer wants and needs\n  - Price => Cost\n  - Promotion => communication\n  - Place (distribution) => Convenience\n\n1. the definition of marketing\n\n   - Aggregate of methods to adapt its offer to changing demand\n     - Assess and anticipate relevant changes \n     - Understand customers' needs and desires\n     - Act on supply and its perception\n   - But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.\n\n\n2. The difference between marketing and sales\n\n   - The marketing aims to facilitate and accompany the act of sale,\n\n   - The marketing Collects / Synthesizes Customer and Market Information\n\n   - The marketing helps to define offers (products / services) adapted to the customers\n\n   - The sales representative is in charge of the act of sale and the relationship with customers\n\n     Marketing provides elements for sales support.\n\n3. The distinction between strategic and operational marketing\n\n   - Strategic marketing is devoted to the conception of the offer: \n\n     It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.\n\n   - Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.\n\n4. Market segmentation\n\n   The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups\n\n# Strategy\n\n**things important:**\n\n- Tools and Analysis Methods\n\n| Level              | Internal Analysis                        | External Analysis                        |\n| ------------------ | ---------------------------------------- | ---------------------------------------- |\n| Corporate strategy | <p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p> | PESTEL                                   |\n| Business strategy  | <p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p> | <p>Porters 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p> |\n\n- **Porters 5 forces mode**\n\n  - Suppliers                ->     induxtry competitors\n  - Potential entrants ->\n  - Buyers                     ->\n  - Substitutes             ->\n\n- Strategic group map\n\n  Something like that below:\n\n  ^(high)\n\n  |            O\n\n  |                                                   O\n\n  |(low)>(high)\n\n- Product life circle (PLC)\n\n  1. market development\n  2. growth\n  3. maturity\n  4. decline\n\n- Key success factors\n\n  The factors we must have to compete in a market.\n\n  The rule of the game common to all players\n\n  The necessary conditions to compete in a market.\n\n  1. Segnentation \n  2. DAS ()\n  3. Stracgical activities areas\n\n- **Value chain analysis**\n\n| Support activities     |\n| ---------------------- |\n| Firm infrastructure    |\n| HR                     |\n| Technology Development |\n| Procurement            |\n\n  **Primary activities:**\n\n| Inbound logistics | Outbound logistics | Operations | Marketing | Service | Design |\n| ----------------- | ------------------ | ---------- | --------- | ------- | ------ |\n|                 |                  |          |         |       |      |\n\n- BCG matrix\n\n  market growth\n\n  ^(high)\n\n  |                       **Star**                                    **?**\n\n  |\n\n  |                        **Cow**                                   **Dog**()\n\n  |                                                \n\n  |(low)(high)>(low) market share\n\n1. Definition of strategy\n\n   A firms theory about how to excel in the game it is playing\n\n   A firms theory about how to create a unique position in the markets and industries within which it is operating\n\n2. Competitive advantage: doing different things\n\n3. Resource-based view (internal analysis)\n\n   - Human \n   - Physical \n   - Financial \n   - Organizational \n\n# Development of the firm\n\nGrowth orientations:\n\n1. Integration  \n2. Diversification  \n3. International strategies  \n\nModes of growth:\n\n1. Internal = organic growth\n   - Based on own funds\n   - Slower\n2. External\n   - Rapid market share, or competency gain\n   - Accelerator to grow internationally\n\n# Organizational structure\n\n1. Simple structure\n\n   Owner/Director -> Employees\n\n   - Taylorism\n   - Fayol\n\n2. Complex structure\n\n   - Functional\n\n     Ex: Finance, R&D, Communication, IT\n\n     - Advantages:\n\n        Specialization\n\n        Accumulation of experience\n\n     - Disadvantages:\n\n        Coordination and collaboration\n\n   - Divisional\n\n     \n\n     - Advantages\n\n        Coordination between functions\n\n        Responsibility of results better defined\n\n     - Disadvantages\n\n        Problem of reinventing the wheel\n\n        Internal competition\n\n   - Staff and line\n\n     staff\n\n     - Advantages:\n\n        Specialized expertise\n\n     - Disadvantages:\n\n        Conflict between staff and line\n\n   - Matrix \n\n     \n\n     - Advantages\n\n        Specialization and coordination are facilitated\n\n     - Disadvantages\n\n        Each employee has two bosses  \n\n        Decision making\n","slug":"management-of-the-firm","published":1,"updated":"2016-12-13T21:26:46.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqc0042gwtlfhf76k0h","content":"<p>This is the note of learning Management of the firm, with the book of GESTION (ecole centrale paris).</p>\n<h1 id=\"The-firm-and-the-management\"><a href=\"#The-firm-and-the-management\" class=\"headerlink\" title=\"The firm and the management\"></a>The firm and the management</h1><h2 id=\"the-firm\"><a href=\"#the-firm\" class=\"headerlink\" title=\"the firm\"></a>the firm</h2><ol>\n<li><p>the definition of the firm</p>\n<ul>\n<li>The company is an economic entity or a place of creation of value</li>\n<li>It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.</li>\n<li>It uses (destroys) resources (mobilized from partners)</li>\n<li>it generates positive or negative externalities on its environment</li>\n</ul>\n</li>\n<li><p>the different types of resources used by the company</p>\n<ul>\n<li>The work, provided by employees who sell their working time</li>\n<li>Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:<ol>\n<li>Tangible resources ()</li>\n<li>Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands</li>\n<li>the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)</p>\n<ul>\n<li>Design or R&amp;D</li>\n<li>Manufacturing or production</li>\n<li>Marketing / sales</li>\n<li>Finance</li>\n</ul>\n</li>\n</ol>\n<ol start=\"4\">\n<li><p>the importance of the companys relations with its partners in the framework of contracts and with its stakeholders more generally.</p>\n<ul>\n<li>The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the companys share capital</li>\n<li>With the sectoral communities (suppliers, distributors ), economic (financiers, prescribers, ) and social (legislation, populations);</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"The-management\"><a href=\"#The-management\" class=\"headerlink\" title=\"The management\"></a>The management</h2><ol>\n<li><p>the definitions of management</p>\n<ul>\n<li>Manages a planning / organization function and a control function (animation and evaluation) of the activity.</li>\n<li>POCCC: prevoir, organiser, commander, coordonner, controle</li>\n</ul>\n</li>\n<li><p>the difference between the operational mode and the strategic management mode</p>\n<ul>\n<li><p>manage operationally :</p>\n<p>to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.</p>\n</li>\n<li><p>manage strategically:</p>\n<p>to make sure that you do the right things (doing the right thing)</p>\n<p>That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the companys balance sheet (stock).</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Marketing\"><a href=\"#Marketing\" class=\"headerlink\" title=\"Marketing\"></a>Marketing</h1><p><strong>Things important:</strong></p>\n<ul>\n<li><p>PESTEL:</p>\n<ul>\n<li>Policy, especially government stability and regulations.</li>\n<li>Economic, in particular state of the economic situation and economic situation</li>\n<li>Sociocultural, particularly demography and changing lifestyles.</li>\n<li>Technological, in particular public and private R&amp;D expenditure.</li>\n<li>Ecological, in particular legislation on the protection of the environment</li>\n<li>Legal, in particular the law of competition and the law of labor.</li>\n</ul>\n</li>\n<li><p>SWOT model: </p>\n<ul>\n<li>Strengths - Internal</li>\n<li>Weaknesses - Internal</li>\n<li>Opportunities - External</li>\n<li>Threats - External</li>\n</ul>\n</li>\n<li><p>Marketing mix ()</p>\n<p>4P =&gt; 4C: </p>\n<ul>\n<li>Product =&gt; Consumer wants and needs</li>\n<li>Price =&gt; Cost</li>\n<li>Promotion =&gt; communication</li>\n<li>Place (distribution) =&gt; Convenience</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li><p>the definition of marketing</p>\n<ul>\n<li>Aggregate of methods to adapt its offer to changing demand<ul>\n<li>Assess and anticipate relevant changes </li>\n<li>Understand customers needs and desires</li>\n<li>Act on supply and its perception</li>\n</ul>\n</li>\n<li>But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.</li>\n</ul>\n</li>\n</ol>\n<ol start=\"2\">\n<li><p>The difference between marketing and sales</p>\n<ul>\n<li><p>The marketing aims to facilitate and accompany the act of sale,</p>\n</li>\n<li><p>The marketing Collects / Synthesizes Customer and Market Information</p>\n</li>\n<li><p>The marketing helps to define offers (products / services) adapted to the customers</p>\n</li>\n<li><p>The sales representative is in charge of the act of sale and the relationship with customers</p>\n<p>Marketing provides elements for sales support.</p>\n</li>\n</ul>\n</li>\n<li><p>The distinction between strategic and operational marketing</p>\n<ul>\n<li><p>Strategic marketing is devoted to the conception of the offer: </p>\n<p>It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.</p>\n</li>\n<li><p>Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.</p>\n</li>\n</ul>\n</li>\n<li><p>Market segmentation</p>\n<p>The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups</p>\n</li>\n</ol>\n<h1 id=\"Strategy\"><a href=\"#Strategy\" class=\"headerlink\" title=\"Strategy\"></a>Strategy</h1><p><strong>things important:</strong></p>\n<ul>\n<li>Tools and Analysis Methods</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Level</th>\n<th>Internal Analysis</th>\n<th>External Analysis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Corporate strategy</td>\n<td><p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p></td>\n<td>PESTEL</td>\n</tr>\n<tr>\n<td>Business strategy</td>\n<td><p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p></td>\n<td><p>Porters 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p></td>\n</tr>\n</tbody></table>\n<ul>\n<li><p><strong>Porters 5 forces mode</strong></p>\n<ul>\n<li>Suppliers                -&gt;     induxtry competitors</li>\n<li>Potential entrants -&gt;</li>\n<li>Buyers                     -&gt;</li>\n<li>Substitutes             -&gt;</li>\n</ul>\n</li>\n<li><p>Strategic group map</p>\n<p>Something like that below:</p>\n<p>^(high)</p>\n<p>|            O</p>\n<p>|                                                   O</p>\n<p>|(low)&gt;(high)</p>\n</li>\n<li><p>Product life circle (PLC)</p>\n<ol>\n<li>market development</li>\n<li>growth</li>\n<li>maturity</li>\n<li>decline</li>\n</ol>\n</li>\n<li><p>Key success factors</p>\n<p>The factors we must have to compete in a market.</p>\n<p>The rule of the game common to all players</p>\n<p>The necessary conditions to compete in a market.</p>\n<ol>\n<li>Segnentation </li>\n<li>DAS ()</li>\n<li>Stracgical activities areas</li>\n</ol>\n</li>\n<li><p><strong>Value chain analysis</strong></p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Support activities</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Firm infrastructure</td>\n</tr>\n<tr>\n<td>HR</td>\n</tr>\n<tr>\n<td>Technology Development</td>\n</tr>\n<tr>\n<td>Procurement</td>\n</tr>\n</tbody></table>\n<p>  <strong>Primary activities:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Inbound logistics</th>\n<th>Outbound logistics</th>\n<th>Operations</th>\n<th>Marketing</th>\n<th>Service</th>\n<th>Design</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>BCG matrix</p>\n<p>market growth</p>\n<p>^(high)</p>\n<p>|                       <strong>Star</strong>                                    <strong>?</strong></p>\n<p>|</p>\n<p>|                        <strong>Cow</strong>                                   <strong>Dog</strong>()</p>\n<p>|                                                </p>\n<p>|(low)(high)&gt;(low) market share</p>\n</li>\n</ul>\n<ol>\n<li><p>Definition of strategy</p>\n<p>A firms theory about how to excel in the game it is playing</p>\n<p>A firms theory about how to create a unique position in the markets and industries within which it is operating</p>\n</li>\n<li><p>Competitive advantage: doing different things</p>\n</li>\n<li><p>Resource-based view (internal analysis)</p>\n<ul>\n<li>Human </li>\n<li>Physical </li>\n<li>Financial </li>\n<li>Organizational </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Development-of-the-firm\"><a href=\"#Development-of-the-firm\" class=\"headerlink\" title=\"Development of the firm\"></a>Development of the firm</h1><p>Growth orientations:</p>\n<ol>\n<li>Integration  </li>\n<li>Diversification  </li>\n<li>International strategies  </li>\n</ol>\n<p>Modes of growth:</p>\n<ol>\n<li>Internal = organic growth<ul>\n<li>Based on own funds</li>\n<li>Slower</li>\n</ul>\n</li>\n<li>External<ul>\n<li>Rapid market share, or competency gain</li>\n<li>Accelerator to grow internationally</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Organizational-structure\"><a href=\"#Organizational-structure\" class=\"headerlink\" title=\"Organizational structure\"></a>Organizational structure</h1><ol>\n<li><p>Simple structure</p>\n<p>Owner/Director -&gt; Employees</p>\n<ul>\n<li>Taylorism</li>\n<li>Fayol</li>\n</ul>\n</li>\n<li><p>Complex structure</p>\n<ul>\n<li><p>Functional</p>\n<p>Ex: Finance, R&amp;D, Communication, IT</p>\n<ul>\n<li><p>Advantages:</p>\n<p> Specialization</p>\n<p> Accumulation of experience</p>\n</li>\n<li><p>Disadvantages:</p>\n<p> Coordination and collaboration</p>\n</li>\n</ul>\n</li>\n<li><p>Divisional</p>\n<p></p>\n<ul>\n<li><p>Advantages</p>\n<p> Coordination between functions</p>\n<p> Responsibility of results better defined</p>\n</li>\n<li><p>Disadvantages</p>\n<p> Problem of reinventing the wheel</p>\n<p> Internal competition</p>\n</li>\n</ul>\n</li>\n<li><p>Staff and line</p>\n<p>staff</p>\n<ul>\n<li><p>Advantages:</p>\n<p> Specialized expertise</p>\n</li>\n<li><p>Disadvantages:</p>\n<p> Conflict between staff and line</p>\n</li>\n</ul>\n</li>\n<li><p>Matrix </p>\n<p></p>\n<ul>\n<li><p>Advantages</p>\n<p> Specialization and coordination are facilitated</p>\n</li>\n<li><p>Disadvantages</p>\n<p> Each employee has two bosses  </p>\n<p> Decision making</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>This is the note of learning Management of the firm, with the book of GESTION (ecole centrale paris).</p>\n<h1 id=\"The-firm-and-the-management\"><a href=\"#The-firm-and-the-management\" class=\"headerlink\" title=\"The firm and the management\"></a>The firm and the management</h1><h2 id=\"the-firm\"><a href=\"#the-firm\" class=\"headerlink\" title=\"the firm\"></a>the firm</h2><ol>\n<li><p>the definition of the firm</p>\n<ul>\n<li>The company is an economic entity or a place of creation of value</li>\n<li>It designs and / or produces and / or distributes goods and services to meet the demand of CUSTOMERS on MARKETS.</li>\n<li>It uses (destroys) resources (mobilized from partners)</li>\n<li>it generates positive or negative externalities on its environment</li>\n</ul>\n</li>\n<li><p>the different types of resources used by the company</p>\n<ul>\n<li>The work, provided by employees who sell their working time</li>\n<li>Financial capital, contributed on a perpetual basis by shareholders or temporary by banks, capital is used to acquire or develop:<ol>\n<li>Tangible resources ()</li>\n<li>Intangible resources such as cognitive resources (knowledge or knowledge, patents or technologies) or brands</li>\n<li>the natural resources (materials and energy) transformed by the company in its process or incorporated in its equipment</li>\n</ol>\n</li>\n</ul>\n</li>\n<li><p>the main functional areas (or functions) of a company and their objective (point not covered in the course but seen in case study!)</p>\n<ul>\n<li>Design or R&amp;D</li>\n<li>Manufacturing or production</li>\n<li>Marketing / sales</li>\n<li>Finance</li>\n</ul>\n</li>\n</ol>\n<ol start=\"4\">\n<li><p>the importance of the companys relations with its partners in the framework of contracts and with its stakeholders more generally.</p>\n<ul>\n<li>The customers to whom its offers are addressed, the people who carry out its activities and the shareholders who bring the capital and hold the companys share capital</li>\n<li>With the sectoral communities (suppliers, distributors ), economic (financiers, prescribers, ) and social (legislation, populations);</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"The-management\"><a href=\"#The-management\" class=\"headerlink\" title=\"The management\"></a>The management</h2><ol>\n<li><p>the definitions of management</p>\n<ul>\n<li>Manages a planning / organization function and a control function (animation and evaluation) of the activity.</li>\n<li>POCCC: prevoir, organiser, commander, coordonner, controle</li>\n</ul>\n</li>\n<li><p>the difference between the operational mode and the strategic management mode</p>\n<ul>\n<li><p>manage operationally :</p>\n<p>to ensure that one does well what one has to do (doing the things right), or it means making good use of resources to reach the objective, or it is to seek efficiency.</p>\n</li>\n<li><p>manage strategically:</p>\n<p>to make sure that you do the right things (doing the right thing)</p>\n<p>That is to say, to choose the assets and the areas where to invest is to build the potential of the company and ensure that it has the relevant resources, this is reflected in the companys balance sheet (stock).</p>\n</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Marketing\"><a href=\"#Marketing\" class=\"headerlink\" title=\"Marketing\"></a>Marketing</h1><p><strong>Things important:</strong></p>\n<ul>\n<li><p>PESTEL:</p>\n<ul>\n<li>Policy, especially government stability and regulations.</li>\n<li>Economic, in particular state of the economic situation and economic situation</li>\n<li>Sociocultural, particularly demography and changing lifestyles.</li>\n<li>Technological, in particular public and private R&amp;D expenditure.</li>\n<li>Ecological, in particular legislation on the protection of the environment</li>\n<li>Legal, in particular the law of competition and the law of labor.</li>\n</ul>\n</li>\n<li><p>SWOT model: </p>\n<ul>\n<li>Strengths - Internal</li>\n<li>Weaknesses - Internal</li>\n<li>Opportunities - External</li>\n<li>Threats - External</li>\n</ul>\n</li>\n<li><p>Marketing mix ()</p>\n<p>4P =&gt; 4C: </p>\n<ul>\n<li>Product =&gt; Consumer wants and needs</li>\n<li>Price =&gt; Cost</li>\n<li>Promotion =&gt; communication</li>\n<li>Place (distribution) =&gt; Convenience</li>\n</ul>\n</li>\n</ul>\n<ol>\n<li><p>the definition of marketing</p>\n<ul>\n<li>Aggregate of methods to adapt its offer to changing demand<ul>\n<li>Assess and anticipate relevant changes </li>\n<li>Understand customers needs and desires</li>\n<li>Act on supply and its perception</li>\n</ul>\n</li>\n<li>But also to orient the behavior of various publics (consumers, distributors, public authorities) in a way favorable to the company.</li>\n</ul>\n</li>\n</ol>\n<ol start=\"2\">\n<li><p>The difference between marketing and sales</p>\n<ul>\n<li><p>The marketing aims to facilitate and accompany the act of sale,</p>\n</li>\n<li><p>The marketing Collects / Synthesizes Customer and Market Information</p>\n</li>\n<li><p>The marketing helps to define offers (products / services) adapted to the customers</p>\n</li>\n<li><p>The sales representative is in charge of the act of sale and the relationship with customers</p>\n<p>Marketing provides elements for sales support.</p>\n</li>\n</ul>\n</li>\n<li><p>The distinction between strategic and operational marketing</p>\n<ul>\n<li><p>Strategic marketing is devoted to the conception of the offer: </p>\n<p>It covers the choice of targets, the analysis of needs, the evaluation of competing offers, the generation and the collection of ideas for solutions, the drafting of specifications (Marketing briefs), estimation of forecast volumes and margins, and the launch plan.</p>\n</li>\n<li><p>Operational marketing refers to the activity of preparation and support to the sales effort, once the offer is constituted. Efforts then was given to the choice of distribution channels, on communication, on the construction of sales pitches and support documents, on the definition of price levels, on the accompaniment and monitoring of sales forces.</p>\n</li>\n</ul>\n</li>\n<li><p>Market segmentation</p>\n<p>The process of dividing markets comprising the heterogeneous needs of many consumers into segments comprising the homogeneous needs of smaller groups</p>\n</li>\n</ol>\n<h1 id=\"Strategy\"><a href=\"#Strategy\" class=\"headerlink\" title=\"Strategy\"></a>Strategy</h1><p><strong>things important:</strong></p>\n<ul>\n<li>Tools and Analysis Methods</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Level</th>\n<th>Internal Analysis</th>\n<th>External Analysis</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Corporate strategy</td>\n<td><p>Management system analysis</p><p>BCG Matrix</p><p>Resources and competence analysis</p></td>\n<td>PESTEL</td>\n</tr>\n<tr>\n<td>Business strategy</td>\n<td><p>Value chain</p><p>General business strategy</p><p>Resources and competence of each domain of activity</p></td>\n<td><p>Porters 5 forces model</p><p>Strategic group mapping</p><p>Product life cycle</p><p>Key success factors</p></td>\n</tr>\n</tbody></table>\n<ul>\n<li><p><strong>Porters 5 forces mode</strong></p>\n<ul>\n<li>Suppliers                -&gt;     induxtry competitors</li>\n<li>Potential entrants -&gt;</li>\n<li>Buyers                     -&gt;</li>\n<li>Substitutes             -&gt;</li>\n</ul>\n</li>\n<li><p>Strategic group map</p>\n<p>Something like that below:</p>\n<p>^(high)</p>\n<p>|            O</p>\n<p>|                                                   O</p>\n<p>|(low)&gt;(high)</p>\n</li>\n<li><p>Product life circle (PLC)</p>\n<ol>\n<li>market development</li>\n<li>growth</li>\n<li>maturity</li>\n<li>decline</li>\n</ol>\n</li>\n<li><p>Key success factors</p>\n<p>The factors we must have to compete in a market.</p>\n<p>The rule of the game common to all players</p>\n<p>The necessary conditions to compete in a market.</p>\n<ol>\n<li>Segnentation </li>\n<li>DAS ()</li>\n<li>Stracgical activities areas</li>\n</ol>\n</li>\n<li><p><strong>Value chain analysis</strong></p>\n</li>\n</ul>\n<table>\n<thead>\n<tr>\n<th>Support activities</th>\n</tr>\n</thead>\n<tbody><tr>\n<td>Firm infrastructure</td>\n</tr>\n<tr>\n<td>HR</td>\n</tr>\n<tr>\n<td>Technology Development</td>\n</tr>\n<tr>\n<td>Procurement</td>\n</tr>\n</tbody></table>\n<p>  <strong>Primary activities:</strong></p>\n<table>\n<thead>\n<tr>\n<th>Inbound logistics</th>\n<th>Outbound logistics</th>\n<th>Operations</th>\n<th>Marketing</th>\n<th>Service</th>\n<th>Design</th>\n</tr>\n</thead>\n<tbody><tr>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n<td></td>\n</tr>\n</tbody></table>\n<ul>\n<li><p>BCG matrix</p>\n<p>market growth</p>\n<p>^(high)</p>\n<p>|                       <strong>Star</strong>                                    <strong>?</strong></p>\n<p>|</p>\n<p>|                        <strong>Cow</strong>                                   <strong>Dog</strong>()</p>\n<p>|                                                </p>\n<p>|(low)(high)&gt;(low) market share</p>\n</li>\n</ul>\n<ol>\n<li><p>Definition of strategy</p>\n<p>A firms theory about how to excel in the game it is playing</p>\n<p>A firms theory about how to create a unique position in the markets and industries within which it is operating</p>\n</li>\n<li><p>Competitive advantage: doing different things</p>\n</li>\n<li><p>Resource-based view (internal analysis)</p>\n<ul>\n<li>Human </li>\n<li>Physical </li>\n<li>Financial </li>\n<li>Organizational </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Development-of-the-firm\"><a href=\"#Development-of-the-firm\" class=\"headerlink\" title=\"Development of the firm\"></a>Development of the firm</h1><p>Growth orientations:</p>\n<ol>\n<li>Integration  </li>\n<li>Diversification  </li>\n<li>International strategies  </li>\n</ol>\n<p>Modes of growth:</p>\n<ol>\n<li>Internal = organic growth<ul>\n<li>Based on own funds</li>\n<li>Slower</li>\n</ul>\n</li>\n<li>External<ul>\n<li>Rapid market share, or competency gain</li>\n<li>Accelerator to grow internationally</li>\n</ul>\n</li>\n</ol>\n<h1 id=\"Organizational-structure\"><a href=\"#Organizational-structure\" class=\"headerlink\" title=\"Organizational structure\"></a>Organizational structure</h1><ol>\n<li><p>Simple structure</p>\n<p>Owner/Director -&gt; Employees</p>\n<ul>\n<li>Taylorism</li>\n<li>Fayol</li>\n</ul>\n</li>\n<li><p>Complex structure</p>\n<ul>\n<li><p>Functional</p>\n<p>Ex: Finance, R&amp;D, Communication, IT</p>\n<ul>\n<li><p>Advantages:</p>\n<p> Specialization</p>\n<p> Accumulation of experience</p>\n</li>\n<li><p>Disadvantages:</p>\n<p> Coordination and collaboration</p>\n</li>\n</ul>\n</li>\n<li><p>Divisional</p>\n<p></p>\n<ul>\n<li><p>Advantages</p>\n<p> Coordination between functions</p>\n<p> Responsibility of results better defined</p>\n</li>\n<li><p>Disadvantages</p>\n<p> Problem of reinventing the wheel</p>\n<p> Internal competition</p>\n</li>\n</ul>\n</li>\n<li><p>Staff and line</p>\n<p>staff</p>\n<ul>\n<li><p>Advantages:</p>\n<p> Specialized expertise</p>\n</li>\n<li><p>Disadvantages:</p>\n<p> Conflict between staff and line</p>\n</li>\n</ul>\n</li>\n<li><p>Matrix </p>\n<p></p>\n<ul>\n<li><p>Advantages</p>\n<p> Specialization and coordination are facilitated</p>\n</li>\n<li><p>Disadvantages</p>\n<p> Each employee has two bosses  </p>\n<p> Decision making</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n"},{"title":"participe prsent et grondif","date":"2016-12-06T04:31:56.000Z","_content":"\n# (le participe prsent)\n\n## 1. \n\n\n-ons-ant \n\n- faire : nous faisons \n\n\n- etre-etant \n- savoir-sachant\n\n## 2. \n1. qui\n   - L'tranger cherche  trouver quelqu'un **connaissant** (=qui conaisse)  la fois franais et l'anglais.\n2. \n   - **Voyant**(=Comme elle voit) que tout le monde est dej assis,elle va vite  sa place.\n   - **Ayant**(=Comme il a) mal  la tete,il dcide de rester au lit.\n\n## 3. \n### I. \n\n1. \n   - Ses yeux **brillants** disent la convoitises. \n   - Je l'ai trouv toute **tremblante**. \n\n2. \n\n   - Une seance **payante** (=o l'on paie) \n   - une collation **soupante** (=si copieuse qu'elle tient lieu de souper) \n\n   \n\n3. \n\n|        |        |\n| ---------- | --------- |\n| provoquant | provocant |\n| fatiguant  | fatigant  |\n| vaquant    | vacant    |\n| naviguant  | navigant  |\n\n\n### II. \n\n\n\n1. qui\n   - C'est un film **captivant** les spectateurs. \n   - Je le vois **lisant**. \n2. \n   - **Prenant** l'escabeau, il s'offoree d'atteindre le dernier rayon. \n   - **Croyant** le bureau vide, il entra. \n3. \n   - Le train repartit, **courant** vers le Midi. \n4. \n   - Midi **sonnant**, on se met  table. \n\n\n\n\n# (le grondif)\n\n## 1. \n\n\nen \n\n- faire : en faisant\n\nayanttanten\n\n## 2. \n1. \n   - N'oubliez pas de fermer la port **en sortant**.\n   - Ne lis pas **en mangeant**. \n2. \n   - Elle arriva **en courant**. \n3. \n   - **En se levant** plus tot le matin, il n'arrivera pas en retard. \n4. \n   - **En voyant** critiquant, il n'avait nulle intention de nous dcourager. \n5. \n   - **En voyant** son embarras, l'agent se fit plus aimable. \n\n**\\***\n\nalleren\n\n- Sa vue va **en s'affaiblissant**. \n\n## 3. \n\n1. Tous + \n2. Rien que + \n\n\n\n\n\n# \n\n## \n\n\n\n## \n\n1. \n\n\\*\n\n- La fortune vient **en dormant**. \n\n\n2. \n\n","source":"_posts/participe-present-et-gerondif.md","raw":"---\ntitle: participe prsent et grondif\ndate: 2016-12-06 12:31:56\ncategories: francais\ntags: [francais, language]\n---\n\n# (le participe prsent)\n\n## 1. \n\n\n-ons-ant \n\n- faire : nous faisons \n\n\n- etre-etant \n- savoir-sachant\n\n## 2. \n1. qui\n   - L'tranger cherche  trouver quelqu'un **connaissant** (=qui conaisse)  la fois franais et l'anglais.\n2. \n   - **Voyant**(=Comme elle voit) que tout le monde est dej assis,elle va vite  sa place.\n   - **Ayant**(=Comme il a) mal  la tete,il dcide de rester au lit.\n\n## 3. \n### I. \n\n1. \n   - Ses yeux **brillants** disent la convoitises. \n   - Je l'ai trouv toute **tremblante**. \n\n2. \n\n   - Une seance **payante** (=o l'on paie) \n   - une collation **soupante** (=si copieuse qu'elle tient lieu de souper) \n\n   \n\n3. \n\n|        |        |\n| ---------- | --------- |\n| provoquant | provocant |\n| fatiguant  | fatigant  |\n| vaquant    | vacant    |\n| naviguant  | navigant  |\n\n\n### II. \n\n\n\n1. qui\n   - C'est un film **captivant** les spectateurs. \n   - Je le vois **lisant**. \n2. \n   - **Prenant** l'escabeau, il s'offoree d'atteindre le dernier rayon. \n   - **Croyant** le bureau vide, il entra. \n3. \n   - Le train repartit, **courant** vers le Midi. \n4. \n   - Midi **sonnant**, on se met  table. \n\n\n\n\n# (le grondif)\n\n## 1. \n\n\nen \n\n- faire : en faisant\n\nayanttanten\n\n## 2. \n1. \n   - N'oubliez pas de fermer la port **en sortant**.\n   - Ne lis pas **en mangeant**. \n2. \n   - Elle arriva **en courant**. \n3. \n   - **En se levant** plus tot le matin, il n'arrivera pas en retard. \n4. \n   - **En voyant** critiquant, il n'avait nulle intention de nous dcourager. \n5. \n   - **En voyant** son embarras, l'agent se fit plus aimable. \n\n**\\***\n\nalleren\n\n- Sa vue va **en s'affaiblissant**. \n\n## 3. \n\n1. Tous + \n2. Rien que + \n\n\n\n\n\n# \n\n## \n\n\n\n## \n\n1. \n\n\\*\n\n- La fortune vient **en dormant**. \n\n\n2. \n\n","slug":"participe-present-et-gerondif","published":1,"updated":"2016-12-13T21:28:32.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqd0046gwtl0t66d1fb","content":"<h1 id=\"-le-participe-present\"><a href=\"#-le-participe-present\" class=\"headerlink\" title=\"(le participe prsent)\"></a>(le participe prsent)</h1><h2 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<p>-ons-ant </p>\n<ul>\n<li>faire : nous faisons </li>\n</ul>\n<p></p>\n<ul>\n<li>etre-etant </li>\n<li>savoir-sachant</li>\n</ul>\n<h2 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h2><ol>\n<li>qui<ul>\n<li>Ltranger cherche  trouver quelquun <strong>connaissant</strong> (=qui conaisse)  la fois franais et langlais.</li>\n</ul>\n</li>\n<li><ul>\n<li><strong>Voyant</strong>(=Comme elle voit) que tout le monde est dej assis,elle va vite  sa place.</li>\n<li><strong>Ayant</strong>(=Comme il a) mal  la tete,il dcide de rester au lit.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h2><h3 id=\"I-\"><a href=\"#I-\" class=\"headerlink\" title=\"I. \"></a>I. </h3><p></p>\n<ol>\n<li><p></p>\n<ul>\n<li>Ses yeux <strong>brillants</strong> disent la convoitises. </li>\n<li>Je lai trouv toute <strong>tremblante</strong>. </li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>Une seance <strong>payante</strong> (=o lon paie) </li>\n<li>une collation <strong>soupante</strong> (=si copieuse quelle tient lieu de souper) </li>\n</ul>\n<p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>provoquant</td>\n<td>provocant</td>\n</tr>\n<tr>\n<td>fatiguant</td>\n<td>fatigant</td>\n</tr>\n<tr>\n<td>vaquant</td>\n<td>vacant</td>\n</tr>\n<tr>\n<td>naviguant</td>\n<td>navigant</td>\n</tr>\n</tbody></table>\n<h3 id=\"II-\"><a href=\"#II-\" class=\"headerlink\" title=\"II. \"></a>II. </h3><p></p>\n<ol>\n<li>qui<ul>\n<li>Cest un film <strong>captivant</strong> les spectateurs. </li>\n<li>Je le vois <strong>lisant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>Prenant</strong> lescabeau, il sofforee datteindre le dernier rayon. </li>\n<li><strong>Croyant</strong> le bureau vide, il entra. </li>\n</ul>\n</li>\n<li><ul>\n<li>Le train repartit, <strong>courant</strong> vers le Midi. </li>\n</ul>\n</li>\n<li><ul>\n<li>Midi <strong>sonnant</strong>, on se met  table. </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"-le-gerondif\"><a href=\"#-le-gerondif\" class=\"headerlink\" title=\"(le grondif)\"></a>(le grondif)</h1><h2 id=\"1--1\"><a href=\"#1--1\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<p>en </p>\n<ul>\n<li>faire : en faisant</li>\n</ul>\n<p>ayanttanten</p>\n<h2 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h2><ol>\n<li><ul>\n<li>Noubliez pas de fermer la port <strong>en sortant</strong>.</li>\n<li>Ne lis pas <strong>en mangeant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li>Elle arriva <strong>en courant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En se levant</strong> plus tot le matin, il narrivera pas en retard. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En voyant</strong> critiquant, il navait nulle intention de nous dcourager. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En voyant</strong> son embarras, lagent se fit plus aimable. </li>\n</ul>\n</li>\n</ol>\n<p><strong>*</strong></p>\n<p>alleren</p>\n<ul>\n<li>Sa vue va <strong>en saffaiblissant</strong>. </li>\n</ul>\n<h2 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h2><ol>\n<li>Tous + </li>\n<li>Rien que + </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li></li>\n</ol>\n<p>*</p>\n<ul>\n<li>La fortune vient <strong>en dormant</strong>. </li>\n</ul>\n<ol start=\"2\">\n<li></li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"-le-participe-present\"><a href=\"#-le-participe-present\" class=\"headerlink\" title=\"(le participe prsent)\"></a>(le participe prsent)</h1><h2 id=\"1-\"><a href=\"#1-\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<p>-ons-ant </p>\n<ul>\n<li>faire : nous faisons </li>\n</ul>\n<p></p>\n<ul>\n<li>etre-etant </li>\n<li>savoir-sachant</li>\n</ul>\n<h2 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h2><ol>\n<li>qui<ul>\n<li>Ltranger cherche  trouver quelquun <strong>connaissant</strong> (=qui conaisse)  la fois franais et langlais.</li>\n</ul>\n</li>\n<li><ul>\n<li><strong>Voyant</strong>(=Comme elle voit) que tout le monde est dej assis,elle va vite  sa place.</li>\n<li><strong>Ayant</strong>(=Comme il a) mal  la tete,il dcide de rester au lit.</li>\n</ul>\n</li>\n</ol>\n<h2 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h2><h3 id=\"I-\"><a href=\"#I-\" class=\"headerlink\" title=\"I. \"></a>I. </h3><p></p>\n<ol>\n<li><p></p>\n<ul>\n<li>Ses yeux <strong>brillants</strong> disent la convoitises. </li>\n<li>Je lai trouv toute <strong>tremblante</strong>. </li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li>Une seance <strong>payante</strong> (=o lon paie) </li>\n<li>une collation <strong>soupante</strong> (=si copieuse quelle tient lieu de souper) </li>\n</ul>\n<p></p>\n</li>\n<li><p></p>\n</li>\n</ol>\n<table>\n<thead>\n<tr>\n<th></th>\n<th></th>\n</tr>\n</thead>\n<tbody><tr>\n<td>provoquant</td>\n<td>provocant</td>\n</tr>\n<tr>\n<td>fatiguant</td>\n<td>fatigant</td>\n</tr>\n<tr>\n<td>vaquant</td>\n<td>vacant</td>\n</tr>\n<tr>\n<td>naviguant</td>\n<td>navigant</td>\n</tr>\n</tbody></table>\n<h3 id=\"II-\"><a href=\"#II-\" class=\"headerlink\" title=\"II. \"></a>II. </h3><p></p>\n<ol>\n<li>qui<ul>\n<li>Cest un film <strong>captivant</strong> les spectateurs. </li>\n<li>Je le vois <strong>lisant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>Prenant</strong> lescabeau, il sofforee datteindre le dernier rayon. </li>\n<li><strong>Croyant</strong> le bureau vide, il entra. </li>\n</ul>\n</li>\n<li><ul>\n<li>Le train repartit, <strong>courant</strong> vers le Midi. </li>\n</ul>\n</li>\n<li><ul>\n<li>Midi <strong>sonnant</strong>, on se met  table. </li>\n</ul>\n</li>\n</ol>\n<h1 id=\"-le-gerondif\"><a href=\"#-le-gerondif\" class=\"headerlink\" title=\"(le grondif)\"></a>(le grondif)</h1><h2 id=\"1--1\"><a href=\"#1--1\" class=\"headerlink\" title=\"1. \"></a>1. </h2><p></p>\n<p>en </p>\n<ul>\n<li>faire : en faisant</li>\n</ul>\n<p>ayanttanten</p>\n<h2 id=\"2-\"><a href=\"#2-\" class=\"headerlink\" title=\"2. \"></a>2. </h2><ol>\n<li><ul>\n<li>Noubliez pas de fermer la port <strong>en sortant</strong>.</li>\n<li>Ne lis pas <strong>en mangeant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li>Elle arriva <strong>en courant</strong>. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En se levant</strong> plus tot le matin, il narrivera pas en retard. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En voyant</strong> critiquant, il navait nulle intention de nous dcourager. </li>\n</ul>\n</li>\n<li><ul>\n<li><strong>En voyant</strong> son embarras, lagent se fit plus aimable. </li>\n</ul>\n</li>\n</ol>\n<p><strong>*</strong></p>\n<p>alleren</p>\n<ul>\n<li>Sa vue va <strong>en saffaiblissant</strong>. </li>\n</ul>\n<h2 id=\"3-\"><a href=\"#3-\" class=\"headerlink\" title=\"3. \"></a>3. </h2><ol>\n<li>Tous + </li>\n<li>Rien que + </li>\n</ol>\n<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><p></p>\n<h2 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h2><ol>\n<li></li>\n</ol>\n<p>*</p>\n<ul>\n<li>La fortune vient <strong>en dormant</strong>. </li>\n</ul>\n<ol start=\"2\">\n<li></li>\n</ol>\n"},{"title":"proba-ch1 ","date":"2016-12-01T04:17:29.000Z","_content":"\n- \n\n\n$$\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}\n$$\n\n- An\n\n$$\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- An\n\n$$\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- \n- \n\n$$\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})\n$$\n\n- (Equation de partition)\n\n$$\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}\n$$\n\n- (de Bay)\n\n$$\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}\n$$\n\n- \n\n- \n\n  P({wn}) = pnpnP\n\n- \n  $$\n  E[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}\n  $$\n\n- \n\n$$\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)\n$$\n\n- \n\n  - Loi discrete uniforme\n\n  - $$\n    \\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}\n    $$\n\n    $$\n    E[X] = \\frac{n+1}{2}\n    $$\n\n  - Loi de Bernoulli\n\n    $$\n    P(X=1) = p, t P(X=0) = 1-p\n    $$\n    $$\n    E[N] = p, Var(N) = p(1-p)\n    $$\n\n  - Loi binomiale \n    $$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Loi geometrique \n    $$\n    P(N=n) = P^n(1-p),$$$$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Distribution de Poisson\n    $$\n    P(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},\n    $$\n    $$\n    E[X] = \\lambda, Var(X) = \\lambda\n    $$\n","source":"_posts/proba-ch1.md","raw":"---\ntitle: proba-ch1 \ndate: 2016-12-01 12:17:29\ncategories: math\ntags: [probability, math]\n---\n\n- \n\n\n$$\nP(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}\n$$\n\n- An\n\n$$\nP(\\cup(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- An\n\n$$\nP(\\cap(A_n)) = \\lim_{n -> + \\inf}{P(A_n)}\n$$\n\n- \n- \n\n$$\nP({A_1}\\cap{...}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)...P(A_n|A_1\\cap{...}\\cap{A_{n-1}})\n$$\n\n- (Equation de partition)\n\n$$\nP(A) = \\sum_{n}{P(A|E_n)P(E_n)}\n$$\n\n- (de Bay)\n\n$$\nP(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}\n$$\n\n- \n\n- \n\n  P({wn}) = pnpnP\n\n- \n  $$\n  E[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}\n  $$\n\n- \n\n$$\nVar(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)\n$$\n\n- \n\n  - Loi discrete uniforme\n\n  - $$\n    \\forall k \\in \\{1,...,n\\}, P(X=k) = \\frac{1}{n}\n    $$\n\n    $$\n    E[X] = \\frac{n+1}{2}\n    $$\n\n  - Loi de Bernoulli\n\n    $$\n    P(X=1) = p, t P(X=0) = 1-p\n    $$\n    $$\n    E[N] = p, Var(N) = p(1-p)\n    $$\n\n  - Loi binomiale \n    $$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Loi geometrique \n    $$\n    P(N=n) = P^n(1-p),$$$$\n    E[N] = np, Var(N) = np(1-p)\n    $$\n\n  - Distribution de Poisson\n    $$\n    P(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},\n    $$\n    $$\n    E[X] = \\lambda, Var(X) = \\lambda\n    $$\n","slug":"proba-ch1","published":1,"updated":"2016-12-01T11:19:38.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqe0049gwtlhlxk2arj","content":"<ul>\n<li></li>\n</ul>\n<p>$$<br>P(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}<br>$$</p>\n<ul>\n<li>An</li>\n</ul>\n<p>$$<br>P(\\cup(A_n)) = \\lim_{n -&gt; + \\inf}{P(A_n)}<br>$$</p>\n<ul>\n<li>An</li>\n</ul>\n<p>$$<br>P(\\cap(A_n)) = \\lim_{n -&gt; + \\inf}{P(A_n)}<br>$$</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p>$$<br>P({A_1}\\cap{}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)P(A_n|A_1\\cap{}\\cap{A_{n-1}})<br>$$</p>\n<ul>\n<li>(Equation de partition)</li>\n</ul>\n<p>$$<br>P(A) = \\sum_{n}{P(A|E_n)P(E_n)}<br>$$</p>\n<ul>\n<li>(de Bay)</li>\n</ul>\n<p>$$<br>P(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}<br>$$</p>\n<ul>\n<li><p></p>\n</li>\n<li><p></p>\n<p>P({wn}) = pnpnP</p>\n</li>\n<li><p><br>$$<br>E[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}<br>$$</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n<p>$$<br>Var(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)<br>$$</p>\n<ul>\n<li><p></p>\n<ul>\n<li><p>Loi discrete uniforme</p>\n</li>\n<li><p>$$<br>\\forall k \\in {1,,n}, P(X=k) = \\frac{1}{n}<br>$$</p>\n<p>$$<br>E[X] = \\frac{n+1}{2}<br>$$</p>\n</li>\n<li><p>Loi de Bernoulli</p>\n<p>$$<br>P(X=1) = p, t P(X=0) = 1-p<br>$$<br>$$<br>E[N] = p, Var(N) = p(1-p)<br>$$</p>\n</li>\n<li><p>Loi binomiale <br>$$<br>E[N] = np, Var(N) = np(1-p)<br>$$</p>\n</li>\n<li><p>Loi geometrique<br>$$<br>P(N=n) = P^n(1-p),$$$$<br>E[N] = np, Var(N) = np(1-p)<br>$$</p>\n</li>\n<li><p>Distribution de Poisson<br>$$<br>P(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},<br>$$<br>$$<br>E[X] = \\lambda, Var(X) = \\lambda<br>$$</p>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<ul>\n<li></li>\n</ul>\n<p>$$<br>P(\\cup(A_n)) \\leq \\sum_{n \\in N}^{}{P(A_n)}<br>$$</p>\n<ul>\n<li>An</li>\n</ul>\n<p>$$<br>P(\\cup(A_n)) = \\lim_{n -&gt; + \\inf}{P(A_n)}<br>$$</p>\n<ul>\n<li>An</li>\n</ul>\n<p>$$<br>P(\\cap(A_n)) = \\lim_{n -&gt; + \\inf}{P(A_n)}<br>$$</p>\n<ul>\n<li></li>\n<li></li>\n</ul>\n<p>$$<br>P({A_1}\\cap{}\\cap{A_{n-1}}) = P(A_1)P(A_2|A_1)P(A_n|A_1\\cap{}\\cap{A_{n-1}})<br>$$</p>\n<ul>\n<li>(Equation de partition)</li>\n</ul>\n<p>$$<br>P(A) = \\sum_{n}{P(A|E_n)P(E_n)}<br>$$</p>\n<ul>\n<li>(de Bay)</li>\n</ul>\n<p>$$<br>P(E_n|A) = \\frac{P(A|E_n)P(E_n)}{\\sum_{m}{P(A|E_m)PE_m}}<br>$$</p>\n<ul>\n<li><p></p>\n</li>\n<li><p></p>\n<p>P({wn}) = pnpnP</p>\n</li>\n<li><p><br>$$<br>E[X] = \\sum_{\\omega \\in{\\Omega}}{X(\\omega) P(\\omega)}<br>$$</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n<p>$$<br>Var(X) = E[(X - E(X))^2] = E[X^2] - (E(X)^2)<br>$$</p>\n<ul>\n<li><p></p>\n<ul>\n<li><p>Loi discrete uniforme</p>\n</li>\n<li><p>$$<br>\\forall k \\in {1,,n}, P(X=k) = \\frac{1}{n}<br>$$</p>\n<p>$$<br>E[X] = \\frac{n+1}{2}<br>$$</p>\n</li>\n<li><p>Loi de Bernoulli</p>\n<p>$$<br>P(X=1) = p, t P(X=0) = 1-p<br>$$<br>$$<br>E[N] = p, Var(N) = p(1-p)<br>$$</p>\n</li>\n<li><p>Loi binomiale <br>$$<br>E[N] = np, Var(N) = np(1-p)<br>$$</p>\n</li>\n<li><p>Loi geometrique<br>$$<br>P(N=n) = P^n(1-p),$$$$<br>E[N] = np, Var(N) = np(1-p)<br>$$</p>\n</li>\n<li><p>Distribution de Poisson<br>$$<br>P(X=n)=\\frac{\\lambda^n}{n!}e^{-\\lambda},<br>$$<br>$$<br>E[X] = \\lambda, Var(X) = \\lambda<br>$$</p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"proba-ch2 ","date":"2016-12-01T04:17:33.000Z","_content":"\n- \n\n$$\n\\pi-system\n$$\n\n- R\n\n  -  la fonction de repartition\n    $$\n    F:x\\rightarrow F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] } {f(t).\\lambda(dt)}\n    $$\n\n  - \n\n    F\n    $$\n    (i) F \\\\(ii)F \\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}\n    $$\n\n  - \n    $$\n    P(\\{x\\}) = F(x) - F(x-)\n    $$\n\n- R^N\n\n  - \n  $$\n    F:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )\n  $$\n\n  - \n    $$\n    P(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}\n    $$\n\n- \n\n  - \n    $$\n    Soit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}\n    $$\n    X\n\n  -  tribu engendree par X\n    $$\n    X^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)\n    $$\n\n- loi\n\n  - \n    $$\n    \\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))\n    $$\n\n- \n\n  - \n    $$\n    E[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}\n    $$\n\n  - \n    $$\n    (X_n)_{n\\in N} \n    $$\n\n    - XnX\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n    - FatouXn\n      $$\n      E[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}\n      $$\n\n    - convergence dominee: limXn = X p.s Z in L1|Xn|<=Z\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n  - (Inegalite de Markov)\n\n    Xadmettant un moment d'ordre 1, a>0\n    $$\n    P(|X| \\geq a) \\leq \\frac{E[|X|]}{a}\n    $$\n\n  - \n    $$\n    E[h(X)] = \\int_E{h(x)P_X(dx)}\n    $$\n\n  - \n  $$\n  \\text{un moment d'ordre n}: \\int_\\Omega{|X|^ndP} < \\infty\n  $$\n\n  - 0<p<qLqLp\n\n  - \n\n    - $$\n      Var(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}\n      $$\n\n    - XVar(X) = 0\n\n  - \n    $$\n    E[h(X)] = \\int_E{h(x)f_X(dx)}\n    $$\n    \n    $$\n    P(X \\in A) = E[1_{ \\{X\\in A\\} } ] = \\int_A{f_X(dx)}\n    $$\n\n- Vecteurs aleatoires\n\n  X = (X1,,XN) \n\n  - \n    $$\n    Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]\n    $$\n\n    - \n      $$\n      Cov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)\n      $$\n\n  - \n    $$\n    \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1\n    $$\n\n  - \n    $$\n    \\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)\n    $$\n\n  - \n\n- \n\n  \n\n  - XY\n\n    1. AB\n    $$\n      P(X \\in A, Y\\in B) = P(X\\in A)\n    $$\n\n    2. fg\n    $$\n      E[f(X)g(Y)] = E[f(X)] E[g(Y)]\n    $$\n\n    3. fgf(X)g(Y)\n\n  - \n    $$\n    \\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.\n    $$\n    $$\n    \\text{XY} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\n    P_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)\n    $$\n\n  - XY\n    $$\n    \\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)\n    $$\n\n  - (X,Y)lebesgueXY\n    $$\n    \\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)\n    $$\n\n  - XY admettant un moment d'ordre 1, \n\n  - $$\n    E[XY]=E[X]E[Y]\n    $$\n\n  - XY admettant un moment d'ordre 2, Cov(X,Y)=0, \n\n  - $$\n    Var(X+Y) =Var(X) + Var(Y)\n    $$\n\n    \n","source":"_posts/proba-ch2.md","raw":"---\ntitle: proba-ch2 \ndate: 2016-12-01 12:17:33\ncategories: math\ntags: [probability, math, aleatoire]\n---\n\n- \n\n$$\n\\pi-system\n$$\n\n- R\n\n  -  la fonction de repartition\n    $$\n    F:x\\rightarrow F(x) = P(] - \\infty,x] ) \\\\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] } {f(t).\\lambda(dt)}\n    $$\n\n  - \n\n    F\n    $$\n    (i) F \\\\(ii)F \\\\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}\n    $$\n\n  - \n    $$\n    P(\\{x\\}) = F(x) - F(x-)\n    $$\n\n- R^N\n\n  - \n  $$\n    F:(x_1,...,x_N)\\xrightarrow{}F(x_1,...,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )\n  $$\n\n  - \n    $$\n    P(dx_1,...,dx_N) = f(x_1,...,x_N)dx_1...dx_N \\\\ where||f||_{L^2}\n    $$\n\n- \n\n  - \n    $$\n    Soit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\\\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}\n    $$\n    X\n\n  -  tribu engendree par X\n    $$\n    X^{-1}({\\cal E}) = \\{X^{-1}(A); A \\in {\\cal E}\\} \\\\ \\sigma(X)\n    $$\n\n- loi\n\n  - \n    $$\n    \\forall A \\in {\\cal E}; P_X(A) = P(\\{\\omega: X(\\omega) \\in A\\}) = P(X^{-1}(A))\n    $$\n\n- \n\n  - \n    $$\n    E[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}\n    $$\n\n  - \n    $$\n    (X_n)_{n\\in N} \n    $$\n\n    - XnX\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n    - FatouXn\n      $$\n      E[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}\n      $$\n\n    - convergence dominee: limXn = X p.s Z in L1|Xn|<=Z\n      $$\n      \\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]\n      $$\n\n  - (Inegalite de Markov)\n\n    Xadmettant un moment d'ordre 1, a>0\n    $$\n    P(|X| \\geq a) \\leq \\frac{E[|X|]}{a}\n    $$\n\n  - \n    $$\n    E[h(X)] = \\int_E{h(x)P_X(dx)}\n    $$\n\n  - \n  $$\n  \\text{un moment d'ordre n}: \\int_\\Omega{|X|^ndP} < \\infty\n  $$\n\n  - 0<p<qLqLp\n\n  - \n\n    - $$\n      Var(aX+b) = a^2 Var(X) \\\\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}\n      $$\n\n    - XVar(X) = 0\n\n  - \n    $$\n    E[h(X)] = \\int_E{h(x)f_X(dx)}\n    $$\n    \n    $$\n    P(X \\in A) = E[1_{ \\{X\\in A\\} } ] = \\int_A{f_X(dx)}\n    $$\n\n- Vecteurs aleatoires\n\n  X = (X1,,XN) \n\n  - \n    $$\n    Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]\n    $$\n\n    - \n      $$\n      Cov(X,X) =Var(X) \\\\ Cov(X,Y) = Cov(Y,X) \\\\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)\n      $$\n\n  - \n    $$\n    \\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1\n    $$\n\n  - \n    $$\n    \\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)\n    $$\n\n  - \n\n- \n\n  \n\n  - XY\n\n    1. AB\n    $$\n      P(X \\in A, Y\\in B) = P(X\\in A)\n    $$\n\n    2. fg\n    $$\n      E[f(X)g(Y)] = E[f(X)] E[g(Y)]\n    $$\n\n    3. fgf(X)g(Y)\n\n  - \n    $$\n    \\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\\\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.\n    $$\n    $$\n    \\text{XY} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\\\\n    P_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)\n    $$\n\n  - XY\n    $$\n    \\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)\n    $$\n\n  - (X,Y)lebesgueXY\n    $$\n    \\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)\n    $$\n\n  - XY admettant un moment d'ordre 1, \n\n  - $$\n    E[XY]=E[X]E[Y]\n    $$\n\n  - XY admettant un moment d'ordre 2, Cov(X,Y)=0, \n\n  - $$\n    Var(X+Y) =Var(X) + Var(Y)\n    $$\n\n    \n","slug":"proba-ch2","published":1,"updated":"2018-03-13T20:35:29.109Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqf004cgwtl34hx7wsh","content":"<ul>\n<li></li>\n</ul>\n<p>$$<br>\\pi-system<br>$$</p>\n<ul>\n<li><p>R</p>\n<ul>\n<li><p> la fonction de repartition<br>$$<br>F:x\\rightarrow F(x) = P(] - \\infty,x] ) \\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] } {f(t).\\lambda(dt)}<br>$$</p>\n</li>\n<li><p></p>\n<p>F<br>$$<br>(i) F \\(ii)F \\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}<br>$$</p>\n</li>\n<li><p><br>$$<br>P({x}) = F(x) - F(x-)<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>R^N</p>\n<ul>\n<li><p>&nbsp;<br>$$<br>F:(x_1,,x_N)\\xrightarrow{}F(x_1,,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )<br>$$</p>\n</li>\n<li><p><br>$$<br>P(dx_1,,dx_N) = f(x_1,,x_N)dx_1dx_N \\ where||f||_{L^2}<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p><br>$$<br>Soit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}<br>$$<br>X</p>\n</li>\n<li><p> tribu engendree par X<br>$$<br>X^{-1}({\\cal E}) = {X^{-1}(A); A \\in {\\cal E}} \\ \\sigma(X)<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>loi</p>\n<ul>\n<li><br>$$<br>\\forall A \\in {\\cal E}; P_X(A) = P({\\omega: X(\\omega) \\in A}) = P(X^{-1}(A))<br>$$</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p><br>$$<br>E[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}<br>$$</p>\n</li>\n<li><p><br>$$<br>(X_n)_{n\\in N} <br>$$</p>\n<ul>\n<li><p>XnX<br>$$<br>\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]<br>$$</p>\n</li>\n<li><p>FatouXn<br>$$<br>E[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}<br>$$</p>\n</li>\n<li><p>convergence dominee: limXn = X p.s Z in L1|Xn|&lt;=Z<br>$$<br>\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>(Inegalite de Markov)</p>\n<p>Xadmettant un moment dordre 1, a&gt;0<br>$$<br>P(|X| \\geq a) \\leq \\frac{E[|X|]}{a}<br>$$</p>\n</li>\n<li><p><br>$$<br>E[h(X)] = \\int_E{h(x)P_X(dx)}<br>$$</p>\n</li>\n<li><p><br>$$<br>\\text{un moment dordre n}: \\int_\\Omega{|X|^ndP} &lt; \\infty<br>$$</p>\n</li>\n<li><p>0&lt;p&lt;qLqLp</p>\n</li>\n<li><p></p>\n<ul>\n<li><p>$$<br>Var(aX+b) = a^2 Var(X) \\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}<br>$$</p>\n</li>\n<li><p>XVar(X) = 0</p>\n</li>\n</ul>\n</li>\n<li><p><br>$$<br>E[h(X)] = \\int_E{h(x)f_X(dx)}<br>$$<br><br>$$<br>P(X \\in A) = E[1_{ {X\\in A} } ] = \\int_A{f_X(dx)}<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>Vecteurs aleatoires</p>\n<p>X = (X1,,XN) </p>\n<ul>\n<li><p><br>$$<br>Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]<br>$$</p>\n<ul>\n<li><br>$$<br>Cov(X,X) =Var(X) \\ Cov(X,Y) = Cov(Y,X) \\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)<br>$$</li>\n</ul>\n</li>\n<li><p><br>$$<br>\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1<br>$$</p>\n</li>\n<li><p><br>$$<br>\\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)<br>$$</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li><p>XY</p>\n<ol>\n<li><p>AB<br>$$<br>P(X \\in A, Y\\in B) = P(X\\in A)<br>$$</p>\n</li>\n<li><p>fg<br>$$<br>E[f(X)g(Y)] = E[f(X)] E[g(Y)]<br>$$</p>\n</li>\n<li><p>fgf(X)g(Y)</p>\n</li>\n</ol>\n</li>\n<li><p><br>$$<br>\\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.<br>$$<br>$$<br>\\text{XY} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\<br>P_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)<br>$$</p>\n</li>\n<li><p>XY<br>$$<br>\\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)<br>$$</p>\n</li>\n<li><p>(X,Y)lebesgueXY<br>$$<br>\\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)<br>$$</p>\n</li>\n<li><p>XY admettant un moment dordre 1, </p>\n</li>\n<li><p>$$<br>E[XY]=E[X]E[Y]<br>$$</p>\n</li>\n<li><p>XY admettant un moment dordre 2, Cov(X,Y)=0, </p>\n</li>\n<li><p>$$<br>Var(X+Y) =Var(X) + Var(Y)<br>$$</p>\n<p></p>\n</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<ul>\n<li></li>\n</ul>\n<p>$$<br>\\pi-system<br>$$</p>\n<ul>\n<li><p>R</p>\n<ul>\n<li><p> la fonction de repartition<br>$$<br>F:x\\rightarrow F(x) = P(] - \\infty,x] ) \\ F:x\\xrightarrow{}F(x) = \\int_{ ]-\\infty,x] } {f(t).\\lambda(dt)}<br>$$</p>\n</li>\n<li><p></p>\n<p>F<br>$$<br>(i) F \\(ii)F \\(iii) \\lim_{n \\rightarrow - \\infty}{F(x)=0}, \\lim_{n \\rightarrow+\\infty}{F(x)=1}<br>$$</p>\n</li>\n<li><p><br>$$<br>P({x}) = F(x) - F(x-)<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>R^N</p>\n<ul>\n<li><p><br>$$<br>F:(x_1,,x_N)\\xrightarrow{}F(x_1,,x_N) = P(\\prod_{i=1}^{N}] - \\infty,x_i] )<br>$$</p>\n</li>\n<li><p><br>$$<br>P(dx_1,,dx_N) = f(x_1,,x_N)dx_1dx_N \\ where||f||_{L^2}<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p><br>$$<br>Soit(\\Omega,{\\cal F})\\rightarrow (E, {\\cal E}); X:\\Omega \\rightarrow E \\ \\forall A\\in {\\cal E}; X^{-1}(A) \\in {\\cal F}<br>$$<br>X</p>\n</li>\n<li><p> tribu engendree par X<br>$$<br>X^{-1}({\\cal E}) = {X^{-1}(A); A \\in {\\cal E}} \\ \\sigma(X)<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>loi</p>\n<ul>\n<li><br>$$<br>\\forall A \\in {\\cal E}; P_X(A) = P({\\omega: X(\\omega) \\in A}) = P(X^{-1}(A))<br>$$</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p><br>$$<br>E[X] = \\int_{\\Omega}{X(\\omega).P(d\\omega)}= \\int_{\\Omega}{X.dP}<br>$$</p>\n</li>\n<li><p><br>$$<br>(X_n)_{n\\in N} <br>$$</p>\n<ul>\n<li><p>XnX<br>$$<br>\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]<br>$$</p>\n</li>\n<li><p>FatouXn<br>$$<br>E[\\lim_{n \\rightarrow \\infty}{\\inf{X_n}}] \\leq \\lim_{n \\rightarrow \\infty}{\\inf{E[X_n]}}<br>$$</p>\n</li>\n<li><p>convergence dominee: limXn = X p.s Z in L1|Xn|&lt;=Z<br>$$<br>\\lim_{n \\rightarrow \\infty}{E[X_n]} = E[X]<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>(Inegalite de Markov)</p>\n<p>Xadmettant un moment dordre 1, a&gt;0<br>$$<br>P(|X| \\geq a) \\leq \\frac{E[|X|]}{a}<br>$$</p>\n</li>\n<li><p><br>$$<br>E[h(X)] = \\int_E{h(x)P_X(dx)}<br>$$</p>\n</li>\n<li><p><br>$$<br>\\text{un moment dordre n}: \\int_\\Omega{|X|^ndP} &lt; \\infty<br>$$</p>\n</li>\n<li><p>0&lt;p&lt;qLqLp</p>\n</li>\n<li><p></p>\n<ul>\n<li><p>$$<br>Var(aX+b) = a^2 Var(X) \\ P(|X-E[X]| \\geq a) \\leq \\frac{Var(X)}{a^2}<br>$$</p>\n</li>\n<li><p>XVar(X) = 0</p>\n</li>\n</ul>\n</li>\n<li><p><br>$$<br>E[h(X)] = \\int_E{h(x)f_X(dx)}<br>$$<br><br>$$<br>P(X \\in A) = E[1_{ {X\\in A} } ] = \\int_A{f_X(dx)}<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>Vecteurs aleatoires</p>\n<p>X = (X1,,XN) </p>\n<ul>\n<li><p><br>$$<br>Cov(X,Y) = E[(X-E[X])(Y-E[Y])] = E[XY] - E[X]E[Y]<br>$$</p>\n<ul>\n<li><br>$$<br>Cov(X,X) =Var(X) \\ Cov(X,Y) = Cov(Y,X) \\ Var(X+Y) = Var(X) +Var(Y) +2Cov(X,Y)<br>$$</li>\n</ul>\n</li>\n<li><p><br>$$<br>\\rho(X,Y) = \\frac{Cov(X,Y)}{\\sigma(X)\\sigma(Y)}, \\sigma(X) = \\sqrt{Var(X)}, -1 \\leq \\rho \\leq 1<br>$$</p>\n</li>\n<li><p><br>$$<br>\\forall y \\in R^N; f_Y(y) = \\frac{f_X(h^{-1}(y))}{|det(Jh(h^{-1}))|} 1_D(y)<br>$$</p>\n</li>\n<li><p></p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<p></p>\n<ul>\n<li><p>XY</p>\n<ol>\n<li><p>AB<br>$$<br>P(X \\in A, Y\\in B) = P(X\\in A)<br>$$</p>\n</li>\n<li><p>fg<br>$$<br>E[f(X)g(Y)] = E[f(X)] E[g(Y)]<br>$$</p>\n</li>\n<li><p>fgf(X)g(Y)</p>\n</li>\n</ol>\n</li>\n<li><p><br>$$<br>\\text{Soient (X, Y) un couple de variables aleatoires a valeurs dans } E\\otimes F \\text{ muni de la tribu produit } \\mathcal{E} \\otimes \\tilde{\\mathcal{E}}. \\ \\text{ X et Y sont independantes si et seulement si la lor jointe du couple (X, Y) est egale a la mesure produit } P_X \\otimes P_Y.<br>$$<br>$$<br>\\text{XY} P((X,Y)\\in A \\times B) = P_X(A)P_Y(B) \\<br>P_X \\otimes P_Y(A \\times B) = P_X(A)P_Y(B)<br>$$</p>\n</li>\n<li><p>XY<br>$$<br>\\forall (x,y) \\in R^2; F_{(X,Y)}(x,y) = F_X(x)F_Y(y)<br>$$</p>\n</li>\n<li><p>(X,Y)lebesgueXY<br>$$<br>\\forall (x,y) \\in R^2; f_{(X,Y)}(x,y) = f_X(x)f_Y(y)<br>$$</p>\n</li>\n<li><p>XY admettant un moment dordre 1, </p>\n</li>\n<li><p>$$<br>E[XY]=E[X]E[Y]<br>$$</p>\n</li>\n<li><p>XY admettant un moment dordre 2, Cov(X,Y)=0, </p>\n</li>\n<li><p>$$<br>Var(X+Y) =Var(X) + Var(Y)<br>$$</p>\n<p></p>\n</li>\n</ul>\n</li>\n</ul>\n"},{"title":"proba-ch3 ","date":"2016-12-01T06:54:10.000Z","_content":"\n1. \n\n    f=0\n\n   1. loi uniforme\n      $$\n      f(x)=\\frac{1}{b-a} si\\ x \\in [a,b]\n      $$\n\n   2. loi exponentielle\n      $$\n      f(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\n      E[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2\n      $$\n\n   3. Loi de weibull\n      $$\n      f(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\n      E[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}\n      $$\n\n   4. loi gamma\n      $$\n      f(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\n      E[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}\n      $$\n\n   5. loi normale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\n      E[X] = m, Var(X) = \\sigma^2\n      $$\n\n   6. Loi lognormale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\n      E[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)\n      $$\n\n   7. Loi du $ \\chi^2 $\n      $$\n      X = U_1^2+...+U_n^2 \\\\\n      U_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\n      E[X] = n, Var(X) = 2n\n      $$\n\n   8. Loi de Student\n      $$\n      X = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\n      U\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\n      Z\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}\n      $$\n\n2. \n   $$\n   \\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\n   t \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}\n   $$\n   XPX = =\n\n   PX $f \\in L^1$\n   $$\n   \\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}\n   $$\n\n   - \n\n     - $$\n       \\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1\n       $$\n\n       $$\n       \\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)\n       $$\n\n       $$\n       \\varphi_X  \\\\\n       \\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0\n       $$\n\n   - \n\n     - \n\n     - PXlebesgue\n\n     - $$\n       \\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0\n       $$\n\n     - XYP\n\n     - $$\n       \\varphi_X=\\varphi_Y\n       $$\n\n     - \n\n     - $$\n       \\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt\n       $$\n\n   - \n\n     - \n       $$\n       X_1,...,X_N \\text{ } \\\\\n       \\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\n       where\\ X = (X_1,...,X_N)\n       $$\n\n     - \n       $$\n       X_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n       \\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n       \\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n       \\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }\n       $$\n\n\n","source":"_posts/proba-ch3.md","raw":"---\ntitle: proba-ch3 \ndate: 2016-12-01 14:54:10\ncategories: math\ntags: [probability, math]\n---\n\n1. \n\n    f=0\n\n   1. loi uniforme\n      $$\n      f(x)=\\frac{1}{b-a} si\\ x \\in [a,b]\n      $$\n\n   2. loi exponentielle\n      $$\n      f(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\\\\n      E[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2\n      $$\n\n   3. Loi de weibull\n      $$\n      f(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\\\\n      E[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}\n      $$\n\n   4. loi gamma\n      $$\n      f(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\\\\n      E[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}\n      $$\n\n   5. loi normale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\\\\n      E[X] = m, Var(X) = \\sigma^2\n      $$\n\n   6. Loi lognormale\n      $$\n      f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\\\\n      E[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)\n      $$\n\n   7. Loi du $ \\chi^2 $\n      $$\n      X = U_1^2+...+U_n^2 \\\\\n      U_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\\\\n      E[X] = n, Var(X) = 2n\n      $$\n\n   8. Loi de Student\n      $$\n      X = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\\\\n      U\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\\\\n      Z\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}\n      $$\n\n2. \n   $$\n   \\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\\\\n   t \\rightarrow \\varphi_X(t) = E[e^{i<t,X>}] = \\int_{\\mathbb{R}^N}{e^{i<t,X>}P_X(dx)}\n   $$\n   XPX = =\n\n   PX $f \\in L^1$\n   $$\n   \\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i<t,X>}f(x)dx}\n   $$\n\n   - \n\n     - $$\n       \\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=> \\varphi_X(0) = 1\n       $$\n\n       $$\n       \\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)\n       $$\n\n       $$\n       \\varphi_X  \\\\\n       \\forall z_1,...,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0\n       $$\n\n   - \n\n     - \n\n     - PXlebesgue\n\n     - $$\n       \\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0\n       $$\n\n     - XYP\n\n     - $$\n       \\varphi_X=\\varphi_Y\n       $$\n\n     - \n\n     - $$\n       \\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i<t,X>}\\varphi_X(t)}dt\n       $$\n\n   - \n\n     - \n       $$\n       X_1,...,X_N \\text{ } \\\\\n       \\forall t = (t_1,...,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\\\\n       where\\ X = (X_1,...,X_N)\n       $$\n\n     - \n       $$\n       X_1,...,X_n independants, P_{X_1},...,P_{X_N}. \\\\\n       \\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\\\\n       \\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\\\\n       \\forall t \\in \\mathbb{R}^N; \\varphi_{X+...+X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }\n       $$\n\n\n","slug":"proba-ch3","published":1,"updated":"2016-12-01T15:28:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqh004fgwtl3ik43tc5","content":"<ol>\n<li><p></p>\n<p> f=0</p>\n<ol>\n<li><p>loi uniforme<br>$$<br>f(x)=\\frac{1}{b-a} si\\ x \\in [a,b]<br>$$</p>\n</li>\n<li><p>loi exponentielle<br>$$<br>f(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\<br>E[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2<br>$$</p>\n</li>\n<li><p>Loi de weibull<br>$$<br>f(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\<br>E[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}<br>$$</p>\n</li>\n<li><p>loi gamma<br>$$<br>f(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\<br>E[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}<br>$$</p>\n</li>\n<li><p>loi normale<br>$$<br>f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\<br>E[X] = m, Var(X) = \\sigma^2<br>$$</p>\n</li>\n<li><p>Loi lognormale<br>$$<br>f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\<br>E[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)<br>$$</p>\n</li>\n<li><p>Loi du $ \\chi^2 $<br>$$<br>X = U_1^2++U_n^2 \\<br>U_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\<br>E[X] = n, Var(X) = 2n<br>$$</p>\n</li>\n<li><p>Loi de Student<br>$$<br>X = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\<br>U\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\<br>Z\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}<br>$$</p>\n</li>\n</ol>\n</li>\n<li><p><br>$$<br>\\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\<br>t \\rightarrow \\varphi_X(t) = E[e^{i&lt;t,X&gt;}] = \\int_{\\mathbb{R}^N}{e^{i&lt;t,X&gt;}P_X(dx)}<br>$$<br>XPX = =</p>\n<p>PX $f \\in L^1$<br>$$<br>\\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i&lt;t,X&gt;}f(x)dx}<br>$$</p>\n<ul>\n<li><p></p>\n<ul>\n<li><p>$$<br>\\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=&gt; \\varphi_X(0) = 1<br>$$</p>\n<p>$$<br>\\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)<br>$$</p>\n<p>$$<br>\\varphi_X  \\<br>\\forall z_1,,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n</li>\n<li><p>PXlebesgue</p>\n</li>\n<li><p>$$<br>\\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0<br>$$</p>\n</li>\n<li><p>XYP</p>\n</li>\n<li><p>$$<br>\\varphi_X=\\varphi_Y<br>$$</p>\n</li>\n<li><p></p>\n</li>\n<li><p>$$<br>\\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i&lt;t,X&gt;}\\varphi_X(t)}dt<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p><br>$$<br>X_1,,X_N \\text{ } \\<br>\\forall t = (t_1,,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\<br>where\\ X = (X_1,,X_N)<br>$$</p>\n</li>\n<li><p><br>$$<br>X_1,,X_n independants, P_{X_1},,P_{X_N}. \\<br>\\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\<br>\\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\<br>\\forall t \\in \\mathbb{R}^N; \\varphi_{X++X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }<br>$$</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<ol>\n<li><p></p>\n<p> f=0</p>\n<ol>\n<li><p>loi uniforme<br>$$<br>f(x)=\\frac{1}{b-a} si\\ x \\in [a,b]<br>$$</p>\n</li>\n<li><p>loi exponentielle<br>$$<br>f(x) = \\lambda e^{-\\lambda x} si\\ x \\ge 0 \\<br>E[X] = \\frac{1}{\\lambda}, Var(X) = \\lambda^2<br>$$</p>\n</li>\n<li><p>Loi de weibull<br>$$<br>f(x) = \\alpha \\lambda^\\alpha x^{\\alpha-1}e^{-(\\lambda x)^\\alpha} si\\ x \\ge 0\\<br>E[X] = \\frac{\\Gamma(1+1/\\alpha)}{\\lambda}, Var(X) = \\frac{\\Gamma(1+2/\\alpha)}{\\lambda^2}<br>$$</p>\n</li>\n<li><p>loi gamma<br>$$<br>f(x) = \\frac{\\lambda}{\\Gamma(p)}(\\lambda x)^{p-1}e^{-\\lambda x}\\<br>E[X] = \\frac{p}{\\lambda}, Var(X) = \\frac{p}{\\lambda^2}<br>$$</p>\n</li>\n<li><p>loi normale<br>$$<br>f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma}exp[-\\frac{(x-m)^2}{2\\sigma^2}], x \\in R\\<br>E[X] = m, Var(X) = \\sigma^2<br>$$</p>\n</li>\n<li><p>Loi lognormale<br>$$<br>f(x) = \\frac{1}{\\sqrt{2\\pi}\\sigma x}exp[-\\frac{(\\ln x-m)^2}{2\\sigma^2}], x \\ge 0 \\<br>E[X] = e^{m+\\sigma^2/2}, Var(X) = e^{2m+\\sigma^2}(e^{\\sigma^@}-1)<br>$$</p>\n</li>\n<li><p>Loi du $ \\chi^2 $<br>$$<br>X = U_1^2++U_n^2 \\<br>U_i\\ est\\ de\\ loi\\ \\mathcal{N}(0,1) \\<br>E[X] = n, Var(X) = 2n<br>$$</p>\n</li>\n<li><p>Loi de Student<br>$$<br>X = \\frac{U}{\\sqrt{\\frac{Z}{n}}} \\<br>U\\ suit\\ la\\ loi\\ normale\\ \\mathcal{N}(0,1) \\<br>Z\\text{ est independante de U et suit la loi du }\\chi^2\\text{ a n degres de liberte}<br>$$</p>\n</li>\n</ol>\n</li>\n<li><p><br>$$<br>\\varphi_X: \\mathbb{R^N} \\rightarrow \\mathbb{C} \\<br>t \\rightarrow \\varphi_X(t) = E[e^{i&lt;t,X&gt;}] = \\int_{\\mathbb{R}^N}{e^{i&lt;t,X&gt;}P_X(dx)}<br>$$<br>XPX = =</p>\n<p>PX $f \\in L^1$<br>$$<br>\\varphi_X(t) = \\int_{\\mathbb{R}^N}{e^{i&lt;t,X&gt;}f(x)dx}<br>$$</p>\n<ul>\n<li><p></p>\n<ul>\n<li><p>$$<br>\\forall t \\in \\mathbb{R}^N, |\\varphi_X(t)| \\le 1=&gt; \\varphi_X(0) = 1<br>$$</p>\n<p>$$<br>\\varphi_{\\lambda X+a}(t) = e^{iat}\\varphi_X(\\lambda t)<br>$$</p>\n<p>$$<br>\\varphi_X  \\<br>\\forall z_1,,z_n\\in \\mathbb{C}, \\sum_{1 \\le j, k\\le n}{z_j \\varphi_X(t_j-t_k)\\bar{z_k}} \\ge 0<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p></p>\n</li>\n<li><p>PXlebesgue</p>\n</li>\n<li><p>$$<br>\\lim_{|t|\\rightarrow \\infty}{\\varphi_X(t)} = 0<br>$$</p>\n</li>\n<li><p>XYP</p>\n</li>\n<li><p>$$<br>\\varphi_X=\\varphi_Y<br>$$</p>\n</li>\n<li><p></p>\n</li>\n<li><p>$$<br>\\forall x \\in \\mathbb{R}^N, f(x)=\\frac{1}{(2\\pi)^N}\\int_{\\mathbb{R}^N}{e^{-i&lt;t,X&gt;}\\varphi_X(t)}dt<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p><br>$$<br>X_1,,X_N \\text{ } \\<br>\\forall t = (t_1,,t_N) \\in \\mathbb{R}^N; \\varphi_X(t) = \\prod_{k=1}^{N}{\\varphi_{X_k}(t_k) } \\<br>where\\ X = (X_1,,X_N)<br>$$</p>\n</li>\n<li><p><br>$$<br>X_1,,X_n independants, P_{X_1},,P_{X_N}. \\<br>\\text{La loi de } \\sum{X_i} \\text{est le produit de concolution } \\prod{P_{X_i}} \\<br>\\text{Pour fonction caracteristique } \\sum{\\varphi_{X_i}} \\text{definie par} \\<br>\\forall t \\in \\mathbb{R}^N; \\varphi_{X++X_n}(t) = \\prod_{i=1}^{n}{\\varphi_{X_i}(t) }<br>$$</p>\n</li>\n</ul>\n</li>\n</ul>\n</li>\n</ol>\n"},{"title":"proba-ch4 ","date":"2016-12-01T08:28:52.000Z","_content":"\n\n\nUn vecteur alatoire est dit gaussien si toute combinaison linaire de ses composantes suit une loi gaussienne.\n\n\n$$\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}\n$$\n\n- \n  $$\n  \\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n  => \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}\n  $$\n  $\\mu$, le vecteur moyenne, \n\n  D, la matrice de covariances de X, \n\n- X=(X1,,XN) XjD\n\n- Densite de la loi d'un vecteur gaussien\n  $$\n  D \\ne 0 \\\\\n  \\mathcal{N}(\\mu,D) \\text{Lebesgue}\\mathbb{R}^N\\text{} \\\\\n  x \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}\n  $$\n\n","source":"_posts/proba-ch4.md","raw":"---\ntitle: proba-ch4 \ndate: 2016-12-01 16:28:52\ncategories: math\ntags: [probability, math, vector]\n---\n\n\n\nUn vecteur alatoire est dit gaussien si toute combinaison linaire de ses composantes suit une loi gaussienne.\n\n\n$$\n\\forall \\lambda_1,...,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}\n$$\n\n- \n  $$\n  \\varphi_X: t \\rightarrow e^{i < \\mu, t> -\\frac{1}{2}<t,Dt>} \\\\\n  => \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}\n  $$\n  $\\mu$, le vecteur moyenne, \n\n  D, la matrice de covariances de X, \n\n- X=(X1,,XN) XjD\n\n- Densite de la loi d'un vecteur gaussien\n  $$\n  D \\ne 0 \\\\\n  \\mathcal{N}(\\mu,D) \\text{Lebesgue}\\mathbb{R}^N\\text{} \\\\\n  x \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}<x-\\mu,D^{-1}(x-\\mu)>}\n  $$\n\n","slug":"proba-ch4","published":1,"updated":"2016-12-19T13:11:37.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqi004jgwtl1whs0az0","content":"<p></p>\n<p>Un vecteur alatoire est dit gaussien si toute combinaison linaire de ses composantes suit une loi gaussienne.</p>\n<p><br>$$<br>\\forall \\lambda_1,,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}<br>$$</p>\n<ul>\n<li><p><br>$$<br>\\varphi_X: t \\rightarrow e^{i &lt; \\mu, t&gt; -\\frac{1}{2}&lt;t,Dt&gt;} \\<br>=&gt; \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}<br>$$<br>$\\mu$, le vecteur moyenne, </p>\n<p>D, la matrice de covariances de X, </p>\n</li>\n<li><p>X=(X1,,XN) XjD</p>\n</li>\n<li><p>Densite de la loi dun vecteur gaussien<br>$$<br>D \\ne 0 \\<br>\\mathcal{N}(\\mu,D) \\text{Lebesgue}\\mathbb{R}^N\\text{} \\<br>x \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}&lt;x-\\mu,D^{-1}(x-\\mu)&gt;}<br>$$</p>\n</li>\n</ul>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p></p>\n<p>Un vecteur alatoire est dit gaussien si toute combinaison linaire de ses composantes suit une loi gaussienne.</p>\n<p><br>$$<br>\\forall \\lambda_1,,\\lambda_N \\in \\mathbb{R} , \\sum_{j=1}^{N}{\\lambda_jX_j \\text{ suit une loi normale.}}<br>$$</p>\n<ul>\n<li><p><br>$$<br>\\varphi_X: t \\rightarrow e^{i &lt; \\mu, t&gt; -\\frac{1}{2}&lt;t,Dt&gt;} \\<br>=&gt; \\varphi_X = e^{i\\sum_{j=1}^{N}{\\mu_j t_j}- \\frac{1}{2}\\sum_{1\\le j,k\\le N}{t_j D_{j,k}t_k}}<br>$$<br>$\\mu$, le vecteur moyenne, </p>\n<p>D, la matrice de covariances de X, </p>\n</li>\n<li><p>X=(X1,,XN) XjD</p>\n</li>\n<li><p>Densite de la loi dun vecteur gaussien<br>$$<br>D \\ne 0 \\<br>\\mathcal{N}(\\mu,D) \\text{Lebesgue}\\mathbb{R}^N\\text{} \\<br>x \\longmapsto \\frac{1}{(2\\pi)^{N/2}\\sqrt{\\det D}}e^{-\\frac{1}{2}&lt;x-\\mu,D^{-1}(x-\\mu)&gt;}<br>$$</p>\n</li>\n</ul>\n"},{"title":"proba-ch5 ","date":"2016-12-01T15:14:28.000Z","_content":"\n# \n\n1. \n\n   > ****  wiki\n\n   $$\n   (X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n   \\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n   \\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}\n   $$\n   - (loi de zero-un)\n\n     A$\\mathcal{T}_{\\infty}$P(A)01\n\n2. \n\n   - convergence presque sure\n\n     \n     $$\n     \\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\n     $$\n     (p.s.)\n     $$\n     P\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1\n     $$\n\n   - Convergence dans Lp\n\n     XnXLpp- -|||\n\n     \n     $$\n     \\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0\n     $$\n\n   - convergence en probabilite\n\n     \n     $$\n     \\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\n     ou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0\n     $$\n     \n\n     1. XnX(p.s.)fXnfX(p.s.)\n     2. XnX(P)fXnfX(P)\n\n     \n\n     Xn\n     $$\n     X_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0\n     $$\n     \n\n     Xn\n     $$\n     X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\n     X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\\n     $$\n     \n\n     XnXnX\n     $$\n     (X_{n_k})_{k \\in \\mathbb{N}}\n     $$\n     \n     $$\n     X_n \\to X, p.s.\n     $$\n     \n\n     XnXnX$Y \\in L^p, |X_n| \\le Y$\n     $$\n     X \\in L^p X_n \\xrightarrow{L^p}X\n     $$\n\n\n\n\n\n3. \n\n   >  wiki\n\n   1. \n   2. \n\n4. \n\n   >   wiki\n\n   - \n     $$\n     X_n \\in L^2 \\text{} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.\n     $$\n\n   - \n     $$\n     X_n  \\text{} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ } E[X_i] \\text{i}\n     $$\n\n5. Convergence en loi\n\n   \n   $$\n   \\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}\n   $$\n   PXnPXXn convergence en loi vers X\n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   \n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]\n   $$\n   \n   $$\n   X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.\n\n   - convergence en loi\n   - convergence en loi\n   - convergence en loi\n\n   =_=\n\n6. \n   $$\n   Var(X_n) < \\infty \\\\\n   S_n = \\sum{Xi} \\\\\n   \\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)\n   $$\n   \n\n","source":"_posts/proba-ch5.md","raw":"---\ntitle: proba-ch5 \ncategories: math\ntags:\n  - math\n  - probability\ndate: 2016-12-01 23:14:28\n---\n\n# \n\n1. \n\n   > ****  wiki\n\n   $$\n   (X_n)_{n \\in \\mathbb{N}} v.a. \\\\\n   \\mathcal{T}_n = \\sigma(X_k; k \\ge n) \\\\\n   \\mathcal{T}_{\\infty} = \\cap_{n \\in \\mathbb{N}}{\\mathcal{T}_n} \\text{ est   appelee tribu de queue de la suite } (X_n)_{n \\in \\mathbb{N}}\n   $$\n   - (loi de zero-un)\n\n     A$\\mathcal{T}_{\\infty}$P(A)01\n\n2. \n\n   - convergence presque sure\n\n     \n     $$\n     \\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\n     $$\n     (p.s.)\n     $$\n     P\\{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)\\} = 1\n     $$\n\n   - Convergence dans Lp\n\n     XnXLpp- -|||\n\n     \n     $$\n     \\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0\n     $$\n\n   - convergence en probabilite\n\n     \n     $$\n     \\forall \\varepsilon, \\lim_{n \\to \\infty}{P\\{\\omega:X_n(\\omega)-X(\\omega)>\\varepsilon}\\}=0 \\\\\n     ou\\  \\lim_{n \\to \\infty}{P\\{X_n-X>\\varepsilon}\\}=0\n     $$\n     \n\n     1. XnX(p.s.)fXnfX(p.s.)\n     2. XnX(P)fXnfX(P)\n\n     \n\n     Xn\n     $$\n     X_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0\n     $$\n     \n\n     Xn\n     $$\n     X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\\\\n     X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\\\\n     $$\n     \n\n     XnXnX\n     $$\n     (X_{n_k})_{k \\in \\mathbb{N}}\n     $$\n     \n     $$\n     X_n \\to X, p.s.\n     $$\n     \n\n     XnXnX$Y \\in L^p, |X_n| \\le Y$\n     $$\n     X \\in L^p X_n \\xrightarrow{L^p}X\n     $$\n\n\n\n\n\n3. \n\n   >  wiki\n\n   1. \n   2. \n\n4. \n\n   >   wiki\n\n   - \n     $$\n     X_n \\in L^2 \\text{} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.\n     $$\n\n   - \n     $$\n     X_n  \\text{} \\\\\n     lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ } E[X_i] \\text{i}\n     $$\n\n5. Convergence en loi\n\n   \n   $$\n   \\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}\n   $$\n   PXnPXXn convergence en loi vers X\n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   \n   $$\n   X_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]\n   $$\n   \n   $$\n   X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X\n   $$\n   si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.\n\n   - convergence en loi\n   - convergence en loi\n   - convergence en loi\n\n   =_=\n\n6. \n   $$\n   Var(X_n) < \\infty \\\\\n   S_n = \\sum{Xi} \\\\\n   \\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)\n   $$\n   \n\n","slug":"proba-ch5","published":1,"updated":"2016-12-11T11:05:17.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqj004ngwtl69iddlyd","content":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<blockquote>\n<p><strong></strong>  wiki</p>\n</blockquote>\n<p>$$<br>(X_n)<em>{n \\in \\mathbb{N}} v.a. \\<br>\\mathcal{T}<em>n = \\sigma(X_k; k \\ge n) \\<br>\\mathcal{T}</em>{\\infty} = \\cap</em>{n \\in \\mathbb{N}}{\\mathcal{T}<em>n} \\text{ est   appelee tribu de queue de la suite } (X_n)</em>{n \\in \\mathbb{N}}<br>$$</p>\n<ul>\n<li><p>(loi de zero-un)</p>\n<p>A$\\mathcal{T}_{\\infty}$P(A)01</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p>convergence presque sure</p>\n<p><br>$$<br>\\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)<br>$$<br>(p.s.)<br>$$<br>P{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)} = 1<br>$$</p>\n</li>\n<li><p>Convergence dans Lp</p>\n<p>XnXLpp- -|||</p>\n<p><br>$$<br>\\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0<br>$$</p>\n</li>\n<li><p>convergence en probabilite</p>\n<p><br>$$<br>\\forall \\varepsilon, \\lim_{n \\to \\infty}{P{\\omega:X_n(\\omega)-X(\\omega)&gt;\\varepsilon}}=0 \\<br>ou\\  \\lim_{n \\to \\infty}{P{X_n-X&gt;\\varepsilon}}=0<br>$$<br></p>\n<ol>\n<li>XnX(p.s.)fXnfX(p.s.)</li>\n<li>XnX(P)fXnfX(P)</li>\n</ol>\n<p></p>\n<p>Xn<br>$$<br>X_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0<br>$$<br></p>\n<p>Xn<br>$$<br>X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\<br>X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\<br>$$<br></p>\n<p>XnXnX<br>$$<br>(X_{n_k})_{k \\in \\mathbb{N}}<br>$$<br><br>$$<br>X_n \\to X, p.s.<br>$$<br></p>\n<p>XnXnX$Y \\in L^p, |X_n| \\le Y$<br>$$<br>X \\in L^p X_n \\xrightarrow{L^p}X<br>$$</p>\n</li>\n</ul>\n</li>\n</ol>\n<ol start=\"3\">\n<li><p></p>\n<blockquote>\n<p> wiki</p>\n</blockquote>\n<ol>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p></p>\n<blockquote>\n<p>  wiki</p>\n</blockquote>\n<ul>\n<li><p><br>$$<br>X_n \\in L^2 \\text{} \\<br>lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.<br>$$</p>\n</li>\n<li><p><br>$$<br>X_n  \\text{} \\<br>lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ } E[X_i] \\text{i}<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>Convergence en loi</p>\n<p><br>$$<br>\\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}<br>$$<br>PXnPXXn convergence en loi vers X<br>$$<br>X_n \\xrightarrow{\\mathcal{D}} X<br>$$<br><br>$$<br>X_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]<br>$$<br><br>$$<br>X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X<br>$$<br>si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.</p>\n<ul>\n<li>convergence en loi</li>\n<li>convergence en loi</li>\n<li>convergence en loi</li>\n</ul>\n<p>=_=</p>\n</li>\n<li><p><br>$$<br>Var(X_n) &lt; \\infty \\<br>S_n = \\sum{Xi} \\<br>\\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)<br>$$<br></p>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"\"><a href=\"#\" class=\"headerlink\" title=\"\"></a></h1><ol>\n<li><p></p>\n<blockquote>\n<p><strong></strong>  wiki</p>\n</blockquote>\n<p>$$<br>(X_n)<em>{n \\in \\mathbb{N}} v.a. \\<br>\\mathcal{T}<em>n = \\sigma(X_k; k \\ge n) \\<br>\\mathcal{T}</em>{\\infty} = \\cap</em>{n \\in \\mathbb{N}}{\\mathcal{T}<em>n} \\text{ est   appelee tribu de queue de la suite } (X_n)</em>{n \\in \\mathbb{N}}<br>$$</p>\n<ul>\n<li><p>(loi de zero-un)</p>\n<p>A$\\mathcal{T}_{\\infty}$P(A)01</p>\n</li>\n</ul>\n</li>\n<li><p></p>\n<ul>\n<li><p>convergence presque sure</p>\n<p><br>$$<br>\\exists \\Omega^*, \\forall \\omega \\in \\Omega^*, \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)<br>$$<br>(p.s.)<br>$$<br>P{\\omega \\in \\Omega^*: \\lim_{n \\rightarrow \\infty}{X_n(\\omega)} = X(\\omega)} = 1<br>$$</p>\n</li>\n<li><p>Convergence dans Lp</p>\n<p>XnXLpp- -|||</p>\n<p><br>$$<br>\\lim_{n \\rightarrow \\infty}{E[|X_n-X|^p]} = 0<br>$$</p>\n</li>\n<li><p>convergence en probabilite</p>\n<p><br>$$<br>\\forall \\varepsilon, \\lim_{n \\to \\infty}{P{\\omega:X_n(\\omega)-X(\\omega)&gt;\\varepsilon}}=0 \\<br>ou\\  \\lim_{n \\to \\infty}{P{X_n-X&gt;\\varepsilon}}=0<br>$$<br></p>\n<ol>\n<li>XnX(p.s.)fXnfX(p.s.)</li>\n<li>XnX(P)fXnfX(P)</li>\n</ol>\n<p></p>\n<p>Xn<br>$$<br>X_n \\xrightarrow{P} X \\Leftrightarrow \\lim_{n \\to \\infty} E(\\frac{|X_n-X|}{1+|X_n-X|}) = 0<br>$$<br></p>\n<p>Xn<br>$$<br>X_n \\xrightarrow{L^P}X, X_n \\xrightarrow{P}{X} \\<br>X_n \\to X p.s., X_n \\xrightarrow{P}{X} \\<br>$$<br></p>\n<p>XnXnX<br>$$<br>(X_{n_k})_{k \\in \\mathbb{N}}<br>$$<br><br>$$<br>X_n \\to X, p.s.<br>$$<br></p>\n<p>XnXnX$Y \\in L^p, |X_n| \\le Y$<br>$$<br>X \\in L^p X_n \\xrightarrow{L^p}X<br>$$</p>\n</li>\n</ul>\n</li>\n</ol>\n<ol start=\"3\">\n<li><p></p>\n<blockquote>\n<p> wiki</p>\n</blockquote>\n<ol>\n<li></li>\n<li></li>\n</ol>\n</li>\n<li><p></p>\n<blockquote>\n<p>  wiki</p>\n</blockquote>\n<ul>\n<li><p><br>$$<br>X_n \\in L^2 \\text{} \\<br>lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s.<br>$$</p>\n</li>\n<li><p><br>$$<br>X_n  \\text{} \\<br>lim_{n \\to \\infty}{\\frac{\\sum_{i=1}^{n}{X_i}}{n}} = \\mu \\ p.s. \\text{ } E[X_i] \\text{i}<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p>Convergence en loi</p>\n<p><br>$$<br>\\int_{\\mathbb{R}^N}{f(x)\\nu_n(dx)} \\xrightarrow{n \\to \\infty} \\int_{\\mathbb{R}^N}{f(x)\\nu(dx)}<br>$$<br>PXnPXXn convergence en loi vers X<br>$$<br>X_n \\xrightarrow{\\mathcal{D}} X<br>$$<br><br>$$<br>X_n \\xrightarrow{\\mathcal{D}} X \\Leftrightarrow \\lim_{n \\to \\infty}E[f(X_n)] = E[f(X)]<br>$$<br><br>$$<br>X_n \\xrightarrow{P} X \\Rightarrow X_n \\xrightarrow{\\mathcal{D}} X<br>$$<br>si Xn converge en loi vers une v.a. constante presque surement, alors elle converge en probabilite.</p>\n<ul>\n<li>convergence en loi</li>\n<li>convergence en loi</li>\n<li>convergence en loi</li>\n</ul>\n<p>=_=</p>\n</li>\n<li><p><br>$$<br>Var(X_n) &lt; \\infty \\<br>S_n = \\sum{Xi} \\<br>\\frac{S_n-n\\mu}{\\sigma\\sqrt{n}} \\xrightarrow{\\mathcal{D}} \\mathcal{N}(0,1)<br>$$<br></p>\n</li>\n</ol>\n"},{"title":"proba-ch6 ","date":"2016-12-02T13:32:30.000Z","_content":"\n$$\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}\n$$\n\n$$\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}\n$$\n\n$$\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0\n$$\n\n$$\nE[X|Y] = \\psi(Y)\n$$\n\n- \n  $$\n  \\mathcal{G} sous-tribu\\\\\n  E[X|\\mathcal{G}] Y, \\\\\n  Y \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP\n  $$\n\n-  L2\n  $$\n  X \\in L^2, \\mathcal{G} sous-tribu \\\\\n  E[X|\\mathcal{G}] Y, \\\\\n  \\forall Z \\in L^2, E[XZ] = E[YZ]\n  $$\n\n  - \n    $$\n    E[E[X|\\mathcal{G}]] = E[X]\n    $$\n\n  - \n    $$\n    X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X\\mathcal{G}\n    $$\n\n  - \n    $$\n    X\\mathcal{G}, X,Y,XY \\in L^1 \\\\\n    \\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]\n    $$\n\n- \n  $$\n  E[X|Y] = E[X|\\sigma(Y)]\n  $$\n\n  -  XYh\n    $$\n    E[X|Y] = h(Y)\n    $$\n","source":"_posts/proba-ch6.md","raw":"---\ntitle: proba-ch6 \ncategories: math\ntags:\n  - math\n  - probability\ndate: 2016-12-02 21:32:30\n---\n\n$$\nP(A|B) = \\frac{P(A\\cap B)}{P(B)}\n$$\n\n$$\nE[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}\n$$\n\n$$\n\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) > 0 \\\\\notherwise\\ 0\n$$\n\n$$\nE[X|Y] = \\psi(Y)\n$$\n\n- \n  $$\n  \\mathcal{G} sous-tribu\\\\\n  E[X|\\mathcal{G}] Y, \\\\\n  Y \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP\n  $$\n\n-  L2\n  $$\n  X \\in L^2, \\mathcal{G} sous-tribu \\\\\n  E[X|\\mathcal{G}] Y, \\\\\n  \\forall Z \\in L^2, E[XZ] = E[YZ]\n  $$\n\n  - \n    $$\n    E[E[X|\\mathcal{G}]] = E[X]\n    $$\n\n  - \n    $$\n    X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X\\mathcal{G}\n    $$\n\n  - \n    $$\n    X\\mathcal{G}, X,Y,XY \\in L^1 \\\\\n    \\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]\n    $$\n\n- \n  $$\n  E[X|Y] = E[X|\\sigma(Y)]\n  $$\n\n  -  XYh\n    $$\n    E[X|Y] = h(Y)\n    $$\n","slug":"proba-ch6","published":1,"updated":"2016-12-02T21:09:54.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqk004rgwtlgijj1k8k","content":"<p>$$<br>P(A|B) = \\frac{P(A\\cap B)}{P(B)}<br>$$</p>\n<p>$$<br>E[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}<br>$$</p>\n<p>$$<br>\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) &gt; 0 \\<br>otherwise\\ 0<br>$$</p>\n<p>$$<br>E[X|Y] = \\psi(Y)<br>$$</p>\n<ul>\n<li><p><br>$$<br>\\mathcal{G} sous-tribu\\<br>E[X|\\mathcal{G}] Y, \\<br>Y \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP<br>$$</p>\n</li>\n<li><p> L2<br>$$<br>X \\in L^2, \\mathcal{G} sous-tribu \\<br>E[X|\\mathcal{G}] Y, \\<br>\\forall Z \\in L^2, E[XZ] = E[YZ]<br>$$</p>\n<ul>\n<li><p><br>$$<br>E[E[X|\\mathcal{G}]] = E[X]<br>$$</p>\n</li>\n<li><p><br>$$<br>X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X\\mathcal{G}<br>$$</p>\n</li>\n<li><p><br>$$<br>X\\mathcal{G}, X,Y,XY \\in L^1 \\<br>\\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p><br>$$<br>E[X|Y] = E[X|\\sigma(Y)]<br>$$</p>\n<ul>\n<li> XYh<br>$$<br>E[X|Y] = h(Y)<br>$$</li>\n</ul>\n</li>\n</ul>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>$$<br>P(A|B) = \\frac{P(A\\cap B)}{P(B)}<br>$$</p>\n<p>$$<br>E[X|Y=y] = E_Q[X] = \\sum_{x \\in \\tilde E}{xP(X=x|Y=y)}<br>$$</p>\n<p>$$<br>\\psi : y \\mapsto E[X|Y=y] \\text{ if } P(Y=y) &gt; 0 \\<br>otherwise\\ 0<br>$$</p>\n<p>$$<br>E[X|Y] = \\psi(Y)<br>$$</p>\n<ul>\n<li><p><br>$$<br>\\mathcal{G} sous-tribu\\<br>E[X|\\mathcal{G}] Y, \\<br>Y \\in L^1, \\forall A \\in \\mathcal{G}, \\int_A X dP = \\int_AYdP<br>$$</p>\n</li>\n<li><p> L2<br>$$<br>X \\in L^2, \\mathcal{G} sous-tribu \\<br>E[X|\\mathcal{G}] Y, \\<br>\\forall Z \\in L^2, E[XZ] = E[YZ]<br>$$</p>\n<ul>\n<li><p><br>$$<br>E[E[X|\\mathcal{G}]] = E[X]<br>$$</p>\n</li>\n<li><p><br>$$<br>X \\in L^1, E[X|\\mathcal{G}] = E[X] \\Leftrightarrow X\\mathcal{G}<br>$$</p>\n</li>\n<li><p><br>$$<br>X\\mathcal{G}, X,Y,XY \\in L^1 \\<br>\\Rightarrow E[XY|\\mathcal{G}] = XE[Y|\\mathcal{G}]<br>$$</p>\n</li>\n</ul>\n</li>\n<li><p><br>$$<br>E[X|Y] = E[X|\\sigma(Y)]<br>$$</p>\n<ul>\n<li> XYh<br>$$<br>E[X|Y] = h(Y)<br>$$</li>\n</ul>\n</li>\n</ul>\n"},{"title":"Chrome - Hello world","date":"2016-11-30T04:01:24.000Z","_content":"\nprojetchrome\n\n# Hello world!\n\nhello world\n\n1. chrome\n\n2. manifest.jsonchrome\n\n   hello worlddefault_popup\n\n   ```json\n   {\n     \"manifest_version\": 2,\n     \"name\": \"TrelloGement\",\n     \"description\": \"Organiser ses recherches d'appartement sur Paris grce  Trello!\",\n     \"version\": \"0.2.1\",\n     \"browser_action\": {\n       \"default_icon\": \"icon.png\",\n       \"default_popup\": \"popup.html\"\n     },\n     \"background\": {\n       \"scripts\": [\"background.js\", \"jquery-3.1.1.min.js\", \"client.js\"]\n     },\n     \"permissions\": [\"activeTab\", \"storage\", \"tabs\", \"https://api.trello.com/*\", \"https://trello.com/*\"]\n   }\n   ```\n\n3. popup.html\n\n   ```html\n   <!DOCTYPE html>\n   <html lang=\"en\">\n   <head>\n   \t<meta charset=\"UTF-8\">\n   \t<title>Trellogement</title>\n   </head>\n   <body>\n     <h1> Hello, world! </h1>\n   </body>\n   </html>\n   ```\n\n4. Hello worldchromepopupHello, world!\n\n","source":"_posts/projet-enjeu-plugin-chrome-101.md","raw":"---\ntitle: Chrome - Hello world\ndate: 2016-11-30 12:01:24\ncategories: programming\ntags: [web, chrome]\n---\n\nprojetchrome\n\n# Hello world!\n\nhello world\n\n1. chrome\n\n2. manifest.jsonchrome\n\n   hello worlddefault_popup\n\n   ```json\n   {\n     \"manifest_version\": 2,\n     \"name\": \"TrelloGement\",\n     \"description\": \"Organiser ses recherches d'appartement sur Paris grce  Trello!\",\n     \"version\": \"0.2.1\",\n     \"browser_action\": {\n       \"default_icon\": \"icon.png\",\n       \"default_popup\": \"popup.html\"\n     },\n     \"background\": {\n       \"scripts\": [\"background.js\", \"jquery-3.1.1.min.js\", \"client.js\"]\n     },\n     \"permissions\": [\"activeTab\", \"storage\", \"tabs\", \"https://api.trello.com/*\", \"https://trello.com/*\"]\n   }\n   ```\n\n3. popup.html\n\n   ```html\n   <!DOCTYPE html>\n   <html lang=\"en\">\n   <head>\n   \t<meta charset=\"UTF-8\">\n   \t<title>Trellogement</title>\n   </head>\n   <body>\n     <h1> Hello, world! </h1>\n   </body>\n   </html>\n   ```\n\n4. Hello worldchromepopupHello, world!\n\n","slug":"projet-enjeu-plugin-chrome-101","published":1,"updated":"2016-11-30T11:19:02.000Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufql004vgwtl2fyf5s0m","content":"<p>projetchrome</p>\n<h1 id=\"Hello-world\"><a href=\"#Hello-world\" class=\"headerlink\" title=\"Hello world!\"></a>Hello world!</h1><p>hello world</p>\n<ol>\n<li><p>chrome</p>\n</li>\n<li><p>manifest.jsonchrome</p>\n<p>hello worlddefault_popup</p>\n<figure class=\"highlight json\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">{</span><br><span class=\"line\">  <span class=\"attr\">\"manifest_version\"</span>: <span class=\"number\">2</span>,</span><br><span class=\"line\">  <span class=\"attr\">\"name\"</span>: <span class=\"string\">\"TrelloGement\"</span>,</span><br><span class=\"line\">  <span class=\"attr\">\"description\"</span>: <span class=\"string\">\"Organiser ses recherches d'appartement sur Paris grce  Trello!\"</span>,</span><br><span class=\"line\">  <span class=\"attr\">\"version\"</span>: <span class=\"string\">\"0.2.1\"</span>,</span><br><span class=\"line\">  <span class=\"attr\">\"browser_action\"</span>: {</span><br><span class=\"line\">    <span class=\"attr\">\"default_icon\"</span>: <span class=\"string\">\"icon.png\"</span>,</span><br><span class=\"line\">    <span class=\"attr\">\"default_popup\"</span>: <span class=\"string\">\"popup.html\"</span></span><br><span class=\"line\">  },</span><br><span class=\"line\">  <span class=\"attr\">\"background\"</span>: {</span><br><span class=\"line\">    <span class=\"attr\">\"scripts\"</span>: [<span class=\"string\">\"background.js\"</span>, <span class=\"string\">\"jquery-3.1.1.min.js\"</span>, <span class=\"string\">\"client.js\"</span>]</span><br><span class=\"line\">  },</span><br><span class=\"line\">  <span class=\"attr\">\"permissions\"</span>: [<span class=\"string\">\"activeTab\"</span>, <span class=\"string\">\"storage\"</span>, <span class=\"string\">\"tabs\"</span>, <span class=\"string\">\"https://api.trello.com/*\"</span>, <span class=\"string\">\"https://trello.com/*\"</span>]</span><br><span class=\"line\">}</span><br></pre></td></tr></tbody></table></figure></li>\n<li><p>popup.html</p>\n<figure class=\"highlight html\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">\"en\"</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">\"UTF-8\"</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>Trellogement<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">h1</span>&gt;</span> Hello, world! <span class=\"tag\">&lt;/<span class=\"name\">h1</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></tbody></table></figure></li>\n<li><p>Hello worldchromepopupHello, world!</p>\n</li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>projetchrome</p>\n<h1 id=\"Hello-world\"><a href=\"#Hello-world\" class=\"headerlink\" title=\"Hello world!\"></a>Hello world!</h1><p>hello world</p>\n<ol>\n<li><p>chrome</p>\n</li>\n<li><p>manifest.jsonchrome</p>\n<p>hello worlddefault_popup</p>\n<figure class=\"highlight json\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br><span class=\"line\">11</span><br><span class=\"line\">12</span><br><span class=\"line\">13</span><br><span class=\"line\">14</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">&#123;</span><br><span class=\"line\">  <span class=\"attr\">&quot;manifest_version&quot;</span>: <span class=\"number\">2</span>,</span><br><span class=\"line\">  <span class=\"attr\">&quot;name&quot;</span>: <span class=\"string\">&quot;TrelloGement&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">&quot;description&quot;</span>: <span class=\"string\">&quot;Organiser ses recherches d&#x27;appartement sur Paris grce  Trello!&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">&quot;version&quot;</span>: <span class=\"string\">&quot;0.2.1&quot;</span>,</span><br><span class=\"line\">  <span class=\"attr\">&quot;browser_action&quot;</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">&quot;default_icon&quot;</span>: <span class=\"string\">&quot;icon.png&quot;</span>,</span><br><span class=\"line\">    <span class=\"attr\">&quot;default_popup&quot;</span>: <span class=\"string\">&quot;popup.html&quot;</span></span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"attr\">&quot;background&quot;</span>: &#123;</span><br><span class=\"line\">    <span class=\"attr\">&quot;scripts&quot;</span>: [<span class=\"string\">&quot;background.js&quot;</span>, <span class=\"string\">&quot;jquery-3.1.1.min.js&quot;</span>, <span class=\"string\">&quot;client.js&quot;</span>]</span><br><span class=\"line\">  &#125;,</span><br><span class=\"line\">  <span class=\"attr\">&quot;permissions&quot;</span>: [<span class=\"string\">&quot;activeTab&quot;</span>, <span class=\"string\">&quot;storage&quot;</span>, <span class=\"string\">&quot;tabs&quot;</span>, <span class=\"string\">&quot;https://api.trello.com/*&quot;</span>, <span class=\"string\">&quot;https://trello.com/*&quot;</span>]</span><br><span class=\"line\">&#125;</span><br></pre></td></tr></table></figure></li>\n<li><p>popup.html</p>\n<figure class=\"highlight html\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br><span class=\"line\">9</span><br><span class=\"line\">10</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">&lt;!DOCTYPE <span class=\"meta-keyword\">html</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">html</span> <span class=\"attr\">lang</span>=<span class=\"string\">&quot;en&quot;</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">meta</span> <span class=\"attr\">charset</span>=<span class=\"string\">&quot;UTF-8&quot;</span>&gt;</span></span><br><span class=\"line\">\t<span class=\"tag\">&lt;<span class=\"name\">title</span>&gt;</span>Trellogement<span class=\"tag\">&lt;/<span class=\"name\">title</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">head</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\">  <span class=\"tag\">&lt;<span class=\"name\">h1</span>&gt;</span> Hello, world! <span class=\"tag\">&lt;/<span class=\"name\">h1</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">body</span>&gt;</span></span><br><span class=\"line\"><span class=\"tag\">&lt;/<span class=\"name\">html</span>&gt;</span></span><br></pre></td></tr></table></figure></li>\n<li><p>Hello worldchromepopupHello, world!</p>\n</li>\n</ol>\n"},{"title":"Set up the RSS feed","date":"2018-05-12T04:57:31.000Z","_content":"\nThis post is both declaration of the update and a test whether the rss works well.\n\nThis RSS feed is generated by [hexo-generator-feed](https://github.com/hexojs/hexo-generator-feed) plugin.\n\n1. Install the plugin\n\n   ```Shell\n   $ npm install hexo-generator-feed --save\n   ```\n\n2. update the theme configuration (_config.yml).\n\n   Enable the plugin:\n\n   ```yaml\n   plugins:\n      ...\n      hexo-generator-feed: true\n\n   feed:\n   \ttype: atom  \n   \tpath: atom.xml  \n   \tlimit: 20\n   ```\n\n   Show the RSS link on the website, this step depends on the theme we use, it should be something like:\n\n   ```yaml\n   links:\n   \trss: /atom.xml # this should be the path you assigned above.\n   ```\n\n   \n\n3. And voil, now you can subscribe to the RSS feed you created.\n\n   <img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-12-image-201805121311408.png\" width=\"20%\">\n\n","source":"_posts/update-rss.md","raw":"---\ntitle: Set up the RSS feed\ndate: 2018-05-12 12:57:31\ncategories: [other]\ntags: [hexo, rss]\n---\n\nThis post is both declaration of the update and a test whether the rss works well.\n\nThis RSS feed is generated by [hexo-generator-feed](https://github.com/hexojs/hexo-generator-feed) plugin.\n\n1. Install the plugin\n\n   ```Shell\n   $ npm install hexo-generator-feed --save\n   ```\n\n2. update the theme configuration (_config.yml).\n\n   Enable the plugin:\n\n   ```yaml\n   plugins:\n      ...\n      hexo-generator-feed: true\n\n   feed:\n   \ttype: atom  \n   \tpath: atom.xml  \n   \tlimit: 20\n   ```\n\n   Show the RSS link on the website, this step depends on the theme we use, it should be something like:\n\n   ```yaml\n   links:\n   \trss: /atom.xml # this should be the path you assigned above.\n   ```\n\n   \n\n3. And voil, now you can subscribe to the RSS feed you created.\n\n   <img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-12-image-201805121311408.png\" width=\"20%\">\n\n","slug":"update-rss","published":1,"updated":"2020-11-03T03:26:00.854Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqm004zgwtlg4182z10","content":"<p>This post is both declaration of the update and a test whether the rss works well.</p>\n<p>This RSS feed is generated by <a href=\"https://github.com/hexojs/hexo-generator-feed\">hexo-generator-feed</a> plugin.</p>\n<ol>\n<li><p>Install the plugin</p>\n<figure class=\"highlight shell\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> npm install hexo-generator-feed --save</span></span><br></pre></td></tr></tbody></table></figure></li>\n<li><p>update the theme configuration (_config.yml).</p>\n<p>Enable the plugin:</p>\n<figure class=\"highlight yaml\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">plugins:</span></span><br><span class=\"line\">   <span class=\"string\">...</span></span><br><span class=\"line\">   <span class=\"attr\">hexo-generator-feed:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">feed:</span></span><br><span class=\"line\">\t<span class=\"attr\">type:</span> <span class=\"string\">atom</span>  </span><br><span class=\"line\">\t<span class=\"attr\">path:</span> <span class=\"string\">atom.xml</span>  </span><br><span class=\"line\">\t<span class=\"attr\">limit:</span> <span class=\"number\">20</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p>Show the RSS link on the website, this step depends on the theme we use, it should be something like:</p>\n<figure class=\"highlight yaml\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">links:</span></span><br><span class=\"line\">\t<span class=\"attr\">rss:</span> <span class=\"string\">/atom.xml</span> <span class=\"comment\"># this should be the path you assigned above.</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p></p>\n</li>\n<li><p>And voil, now you can subscribe to the RSS feed you created.</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-12-image-201805121311408.png\" width=\"20%\"></li>\n</ol>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<p>This post is both declaration of the update and a test whether the rss works well.</p>\n<p>This RSS feed is generated by <a href=\"https://github.com/hexojs/hexo-generator-feed\">hexo-generator-feed</a> plugin.</p>\n<ol>\n<li><p>Install the plugin</p>\n<figure class=\"highlight shell\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"meta\">$</span><span class=\"bash\"> npm install hexo-generator-feed --save</span></span><br></pre></td></tr></table></figure></li>\n<li><p>update the theme configuration (_config.yml).</p>\n<p>Enable the plugin:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br><span class=\"line\">6</span><br><span class=\"line\">7</span><br><span class=\"line\">8</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">plugins:</span></span><br><span class=\"line\">   <span class=\"string\">...</span></span><br><span class=\"line\">   <span class=\"attr\">hexo-generator-feed:</span> <span class=\"literal\">true</span></span><br><span class=\"line\"></span><br><span class=\"line\"><span class=\"attr\">feed:</span></span><br><span class=\"line\">\t<span class=\"attr\">type:</span> <span class=\"string\">atom</span>  </span><br><span class=\"line\">\t<span class=\"attr\">path:</span> <span class=\"string\">atom.xml</span>  </span><br><span class=\"line\">\t<span class=\"attr\">limit:</span> <span class=\"number\">20</span></span><br></pre></td></tr></table></figure>\n\n<p>Show the RSS link on the website, this step depends on the theme we use, it should be something like:</p>\n<figure class=\"highlight yaml\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br></pre></td><td class=\"code\"><pre><span class=\"line\"><span class=\"attr\">links:</span></span><br><span class=\"line\">\t<span class=\"attr\">rss:</span> <span class=\"string\">/atom.xml</span> <span class=\"comment\"># this should be the path you assigned above.</span></span><br></pre></td></tr></table></figure>\n\n<p></p>\n</li>\n<li><p>And voil, now you can subscribe to the RSS feed you created.</p>\n<img src=\"https://lorrin-1251763245.cos.ap-shanghai.myqcloud.com/photo/2018-05-12-image-201805121311408.png\" width=\"20%\"></li>\n</ol>\n"},{"title":"CheatSheet for Setting up New VPS","date":"2020-02-09T08:18:11.000Z","_content":"\n# Basics\n\n## Create New Users\n\nfirst login in the root account.\n\nto add a user:\n\n```bash\nadduser [UserName]\n```\n\nif want it to have sudo privilege, then:\n\n~~~bash\nusermod -aG sudo [UserName]\n~~~\n\n## Set Up SSH Config\n\nadd these to ~/.ssh/config\n\n```\nHost [ShortNameForTheVPS]\nHostName [ItsIPOrDomain]\nUser [TheUserToLogin]\nIdentitiesOnly yes\n```\n\nif you want to ssh via proxy, for MacOS users:\n\n```\nHost [ShortNameForTheVPS]\nHostName [ItsIPOrDomain]\nProxyCommand nc -X 5 -x 127.0.0.1:1082 %h %p\nUser [TheUserToLogin]\nIdentitiesOnly yes\n```\n\n-X 5 means using socks5; -x specify proxy server ip and port.\n\nthen ssh-copy-id, so we don't have to type password every time we ssh:\n\n```bash\nssh-copy-id [ShortNameForTheVPS]\n```\n\nAs the result, we only need to type to login:\n\n```bash\nssh [ShortNameForTheVPS]\n```\n\n## Powerful Vim\n\nLife is short, I use spf13.\n\n```bash\ncurl https://j.mp/spf13-vim3 -L > spf13-vim.sh && sh spf13-vim.sh\n```\n\nif every thing goes fine, it will usually take within 5 minnutes.\n\n## Powerful Zsh\n\nBash is good but Zsh is better. For ubuntu users:\n\n```bash\nsudo apt install zsh\n```\n\nAgain, life is short, I use oh-my-zsh.\n\n```bash\nsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\nit is installed instantly.\n\n# Network Related\n\nUsually it is suggested to expose ports as few as possible, and only preserve 80(HTTP) and 443(HTTPS).\n\nWe can use nginx/caddy/... to do HTTP(S) reverse proxy.\n\n## Caddy\n\ninstall go\n\n```bash\nsudo apt install golang\n```\n\ninstall caddy. we choose caddy 1 here.\n\n```bash\ncurl https://getcaddy.com | bash -s personal\n```\n\nrun caddy, and it should run as a simple server on port 2015. it should return 404 when visit.\n\n```bash\ncaddy\n```\n\nto run caddy as server, follow instructions [here](https://github.com/caddyserver/caddy/tree/master/dist/init/linux-systemd).\n\nto use CloudFlare CDN, follow instuctions [here(chinese)](https://melty.land/blog/caddy-and-cloudflare)\n\n# Scientific Purpose\n\ne.g. interactive demo.\n\n## Python Environment\n\ndownload anaconda, the latest address can be found [here](https://www.anaconda.com/distribution/).\n\n```bash\nwget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh\n```\n\ninstall it.\n\n```bash\nbash Anaconda3-2019.10-Linux-x86_64.sh\n```\n\nif use zsh, the install script won't add initialization script to .zshrc, so we need to copy from .bashrc\n\nre-login, so the initialization script will work.\n\ninstall pytorch will be another long story, so we won't go in deep here.\n\n","source":"_posts/vps-cheatsheet.md","raw":"---\ntitle: CheatSheet for Setting up New VPS\ndate: 2020-02-09 16:18:11\ncategories: other\ntags: [vps]\n---\n\n# Basics\n\n## Create New Users\n\nfirst login in the root account.\n\nto add a user:\n\n```bash\nadduser [UserName]\n```\n\nif want it to have sudo privilege, then:\n\n~~~bash\nusermod -aG sudo [UserName]\n~~~\n\n## Set Up SSH Config\n\nadd these to ~/.ssh/config\n\n```\nHost [ShortNameForTheVPS]\nHostName [ItsIPOrDomain]\nUser [TheUserToLogin]\nIdentitiesOnly yes\n```\n\nif you want to ssh via proxy, for MacOS users:\n\n```\nHost [ShortNameForTheVPS]\nHostName [ItsIPOrDomain]\nProxyCommand nc -X 5 -x 127.0.0.1:1082 %h %p\nUser [TheUserToLogin]\nIdentitiesOnly yes\n```\n\n-X 5 means using socks5; -x specify proxy server ip and port.\n\nthen ssh-copy-id, so we don't have to type password every time we ssh:\n\n```bash\nssh-copy-id [ShortNameForTheVPS]\n```\n\nAs the result, we only need to type to login:\n\n```bash\nssh [ShortNameForTheVPS]\n```\n\n## Powerful Vim\n\nLife is short, I use spf13.\n\n```bash\ncurl https://j.mp/spf13-vim3 -L > spf13-vim.sh && sh spf13-vim.sh\n```\n\nif every thing goes fine, it will usually take within 5 minnutes.\n\n## Powerful Zsh\n\nBash is good but Zsh is better. For ubuntu users:\n\n```bash\nsudo apt install zsh\n```\n\nAgain, life is short, I use oh-my-zsh.\n\n```bash\nsh -c \"$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)\"\n```\n\nit is installed instantly.\n\n# Network Related\n\nUsually it is suggested to expose ports as few as possible, and only preserve 80(HTTP) and 443(HTTPS).\n\nWe can use nginx/caddy/... to do HTTP(S) reverse proxy.\n\n## Caddy\n\ninstall go\n\n```bash\nsudo apt install golang\n```\n\ninstall caddy. we choose caddy 1 here.\n\n```bash\ncurl https://getcaddy.com | bash -s personal\n```\n\nrun caddy, and it should run as a simple server on port 2015. it should return 404 when visit.\n\n```bash\ncaddy\n```\n\nto run caddy as server, follow instructions [here](https://github.com/caddyserver/caddy/tree/master/dist/init/linux-systemd).\n\nto use CloudFlare CDN, follow instuctions [here(chinese)](https://melty.land/blog/caddy-and-cloudflare)\n\n# Scientific Purpose\n\ne.g. interactive demo.\n\n## Python Environment\n\ndownload anaconda, the latest address can be found [here](https://www.anaconda.com/distribution/).\n\n```bash\nwget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh\n```\n\ninstall it.\n\n```bash\nbash Anaconda3-2019.10-Linux-x86_64.sh\n```\n\nif use zsh, the install script won't add initialization script to .zshrc, so we need to copy from .bashrc\n\nre-login, so the initialization script will work.\n\ninstall pytorch will be another long story, so we won't go in deep here.\n\n","slug":"vps-cheatsheet","published":1,"updated":"2020-02-09T13:43:52.811Z","comments":1,"layout":"post","photos":[],"link":"","_id":"ckw4qufqp0053gwtl5crh54nc","content":"<h1 id=\"Basics\"><a href=\"#Basics\" class=\"headerlink\" title=\"Basics\"></a>Basics</h1><h2 id=\"Create-New-Users\"><a href=\"#Create-New-Users\" class=\"headerlink\" title=\"Create New Users\"></a>Create New Users</h2><p>first login in the root account.</p>\n<p>to add a user:</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">adduser [UserName]</span><br></pre></td></tr></tbody></table></figure>\n\n<p>if want it to have sudo privilege, then:</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">usermod -aG sudo [UserName]</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"Set-Up-SSH-Config\"><a href=\"#Set-Up-SSH-Config\" class=\"headerlink\" title=\"Set Up SSH Config\"></a>Set Up SSH Config</h2><p>add these to ~/.ssh/config</p>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host [ShortNameForTheVPS]</span><br><span class=\"line\">HostName [ItsIPOrDomain]</span><br><span class=\"line\">User [TheUserToLogin]</span><br><span class=\"line\">IdentitiesOnly yes</span><br></pre></td></tr></tbody></table></figure>\n\n<p>if you want to ssh via proxy, for MacOS users:</p>\n<figure class=\"highlight plaintext\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host [ShortNameForTheVPS]</span><br><span class=\"line\">HostName [ItsIPOrDomain]</span><br><span class=\"line\">ProxyCommand nc -X 5 -x 127.0.0.1:1082 %h %p</span><br><span class=\"line\">User [TheUserToLogin]</span><br><span class=\"line\">IdentitiesOnly yes</span><br></pre></td></tr></tbody></table></figure>\n\n<p>-X 5 means using socks5; -x specify proxy server ip and port.</p>\n<p>then ssh-copy-id, so we dont have to type password every time we ssh:</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-copy-id [ShortNameForTheVPS]</span><br></pre></td></tr></tbody></table></figure>\n\n<p>As the result, we only need to type to login:</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh [ShortNameForTheVPS]</span><br></pre></td></tr></tbody></table></figure>\n\n<h2 id=\"Powerful-Vim\"><a href=\"#Powerful-Vim\" class=\"headerlink\" title=\"Powerful Vim\"></a>Powerful Vim</h2><p>Life is short, I use spf13.</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl https://j.mp/spf13-vim3 -L &gt; spf13-vim.sh &amp;&amp; sh spf13-vim.sh</span><br></pre></td></tr></tbody></table></figure>\n\n<p>if every thing goes fine, it will usually take within 5 minnutes.</p>\n<h2 id=\"Powerful-Zsh\"><a href=\"#Powerful-Zsh\" class=\"headerlink\" title=\"Powerful Zsh\"></a>Powerful Zsh</h2><p>Bash is good but Zsh is better. For ubuntu users:</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install zsh</span><br></pre></td></tr></tbody></table></figure>\n\n<p>Again, life is short, I use oh-my-zsh.</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh -c <span class=\"string\">\"<span class=\"subst\">$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)</span>\"</span></span><br></pre></td></tr></tbody></table></figure>\n\n<p>it is installed instantly.</p>\n<h1 id=\"Network-Related\"><a href=\"#Network-Related\" class=\"headerlink\" title=\"Network Related\"></a>Network Related</h1><p>Usually it is suggested to expose ports as few as possible, and only preserve 80(HTTP) and 443(HTTPS).</p>\n<p>We can use nginx/caddy/ to do HTTP(S) reverse proxy.</p>\n<h2 id=\"Caddy\"><a href=\"#Caddy\" class=\"headerlink\" title=\"Caddy\"></a>Caddy</h2><p>install go</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install golang</span><br></pre></td></tr></tbody></table></figure>\n\n<p>install caddy. we choose caddy 1 here.</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl https://getcaddy.com | bash -s personal</span><br></pre></td></tr></tbody></table></figure>\n\n<p>run caddy, and it should run as a simple server on port 2015. it should return 404 when visit.</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">caddy</span><br></pre></td></tr></tbody></table></figure>\n\n<p>to run caddy as server, follow instructions <a href=\"https://github.com/caddyserver/caddy/tree/master/dist/init/linux-systemd\">here</a>.</p>\n<p>to use CloudFlare CDN, follow instuctions <a href=\"https://melty.land/blog/caddy-and-cloudflare\">here(chinese)</a></p>\n<h1 id=\"Scientific-Purpose\"><a href=\"#Scientific-Purpose\" class=\"headerlink\" title=\"Scientific Purpose\"></a>Scientific Purpose</h1><p>e.g. interactive demo.</p>\n<h2 id=\"Python-Environment\"><a href=\"#Python-Environment\" class=\"headerlink\" title=\"Python Environment\"></a>Python Environment</h2><p>download anaconda, the latest address can be found <a href=\"https://www.anaconda.com/distribution/\">here</a>.</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh</span><br></pre></td></tr></tbody></table></figure>\n\n<p>install it.</p>\n<figure class=\"highlight bash\"><table><tbody><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bash Anaconda3-2019.10-Linux-x86_64.sh</span><br></pre></td></tr></tbody></table></figure>\n\n<p>if use zsh, the install script wont add initialization script to .zshrc, so we need to copy from .bashrc</p>\n<p>re-login, so the initialization script will work.</p>\n<p>install pytorch will be another long story, so we wont go in deep here.</p>\n","site":{"data":{"recommended_posts":{"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"},{"title":"Open-World Knowledge Graph Completion ","permalink":"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/"}],"https://LorrinWWW.github.io/posts/complexity/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/hexo-with-latex/":[{"title":"HexoCoinhive","permalink":"http://www.davidfnck.com/blockchain/mine-xmr-in-hexo-by-coinhive.html/"}],"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/":[{"title":"Reinforcement Learning for Relation Classification from Noisy Data ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/Note-of-statistic/":[{"title":" Bayes estimation","permalink":"https://LorrinWWW.github.io/posts/Bayes-estimation/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"}],"https://LorrinWWW.github.io/posts/[2018.2.5]Nested-LSTMs/":[{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"}],"https://LorrinWWW.github.io/posts/datamining-pretreatment/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/[2018.2.26]Open-World-Knowledge-Graph-Completion/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"Several models for knowledge graph representing and completing ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.10]Several-models-for-kenowledge-graoh-representing-and-completing/"}],"https://LorrinWWW.github.io/posts/compression/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/Sobolev-space/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/proba-ch5/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch3/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"}],"https://LorrinWWW.github.io/posts/proba-ch1/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/ML-CNN/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"machine learning","permalink":"https://LorrinWWW.github.io/posts/machine-learning/"}],"https://LorrinWWW.github.io/posts/EDP-basic-models/":[{"title":"EDP","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"},{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"}],"https://LorrinWWW.github.io/posts/machine-learning/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/datamining-class-pred/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-basic-matrix-review/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Sobolev space","permalink":"https://LorrinWWW.github.io/posts/Sobolev-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.29]A-convolution BiLSTM-neural-network-model-for-chinese-event-extraction/":[],"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/":[{"title":"OS notes","permalink":"https://LorrinWWW.github.io/posts/OS-notes/"}],"https://LorrinWWW.github.io/posts/projet-enjeu-plugin-chrome-101/":[{"title":"Chrome","permalink":"http://gubangzhong.cn/2017/06/13/Chrome/"}],"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/":[{"title":"MongoDB, Docker and Python","permalink":"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/MongoDB-Docker-and-Python/":[{"title":"Hands on Scrapy","permalink":"https://LorrinWWW.github.io/posts/Hands-on-Scrapy/"},{"title":"Python ","permalink":"http://www.davidfnck.com/python/python-tutorial-01-install.html/"}],"https://LorrinWWW.github.io/posts/OS-notes/":[{"title":"learning OS and building LorriOS","permalink":"https://LorrinWWW.github.io/posts/learning-OS-and-building-LorriOS/"}],"https://LorrinWWW.github.io/posts/Bayes-estimation/":[{"title":"Note of statistic","permalink":"https://LorrinWWW.github.io/posts/Note-of-statistic/"}],"https://LorrinWWW.github.io/posts/management-of-the-firm/":[],"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/":[{"title":"Event detection and co-reference with minimal supervision ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/[2018.4.14]Reinforcement-Learning-for-Relation-Classification-from-Noisy-Data/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":" Entity resolution","permalink":"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/"}],"https://LorrinWWW.github.io/posts/datamining-qualitative-induction/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/graph/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/EDP-finite-element-method/":[{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/QuadTree/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"}],"https://LorrinWWW.github.io/posts/proba-ch4/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/proba-ch2/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/[2018.1.21]Event-detection-and-co-referentce/":[{"title":"Event detection ","permalink":"https://LorrinWWW.github.io/posts/[2018.3.20]Event-detection/"},{"title":"A Neural Model for Joint Event Detection and Summarization ","permalink":"https://LorrinWWW.github.io/posts/[2018.4.4]A-Neural-Model-for-Joint-Event-Detection-and-Summarization/"}],"https://LorrinWWW.github.io/posts/Note-of-NLP/":[{"title":"Generative Adversarial Network","permalink":"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/"},{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"}],"https://LorrinWWW.github.io/posts/[2017.12.10]Entity-resolution/":[{"title":"Relation Classification via Attention Model ","permalink":"https://LorrinWWW.github.io/posts/[2017.12.17]Relation-Classification-via-Attention-Model/"},{"title":"Overcoming Limited Supervision in Relation Extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.4]Overcoming-Limited-Supervision-in-Relation-Extraction/"},{"title":" relation extraction ","permalink":"https://LorrinWWW.github.io/posts/[2018.1.14]Models-for-relation-extraction/"},{"title":"RNN","permalink":"http://gubangzhong.cn/2018/01/07/RNN/"}],"https://LorrinWWW.github.io/posts/Generative-Adversarial-Network/":[{"title":"Note of NLP","permalink":"https://LorrinWWW.github.io/posts/Note-of-NLP/"}],"https://LorrinWWW.github.io/posts/Note-of-datamining/":[{"title":"Note of knowledge graph","permalink":"https://LorrinWWW.github.io/posts/Note-of-knowledge-graph/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-class-pred/"},{"title":"-","permalink":"https://LorrinWWW.github.io/posts/datamining-pretreatment/"}],"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Note of learning Algo","permalink":"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/Note-of-probability/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}],"https://LorrinWWW.github.io/posts/participe-present-et-gerondif/":[],"https://LorrinWWW.github.io/posts/Hilbert-space/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":" Note of probability","permalink":"https://LorrinWWW.github.io/posts/Note-of-probability/"}],"https://LorrinWWW.github.io/posts/Note-of-learning-Algo/":[{"title":"ML CNN","permalink":"https://LorrinWWW.github.io/posts/ML-CNN/"},{"title":" Method of programming facing to exams","permalink":"https://LorrinWWW.github.io/posts/Method-of-programming-facing-to-exams/"},{"title":" compression","permalink":"https://LorrinWWW.github.io/posts/compression/"}],"https://LorrinWWW.github.io/posts/proba-ch6/":[{"title":"EDP finite element method","permalink":"https://LorrinWWW.github.io/posts/EDP-finite-element-method/"},{"title":"EDP basic models","permalink":"https://LorrinWWW.github.io/posts/EDP-basic-models/"},{"title":"Hilbert space","permalink":"https://LorrinWWW.github.io/posts/Hilbert-space/"}]}}},"excerpt":"","more":"<h1 id=\"Basics\"><a href=\"#Basics\" class=\"headerlink\" title=\"Basics\"></a>Basics</h1><h2 id=\"Create-New-Users\"><a href=\"#Create-New-Users\" class=\"headerlink\" title=\"Create New Users\"></a>Create New Users</h2><p>first login in the root account.</p>\n<p>to add a user:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">adduser [UserName]</span><br></pre></td></tr></table></figure>\n\n<p>if want it to have sudo privilege, then:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">usermod -aG sudo [UserName]</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Set-Up-SSH-Config\"><a href=\"#Set-Up-SSH-Config\" class=\"headerlink\" title=\"Set Up SSH Config\"></a>Set Up SSH Config</h2><p>add these to ~/.ssh/config</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host [ShortNameForTheVPS]</span><br><span class=\"line\">HostName [ItsIPOrDomain]</span><br><span class=\"line\">User [TheUserToLogin]</span><br><span class=\"line\">IdentitiesOnly yes</span><br></pre></td></tr></table></figure>\n\n<p>if you want to ssh via proxy, for MacOS users:</p>\n<figure class=\"highlight plaintext\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br><span class=\"line\">2</span><br><span class=\"line\">3</span><br><span class=\"line\">4</span><br><span class=\"line\">5</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">Host [ShortNameForTheVPS]</span><br><span class=\"line\">HostName [ItsIPOrDomain]</span><br><span class=\"line\">ProxyCommand nc -X 5 -x 127.0.0.1:1082 %h %p</span><br><span class=\"line\">User [TheUserToLogin]</span><br><span class=\"line\">IdentitiesOnly yes</span><br></pre></td></tr></table></figure>\n\n<p>-X 5 means using socks5; -x specify proxy server ip and port.</p>\n<p>then ssh-copy-id, so we dont have to type password every time we ssh:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh-copy-id [ShortNameForTheVPS]</span><br></pre></td></tr></table></figure>\n\n<p>As the result, we only need to type to login:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">ssh [ShortNameForTheVPS]</span><br></pre></td></tr></table></figure>\n\n<h2 id=\"Powerful-Vim\"><a href=\"#Powerful-Vim\" class=\"headerlink\" title=\"Powerful Vim\"></a>Powerful Vim</h2><p>Life is short, I use spf13.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl https://j.mp/spf13-vim3 -L &gt; spf13-vim.sh &amp;&amp; sh spf13-vim.sh</span><br></pre></td></tr></table></figure>\n\n<p>if every thing goes fine, it will usually take within 5 minnutes.</p>\n<h2 id=\"Powerful-Zsh\"><a href=\"#Powerful-Zsh\" class=\"headerlink\" title=\"Powerful Zsh\"></a>Powerful Zsh</h2><p>Bash is good but Zsh is better. For ubuntu users:</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install zsh</span><br></pre></td></tr></table></figure>\n\n<p>Again, life is short, I use oh-my-zsh.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sh -c <span class=\"string\">&quot;<span class=\"subst\">$(curl -fsSL https://raw.github.com/ohmyzsh/ohmyzsh/master/tools/install.sh)</span>&quot;</span></span><br></pre></td></tr></table></figure>\n\n<p>it is installed instantly.</p>\n<h1 id=\"Network-Related\"><a href=\"#Network-Related\" class=\"headerlink\" title=\"Network Related\"></a>Network Related</h1><p>Usually it is suggested to expose ports as few as possible, and only preserve 80(HTTP) and 443(HTTPS).</p>\n<p>We can use nginx/caddy/ to do HTTP(S) reverse proxy.</p>\n<h2 id=\"Caddy\"><a href=\"#Caddy\" class=\"headerlink\" title=\"Caddy\"></a>Caddy</h2><p>install go</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">sudo apt install golang</span><br></pre></td></tr></table></figure>\n\n<p>install caddy. we choose caddy 1 here.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">curl https://getcaddy.com | bash -s personal</span><br></pre></td></tr></table></figure>\n\n<p>run caddy, and it should run as a simple server on port 2015. it should return 404 when visit.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">caddy</span><br></pre></td></tr></table></figure>\n\n<p>to run caddy as server, follow instructions <a href=\"https://github.com/caddyserver/caddy/tree/master/dist/init/linux-systemd\">here</a>.</p>\n<p>to use CloudFlare CDN, follow instuctions <a href=\"https://melty.land/blog/caddy-and-cloudflare\">here(chinese)</a></p>\n<h1 id=\"Scientific-Purpose\"><a href=\"#Scientific-Purpose\" class=\"headerlink\" title=\"Scientific Purpose\"></a>Scientific Purpose</h1><p>e.g. interactive demo.</p>\n<h2 id=\"Python-Environment\"><a href=\"#Python-Environment\" class=\"headerlink\" title=\"Python Environment\"></a>Python Environment</h2><p>download anaconda, the latest address can be found <a href=\"https://www.anaconda.com/distribution/\">here</a>.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">wget https://repo.anaconda.com/archive/Anaconda3-2019.10-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>\n\n<p>install it.</p>\n<figure class=\"highlight bash\"><table><tr><td class=\"gutter\"><pre><span class=\"line\">1</span><br></pre></td><td class=\"code\"><pre><span class=\"line\">bash Anaconda3-2019.10-Linux-x86_64.sh</span><br></pre></td></tr></table></figure>\n\n<p>if use zsh, the install script wont add initialization script to .zshrc, so we need to copy from .bashrc</p>\n<p>re-login, so the initialization script will work.</p>\n<p>install pytorch will be another long story, so we wont go in deep here.</p>\n"}],"PostAsset":[],"PostCategory":[{"post_id":"ckw4qufom0001gwtl4ehk83to","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufoz000ggwtl7el8ec12"},{"post_id":"ckw4qufox000dgwtldq2v1h0p","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufp2000lgwtlhutybxnv"},{"post_id":"ckw4qufop0003gwtl3dk5e0gb","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufp4000qgwtl4q9c2ohm"},{"post_id":"ckw4qufot0007gwtldi2mbss0","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufp5000sgwtl7vlpfr2y"},{"post_id":"ckw4qufou0009gwtlab327nnk","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufp8000ygwtl2tnvfwgs"},{"post_id":"ckw4qufou0009gwtlab327nnk","category_id":"ckw4qufp2000mgwtl0radcg7s","_id":"ckw4qufp90013gwtl71ff0src"},{"post_id":"ckw4qufov000agwtleg6gd9g5","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpa0016gwtlestb0zkj"},{"post_id":"ckw4qufp7000xgwtl0rnhe8o8","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpb0019gwtleaz0dzhv"},{"post_id":"ckw4qufp80011gwtl9j3b7d15","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpc001dgwtl9067337k"},{"post_id":"ckw4qufoy000egwtlcr1j4206","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpe001hgwtl0gcu24m1"},{"post_id":"ckw4qufp90014gwtlg8dt7wef","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufpe001lgwtla5izgkx9"},{"post_id":"ckw4qufpa0017gwtl2o49btu3","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufph001pgwtlb1jj904m"},{"post_id":"ckw4qufpa0017gwtl2o49btu3","category_id":"ckw4qufp2000mgwtl0radcg7s","_id":"ckw4qufpi001tgwtl8lw1duge"},{"post_id":"ckw4qufpd001fgwtlc4g6f3la","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpm001wgwtlea3t86sm"},{"post_id":"ckw4qufp2000kgwtl01ad8zyn","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpn0020gwtl5a9p02v2"},{"post_id":"ckw4qufpe001jgwtl4fjl5y7q","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufpo0022gwtlhxudbxeg"},{"post_id":"ckw4qufpe001jgwtl4fjl5y7q","category_id":"ckw4qufp2000mgwtl0radcg7s","_id":"ckw4qufpp0025gwtle6aq5914"},{"post_id":"ckw4qufp3000pgwtl2fv8cajr","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpq0028gwtl0b5b4qhc"},{"post_id":"ckw4qufp4000rgwtlg65o8sme","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpr002bgwtl0dppb4e4"},{"post_id":"ckw4qufp6000vgwtl7kika36r","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufps002egwtldb2j3qbs"},{"post_id":"ckw4qufp6000vgwtl7kika36r","category_id":"ckw4qufpn001zgwtlf76efbqh","_id":"ckw4qufpt002hgwtlhrv10rf3"},{"post_id":"ckw4qufp0000igwtlg2ur61jm","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpu002lgwtl7oikbi2i"},{"post_id":"ckw4qufp0000igwtlg2ur61jm","category_id":"ckw4qufpn001zgwtlf76efbqh","_id":"ckw4qufpv002ogwtlg58a883u"},{"post_id":"ckw4qufpc001bgwtl809wau5y","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufpw002tgwtl8rl4cgkm"},{"post_id":"ckw4qufpc001bgwtl809wau5y","category_id":"ckw4qufpn001zgwtlf76efbqh","_id":"ckw4qufpx002wgwtlg1qa7nst"},{"post_id":"ckw4qufpu002mgwtl1ggb971o","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufpy0030gwtl606a5vw4"},{"post_id":"ckw4qufpf001ngwtlek9x1j7n","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufpz0032gwtl10h4erod"},{"post_id":"ckw4qufpv002qgwtl5hcyhnfp","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufq00036gwtlh0d6200d"},{"post_id":"ckw4qufpw002ugwtl2aagaeeh","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufq10039gwtld3l6faxm"},{"post_id":"ckw4qufph001qgwtldfrq166l","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufq2003egwtle2ja9696"},{"post_id":"ckw4qufpx002ygwtlfb0shkrr","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufq3003hgwtl7ulcca8h"},{"post_id":"ckw4qufpi001ugwtlfxsu6m4s","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufq7003lgwtlex260sb2"},{"post_id":"ckw4qufpz0034gwtl8swk33xy","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufq8003ogwtl5zto17bb"},{"post_id":"ckw4qufq10038gwtle9ta0x74","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufq9003sgwtl3i751eo2"},{"post_id":"ckw4qufpm001ygwtl9ur9czfz","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqa003vgwtla9zifiu3"},{"post_id":"ckw4qufq1003bgwtlfgnpfpxn","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufqb003ygwtleb9eg1bd"},{"post_id":"ckw4qufq3003ggwtl84r119e1","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufqc0041gwtl17vg938s"},{"post_id":"ckw4qufpn0021gwtl3zwebh66","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqd0044gwtlhbj62tig"},{"post_id":"ckw4qufq3003igwtl5rl03yxp","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufqe0048gwtle1owakv6"},{"post_id":"ckw4qufq7003mgwtldit7eklh","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufqf004bgwtl32h47jdz"},{"post_id":"ckw4qufpo0024gwtlezik90yy","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqg004egwtl78zzd4rd"},{"post_id":"ckw4qufqa003ugwtldlh2fq72","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqh004igwtl7ak1gvi7"},{"post_id":"ckw4qufpp0027gwtl4fief2tn","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqi004mgwtld9ovft1e"},{"post_id":"ckw4qufqa003wgwtl8s2d3e71","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufqk004qgwtl7l5h1h2j"},{"post_id":"ckw4qufqa003wgwtl8s2d3e71","category_id":"ckw4qufpn001zgwtlf76efbqh","_id":"ckw4qufql004ugwtlg7s64jm7"},{"post_id":"ckw4qufpq0029gwtlb95sfef3","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqm004ygwtl10nv6ozh"},{"post_id":"ckw4qufqc0040gwtlcxv3hxw6","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufqn0051gwtlce8729qy"},{"post_id":"ckw4qufqc0040gwtlcxv3hxw6","category_id":"ckw4qufpn001zgwtlf76efbqh","_id":"ckw4qufqq0055gwtld10n5fim"},{"post_id":"ckw4qufpr002dgwtl3nxy0i7w","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqr0056gwtl8j1i638s"},{"post_id":"ckw4qufqe0049gwtlhlxk2arj","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufqr0058gwtl4qol2g0u"},{"post_id":"ckw4qufqf004cgwtl34hx7wsh","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufqr0059gwtl2x82cels"},{"post_id":"ckw4qufps002fgwtl1uppb39d","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqr005bgwtlb6u1en1j"},{"post_id":"ckw4qufqh004fgwtl3ik43tc5","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufqr005cgwtl4yf23wyn"},{"post_id":"ckw4qufqi004jgwtl1whs0az0","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufqs005egwtl74aeej4n"},{"post_id":"ckw4qufpt002jgwtl6mih547q","category_id":"ckw4qufpt002igwtl4r5aa33y","_id":"ckw4qufqs005ggwtl4b438cfz"},{"post_id":"ckw4qufqj004ngwtl69iddlyd","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufqs005jgwtl3obz51ps"},{"post_id":"ckw4qufqk004rgwtlgijj1k8k","category_id":"ckw4qufor0004gwtldwdudn8l","_id":"ckw4qufqt005lgwtl8b18g9w2"},{"post_id":"ckw4qufq8003pgwtldso8fm3u","category_id":"ckw4qufqj004ogwtlejyf8alu","_id":"ckw4qufqt005ogwtlb39yd0ii"},{"post_id":"ckw4qufql004vgwtl2fyf5s0m","category_id":"ckw4qufp5000tgwtl6ywt3c4w","_id":"ckw4qufqt005pgwtlh04743xl"},{"post_id":"ckw4qufqm004zgwtlg4182z10","category_id":"ckw4qufqj004ogwtlejyf8alu","_id":"ckw4qufqt005rgwtla1bn025c"},{"post_id":"ckw4qufqc0042gwtlfhf76k0h","category_id":"ckw4qufqj004ogwtlejyf8alu","_id":"ckw4qufqt005tgwtl9huw3gjr"},{"post_id":"ckw4qufqp0053gwtl5crh54nc","category_id":"ckw4qufqj004ogwtlejyf8alu","_id":"ckw4qufqu005vgwtl0tb76ibb"},{"post_id":"ckw4qufqd0046gwtl0t66d1fb","category_id":"ckw4qufqq0054gwtl0f4z5t7h","_id":"ckw4qufqu005ygwtla1eid0ts"}],"PostTag":[{"post_id":"ckw4qufom0001gwtl4ehk83to","tag_id":"ckw4qufos0005gwtlay367zy2","_id":"ckw4qufp1000jgwtle2x7hrvj"},{"post_id":"ckw4qufom0001gwtl4ehk83to","tag_id":"ckw4qufow000cgwtl78jdaw7h","_id":"ckw4qufp2000ngwtl7f80fl9d"},{"post_id":"ckw4qufop0003gwtl3dk5e0gb","tag_id":"ckw4qufoz000hgwtladbd29db","_id":"ckw4qufp7000wgwtl9oy6cdtd"},{"post_id":"ckw4qufop0003gwtl3dk5e0gb","tag_id":"ckw4qufp3000ogwtl4wno0fr5","_id":"ckw4qufp80010gwtlbks65pd0"},{"post_id":"ckw4qufot0007gwtldi2mbss0","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufpc001agwtlbm8b6jla"},{"post_id":"ckw4qufot0007gwtldi2mbss0","tag_id":"ckw4qufoz000hgwtladbd29db","_id":"ckw4qufpd001egwtlb0bgey8p"},{"post_id":"ckw4qufpa0017gwtl2o49btu3","tag_id":"ckw4qufow000cgwtl78jdaw7h","_id":"ckw4qufpe001igwtlbeo45xx9"},{"post_id":"ckw4qufpa0017gwtl2o49btu3","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufpf001mgwtl3zsadegj"},{"post_id":"ckw4qufou0009gwtlab327nnk","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufpi001rgwtlcdqaho89"},{"post_id":"ckw4qufou0009gwtlab327nnk","tag_id":"ckw4qufpd001ggwtl17bbbsh6","_id":"ckw4qufpl001vgwtlf6yx5wpi"},{"post_id":"ckw4qufov000agwtleg6gd9g5","tag_id":"ckw4qufpf001ogwtl6llwh6ul","_id":"ckw4qufpu002kgwtla96hd0qj"},{"post_id":"ckw4qufov000agwtleg6gd9g5","tag_id":"ckw4qufpm001xgwtlfvsdd6rw","_id":"ckw4qufpv002ngwtlfl270wnx"},{"post_id":"ckw4qufov000agwtleg6gd9g5","tag_id":"ckw4qufpo0023gwtl7yn08xnj","_id":"ckw4qufpw002sgwtla37f7ta6"},{"post_id":"ckw4qufov000agwtleg6gd9g5","tag_id":"ckw4qufpr002agwtl809ldyee","_id":"ckw4qufpx002vgwtlcfjj46ux"},{"post_id":"ckw4qufox000dgwtldq2v1h0p","tag_id":"ckw4qufpt002ggwtlgvx77lg6","_id":"ckw4qufq00037gwtlgu8uar7w"},{"post_id":"ckw4qufox000dgwtldq2v1h0p","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufq1003agwtl3womhkkx"},{"post_id":"ckw4qufox000dgwtldq2v1h0p","tag_id":"ckw4qufpx002xgwtl6wts79f8","_id":"ckw4qufq2003fgwtl5vey9ge3"},{"post_id":"ckw4qufoy000egwtlcr1j4206","tag_id":"ckw4qufpz0033gwtlb6c01n88","_id":"ckw4qufq8003ngwtl6sae1px6"},{"post_id":"ckw4qufoy000egwtlcr1j4206","tag_id":"ckw4qufq2003dgwtlb0scc2ss","_id":"ckw4qufq9003rgwtl8dfs6r8g"},{"post_id":"ckw4qufqc0040gwtlcxv3hxw6","tag_id":"ckw4qufq4003kgwtl2xhq1q32","_id":"ckw4qufqd0045gwtle07yc085"},{"post_id":"ckw4qufp0000igwtlg2ur61jm","tag_id":"ckw4qufq4003kgwtl2xhq1q32","_id":"ckw4qufqh004hgwtl68155dhl"},{"post_id":"ckw4qufp0000igwtlg2ur61jm","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufqi004kgwtlfn7f43bz"},{"post_id":"ckw4qufp0000igwtlg2ur61jm","tag_id":"ckw4qufqb003zgwtl9kdj3chy","_id":"ckw4qufqj004pgwtl258xdtbw"},{"post_id":"ckw4qufp0000igwtlg2ur61jm","tag_id":"ckw4qufqe0047gwtl42ptggfv","_id":"ckw4qufqk004sgwtl71ychyoc"},{"post_id":"ckw4qufp2000kgwtl01ad8zyn","tag_id":"ckw4qufqb003zgwtl9kdj3chy","_id":"ckw4qufqm004wgwtlcz1b6abj"},{"post_id":"ckw4qufp2000kgwtl01ad8zyn","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufqn0050gwtlf2y7djny"},{"post_id":"ckw4qufp3000pgwtl2fv8cajr","tag_id":"ckw4qufqk004tgwtl9vcfe3a0","_id":"ckw4qufqs005fgwtl6mla6gfm"},{"post_id":"ckw4qufp3000pgwtl2fv8cajr","tag_id":"ckw4qufqn0052gwtlgk31blmp","_id":"ckw4qufqs005hgwtl5lnncijw"},{"post_id":"ckw4qufp3000pgwtl2fv8cajr","tag_id":"ckw4qufqr0057gwtl0xrpgerg","_id":"ckw4qufqs005kgwtl5kyj1v4g"},{"post_id":"ckw4qufp3000pgwtl2fv8cajr","tag_id":"ckw4qufpm001xgwtlfvsdd6rw","_id":"ckw4qufqt005mgwtl9wrggo4c"},{"post_id":"ckw4qufp4000rgwtlg65o8sme","tag_id":"ckw4qufqs005dgwtlbupwc4nw","_id":"ckw4qufqt005sgwtl97mpcjfe"},{"post_id":"ckw4qufp4000rgwtlg65o8sme","tag_id":"ckw4qufq4003kgwtl2xhq1q32","_id":"ckw4qufqt005ugwtl4yvj09s4"},{"post_id":"ckw4qufp4000rgwtlg65o8sme","tag_id":"ckw4qufq2003dgwtlb0scc2ss","_id":"ckw4qufqu005xgwtl5fga9hti"},{"post_id":"ckw4qufp6000vgwtl7kika36r","tag_id":"ckw4qufqt005qgwtl96ktd0qf","_id":"ckw4qufqu005zgwtlducwazrq"},{"post_id":"ckw4qufp7000xgwtl0rnhe8o8","tag_id":"ckw4qufqu005wgwtleerbfs64","_id":"ckw4qufqv0063gwtl4xbvdgzi"},{"post_id":"ckw4qufp7000xgwtl0rnhe8o8","tag_id":"ckw4qufq4003kgwtl2xhq1q32","_id":"ckw4qufqv0064gwtldbzgeaw6"},{"post_id":"ckw4qufp7000xgwtl0rnhe8o8","tag_id":"ckw4qufqt005qgwtl96ktd0qf","_id":"ckw4qufqv0066gwtl9z1vcl25"},{"post_id":"ckw4qufp80011gwtl9j3b7d15","tag_id":"ckw4qufqb003zgwtl9kdj3chy","_id":"ckw4qufqw0068gwtl4wh4dnpn"},{"post_id":"ckw4qufp80011gwtl9j3b7d15","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufqw0069gwtl9v5xcgta"},{"post_id":"ckw4qufp90014gwtlg8dt7wef","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufqw006bgwtl8wgd8ktn"},{"post_id":"ckw4qufp90014gwtlg8dt7wef","tag_id":"ckw4qufqv0067gwtl8ky8ctym","_id":"ckw4qufqw006cgwtl7lku4mah"},{"post_id":"ckw4qufpc001bgwtl809wau5y","tag_id":"ckw4qufqw006agwtl2hqlbnfg","_id":"ckw4qufqw006egwtl2uyccvh3"},{"post_id":"ckw4qufpd001fgwtlc4g6f3la","tag_id":"ckw4qufqb003zgwtl9kdj3chy","_id":"ckw4qufqx006hgwtlbc9zhq18"},{"post_id":"ckw4qufpd001fgwtlc4g6f3la","tag_id":"ckw4qufqw006fgwtlfkjk4o9m","_id":"ckw4qufqx006igwtl8hnoclr3"},{"post_id":"ckw4qufpe001jgwtl4fjl5y7q","tag_id":"ckw4qufqx006ggwtlelps9xrq","_id":"ckw4qufqx006lgwtl8sznhxxd"},{"post_id":"ckw4qufpe001jgwtl4fjl5y7q","tag_id":"ckw4qufpx002xgwtl6wts79f8","_id":"ckw4qufqx006mgwtl8pu82zna"},{"post_id":"ckw4qufpe001jgwtl4fjl5y7q","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufqy006ogwtlfnvl8op6"},{"post_id":"ckw4qufpe001jgwtl4fjl5y7q","tag_id":"ckw4qufoz000hgwtladbd29db","_id":"ckw4qufqy006pgwtld3uheqk6"},{"post_id":"ckw4qufpf001ngwtlek9x1j7n","tag_id":"ckw4qufqx006kgwtlamww4ut7","_id":"ckw4qufqz006ugwtl5iqf4myj"},{"post_id":"ckw4qufpf001ngwtlek9x1j7n","tag_id":"ckw4qufqy006ngwtlgoqr8nef","_id":"ckw4qufqz006vgwtlg3vkf15t"},{"post_id":"ckw4qufpf001ngwtlek9x1j7n","tag_id":"ckw4qufqy006qgwtla8bhcj4b","_id":"ckw4qufr0006xgwtlh50g2qsd"},{"post_id":"ckw4qufpf001ngwtlek9x1j7n","tag_id":"ckw4qufqy006rgwtl5bhweofz","_id":"ckw4qufr0006ygwtl8fyucrvv"},{"post_id":"ckw4qufpf001ngwtlek9x1j7n","tag_id":"ckw4qufqy006sgwtlh7it7du6","_id":"ckw4qufr10070gwtlaq973ia8"},{"post_id":"ckw4qufph001qgwtldfrq166l","tag_id":"ckw4qufqy006qgwtla8bhcj4b","_id":"ckw4qufr10071gwtlezf7hyl6"},{"post_id":"ckw4qufph001qgwtldfrq166l","tag_id":"ckw4qufqz006wgwtlahaagyw9","_id":"ckw4qufr10073gwtld36ign60"},{"post_id":"ckw4qufpi001ugwtlfxsu6m4s","tag_id":"ckw4qufr1006zgwtleaty1ja3","_id":"ckw4qufr20076gwtl15fp2z6r"},{"post_id":"ckw4qufpi001ugwtlfxsu6m4s","tag_id":"ckw4qufr10072gwtlazka3t5f","_id":"ckw4qufr20077gwtl9rgs4gpk"},{"post_id":"ckw4qufpi001ugwtlfxsu6m4s","tag_id":"ckw4qufqy006qgwtla8bhcj4b","_id":"ckw4qufr20079gwtl8u9t8o3m"},{"post_id":"ckw4qufpm001ygwtl9ur9czfz","tag_id":"ckw4qufr20075gwtlcb7ecevi","_id":"ckw4qufr3007bgwtl75tp0ghl"},{"post_id":"ckw4qufpm001ygwtl9ur9czfz","tag_id":"ckw4qufr20078gwtl10u3g04z","_id":"ckw4qufr3007cgwtlfltsb0p9"},{"post_id":"ckw4qufpn0021gwtl3zwebh66","tag_id":"ckw4qufr2007agwtl4mmggk72","_id":"ckw4qufr4007ggwtlhok12092"},{"post_id":"ckw4qufpn0021gwtl3zwebh66","tag_id":"ckw4qufr3007dgwtle4oz7slw","_id":"ckw4qufr4007hgwtlfivdfqx9"},{"post_id":"ckw4qufpn0021gwtl3zwebh66","tag_id":"ckw4qufr3007egwtl6216fyl4","_id":"ckw4qufr4007jgwtl3al5ek06"},{"post_id":"ckw4qufpo0024gwtlezik90yy","tag_id":"ckw4qufqy006qgwtla8bhcj4b","_id":"ckw4qufr4007mgwtl1f9d8mfs"},{"post_id":"ckw4qufpo0024gwtlezik90yy","tag_id":"ckw4qufr4007igwtl3x2uh3e2","_id":"ckw4qufr5007ngwtl6ua2b6a0"},{"post_id":"ckw4qufpo0024gwtlezik90yy","tag_id":"ckw4qufr4007kgwtlfwe1csr0","_id":"ckw4qufr5007pgwtl58ksae3h"},{"post_id":"ckw4qufpp0027gwtl4fief2tn","tag_id":"ckw4qufr4007lgwtla60aaaqr","_id":"ckw4qufr6007sgwtlee6yg74n"},{"post_id":"ckw4qufpp0027gwtl4fief2tn","tag_id":"ckw4qufqe0047gwtl42ptggfv","_id":"ckw4qufr6007tgwtlcdww0a5p"},{"post_id":"ckw4qufpp0027gwtl4fief2tn","tag_id":"ckw4qufqu005wgwtleerbfs64","_id":"ckw4qufr6007vgwtlaxl0hoqn"},{"post_id":"ckw4qufpq0029gwtlb95sfef3","tag_id":"ckw4qufqy006rgwtl5bhweofz","_id":"ckw4qufr6007xgwtld6sf9qtd"},{"post_id":"ckw4qufpq0029gwtlb95sfef3","tag_id":"ckw4qufqy006sgwtlh7it7du6","_id":"ckw4qufr6007ygwtl9yupf5ze"},{"post_id":"ckw4qufpr002dgwtl3nxy0i7w","tag_id":"ckw4qufr4007lgwtla60aaaqr","_id":"ckw4qufr70081gwtl3ejugxxf"},{"post_id":"ckw4qufpr002dgwtl3nxy0i7w","tag_id":"ckw4qufqu005wgwtleerbfs64","_id":"ckw4qufr70082gwtl8dzw9moa"},{"post_id":"ckw4qufps002fgwtl1uppb39d","tag_id":"ckw4qufr20075gwtlcb7ecevi","_id":"ckw4qufr70085gwtlfh2uecd0"},{"post_id":"ckw4qufps002fgwtl1uppb39d","tag_id":"ckw4qufr70083gwtl2coo77sh","_id":"ckw4qufr70086gwtl2a549a4d"},{"post_id":"ckw4qufpt002jgwtl6mih547q","tag_id":"ckw4qufr1006zgwtleaty1ja3","_id":"ckw4qufr8008agwtl7b7p2veh"},{"post_id":"ckw4qufpt002jgwtl6mih547q","tag_id":"ckw4qufqy006qgwtla8bhcj4b","_id":"ckw4qufr8008bgwtl3j1qgl3f"},{"post_id":"ckw4qufpt002jgwtl6mih547q","tag_id":"ckw4qufr80088gwtl9eoa50pt","_id":"ckw4qufr8008dgwtl2o1l7ucn"},{"post_id":"ckw4qufpu002mgwtl1ggb971o","tag_id":"ckw4qufr20075gwtlcb7ecevi","_id":"ckw4qufr9008fgwtl6w7906gk"},{"post_id":"ckw4qufpu002mgwtl1ggb971o","tag_id":"ckw4qufr8008cgwtlaw9lfdkt","_id":"ckw4qufr9008ggwtlcl7f2qvc"},{"post_id":"ckw4qufpv002qgwtl5hcyhnfp","tag_id":"ckw4qufr70083gwtl2coo77sh","_id":"ckw4qufra008kgwtl275mav8y"},{"post_id":"ckw4qufpv002qgwtl5hcyhnfp","tag_id":"ckw4qufr9008hgwtl0xq75ksk","_id":"ckw4qufra008lgwtl11gcfkdq"},{"post_id":"ckw4qufpv002qgwtl5hcyhnfp","tag_id":"ckw4qufqu005wgwtleerbfs64","_id":"ckw4qufra008ngwtl7lbc9m30"},{"post_id":"ckw4qufpw002ugwtl2aagaeeh","tag_id":"ckw4qufr70083gwtl2coo77sh","_id":"ckw4qufra008pgwtl5qgv7l3d"},{"post_id":"ckw4qufpw002ugwtl2aagaeeh","tag_id":"ckw4qufra008mgwtlhrfsam25","_id":"ckw4qufrb008qgwtl5999hz1x"},{"post_id":"ckw4qufpx002ygwtlfb0shkrr","tag_id":"ckw4qufra008ogwtlg6nq85d8","_id":"ckw4qufrb008tgwtl2geb6sif"},{"post_id":"ckw4qufpx002ygwtlfb0shkrr","tag_id":"ckw4qufqs005dgwtlbupwc4nw","_id":"ckw4qufrb008ugwtlgkmd27cy"},{"post_id":"ckw4qufpz0034gwtl8swk33xy","tag_id":"ckw4qufqb003zgwtl9kdj3chy","_id":"ckw4qufrc008ygwtlcqeg8pvh"},{"post_id":"ckw4qufpz0034gwtl8swk33xy","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufrc008zgwtl4ftgai29"},{"post_id":"ckw4qufpz0034gwtl8swk33xy","tag_id":"ckw4qufrb008wgwtleawtfqdr","_id":"ckw4qufrc0091gwtl34ix1jm3"},{"post_id":"ckw4qufq10038gwtle9ta0x74","tag_id":"ckw4qufqb003zgwtl9kdj3chy","_id":"ckw4qufrd0094gwtlebtufgim"},{"post_id":"ckw4qufq10038gwtle9ta0x74","tag_id":"ckw4qufrc0090gwtl2e4lgg7e","_id":"ckw4qufrd0095gwtl1raybmmq"},{"post_id":"ckw4qufq10038gwtle9ta0x74","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufrd0097gwtlexwz59dk"},{"post_id":"ckw4qufq1003bgwtlfgnpfpxn","tag_id":"ckw4qufqt005qgwtl96ktd0qf","_id":"ckw4qufre009bgwtl0c06ar1j"},{"post_id":"ckw4qufq1003bgwtlfgnpfpxn","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufre009cgwtle7l96uzi"},{"post_id":"ckw4qufq1003bgwtlfgnpfpxn","tag_id":"ckw4qufrd0098gwtlf4fy9xm5","_id":"ckw4qufre009egwtla2vddi9e"},{"post_id":"ckw4qufq1003bgwtlfgnpfpxn","tag_id":"ckw4qufre0099gwtldqai8mu3","_id":"ckw4qufre009fgwtl8mbfhbp3"},{"post_id":"ckw4qufq3003ggwtl84r119e1","tag_id":"ckw4qufqt005qgwtl96ktd0qf","_id":"ckw4qufrg009hgwtl423k9j76"},{"post_id":"ckw4qufq3003ggwtl84r119e1","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufrg009igwtl3lpq8m8j"},{"post_id":"ckw4qufq3003igwtl5rl03yxp","tag_id":"ckw4qufqt005qgwtl96ktd0qf","_id":"ckw4qufrh009mgwtlal95c0vp"},{"post_id":"ckw4qufq3003igwtl5rl03yxp","tag_id":"ckw4qufrg009jgwtlbfpt2enm","_id":"ckw4qufrh009ngwtl1see0ww4"},{"post_id":"ckw4qufq3003igwtl5rl03yxp","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufri009pgwtlg3cmcodc"},{"post_id":"ckw4qufq7003mgwtldit7eklh","tag_id":"ckw4qufrh009lgwtlf9zi1l9s","_id":"ckw4qufrj009sgwtl1hgj01q1"},{"post_id":"ckw4qufq7003mgwtldit7eklh","tag_id":"ckw4qufqb003zgwtl9kdj3chy","_id":"ckw4qufrj009tgwtlcbzn7ndj"},{"post_id":"ckw4qufq7003mgwtldit7eklh","tag_id":"ckw4qufq9003tgwtl25z0hfyj","_id":"ckw4qufrj009vgwtl2em15yi9"},{"post_id":"ckw4qufq8003pgwtldso8fm3u","tag_id":"ckw4qufri009rgwtl1nh08i1n","_id":"ckw4qufrk009zgwtldcnpb47d"},{"post_id":"ckw4qufq8003pgwtldso8fm3u","tag_id":"ckw4qufrj009ugwtl54s44vev","_id":"ckw4qufrk00a0gwtl5oczf5h9"},{"post_id":"ckw4qufq8003pgwtldso8fm3u","tag_id":"ckw4qufrj009wgwtl3gm3dlla","_id":"ckw4qufrk00a2gwtl0ho38xvo"},{"post_id":"ckw4qufq8003pgwtldso8fm3u","tag_id":"ckw4qufrj009xgwtlcwxf4ov8","_id":"ckw4qufrk00a3gwtlelvsb2gu"},{"post_id":"ckw4qufqa003ugwtldlh2fq72","tag_id":"ckw4qufqu005wgwtleerbfs64","_id":"ckw4qufrl00a5gwtl2ce3bxoj"},{"post_id":"ckw4qufqa003ugwtldlh2fq72","tag_id":"ckw4qufrk00a1gwtl3hqhg8jg","_id":"ckw4qufrl00a6gwtl07a2eb9s"},{"post_id":"ckw4qufqa003ugwtldlh2fq72","tag_id":"ckw4qufq2003dgwtlb0scc2ss","_id":"ckw4qufrl00a8gwtl0qjnhj5w"},{"post_id":"ckw4qufqa003ugwtldlh2fq72","tag_id":"ckw4qufq4003kgwtl2xhq1q32","_id":"ckw4qufrl00a9gwtlgsw756ti"},{"post_id":"ckw4qufqa003wgwtl8s2d3e71","tag_id":"ckw4qufqw006agwtl2hqlbnfg","_id":"ckw4qufrl00abgwtl8aewg26a"},{"post_id":"ckw4qufqa003wgwtl8s2d3e71","tag_id":"ckw4qufrl00a7gwtl2mfuh5ko","_id":"ckw4qufrl00acgwtl055m0xtt"},{"post_id":"ckw4qufqc0042gwtlfhf76k0h","tag_id":"ckw4qufrl00aagwtlcqe6giyt","_id":"ckw4qufrm00afgwtlav7gbw0z"},{"post_id":"ckw4qufqc0042gwtlfhf76k0h","tag_id":"ckw4qufrl00adgwtl0kcgakna","_id":"ckw4qufrm00aggwtl256dcw7m"},{"post_id":"ckw4qufqd0046gwtl0t66d1fb","tag_id":"ckw4qufrm00aegwtl2pxhcric","_id":"ckw4qufrm00ajgwtl0sodgwvr"},{"post_id":"ckw4qufqd0046gwtl0t66d1fb","tag_id":"ckw4qufrm00ahgwtl1ij0h0np","_id":"ckw4qufrm00akgwtl2xai4ery"},{"post_id":"ckw4qufqe0049gwtlhlxk2arj","tag_id":"ckw4qufqv0067gwtl8ky8ctym","_id":"ckw4qufrn00amgwtlhbj0fkq0"},{"post_id":"ckw4qufqe0049gwtlhlxk2arj","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufrn00angwtl5wdc3k7j"},{"post_id":"ckw4qufqf004cgwtl34hx7wsh","tag_id":"ckw4qufqv0067gwtl8ky8ctym","_id":"ckw4qufrn00aqgwtlf121bf9w"},{"post_id":"ckw4qufqf004cgwtl34hx7wsh","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufrn00argwtl5pyvfjus"},{"post_id":"ckw4qufqf004cgwtl34hx7wsh","tag_id":"ckw4qufrn00aogwtl2dw1ebq7","_id":"ckw4qufro00atgwtlhvnbhrjj"},{"post_id":"ckw4qufqh004fgwtl3ik43tc5","tag_id":"ckw4qufqv0067gwtl8ky8ctym","_id":"ckw4qufro00augwtl5vsp7fpv"},{"post_id":"ckw4qufqh004fgwtl3ik43tc5","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufro00awgwtlbsrl2iom"},{"post_id":"ckw4qufqi004jgwtl1whs0az0","tag_id":"ckw4qufqv0067gwtl8ky8ctym","_id":"ckw4qufro00aygwtlcj1u83rh"},{"post_id":"ckw4qufqi004jgwtl1whs0az0","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufro00azgwtldwnf37ar"},{"post_id":"ckw4qufqi004jgwtl1whs0az0","tag_id":"ckw4qufro00avgwtl3fkqd7s7","_id":"ckw4qufrp00b1gwtlcap636ty"},{"post_id":"ckw4qufqj004ngwtl69iddlyd","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufrp00b2gwtl1c817o1b"},{"post_id":"ckw4qufqj004ngwtl69iddlyd","tag_id":"ckw4qufqv0067gwtl8ky8ctym","_id":"ckw4qufrp00b4gwtl50qi4ziq"},{"post_id":"ckw4qufqk004rgwtlgijj1k8k","tag_id":"ckw4qufp6000ugwtlcfuj7k5r","_id":"ckw4qufrp00b5gwtlaq6a70lk"},{"post_id":"ckw4qufqk004rgwtlgijj1k8k","tag_id":"ckw4qufqv0067gwtl8ky8ctym","_id":"ckw4qufrq00b7gwtl3hgo4w9g"},{"post_id":"ckw4qufql004vgwtl2fyf5s0m","tag_id":"ckw4qufrp00b3gwtld7jtf556","_id":"ckw4qufrq00b9gwtlbkhu4nim"},{"post_id":"ckw4qufql004vgwtl2fyf5s0m","tag_id":"ckw4qufrp00b6gwtl8bd1cveu","_id":"ckw4qufrq00bagwtlfbq9docm"},{"post_id":"ckw4qufqm004zgwtlg4182z10","tag_id":"ckw4qufri009rgwtl1nh08i1n","_id":"ckw4qufrq00bdgwtl8wix6x79"},{"post_id":"ckw4qufqm004zgwtlg4182z10","tag_id":"ckw4qufrq00bbgwtl3q933e1g","_id":"ckw4qufrr00begwtla3gq3n4d"},{"post_id":"ckw4qufqp0053gwtl5crh54nc","tag_id":"ckw4qufrq00bcgwtl66wsgsew","_id":"ckw4qufrr00bfgwtlernte4u7"}],"Tag":[{"name":"Bayes","_id":"ckw4qufos0005gwtlay367zy2"},{"name":"statistic","_id":"ckw4qufow000cgwtl78jdaw7h"},{"name":"EDP","_id":"ckw4qufoz000hgwtladbd29db"},{"name":"matrix","_id":"ckw4qufp3000ogwtl4wno0fr5"},{"name":"math","_id":"ckw4qufp6000ugwtlcfuj7k5r"},{"name":"FEM","_id":"ckw4qufpd001ggwtl17bbbsh6"},{"name":"scrapy","_id":"ckw4qufpf001ogwtl6llwh6ul"},{"name":"python","_id":"ckw4qufpm001xgwtlfvsdd6rw"},{"name":"spider","_id":"ckw4qufpo0023gwtl7yn08xnj"},{"name":"crawl","_id":"ckw4qufpr002agwtl809ldyee"},{"name":"Hilbert","_id":"ckw4qufpt002ggwtlgvx77lg6"},{"name":"analyse","_id":"ckw4qufpx002xgwtl6wts79f8"},{"name":"GAN","_id":"ckw4qufpz0033gwtlb6c01n88"},{"name":"deep-learning","_id":"ckw4qufq2003dgwtlb0scc2ss"},{"name":"machine-learning","_id":"ckw4qufq4003kgwtl2xhq1q32"},{"name":"programming","_id":"ckw4qufq9003tgwtl25z0hfyj"},{"name":"algo","_id":"ckw4qufqb003zgwtl9kdj3chy"},{"name":"CNN","_id":"ckw4qufqe0047gwtl42ptggfv"},{"name":"mongo","_id":"ckw4qufqk004tgwtl9vcfe3a0"},{"name":"mongodb","_id":"ckw4qufqn0052gwtlgk31blmp"},{"name":"docker","_id":"ckw4qufqr0057gwtl0xrpgerg"},{"name":"nlp","_id":"ckw4qufqs005dgwtlbupwc4nw"},{"name":"datamining","_id":"ckw4qufqt005qgwtl96ktd0qf"},{"name":"knowledge-graph","_id":"ckw4qufqu005wgwtleerbfs64"},{"name":"probability","_id":"ckw4qufqv0067gwtl8ky8ctym"},{"name":"OS","_id":"ckw4qufqw006agwtl2hqlbnfg"},{"name":"data-structure","_id":"ckw4qufqw006fgwtlfkjk4o9m"},{"name":"Sobolev","_id":"ckw4qufqx006ggwtlelps9xrq"},{"name":"entity-resolution","_id":"ckw4qufqx006kgwtlamww4ut7"},{"name":"sequence-labeling","_id":"ckw4qufqy006ngwtlgoqr8nef"},{"name":"relation-extraction","_id":"ckw4qufqy006qgwtla8bhcj4b"},{"name":"LSTM","_id":"ckw4qufqy006rgwtl5bhweofz"},{"name":"RNN","_id":"ckw4qufqy006sgwtlh7it7du6"},{"name":"distant-supervision","_id":"ckw4qufqz006wgwtlahaagyw9"},{"name":"relation-classification","_id":"ckw4qufr1006zgwtleaty1ja3"},{"name":"attention","_id":"ckw4qufr10072gwtlazka3t5f"},{"name":"event-detection","_id":"ckw4qufr20075gwtlcb7ecevi"},{"name":"co-reference","_id":"ckw4qufr20078gwtl10u3g04z"},{"name":"convolution","_id":"ckw4qufr2007agwtl4mmggk72"},{"name":"BiLSTM","_id":"ckw4qufr3007dgwtle4oz7slw"},{"name":"event-extraction","_id":"ckw4qufr3007egwtl6216fyl4"},{"name":"limited-supervision","_id":"ckw4qufr4007igwtl3x2uh3e2"},{"name":"weak-supervision","_id":"ckw4qufr4007kgwtlfwe1csr0"},{"name":"KGC","_id":"ckw4qufr4007lgwtla60aaaqr"},{"name":"neural-network","_id":"ckw4qufr70083gwtl2coo77sh"},{"name":"reinforcement-learning","_id":"ckw4qufr80088gwtl9eoa50pt"},{"name":"summarization","_id":"ckw4qufr8008cgwtlaw9lfdkt"},{"name":"NLP","_id":"ckw4qufr9008hgwtl0xq75ksk"},{"name":"regular-expression","_id":"ckw4qufra008mgwtlhrfsam25"},{"name":"review","_id":"ckw4qufra008ogwtlg6nq85d8"},{"name":"complexity","_id":"ckw4qufrb008wgwtleawtfqdr"},{"name":"compression","_id":"ckw4qufrc0090gwtl2e4lgg7e"},{"name":"classification","_id":"ckw4qufrd0098gwtlf4fy9xm5"},{"name":"prediction","_id":"ckw4qufre0099gwtldqai8mu3"},{"name":"qualitative-induction","_id":"ckw4qufrg009jgwtlbfpt2enm"},{"name":"graph","_id":"ckw4qufrh009lgwtlf9zi1l9s"},{"name":"hexo","_id":"ckw4qufri009rgwtl1nh08i1n"},{"name":"latex","_id":"ckw4qufrj009ugwtl54s44vev"},{"name":"mathjax","_id":"ckw4qufrj009wgwtl3gm3dlla"},{"name":"marked","_id":"ckw4qufrj009xgwtlcwxf4ov8"},{"name":"knowledge-reasoning","_id":"ckw4qufrk00a1gwtl3hqhg8jg"},{"name":"kernel","_id":"ckw4qufrl00a7gwtl2mfuh5ko"},{"name":"management","_id":"ckw4qufrl00aagwtlcqe6giyt"},{"name":"firm","_id":"ckw4qufrl00adgwtl0kcgakna"},{"name":"francais","_id":"ckw4qufrm00aegwtl2pxhcric"},{"name":"language","_id":"ckw4qufrm00ahgwtl1ij0h0np"},{"name":"aleatoire","_id":"ckw4qufrn00aogwtl2dw1ebq7"},{"name":"vector","_id":"ckw4qufro00avgwtl3fkqd7s7"},{"name":"web","_id":"ckw4qufrp00b3gwtld7jtf556"},{"name":"chrome","_id":"ckw4qufrp00b6gwtl8bd1cveu"},{"name":"rss","_id":"ckw4qufrq00bbgwtl3q933e1g"},{"name":"vps","_id":"ckw4qufrq00bcgwtl66wsgsew"}]}}